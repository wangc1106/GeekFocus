<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>LTR-RT/LTR REs</title>
    <link href="/GeekFocus/2022/06/05/2022-06-05-RunningAugustus/"/>
    <url>/GeekFocus/2022/06/05/2022-06-05-RunningAugustus/</url>
    
    <content type="html"><![CDATA[<p>AUGUSTUS Guidline</p><span id="more"></span><h2 id="RUNNING-AUGUSTUS"><a href="#RUNNING-AUGUSTUS" class="headerlink" title="RUNNING AUGUSTUS"></a>RUNNING AUGUSTUS</h2><ol><li><a href="https://github.com/Gaius-Augustus/Augustus/blob/master/docs/RUNNING-AUGUSTUS.md#basic-usage">BASIC USAGE</a></li><li><a href="https://github.com/Gaius-Augustus/Augustus/blob/master/docs/RUNNING-AUGUSTUS.md#sampling-alternative-transcripts-and-posterior-probabilities">SAMPLING: ALTERNATIVE TRANSCRIPTS AND POSTERIOR PROBABILITIES</a></li><li><a href="https://github.com/Gaius-Augustus/Augustus/blob/master/docs/RUNNING-AUGUSTUS.md#using-hints">USING HINTS</a></li><li><a href="https://github.com/Gaius-Augustus/Augustus/blob/master/docs/RUNNING-AUGUSTUS.md#predictions-using-cdna">PREDICTIONS USING CDNA</a></li><li><a href="https://github.com/Gaius-Augustus/Augustus/blob/master/docs/RUNNING-AUGUSTUS.md#ppx">AUGUSTUS-PPX: PREDICTIONS USING PROTEIN PROFILES</a></li><li><a href="https://github.com/Gaius-Augustus/Augustus/blob/master/docs/RUNNING-AUGUSTUS.md#retraining-augustus">RETRAINING AUGUSTUS</a></li><li><a href="https://github.com/Gaius-Augustus/Augustus/blob/master/docs/RUNNING-AUGUSTUS.md#mea-using-the-maximum-expected-accuracy-approach">MEA: USING THE MAXIMUM EXPECTED ACCURACY APPROACH</a></li></ol><h1 id="BASIC-USAGE"><a href="#BASIC-USAGE" class="headerlink" title="BASIC USAGE"></a>BASIC USAGE</h1><p>AUGUSTUS has 2 mandatory arguments. The <font color="blue">query file and the species</font>. The query file contains the DNA input sequence and must be in uncompressed (multiple) fasta format, e.g. the file may look like this:</p><figure class="highlight gcode"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs gcode">&gt;<span class="hljs-symbol">name_of_sequence_1</span><br>agtgctgcatgctagctagct<br>&gt;<span class="hljs-symbol">name_of_sequence_2</span><br>gtgct<span class="hljs-symbol">ngcatgctagctagctggtgtnntgaaaaatt</span><br></code></pre></td></tr></table></figure><p>Every letter other than a,c,g,t,A,C,G and T is interpreted as an unknown base. Digits and white spaces are ignored. The number of characters per line is not restricted.</p><p>To execute augustus, run the following command with the appropriate <a href="https://github.com/Gaius-Augustus/Augustus/blob/master/docs/RUNNING-AUGUSTUS.md#important-parameters">parameters</a>.</p><figure class="highlight gams"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs gams">augustus [<span class="hljs-keyword">parameters</span>] --species=SPECIES <span class="hljs-comment">queryfilename</span><br></code></pre></td></tr></table></figure><p>If you want to output to be redirected to a file (see also outfile parameter), you can use pipe operators, for example:</p><figure class="highlight gams"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs gams">augustus [<span class="hljs-keyword">parameters</span>] --species=SPECIES <span class="hljs-comment">queryfilename &gt; output.gff</span><br></code></pre></td></tr></table></figure><p>SPECIES is one of the following identifiers. The directory names under config&#x2F;species constitutes the complete list. The identifiers in parentheses denote older versions for that species. ‘queryfilename’ is the filename (including relative path) to the file containing the query sequence(s) in fasta format.</p><table><thead><tr><th>identifier</th><th>species</th></tr></thead><tbody><tr><td>human</td><td>Homo sapiens</td></tr><tr><td>fly</td><td>Drosophila melanogaster</td></tr><tr><td>arabidopsis</td><td>Arabidopsis thaliana</td></tr><tr><td>brugia</td><td>Brugia malayi</td></tr><tr><td>aedes</td><td>Aedes aegypti</td></tr><tr><td>tribolium</td><td>Tribolium castaneum</td></tr><tr><td>schistosoma</td><td>Schistosoma mansoni</td></tr><tr><td>tetrahymena</td><td>Tetrahymena thermophila</td></tr><tr><td>galdieria</td><td>Galdieria sulphuraria</td></tr><tr><td>maize</td><td>Zea mays</td></tr><tr><td>toxoplasma</td><td>Toxoplasma gondii</td></tr><tr><td>caenorhabditis</td><td>Caenorhabditis elegans</td></tr><tr><td>(elegans)</td><td>Caenorhabditis elegans</td></tr><tr><td>aspergillus_fumigatus</td><td>Aspergillus fumigatus</td></tr><tr><td>aspergillus_nidulans</td><td>Aspergillus nidulans</td></tr><tr><td>(anidulans)</td><td>Aspergillus nidulans</td></tr><tr><td>aspergillus_oryzae</td><td>Aspergillus oryzae</td></tr><tr><td>aspergillus_terreus</td><td>Aspergillus terreus</td></tr><tr><td>botrytis_cinerea</td><td>Botrytis cinerea</td></tr><tr><td>candida_albicans</td><td>Candida albicans</td></tr><tr><td>candida_guilliermondii</td><td>Candida guilliermondii</td></tr><tr><td>candida_tropicalis</td><td>Candida tropicalis</td></tr><tr><td>chaetomium_globosum</td><td>Chaetomium globosum</td></tr><tr><td>coccidioides_immitis</td><td>Coccidioides immitis</td></tr><tr><td>coprinus</td><td>Coprinus cinereus</td></tr><tr><td>coprinus_cinereus</td><td>Coprinus cinereus</td></tr><tr><td>coyote_tobacco</td><td>Nicotiana attenuata</td></tr><tr><td>cryptococcus_neoformans_gattii</td><td>Cryptococcus neoformans gattii</td></tr><tr><td>cryptococcus_neoformans_neoformans_B</td><td>Cryptococcus neoformans neoformans</td></tr><tr><td>cryptococcus_neoformans_neoformans_JEC21</td><td>Cryptococcus neoformans neoformans</td></tr><tr><td>(cryptococcus)</td><td>Cryptococcus neoformans</td></tr><tr><td>debaryomyces_hansenii</td><td>Debaryomyces hansenii</td></tr><tr><td>encephalitozoon_cuniculi_GB</td><td>Encephalitozoon cuniculi</td></tr><tr><td>eremothecium_gossypii</td><td>Eremothecium gossypii</td></tr><tr><td>fusarium_graminearum</td><td>Fusarium graminearum</td></tr><tr><td>(fusarium)</td><td>Fusarium graminearum</td></tr><tr><td>histoplasma_capsulatum</td><td>Histoplasma capsulatum</td></tr><tr><td>(histoplasma)</td><td>Histoplasma capsulatum</td></tr><tr><td>kluyveromyces_lactis</td><td>Kluyveromyces lactis</td></tr><tr><td>laccaria_bicolor</td><td>Laccaria bicolor</td></tr><tr><td>lamprey</td><td>Petromyzon marinus</td></tr><tr><td>leishmania_tarentolae</td><td>Leishmania tarentolae</td></tr><tr><td>lodderomyces_elongisporus</td><td>Lodderomyces elongisporus</td></tr><tr><td>magnaporthe_grisea</td><td>Magnaporthe grisea</td></tr><tr><td>neurospora_crassa</td><td>Neurospora crassa</td></tr><tr><td>(neurospora)</td><td>Neurospora crassa</td></tr><tr><td>phanerochaete_chrysosporium</td><td>Phanerochaete chrysosporium</td></tr><tr><td>(pchrysosporium)</td><td>Phanerochaete chrysosporium</td></tr><tr><td>pichia_stipitis</td><td>Pichia stipitis</td></tr><tr><td>rhizopus_oryzae</td><td>Rhizopus oryzae</td></tr><tr><td>saccharomyces_cerevisiae_S288C</td><td>Saccharomyces cerevisiae</td></tr><tr><td>saccharomyces_cerevisiae_rm11-1a_1</td><td>Saccharomyces cerevisiae</td></tr><tr><td>(saccharomyces)</td><td>Saccharomyces cerevisiae</td></tr><tr><td>schizosaccharomyces_pombe</td><td>Schizosaccharomyces pombe</td></tr><tr><td>thermoanaerobacter_tengcongensis</td><td>Thermoanaerobacter tengcongensis</td></tr><tr><td>trichinella</td><td>Trichinella spiralis</td></tr><tr><td>ustilago_maydis</td><td>Ustilago maydis</td></tr><tr><td>(ustilago)</td><td>Ustilago maydis</td></tr><tr><td>yarrowia_lipolytica</td><td>Yarrowia lipolytica</td></tr><tr><td>nasonia</td><td>Nasonia vitripennis</td></tr><tr><td>tomato</td><td>Solanum lycopersicum</td></tr><tr><td>chlamydomonas</td><td>Chlamydomonas reinhardtii</td></tr><tr><td>amphimedon</td><td>Amphimedon queenslandica</td></tr><tr><td>pneumocystis</td><td>Pneumocystis jirovecii</td></tr><tr><td>wheat</td><td>Triticum aestivum</td></tr><tr><td>chicken</td><td>Gallus gallus</td></tr><tr><td>zebrafish</td><td>Danio rerio</td></tr><tr><td>E_coli_K12</td><td>Escherichia coli</td></tr><tr><td>s_aureus</td><td>Staphylococcus aureus</td></tr><tr><td>volvox</td><td>Volvox carteri</td></tr></tbody></table><h2 id="Important-Parameters"><a href="#Important-Parameters" class="headerlink" title="Important Parameters"></a>Important Parameters</h2><ul><li><font color="red">–strand&#x3D;both</font>, –strand&#x3D;forward or –strand&#x3D;backward report <font color="blue">predicted genes on both strands</font>, just the forward or just the backward strand. <font color="blue">default is ‘both’</font></li><li><font color="red">–genemodel</font>&#x3D;partial, –genemodel&#x3D;intronless, –genemodel&#x3D;complete, –genemodel&#x3D;atleastone or –genemodel&#x3D;exactlyone <ul><li>partial : <font color="blue">allow prediction of incomplete genes at the sequence boundaries <strong>(default)</strong> </font></li><li>intronless : <font color="blue">only predict single-exon genes</font> like in prokaryotes and some eukaryotes </li><li>complete : <font color="blue"><strong>only predict complete</strong> genes </font></li><li>atleastone : predict <font color="blue"><strong>at least one</strong> complete gene </font></li><li>exactlyone : predict <font color="blue"><strong>exactly one</strong> complete gene</font></li></ul></li><li>–singlestrand&#x3D;true <font color="blue">predict genes independently on each strand</font>, <font color="blue">allow overlapping genes on opposite strands</font> This option is <font color="blue"><strong>turned off by default</strong></font>.</li><li>–hintsfile&#x3D;hintsfilename When this option is used the prediction considering hints (extrinsic information) is turned on. hintsfile name contains the hints in gff format.</li><li>–extrinsicCfgFile&#x3D;cfgfilename Optional. This file contains the list of used sources for the hints and their boni and mali. If not specified the file “extrinsic.cfg” in the config directory $AUGUSTUS_CONFIG_PATH is used.</li><li>–maxDNAPieceSize&#x3D;n This value specifies the maximal length of the pieces that the sequence is cut into for the core algorithm (Viterbi) to be run. Default is –maxDNAPieceSize&#x3D;200000. AUGUSTUS tries to place the boundaries of these pieces in the intergenic region, which is inferred by a preliminary prediction. GC-content dependent parameters are chosen for each piece of DNA if &#x2F;Constant&#x2F;decomp_num_steps &gt; 1 for that species. This is why this value should not be set very large, even if you have plenty of memory.</li><li>–protein&#x3D;on&#x2F;off</li><li>–codingseq&#x3D;on&#x2F;off</li><li>–introns&#x3D;on&#x2F;off</li><li>–start&#x3D;on&#x2F;off</li><li>–stop&#x3D;on&#x2F;off</li><li>–cds&#x3D;on&#x2F;off</li><li>–exonnames&#x3D;on&#x2F;off<br>Output options. Output predicted amino acid sequences or coding sequences. Or toggle the display of the GFF features&#x2F;lines of type intron, start codon, stop codon, CDS or ‘initial’, ‘internal’, ‘terminal’ and ‘single’ exon type names. <font color="blue">The CDS excludes the stop codon</font> (unless <font color="red">stopCodonExcludedFromCDS&#x3D;false</font>) <font color="blue">whereas the terminal and single exon include the stop codon</font>.</li><li>–AUGUSTUS_CONFIG_PATH&#x3D;path path to config directory (if not specified as environment variable)</li><li><font color="red">【–alternatives-from-evidence】&#x3D;true&#x2F;false</font> report alternative transcripts when they are suggested by hints</li><li>–alternatives-from-sampling&#x3D;true&#x2F;false report alternative transcripts generated through probabilistic sampling</li><li>–sample&#x3D;n</li><li>–minexonintronprob&#x3D;p</li><li>–minmeanexonintronprob&#x3D;p</li><li>–maxtracks&#x3D;n For a description of these parameters see section 4 below.</li><li>–proteinprofile&#x3D;filename Read a protein profile from file filename. See <a href="https://github.com/Gaius-Augustus/Augustus/blob/master/docs/RUNNING-AUGUSTUS.md#ppx">section on PPX</a> below.</li><li>–predictionStart&#x3D;A, –predictionEnd&#x3D;B A and B define the range of the sequence for which predictions should be found. Quicker if you need predictions only for a small part.</li><li>–gff3&#x3D;on&#x2F;off output in gff3 format</li><li>–UTR&#x3D;on&#x2F;off predict the untranslated regions in addition to the coding sequence. <font color="blue">This currently works only for human, galdieria, toxoplasma and caenorhabditis.</font></li><li>–outfile&#x3D;filename print output to filename instead to standard output. This is useful for computing environments, e.g. parasol jobs, which do not allow shell redirection.</li><li><font color="red">【–noInFrameStop&#x3D;true&#x2F;false】 </font>Don’t report transcripts with in-frame stop codons. Otherwise, intron-spanning stop codons could occur. Default: false</li><li>–noprediction&#x3D;true&#x2F;false If true and input is in genbank format, no prediction is made. Useful for getting the annotated protein sequences.</li><li>–contentmodels&#x3D;on&#x2F;off If ‘off’ the content models are disabled (all emissions uniformly 1&#x2F;4). The content models are; coding region Markov chain (emiprobs), initial k-mers in coding region (Pls), intron and intergenic regin Markov chain. This option is intended for special applications that require judging gene structures from the signal models only, e.g. for predicting the effect of SNPs or mutations on splicing. For all typical gene predictions, this should be true. Default: on</li></ul><p>For example you may type</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs routeros">augustus <span class="hljs-attribute">--species</span>=human <span class="hljs-attribute">--UTR</span>=on <span class="hljs-built_in">..</span>/examples/example.fa<br></code></pre></td></tr></table></figure><p>The output format is gtf similar to General Feature Format (gff), see <a href="http://www.sanger.ac.uk/Software/formats/GFF/">http://www.sanger.ac.uk/Software/formats/GFF/</a>. It contains one line per predicted exon. Example:</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">HS04636</span>   AUGUSTUS   initial    <span class="hljs-number">966</span>     <span class="hljs-number">1017</span>    .       +       <span class="hljs-number">0</span>       transcript_id <span class="hljs-string">&quot;g1.1&quot;</span>; gene_id <span class="hljs-string">&quot;g1&quot;</span>;<br><span class="hljs-attribute">HS04636</span>   AUGUSTUS   internal   <span class="hljs-number">1818</span>    <span class="hljs-number">1934</span>    .       +       <span class="hljs-number">2</span>       transcript_id <span class="hljs-string">&quot;g1.1&quot;</span>; gene_id <span class="hljs-string">&quot;g1&quot;</span>;<br></code></pre></td></tr></table></figure><p>The columns (fields) contain:</p><figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs pgsql">seqname   source     feature    <span class="hljs-keyword">start</span>   <span class="hljs-keyword">end</span>   score   strand   frame    transcript <span class="hljs-keyword">and</span> gene <span class="hljs-type">name</span><br></code></pre></td></tr></table></figure><p>AUGUSTUS also accepts files in annotated <strong>GENBANK format as input</strong>. This is needed for training. Also when predicting on a genbank file AUGUSTUS compares its prediction to the annotation and prints out a statistic. Example genbank file format accepted by AUGUSTUS:</p><figure class="highlight dns"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs dns">LOCUS       HS04636   <span class="hljs-number">9453</span> bp  DNA<br>FEATURES             Location/Qualifiers<br>     source          <span class="hljs-number">1</span>..<span class="hljs-number">9453</span><br>     <span class="hljs-keyword">CDS</span>             join(<span class="hljs-number">966</span>..<span class="hljs-number">1017,1818</span>..<span class="hljs-number">1934,2055</span>..<span class="hljs-number">2198,2852</span>..<span class="hljs-number">2995,3426</span>..<span class="hljs-number">3607</span>,<br>                     <span class="hljs-number">4340</span>..<span class="hljs-number">4423,4543</span>..<span class="hljs-number">4789,5072</span>..<span class="hljs-number">5358,5860</span>..<span class="hljs-number">6007,6494</span>..<span class="hljs-number">6903</span>)<br>BASE COUNT     <span class="hljs-number">2937</span> a   <span class="hljs-number">1716</span> c  <span class="hljs-number">1710</span> g   <span class="hljs-number">3090</span> t<br>ORIGIN<br>        <span class="hljs-number">1</span> gagctcacat taactattta cagggtaact gcttaggacc agtattatga ggagaattta<br>       <span class="hljs-number">61</span> cctttcccgc ctctctttcc aagaaacaag gagggggtga aggtacggag aacagtattt<br>      <span class="hljs-number">121</span> cttctgttga aagcaactta gctacaaaga taaattacag ctatgtacac tgaaggtagc<br>      ...<br>     <span class="hljs-number">9421</span> aaaaaaaaaa aaaaatcgat gtcgactcga gtc<br>//<br></code></pre></td></tr></table></figure><p>Another example that is important for training the UTR models. The following genbank file will be interpreted as having three genes. One gene (‘A’) with both 5’ and 3’ UTR and two single UTRs without matching coding sequence. Gene ‘B’ consists just of the 5’UTR, gene ‘C’ just of the 3’ UTR.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs bash">LOCUS       example2   9453 bp  DNA<br>FEATURES             Location/Qualifiers<br>     <span class="hljs-built_in">source</span>          1..9453<br>     mRNA            <span class="hljs-built_in">join</span>(100..200,900..1017,1818..2000,2100..2200)<br>                     /gene=<span class="hljs-string">&quot;A&quot;</span><br>     CDS             <span class="hljs-built_in">join</span>(966..1017,1818..1934)<br>                     /gene=<span class="hljs-string">&quot;A&quot;</span><br>     mRNA            <span class="hljs-built_in">join</span>(3100..3200,3500..&gt;3600)<br>                     /gene=<span class="hljs-string">&quot;B&quot;</span><br>     mRNA            <span class="hljs-built_in">join</span>(&lt;4100..4200,4500..4600)<br>                     /gene=<span class="hljs-string">&quot;C&quot;</span><br><br>BASE COUNT     2937 a   1716 c  1710 g   3090 t<br>ORIGIN<br>        1 gagctcacat taactattta cagggtaact gcttaggacc agtattatga ggagaattta<br>       61 cctttcccgc ctctctttcc aagaaacaag gagggggtga aggtacggag aacagtattt<br>      121 cttctgttga aagcaactta gctacaaaga taaattacag ctatgtacac tgaaggtagc<br>      ...<br>     9421 aaaaaaaaaa aaaaatcgat gtcgactcga gtc<br>//<br></code></pre></td></tr></table></figure><h1 id="SAMPLING-ALTERNATIVE-TRANSCRIPTS-AND-POSTERIOR-PROBABILITIES"><a href="#SAMPLING-ALTERNATIVE-TRANSCRIPTS-AND-POSTERIOR-PROBABILITIES" class="headerlink" title="SAMPLING: ALTERNATIVE TRANSCRIPTS AND POSTERIOR PROBABILITIES"></a>SAMPLING: ALTERNATIVE TRANSCRIPTS AND POSTERIOR PROBABILITIES</h1><p>Note that for the prediction of alternative splicing there is another method described in 5. below.</p><h2 id="Alternative-transcripts-from-sampling"><a href="#Alternative-transcripts-from-sampling" class="headerlink" title="Alternative transcripts (from sampling)"></a>Alternative transcripts (from sampling)</h2><p>When you say on the command line</p><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs ini"><span class="hljs-attr">--alternatives-from-sampling</span>=<span class="hljs-literal">true</span><br></code></pre></td></tr></table></figure><p>or edit the appropriate line in the configuration file for your species to <font color="blue">alternatives true then AUGUSTUS may report multiple transcripts per gene</font>. A gene is then defined as a set of transcripts, whose coding sequences (indirectly) overlap. The number of alternatives AUGUSTUS reports for a gene depends on which ones are likely alternatives. If just one transcript is likely in that region then also just one transcript is reported. The behavior of AUGUSTUS can be adjusted with the parameters</p><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs ini"><span class="hljs-attr">--minexonintronprob</span>=p<br><span class="hljs-attr">--minmeanexonintronprob</span>=p<br><span class="hljs-attr">--maxtracks</span>=n (default -<span class="hljs-number">1</span>, <span class="hljs-literal">no</span> limit)<br></code></pre></td></tr></table></figure><p>The posterior probability of every exon and every intron in a transcript must be at least ‘minexonintronprob’, otherwise the transcript is not reported. minexonintronprob&#x3D;0.1 is a reasonable value. In addition the geometric mean of the probabilities of all exons and introns must be at least ‘minmeanexonintronprob’. minmeanexonintronprob&#x3D;0.4 is a reasonable value. The maximum number of tracks when displayed in a genome browser is ‘maxtracks’ (unless maxtracks&#x3D;-1, then it is unbounded). In cases where all transcripts of a gene overlap at some position this is also the maximal number of transcripts for that gene. I recommend increasing the parameter ‘maxtracks’ for improving sensitivity and setting ‘maxtracks’ to 1 and increasing minmeanexonintronprob and&#x2F;or minexonintronprob in order to improve specificity.</p><h2 id="Posterior-probabilities"><a href="#Posterior-probabilities" class="headerlink" title="Posterior probabilities"></a>Posterior probabilities</h2><p>AUGUSTUS reports the posterior probabilities of exons, introns, transcripts and genes. The <font color="blue">posterior probability of an exon is the conditional probability that the random gene structure has some exon with these coordinates on this strand given the input sequence</font>. It not only depends on the sequence in the range of the exon itself like an exon score but is influenced for example by the possibilities of compatible neighboring exons. The intron score is similar. The reported probability of a transcript is the probability that a splice variant is exactly like in the given transcript. The reported probability of a gene is the probability that SOME coding sequence is in the reported range on the reported strand, regardless of the exact transcript.</p><p>The posterior probabilities are estimated using a sampling algorithm. The parameter –sample&#x3D;&#x3D;n adjusts the number of sampling iterations. The higher ‘n’ is the more accurate is the estimation but it usually isn’t important that the posterior probability is very accurate. Every 30 sample iterations take about the same time as one run without sampling, e.g. –sample&#x3D;60 takes about 3 times as much time as –sample&#x3D;0 (which was standard up to version 1.6). The <font color="blue">default is</font></p><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs ini"><span class="hljs-attr">--sample</span>=<span class="hljs-number">100</span><br></code></pre></td></tr></table></figure><p>If you do not need the posterior probabilities or alternative transcripts, say</p><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs ini"><span class="hljs-attr">--sample</span>=<span class="hljs-number">0</span><br></code></pre></td></tr></table></figure><p>There are 3 common scenarios for above parameters, depending on what you want:</p><ol><li><font color="blue">Just output the <strong>most likely gene structure</strong> as in previous versions. No posterior probabilities, no alternatives:</font></li></ol><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sh">--sample=0 --alternatives=<span class="hljs-literal">false</span><br></code></pre></td></tr></table></figure><ol><li><font color="blue">Output the <strong>most likely gene structure</strong> and report posterior probabilities:</font></li></ol><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs routeros"><span class="hljs-attribute">--sample</span>=100 <span class="hljs-attribute">--alternatives</span>=<span class="hljs-literal">false</span><br></code></pre></td></tr></table></figure><ol><li><font color="blue">Output <strong>alternative transcripts</strong> and report posterior probabilities:</font></li></ol><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs routeros"><span class="hljs-attribute">--sample</span>=100 <span class="hljs-attribute">--alternatives</span>=<span class="hljs-literal">true</span><br></code></pre></td></tr></table></figure><p>Be aware that sampling is pseudorandom and that the results may vary from machine to machine.</p><h2 id="Heating"><a href="#Heating" class="headerlink" title="Heating?"></a>Heating?</h2><p>The probabilistic model of AUGUSTUS can be seen as a rough approximation to reality. A consequence is that the posterior probabilities for the strong exons (e.g. the ones called by the Viterbi algorithm) tend to be larger than the actually measured precision (specificity) values. For example, in human, only 94.5% of the exons with predicted posterior probability &gt;&#x3D; 98% (under the default –sample&#x3D;100) are actually correct. See docs&#x2F;CDS.sp.{pdf,README} for more data and an explanation. If the aim of the sampling is to produce a diverse, sensitive (including) set of gene structures, you can use this parameter</p><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs ini"><span class="hljs-attr">--temperature</span>=t<br></code></pre></td></tr></table></figure><p>where t is one of 0,1,2,3,4,5,6,7. All probabilities of the model are then taken to the power of (8-t)&#x2F;8, i.e. <font color="blue">t&#x3D;0 (the default) does nothing</font>. The larger t the more alternatives are sampled. <font color="blue">t&#x3D;3 is a good compromise between getting a high sensitivity but not getting too many exons sampled in total</font>. For t&#x3D;3, 96.1% of human exons with posterior probability &gt;&#x3D; 98% are correct.</p><h1 id="USING-HINTS"><a href="#USING-HINTS" class="headerlink" title="USING HINTS"></a>USING HINTS</h1><p>AUGUSTUS can take hints on the gene structure. Previously, this was also called AUGUSTUS+. It currently accepts 16 types of hints:<br>start, stop, tss, tts, ass, dss, exonpart, exon, intronpart, intron, CDSpart, CDS, UTRpart, UTR, irpart, nonexonpart. The hints must be stored in a file in gff format containing one hint per line. Below is an example of a hintsfile:</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">HS04636</span>mario   exonpart   <span class="hljs-number">500</span>   <span class="hljs-number">506</span>     .-.source=M<br><span class="hljs-attribute">HS04636</span>mario   exon       <span class="hljs-number">966</span>  <span class="hljs-number">1017</span>     .+<span class="hljs-number">0</span>source=P<br><span class="hljs-attribute">HS04636</span>AGRIPPA start      <span class="hljs-number">966</span>   <span class="hljs-number">968</span>  <span class="hljs-number">6</span>.<span class="hljs-number">3</span>e-<span class="hljs-number">239</span>+<span class="hljs-number">0</span>group=gb|AAA35803.<span class="hljs-number">1</span>;source=P<br><span class="hljs-attribute">HS04636</span>AGRIPPA dss       <span class="hljs-number">2199</span>  <span class="hljs-number">2199</span>  <span class="hljs-number">1</span>.<span class="hljs-number">3</span>e-<span class="hljs-number">216</span>+.group=gb|AAA35803.<span class="hljs-number">1</span>;source=P<br><span class="hljs-attribute">HS04636</span>mario   stop      <span class="hljs-number">7631</span>  <span class="hljs-number">7633</span>     .+<span class="hljs-number">0</span>source=M<br><span class="hljs-attribute">HS08198</span>AGRIPPA intron    <span class="hljs-number">2000</span>  <span class="hljs-number">2000</span>     <span class="hljs-number">0</span>+.group=ref|NP_000597.<span class="hljs-number">1</span>;source=E<br><span class="hljs-attribute">HS08198</span>AGRIPPA ass        <span class="hljs-number">757</span>   <span class="hljs-number">757</span>   <span class="hljs-number">1</span>.<span class="hljs-number">4</span>e-<span class="hljs-number">52</span>+.group=ref|NP_000597.<span class="hljs-number">1</span>;source=E<br></code></pre></td></tr></table></figure><p>The fields must be separated by a tabulator. In the first column (field) the sequence name is given. In this case the hints are together about two sequences. The second field is the name of the program that produced the hint. It is ignored here. The third column specifies the type of the hint. The 4th and 5th column specify the begin and end position of the hint. Positions start at 1. The 6th colum gives a score. The 7th the strand. The 8th the reading frame as defined in the GFF standard. The 9th column contains arbitrary extra information but it must contain a string ‘source&#x3D;X’ where X is the source identifier of the hint. Which values for X are possible is specified in the file augustus&#x2F;config&#x2F;extrinsic.cfg, e.g. X&#x3D;M, E, or P.</p><p>AUGUSTUS can follow a hint, i.e. predict a gene structure that is compatible with it, or AUGUSTUS can ignore a hint, i.e. predict a gene structure that is not compatible with it. The probability that AUGUSTUS ignores a hint is the smaller the more reliable the hints of this type are.</p><p>Below in an example to run AUGUSTUS using the –hintsfile option:</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs awk">augustus --species=human --hintsfile=..<span class="hljs-regexp">/examples/</span>hints.gff --extrinsicCfgFile=..<span class="hljs-regexp">/config/</span>extrinsic<span class="hljs-regexp">/extrinsic.MPE.cfg ../</span>examples/example.fa<br></code></pre></td></tr></table></figure><p>As an alternative to giving the option –extrinsicCfgFile you can replace augustus&#x2F;config&#x2F;extrinsic.cfg with the appropriate file, as this file is read by default when the option –extrinsicCfgFile is not given.</p><p>The preferable way to use repeat information is via softmasking in which the bases in repeat regions are lower case (a,c,g,t instead of A,C,G,T) in the input. Running augustus could look like this:</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs routeros">augustus <span class="hljs-attribute">--species</span>=human <span class="hljs-attribute">--softmasking</span>=1<br></code></pre></td></tr></table></figure><p>will interpret masked regions as evidence against exons (nonexonparts hints with a default bonus of 1.15). This is slightly more accurate than hard masking (with N’s), which looses information. On human augustus is also more than twice as fast with softmasking&#x3D;1 than on hard masked sequence.</p><h2 id="Explanation-of-the-file-format-of-the-extrinsic-cfg-file"><a href="#Explanation-of-the-file-format-of-the-extrinsic-cfg-file" class="headerlink" title="Explanation of the file format of the extrinsic.cfg file."></a>Explanation of the file format of the extrinsic.cfg file.</h2><p>The gff&#x2F;gtf file containint the hints must contain somewhere in the last column an entry source&#x3D;?, where ? is one of the source characters listed in the line after [SOURCES] above. You can use different sources when you have hints of different reliability of the same type, e.g. exon hints from ESTs and exon hints from evolutionary conservation information.</p><p>In the [GENERAL] section the entries second column specify a bonus for obeying a hint and the entry in the third column specify a malus (penalty) for predicting a feature that is not supported by any hint. The bonus and the malus is a factor that is multiplied to the posterior probability of gene structures. Example:</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">CDS</span>     <span class="hljs-number">1000</span>  <span class="hljs-number">0</span>.<span class="hljs-number">7</span>  ....<br></code></pre></td></tr></table></figure><p>means that, when AUGUSTUS is searching for the most likely gene structure, every gene structure that has a CDS exactly as given in a hint gets a bonus factor of 1000. Also, for every CDS that is not supported the probability of the gene structure gets a malus of 0.7. Increase the bonus to make AUGUSTUS obey more hints, decrease the malus to make AUGUSTUS predict few features that are not supported by hints. The malus helps increasing specificity, e.g. when the exons predicted by AUGUSTUS are suspicious because there is no evidence from ESTs, mRNAs, protein databases, sequence conservation, transMapped expressed sequences. Setting the malus to 1.0 disables those penalties. Setting the bonus to 1.0 disables the boni.</p><ul><li>start: translation start (start codon), specifies an interval that contains the start codon. The interval can be larger than 3bp, in which case every ATG in the interval gets a bonus. The highest bonus is given to ATGs in the middle of the interval, the bonus fades off towards the ends.</li><li>stop: translation end (stop codon), see ‘start’</li><li>tss: transcription start site, see ‘start’</li><li>tts: transcription termination site, see ‘start’</li><li>ass: acceptor (3’) splice site, the last intron position, for only approximately known ass an interval can be specified</li><li>dss: donor (5’) splice site, the first intron position, for only approximately known dss an interval can be specified</li><li>exonpart: part of an exon in the biological sense. The bonus applies only to exons that contain the interval from the hint. Just overlapping means no bonus at all. The malus applies to every base of an exon. Therefore the malus for an exon is exponential in the length of an exon: malus&#x3D;exonpartmalus^length. Therefore the malus should be close to 1, e.g. 0.99.</li><li>exon: exon in the biological sense. Only exons that exactly match the hint get a bonus. Exception: The exons that contain the start codon and stop codon. This malus applies to a complete exon independent of its length.</li><li>intronpart: introns both between coding and non-coding exons. The bonus applies to every intronic base in the interval of the hint.</li><li>intron: An intron gets the bonus if and only if it is exactly as in the hint.</li><li>CDSpart: part of the coding part of an exon. (CDS &#x3D; coding sequence)</li><li>CDS: coding part of an exon with exact boundaries. For internal exons of a multi exon gene this is identical to the biological boundaries of the exon. For the first and the last coding exon the boundaries are the boundaries of the coding sequence (start, stop).</li><li>UTR: exact boundaries of a UTR exon or the untranslated part of a partially coding exon.</li><li>UTRpart: The hint interval must be included in the UTR part of an exon.</li><li>irpart: The bonus applies to every base of the intergenic region. If UTR prediction is turned on (–UTR&#x3D;on) then UTR is considered genic. If you choose against the usual meaning the bonus of irparts to be much smaller than 1 in the configuration file you can force AUGUSTUS to not predict an intergenic region in the specified interval. This is useful if you want to tell AUGUSTUS that two distant exons belong to the same gene, when AUGUSTUS tends to split that gene into smaller genes.</li><li>nonexonpart: intergenic region or intron. The bonus applies to very non-exon base that overlaps with the interval from the hint. It is geometric in the length of that overlap, so choose it close to 1.0. This is useful as a weak kind of masking, e.g. when it is unlikely that a retroposed gene contains a coding region but you do not want to completely forbid exons.</li><li>genicpart: everything that is not intergenic region, i.e. intron or exon or UTR if applicable. The bonus applies to every genic base that overlaps with the interval from the hint. This can be used in particular to make Augustus predict one gene between positions a and b if a and b are experimentally confirmed to be part of the same gene, e.g. through ESTs from the same clone. alias: nonirpart</li></ul><p>Any hints of types dss, intron, exon, CDS, UTR that (implicitly) suggest a donor splice site allow AUGUSTUS to predict a donor splice site that has a GC instead of the much more common GT. AUGUSTUS does not predict a GC donor splice site unless there is a hint for one.</p><p>Starting in column number 4 you can tell AUGUSTUS how to modify the bonus depending on the source of the hint and the score of the hint. The score of the hints is specified in the 6th column of the hint gff&#x2F;gtf. If the score is used at all, the score is not used directly through some conversion formula but by distinguishing different classes of scores, e.g. low score, medium score, high score. The format is the following: First, you specify the source character, then the number of classes (say n), then you specify the score boundaries that separate the classes (n-1 thresholds) and then you specify for each score class the multiplicative modifier to the bonus (n factors).</p><h3 id="Examples"><a href="#Examples" class="headerlink" title="Examples"></a>Examples</h3><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">M</span> <span class="hljs-number">1</span> <span class="hljs-number">1</span>e+<span class="hljs-number">100</span><br></code></pre></td></tr></table></figure><p>means for the manual hint there is only one score class, the bonus for this type of hint is multiplied by 10^100. This practically forces AUGUSTUS to obey all manual hints.</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">T</span>    <span class="hljs-number">2</span>       <span class="hljs-number">1</span>.<span class="hljs-number">5</span> <span class="hljs-number">1</span> <span class="hljs-number">5</span>e29<br></code></pre></td></tr></table></figure><p>For the transMap hints distinguish 2 classes. Those with a score below 1.5 and with a score above 1.5. The bonus if the lower score hints is unchanged and the bonus of the higher score hints is multiplied by 5x10^29.</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">D</span>    <span class="hljs-number">8</span>     <span class="hljs-number">1</span>.<span class="hljs-number">5</span>  <span class="hljs-number">2</span>.<span class="hljs-number">5</span>  <span class="hljs-number">3</span>.<span class="hljs-number">5</span>  <span class="hljs-number">4</span>.<span class="hljs-number">5</span>  <span class="hljs-number">5</span>.<span class="hljs-number">5</span>  <span class="hljs-number">6</span>.<span class="hljs-number">5</span>  <span class="hljs-number">7</span>.<span class="hljs-number">5</span>  <span class="hljs-number">0</span>.<span class="hljs-number">58</span>  <span class="hljs-number">0</span>.<span class="hljs-number">4</span>  <span class="hljs-number">0</span>.<span class="hljs-number">2</span>  <span class="hljs-number">2</span>.<span class="hljs-number">9</span>  <span class="hljs-number">0</span>.<span class="hljs-number">87</span>  <span class="hljs-number">0</span>.<span class="hljs-number">44</span> <span class="hljs-number">0</span>.<span class="hljs-number">31</span>  <span class="hljs-number">7</span>.<span class="hljs-number">3</span><br></code></pre></td></tr></table></figure><p>Use 8 score classes for the DIALIGN hints. DIALIGN hints give a score, a strand and reading frame information for CDSpart hints. The strand and reading frame are often correct but not often enough to rely on them. To account for that I generated hints for all 6 combinations of a strand and reading frame and then used 2x2x2&#x3D;8 different score classes: {low score, high score} x {DIALIGN strand, opposite strand} x {DIALIGN reading frame, other reading frame} This example shows that scores don’t have to be monotonous. A higher score does not have to mean a higher bonus. They are merely a way of classifying the hints into categories as you wish. In particular, you could get the effect of having different sources by having just hints of one source and then distinguishing more scores classes.</p><h2 id="Alternative-Transcripts-x2F-Alternative-Splicing-evidence-based"><a href="#Alternative-Transcripts-x2F-Alternative-Splicing-evidence-based" class="headerlink" title="Alternative Transcripts &#x2F; Alternative Splicing (evidence based)"></a>Alternative Transcripts &#x2F; Alternative Splicing (evidence based)</h2><p>AUGUSTUS can predict alternative splicing or - more general - alternative transcripts that are suggested by evidence given in hints. The method is very general. But to give an example: If two EST alignments to the same genomic area cannot be explained by a single transcript then AUGUSTUS can predict a gene with two different splice forms, one splice form compatible with each of the EST alignments.</p><h3 id="Grouping-hints"><a href="#Grouping-hints" class="headerlink" title="Grouping hints"></a>Grouping hints</h3><p>Each hint can be given a group name, by specifying ‘group&#x3D;goupname;’ or ‘grp&#x3D;goupname;’ in the last column for the hint in the gff file. This should be used to group all the hints coming from the alignment of the same sequence to the genome. For example, if an EST with the name est_xyz aligns to the genome with one gap suggesting an intron then the hints resulting from that alignment could look like this</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs routeros">HS04636blat2hintsexonpart   500599.+.<span class="hljs-attribute">group</span>=est_xyz; <span class="hljs-attribute">source</span>=E<br>HS04636blat2hintsintron     600700.+.<span class="hljs-attribute">group</span>=est_xyz; <span class="hljs-attribute">source</span>=E<br>HS04636blat2hintsexonpart   701900.+.<span class="hljs-attribute">group</span>=est_xyz; <span class="hljs-attribute">source</span>=E<br></code></pre></td></tr></table></figure><p>Grouping tells AUGUSTUS that hints belong together. Ideally, all hints of a group are obeyed by a predicted transcript or the whole group of hints is ignored when making the prediction.</p><h3 id="Prioritizing-groups"><a href="#Prioritizing-groups" class="headerlink" title="Prioritizing groups:"></a>Prioritizing groups:</h3><p>Hints or hint groups can be given a priority by specifying ‘priority&#x3D;n;’ or ‘pri&#x3D;n’ in the last column for the hint in the gff file. For example</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs routeros">HS04636blat2hintsexonpart   500599.+.<span class="hljs-attribute">priority</span>=2; <span class="hljs-attribute">source</span>=E<br>HS04636blat2hintsintron     550650.+.<span class="hljs-attribute">priority</span>=5; <span class="hljs-attribute">source</span>=mRNA<br></code></pre></td></tr></table></figure><p>When two hints or hint groups contradict each other then the hints with the lower priority number are ignored. This is especially useful if for a genome several sources of hints are available, where one source should be trusted when in doubt. For example, the rhesus macaque currently has few native ESTs but human ESTs often also align to rhesus. Giving the hints from native ESTs a higher priority means that AUGUSTUS uses only them for genes with support by native ESTs and uses the alien EST alignments when native ESTs alignments are not available for a gene. When the priority is not specified, it is internally set to -1.</p><p>When AUGUSTUS is run with –alternatives-from-evidence&#x3D;false then all hints are given to AUGUSTUS at the same time no whether they can be explained with a single transcript per gene. AUGUSTUS will then choose the most likely transcript variant.</p><p>When AUGUSTUS is run with –alternatives-from-evidence&#x3D;true then AUGUSTUS will predict alternative transcripts based on the alternatives the hints suggest. This can be any form of alternative splicing, including nested genes contained in introns of other genes, overlapping genes, alternative translation starts and variation in UTR.</p><h1 id="PREDICTIONS-USING-CDNA"><a href="#PREDICTIONS-USING-CDNA" class="headerlink" title="PREDICTIONS USING CDNA"></a>PREDICTIONS USING CDNA</h1><p>Improving the predictions by integrating ESTs or mRNA data is fairly simple. Let cdna.fa be a fasta file with ESTs and&#x2F;or mRNAs. Here is the list of commands that will do the trick:</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs stylus">blat -minIdentity=<span class="hljs-number">92</span> genome<span class="hljs-selector-class">.fa</span> cdna<span class="hljs-selector-class">.fa</span> cdna<span class="hljs-selector-class">.psl</span><br>blat2hints<span class="hljs-selector-class">.pl</span> <span class="hljs-attr">--in</span>=cdna<span class="hljs-selector-class">.psl</span> <span class="hljs-attr">--out</span>=hints<span class="hljs-selector-class">.E</span><span class="hljs-selector-class">.gff</span><br>augustus <span class="hljs-attr">--species</span>=human <span class="hljs-attr">--hintsfile</span>=hints<span class="hljs-selector-class">.E</span><span class="hljs-selector-class">.gff</span> <span class="hljs-attr">--extrinsicCfgFile</span>=extrinsic<span class="hljs-selector-class">.ME</span><span class="hljs-selector-class">.cfg</span> genome.fa<br></code></pre></td></tr></table></figure><h2 id="Explanation-and-possible-improvements"><a href="#Explanation-and-possible-improvements" class="headerlink" title="Explanation and possible improvements"></a>Explanation and possible improvements</h2><p>BLAT is a fast spliced alignment program from Jim Kent. blat2hints.pl is a script from the AUGUSTUS scripts directory. The file extrinsic.ME.cfg states the parameters for the inclusion of the hints. You can manually adjust the few parameters for your genome. I recommend adjusting the bonuses and maluses in extrinsic.ME.cfg after a visual inspection of the predictions. For example, if it looks as if AUGUSTUS is trying to fit too many spurious EST alignments then reduce the bonuses. From experience, some ESTs often align to very many places in the genome. Most of those matches do not correspond to real protein coding gene structures. It is therefore better to add another step after the BLAT run. The command</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs routeros">pslCDnaFilter <span class="hljs-attribute">-maxAligns</span>=1 cdna.psl cdna.f.psl<br></code></pre></td></tr></table></figure><p>will filter the cDNA alignments and report only the highest-scoring spliced alignment(s) for each cDNA. Then use the filtered file cdna.f.psl to create hints. The program pslCDnaFilter is part of the Kent source tree (but not in the BLAT distribution).</p><p>For RNA-Seq integration please refer to the documentation in doc&#x2F;readme.rnaseq.html.</p><h1 id="AUGUSTUS-PPX-PREDICTIONS-USING-PROTEIN-PROFILES"><a href="#AUGUSTUS-PPX-PREDICTIONS-USING-PROTEIN-PROFILES" class="headerlink" title="AUGUSTUS-PPX: PREDICTIONS USING PROTEIN PROFILES"></a>AUGUSTUS-PPX: PREDICTIONS USING PROTEIN PROFILES</h1><p>AUGUSTUS can make its prediction based on a protein profile that can be generated from a Multiple Sequence Alignment. The protein profile is passed to AUGUSTUS by specifying the parameter –proteinprofile as in the following example:</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs stylus">msa2prfl<span class="hljs-selector-class">.pl</span> fam<span class="hljs-selector-class">.aln</span> &gt; fam<span class="hljs-selector-class">.prfl</span> <br>augustus <span class="hljs-attr">--proteinprofile</span> fam<span class="hljs-selector-class">.prfl</span> genome.fa<br></code></pre></td></tr></table></figure><p>The profile consists of a set of position-specific frequency matrices that model conserved regions in a MSA, without deletions or insertions. When equipped with a profile, AUGUSTUS will make extra effort to predict genes that are similar to the profile, for example members of a specific protein family of interest. Prediction accuracy for these genes is generally enhanced by the extra information from the protein model, while other genes are predicted identically to the ab-initio version.</p><h2 id="Creating-protein-profiles-from-Multiple-Sequence-Alignments"><a href="#Creating-protein-profiles-from-Multiple-Sequence-Alignments" class="headerlink" title="Creating protein profiles from Multiple Sequence Alignments"></a>Creating protein profiles from Multiple Sequence Alignments</h2><p>The script msa2prfl.pl converts a Multiple Sequence Alignment given in FASTA or CLUSTAL format to a protein profile, by computing frequencies from all blocks of at least 6 gapless columns in the alignment. Minimal block width can be changed with the parameter –width. The script blocks2prfl.pl converts a flat file from the BLOCKS database to a protein profile</p><h2 id="Preparing-Core-Alignments"><a href="#Preparing-Core-Alignments" class="headerlink" title="Preparing Core Alignments"></a>Preparing Core Alignments</h2><p>Large alignments may not be represented by a block profile, if they do not have sufficiently many gapless columns. It is then recommended to cluster the sequences according to similarity, or to discard sequences from the alignment that do not cover most of the blocks. The program prepareAlign can do that with an MSA in FASTA format. Usage:</p><figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs lua">prepareAlign &lt; <span class="hljs-built_in">input</span>.fa &gt; <span class="hljs-built_in">output</span>.fa<br></code></pre></td></tr></table></figure><p>The environment variables PA_FULL_COL_WEIGHT, PA_SKIP_COL_WEIGHT, PA_MINSIZE, PA_MIN_COL_COUNT control the behaviour of the program. See the source file for details.</p><h2 id="Format-of-the-protein-profile-inputfile"><a href="#Format-of-the-protein-profile-inputfile" class="headerlink" title="Format of the protein profile inputfile"></a>Format of the protein profile inputfile</h2><p>A section “[name]”, followed by the name of the family. Alternating sections “[dist]”, and “[block]”; each “[dist]” section contains a line with minimum and maximum distance between blocks. can be specified as “*” to indicate unbounded distance.</p><figure class="highlight processing"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs processing">[<span class="hljs-built_in">dist</span>]<br>&lt;<span class="hljs-built_in">min</span>&gt; &lt;<span class="hljs-built_in">max</span>&gt;<br></code></pre></td></tr></table></figure><p>Each “[block]” section contains a frequency matrix, one line in the section corresponding to a column in the alignment. Each line contains 21 tab-separated values, the first is the column index in the block (0,1,2,…), the other 20 values are the frequencies (adding up to 1), given in the order G,D,E,R,K,N,Q,S,T,A,V,L,I,F,Y,W,H,M,C,P</p><p>Example protein profiles are in the directory examples&#x2F;profile&#x2F;</p><h2 id="Running-AUGUSTUS-PPX"><a href="#Running-AUGUSTUS-PPX" class="headerlink" title="Running AUGUSTUS-PPX"></a>Running AUGUSTUS-PPX</h2><p>The running time of AUGUSTUS-PPX is proportional to the size of the profile; as a rule of thumb, the factor compared to AUGUSTUS is approximately the number of blocks in the profile. For large profiles, it is recommended to restrict the prediction with –predictionStart and –predictionEnd. On standard intel machines, running times of about one hour for a large profile on a region of 1 Mbps size, were observed. To determine regions where a profile is relevant, run a fastBlockSearch (see below). Important parameters for running AUGUSTUS-PPX are:</p><ul><li>&#x2F;ProteinModel&#x2F;allow_truncated: Enables having profile hits in right-truncated genes (default: yes)</li><li>&#x2F;ProteinModel&#x2F;block_threshold_spec: Control the specificity (default: spec&#x3D;4.0)</li><li>&#x2F;ProteinModel&#x2F;block_threshold_sens: Control the sensitivity when determining block hits (default: sens&#x3D;0.4)</li></ul><p>Increasing …_sens and decreasing …_spec will both result in more block hits found (and possibly more genes with profile hits), at the expense of more false positive hits. When the requirements cannot be both met, a block is discarded from the profile used for the prediction. Specificity and Sensitivity are given in units of standard deviation from the expected block score (Percentages can be calculated by applying the Gaussian distribution function; e.g., the default value of 2.5 corresponds to an estimated specificity of 99.3%: 7 FP hits in 1000bps). Note that filtering block hits is mainly a performance issue, and it is very unlikely that a false positive block hit affects the prediction if its score is low. To prevent blocks from being discarded from the profile, decrease either of the parameters.</p><ul><li>&#x2F;ProteinModel&#x2F;blockpart_threshold_spec: specificity for block prefixes or suffixes (4.5)</li><li>&#x2F;ProteinModel&#x2F;blockpart_threshold_sens: sensitivity for block prefixes or suffixes (2.0)</li></ul><p>The same for the case that a block is disconnected by an intron.</p><ul><li>&#x2F;ProteinModel&#x2F;weight:influence of the protein model to the combined score, can be weighted (default: 1, equal contribution) A higher value will result in more gene structures closer the protein model if there are.</li></ul><h2 id="Output-of-AUGUSTUS-PPX"><a href="#Output-of-AUGUSTUS-PPX" class="headerlink" title="Output of AUGUSTUS-PPX"></a>Output of AUGUSTUS-PPX</h2><p>If a gene is a profile hit, the following lines are added to the gff output:</p><ul><li>a protein_match feature for every block mapped to the DNA (or block part, if the block was disconnected by an intron). If –gff3&#x3D;on is specified, then target block and protein location are given in the attributes column:</li></ul><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">chr1</span>    AUGUSTUS        protein_match   <span class="hljs-number">161494506</span>       <span class="hljs-number">161494595</span>       <span class="hljs-number">7</span>.<span class="hljs-number">54</span>    +       <span class="hljs-number">0</span>       ID=pp.g2.t1.PF00012.<span class="hljs-number">13</span>_A;Target=PF00012.<span class="hljs-number">13</span>_A <span class="hljs-number">1</span> <span class="hljs-number">30</span>;Target_start=<span class="hljs-number">19</span>;<br></code></pre></td></tr></table></figure><ul><li>a interblock_region feature for every exon part in the gene that is not mapped to a block</li></ul><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">chr1</span>    AUGUSTUS        interblock_region       <span class="hljs-number">161494449</span>       <span class="hljs-number">161494505</span>       .       +       <span class="hljs-number">0</span>       ID=pp.g2.t1.iBR0<br></code></pre></td></tr></table></figure><ul><li>each translated protein sequence of a block match, as a comment (if –protein&#x3D;on is specified)</li></ul><figure class="highlight fortran"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs fortran"># <span class="hljs-keyword">sequence</span> of <span class="hljs-keyword">block</span> PF00012<span class="hljs-number">.13_A</span>   <span class="hljs-number">19</span> [VGVFQQGRVEILANDQGNRTTPSYVAFTDT] <span class="hljs-number">49</span><br></code></pre></td></tr></table></figure><h2 id="Fast-block-search-to-determine-regions-for-the-gene-prediction"><a href="#Fast-block-search-to-determine-regions-for-the-gene-prediction" class="headerlink" title="Fast block search to determine regions for the gene prediction"></a>Fast block search to determine regions for the gene prediction</h2><p>If a protein profile and a genome are given, a preliminary search can be performed with the program fastBlockSearch. It will output the locations of profile hits. An AUGUSTUS-PPX run can then be restricted to regions containing these locations. It should be run with the same parameters as the AUGUSTUS-PPX run. In addition, a threshold can be specified with the parameter –cutoff that controls the number of profile hits shown.</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">fastBlockSearch</span> --cutoff=<span class="hljs-number">0</span>.<span class="hljs-number">5</span> genome.fa fam.prfl<br></code></pre></td></tr></table></figure><p>The profile hits found by the fastBlockSearch may not contain always all blocks. In this case, it may improve the prediction to modify the profile with the following command</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">del_from_prfl</span>.pl fam.prfl <span class="hljs-number">2</span>,<span class="hljs-number">3</span>,<span class="hljs-number">5</span><br></code></pre></td></tr></table></figure><p>where 2,3,5 is to be replaced with the list of blocks to be deleted from the profile.</p><h1 id="RETRAINING-AUGUSTUS"><a href="#RETRAINING-AUGUSTUS" class="headerlink" title="RETRAINING AUGUSTUS"></a>RETRAINING AUGUSTUS</h1><p>Please see the file README.autoAug for documentation for the automatic training script autoAug.pl. See also the file retraining.html. Here is some background:</p><p>AUGUSTUS uses parameters which are species specific like the Markov chain transition probability of coding and non-coding regions. These parameters can be trained on training sets of annotated genes in genbank format. They are stored in the config directory in 3 files containing the parameters for the exon-related, intron-related and intergenic-region-related parameters, e.g. human_exon_probs.pbl, human_intron_probs.pbl, human_igenic_probs.pbl. For each species there are also parameters like the order of the markov chain or the size of the window used for the splice site models. Let’s call these meta parameters. These meta parameters are stored in a separate file, e.g. human_parameters.cfg. Which meta parameters work best depends on the species and on the training set, in particular on the size of the training set. Using the meta parameters of another species or for another training set is likely to result in poor prediction performance. The meta parameters are not documented sufficiently. However, when optimizing the meta parameters for a new species it helps to know their meaning. Please contact me in case you want me to do the training. The program ‘etraining’ reads the meta parameters from the .cfg file and a genbank file with annotated genes and writes the other species specific parameters into the 3 .pbl files.</p><p>usage:</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs routeros">etraining <span class="hljs-attribute">--species</span>=SPECIES trainfilename<br></code></pre></td></tr></table></figure><p>‘trainfilename’ is the filename (including relative path) to the file in genbank format containing the training sequences. These can be multi-gene sequences and genes on the reverse strand. However, the genes must not overlap.</p><h1 id="MEA-USING-THE-MAXIMUM-EXPECTED-ACCURACY-APPROACH"><a href="#MEA-USING-THE-MAXIMUM-EXPECTED-ACCURACY-APPROACH" class="headerlink" title="MEA: USING THE MAXIMUM EXPECTED ACCURACY APPROACH"></a>MEA: USING THE MAXIMUM EXPECTED ACCURACY APPROACH</h1><p>MEA is an alternative decoding approach and is described in the Poster found in <a href="https://github.com/Gaius-Augustus/Augustus/blob/master/docs/MEAposter.pdf">MEAposter.pdf</a>. For predictions using MEA the corresponding AUGUSTUS parameter has to be turned on: –mea&#x3D;1</p>]]></content>
    
    
    <categories>
      
      <category>Software</category>
      
    </categories>
    
    
    <tags>
      
      <tag>annotation</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【FuncAnno】【InterProScan】</title>
    <link href="/GeekFocus/2022/06/05/2022-06-05-FuncAnno-InterPro/"/>
    <url>/GeekFocus/2022/06/05/2022-06-05-FuncAnno-InterPro/</url>
    
    <content type="html"><![CDATA[<h1 id="鉴定蛋白质结构域保守位点，并进行家族分类"><a href="#鉴定蛋白质结构域保守位点，并进行家族分类" class="headerlink" title="鉴定蛋白质结构域保守位点，并进行家族分类"></a>鉴定蛋白质结构域保守位点，并进行家族分类</h1><span id="more"></span><p><a href="https://interproscan-docs.readthedocs.io/en/latest/HowToRun.html">https://interproscan-docs.readthedocs.io/en/latest/HowToRun.html</a></p><p><a href="https://www.jianshu.com/p/9d832ea9904f">https://www.jianshu.com/p/9d832ea9904f</a></p><p><a href="https://sr-c.github.io/2018/09/13/interproscan-config/">https://sr-c.github.io/2018/09/13/interproscan-config/</a></p><h2 id="0-介绍"><a href="#0-介绍" class="headerlink" title="0. 介绍"></a>0. 介绍</h2><p>主要功能：</p><ol><li>预测蛋白质的结构域和功能位点</li><li>根据蛋白质含有的结构域和特殊位点进行分类</li></ol><p>默认包含所有的数据库，<font color="blue">结构域，特征序列，和信号肽</font>，可以选择部分数据库</p><h3 id="Familys-domains-sites-amp-repeats"><a href="#Familys-domains-sites-amp-repeats" class="headerlink" title="Familys, domains, sites &amp; repeats"></a>Familys, domains, sites &amp; repeats</h3><p>TIGRFAMS</p><p>SFLD</p><p>PANTHER</p><p>HAMAP</p><p>PROSITE profiles?fail</p><p>PROSITE patterns?</p><p>SMART</p><p>CDD</p><p>PRINTS</p><p>Pfam</p><p>PIRSF</p><h3 id="Structual-domains"><a href="#Structual-domains" class="headerlink" title="Structual domains"></a>Structual domains</h3><p>SUPERFAMILY</p><p>Gene3D</p><h3 id="Other-sequence-features"><a href="#Other-sequence-features" class="headerlink" title="Other sequence features"></a>Other sequence features</h3><p>SignalP</p><p>Coils</p><p>TMHMM</p><p>MobiDBLite</p><p>Phobius</p><h3 id="other-category"><a href="#other-category" class="headerlink" title="other category"></a>other category</h3><p>SIngnalP_EUK; Signal_GRAM_POSITIVE; </p><h3 id="单独配置分析"><a href="#单独配置分析" class="headerlink" title="单独配置分析"></a>单独配置分析</h3><p>分析信号肽，真核，Gram+细菌，Gram-细菌，跨膜结构，这部分软件需要自行配置</p><p>SignalP, TMHMM, 严格按照版本， deactivated 提示</p><h2 id="1-下载安装"><a href="#1-下载安装" class="headerlink" title="1. 下载安装"></a>1. 下载安装</h2><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-comment"># 此处为最新版本5.52-86.0，64位，下载MD5文件用来检验下载的完整性</span><br>wget https://ftp.ebi.ac.uk/pub/software/unix/iprscan/5/5.52-86.0/interproscan-5.52-86.0-64-bit.tar.gz<br>wget https://ftp.ebi.ac.uk/pub/software/unix/iprscan/5/5.52-86.0/interproscan-5.52-86.0-64-bit.tar.gz.md5<br><span class="hljs-built_in">md5sum</span> -c interproscan-5.52-86.0-64-bit.tar.gz.md5<br><span class="hljs-comment"># 返回ok则说明下载完整</span><br>tar -pxvzf interproscan-5.52-86.0-*-bit.tar.gz<br><br><span class="hljs-comment">###Latest version 5.56-89.0</span><br>https://github.com/ebi-pf-team/interproscan/releases<br>interproscan-5.56-89.0 Latest<br>release: interproscan-5.56-89.0<br>md5: f3288327a6c7be1ff42220c3b7a1de43<br>cpu: 64 bit<br>os: Linux<br>size: 7.5GB compressed<br><br>https://ftp.ebi.ac.uk/pub/software/unix/iprscan/5/5.56-89.0/interproscan-5.56-89.0-64-bit.tar.gz<br>https://ftp.ebi.ac.uk/pub/software/unix/iprscan/5/5.56-89.0/interproscan-5.56-89.0-64-bit.tar.gz.md5<br><span class="hljs-built_in">md5sum</span> -c interproscan-5.56-89.0-64-bit.tar.gz.md5<br>interproscan-5.56-89.0-64-bit.tar.gz: OK<br><span class="hljs-comment">#解压</span><br>tar -pxvzf interproscan-5.56-89.0-64-bit.tar.gz<br><br><span class="hljs-comment"># 解压完后，进入目录，查看是否安装完好，若有用法说明弹出则表示安装成功。</span><br>./interproscan.sh<br><br>Java version 11 is required to run InterProScan.<br>download jdk-11.0.15.1[https://www.oracle.com/java/technologies/downloads/<span class="hljs-comment">#java11]</span><br>jdk-11.0.15.1_linux-x64_bin.tar.gz<br><br><span class="hljs-comment">#export JAVA_HOME=/usr/local/jdk-11.0.8</span><br><span class="hljs-comment">#export CLASSPATH=.:$JAVA_HOME/jre/lib:$JAVA_HOME/lib:$JAVA_HOME/lib/tools.jar</span><br><span class="hljs-comment">#export PATH=$PATH:$JAVA_HOME/bin:$JAVA_HOME/jre/bin</span><br><br><span class="hljs-built_in">export</span> JAVA_HOME=/path/jdk-11.0.15.1<br><span class="hljs-built_in">export</span> PATH=<span class="hljs-variable">$PATH</span>:<span class="hljs-variable">$JAVA_HOME</span>/bin<br>failed，still /usr/bin/java<br>vi ./interproscan.sh<br><span class="hljs-comment"># old JAVA=$(type -p java)</span><br>JAVA=$(<span class="hljs-built_in">type</span> -p /path/jdk-11.0.15.1/bin/java)<br><span class="hljs-comment">#https://blog.csdn.net/weixin_43484846/article/details/121400487</span><br><span class="hljs-comment">#此blog 用ln -s /path/jdk-11.0.15.1/bin/java  /usr/bin/java 未尝试此法</span><br>./interproscan.sh <br>Checking any hmm models that need indexing ... this may take a few minutes<br>Working...    <span class="hljs-keyword">done</span>.<br>Pressed and indexed 263 HMMs (263 names and 263 accessions).<br>Models pressed into binary file:   data/antifam/7.0/AntiFam.hmm.h3m<br>SSI index <span class="hljs-keyword">for</span> binary model file:   data/antifam/7.0/AntiFam.hmm.h3i<br>Profiles (MSV part) pressed into:  data/antifam/7.0/AntiFam.hmm.h3f<br>Profiles (remainder) pressed into: data/antifam/7.0/AntiFam.hmm.h3p<br>Working...    <span class="hljs-keyword">done</span>.<br>Pressed and indexed 66720 HMMs (66720 names).<br>Models pressed into binary file:   data/gene3d/4.3.0/gene3d_main.hmm.h3m<br>SSI index <span class="hljs-keyword">for</span> binary model file:   data/gene3d/4.3.0/gene3d_main.hmm.h3i<br>Profiles (MSV part) pressed into:  data/gene3d/4.3.0/gene3d_main.hmm.h3f<br>Profiles (remainder) pressed into: data/gene3d/4.3.0/gene3d_main.hmm.h3p<br>Working...    <span class="hljs-keyword">done</span>.<br>Pressed and indexed 2383 HMMs (2383 names).<br>Models pressed into binary file:   data/hamap/2021_04/hamap.hmm.lib.h3m<br>SSI index <span class="hljs-keyword">for</span> binary model file:   data/hamap/2021_04/hamap.hmm.lib.h3i<br>Profiles (MSV part) pressed into:  data/hamap/2021_04/hamap.hmm.lib.h3f<br>Profiles (remainder) pressed into: data/hamap/2021_04/hamap.hmm.lib.h3p<br>Working...    <span class="hljs-keyword">done</span>.<br>Pressed and indexed 134000 HMMs (134000 names).<br>Models pressed into binary file:   data/panther/15.0/panther.hmm.h3m<br>SSI index <span class="hljs-keyword">for</span> binary model file:   data/panther/15.0/panther.hmm.h3i<br>Profiles (MSV part) pressed into:  data/panther/15.0/panther.hmm.h3f<br>Profiles (remainder) pressed into: data/panther/15.0/panther.hmm.h3p<br>Working...    <span class="hljs-keyword">done</span>.<br>Pressed and indexed 19179 HMMs (19179 names and 19179 accessions).<br>Models pressed into binary file:   data/pfam/34.0/pfam_a.hmm.h3m<br>SSI index <span class="hljs-keyword">for</span> binary model file:   data/pfam/34.0/pfam_a.hmm.h3i<br>Profiles (MSV part) pressed into:  data/pfam/34.0/pfam_a.hmm.h3f<br>Profiles (remainder) pressed into: data/pfam/34.0/pfam_a.hmm.h3p<br>Working...    <span class="hljs-keyword">done</span>.<br>Pressed and indexed 3283 HMMs (3283 names and 3283 accessions).<br>Models pressed into binary file:   data/pirsf/3.10/sf_hmm_all.h3m<br>SSI index <span class="hljs-keyword">for</span> binary model file:   data/pirsf/3.10/sf_hmm_all.h3i<br>Profiles (MSV part) pressed into:  data/pirsf/3.10/sf_hmm_all.h3f<br>Profiles (remainder) pressed into: data/pirsf/3.10/sf_hmm_all.h3p<br>Working...    <span class="hljs-keyword">done</span>.<br>Pressed and indexed 1510 HMMs (1510 names and 1510 accessions).<br>Models pressed into binary file:   data/pirsr/2021_05/sr_hmm_all.h3m<br>SSI index <span class="hljs-keyword">for</span> binary model file:   data/pirsr/2021_05/sr_hmm_all.h3i<br>Profiles (MSV part) pressed into:  data/pirsr/2021_05/sr_hmm_all.h3f<br>Profiles (remainder) pressed into: data/pirsr/2021_05/sr_hmm_all.h3p<br>Working...    <span class="hljs-keyword">done</span>.<br>Pressed and indexed 299 HMMs (299 names and 299 accessions).<br>Models pressed into binary file:   data/sfld/4/sfld.hmm.h3m<br>SSI index <span class="hljs-keyword">for</span> binary model file:   data/sfld/4/sfld.hmm.h3i<br>Profiles (MSV part) pressed into:  data/sfld/4/sfld.hmm.h3f<br>Profiles (remainder) pressed into: data/sfld/4/sfld.hmm.h3p<br>Working...    <span class="hljs-keyword">done</span>.<br>Pressed and indexed 15438 HMMs (15438 names and 15438 accessions).<br>Models pressed into binary file:   data/superfamily/1.75/hmmlib_1.75.h3m<br>SSI index <span class="hljs-keyword">for</span> binary model file:   data/superfamily/1.75/hmmlib_1.75.h3i<br>Profiles (MSV part) pressed into:  data/superfamily/1.75/hmmlib_1.75.h3f<br>Profiles (remainder) pressed into: data/superfamily/1.75/hmmlib_1.75.h3p<br>Working...    <span class="hljs-keyword">done</span>.<br>Pressed and indexed 4488 HMMs (4488 names and 4488 accessions).<br>Models pressed into binary file:   data/tigrfam/15.0/TIGRFAMs_HMM.LIB.h3m<br>SSI index <span class="hljs-keyword">for</span> binary model file:   data/tigrfam/15.0/TIGRFAMs_HMM.LIB.h3i<br>Profiles (MSV part) pressed into:  data/tigrfam/15.0/TIGRFAMs_HMM.LIB.h3f<br>Profiles (remainder) pressed into: data/tigrfam/15.0/TIGRFAMs_HMM.LIB.h3p<br>Completed indexing the hmm models.<br>30/05/2022 22:41:20:513 Welcome to InterProScan-5.56-89.0<br>30/05/2022 22:41:20:516 Running InterProScan v5 <span class="hljs-keyword">in</span> STANDALONE mode... on Linux<br>usage: java -XX:+UseParallelGC -XX:ParallelGCThreads=2 -XX:+AggressiveOpts -XX:+UseFastAccessorMethods -Xms128M<br>            -Xmx2048M -jar interproscan-5.jar<br><br><span class="hljs-comment"># 进行初始化，此命令大致是准备好HMM模型以供hmmscan使用</span><br>python3 initial_setup.py<br><span class="hljs-comment"># no fat local</span><br>/xtdisk/xueyb_group/wangchenA/miniconda3/bin/python3 initial_setup.py<br></code></pre></td></tr></table></figure><h2 id="2-测试与参数"><a href="#2-测试与参数" class="headerlink" title="2. 测试与参数"></a>2. 测试与参数</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs bash">./interproscan.sh<br><span class="hljs-comment"># 短暂等待后，即会输出帮助信息</span><br>30/05/2022 22:44:40:746 Welcome to InterProScan-5.56-89.0<br>30/05/2022 22:44:40:747 Running InterProScan v5 <span class="hljs-keyword">in</span> STANDALONE mode... on Linux<br>usage: java -XX:+UseParallelGC -XX:ParallelGCThreads=2 -XX:+AggressiveOpts -XX:+UseFastAccessorMethods -Xms128M<br>            -Xmx2048M -jar interproscan-5.jar<br><br><span class="hljs-comment">#完成上面的步骤后，即可进行测试（以下两条命令选一即可）</span><br><span class="hljs-comment"># 程序不联网，使用本地的Lookup Service</span><br>./interproscan.sh -i test_all_appl.fasta -f tsv -dp<br><span class="hljs-comment"># 使用程序自带的测试数据进行测试</span><br>./interproscan.sh -i test_all_appl.fasta -f tsv<br>    <span class="hljs-comment"># -dp参数的含义：含有-dp则是关闭了连接EBI联网搜索的权限而使用本地化搜索，默认情况下是支持EBI联网搜索，若只需本地则使用-dp。（可能不正确）</span><br>    -dp,--disable-precalc Optional.  Disables use of the precalculated match lookup service.  All match calculations will be run locally.<br></code></pre></td></tr></table></figure><ul><li>-appl &#x2F; -applications 搜索应用的名字(可选)<ul><li>默认情况下，运行所有的分析，也可以自己指定一个或多个。</li></ul></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 指定pfam搜索</span><br>./interproscan.sh -appl Pfam -i /path/to/sequences.fasta<br><span class="hljs-comment">#同时指定多个进行搜索</span><br>./interproscan.sh -appl CDD,COILS,Gene3D,HAMAP,MobiDBLite,PANTHER,Pfam,PIRSF,PRINTS,PROSITEPATTERNS,PROSITEPROFILES,SFLD,SMART,SUPERFAMILY,TIGRFAM -i /path/to/sequences.fasta<br></code></pre></td></tr></table></figure><ul><li>-i &#x2F;-fasta 序列文件<ul><li>输入的是蛋白或者核酸的fasta文件，将会返回TSV,XML,Gff3三个输出结果</li></ul></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">./interproscan.sh -i /path/to/sequences.fasta<br><span class="hljs-comment"># 输出结果为sequences.tsv, sequence.xml, sequences.gff3</span><br></code></pre></td></tr></table></figure><ul><li>-t &#x2F; 序列类型<ul><li>默认是蛋白序列，若为核苷酸序列，则需要加上此参数</li></ul></li></ul><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sh">./interproscan.sh -t n -i /path/to/sequences.fasta<br></code></pre></td></tr></table></figure><p>其他参数</p><h2 id="3-包含分析"><a href="#3-包含分析" class="headerlink" title="3. 包含分析"></a>3. 包含分析</h2><blockquote><ul><li>CDD</li><li>COLIS</li><li>Gene3D</li><li>HAMAP</li><li>MOBIDB</li><li>PANTHER</li><li>Pfam</li><li>PIRSF</li><li>SMART</li><li>…</li></ul></blockquote><h2 id="4-线程"><a href="#4-线程" class="headerlink" title="4. 线程"></a>4. 线程</h2><p>在单机运行InterProScan时，可在配置文件<code>interproscan.properties</code>中设置线程，其默认设置如下</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-comment"># Set the number of embedded workers to the number of processors that you would like to employ</span><br><span class="hljs-comment"># on the machine you are using to run InterProScan.</span><br><span class="hljs-comment">#number of embedded workers  a master process can have</span><br>number.of.embedded.workers=6<br>maxnumber.of.embedded.workers=8<br></code></pre></td></tr></table></figure><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-comment">#对于一个40核的机器，推荐的设置如下</span><br><span class="hljs-comment">#Number of embedded workers at start time</span><br>number.of.embedded.workers=1<br><span class="hljs-comment">#Maximum number of embedded workers</span><br>maxnumber.of.embedded.workers=35<br></code></pre></td></tr></table></figure><p>推荐单次输入蛋白序列10000条，核酸序列1000条。若输入数据过多，建议将其分组运行。</p><p>使用<code>-appl</code>参数设置比对的项目，减少程序耗时</p><p>进行比对的蛋白序列中不应含有星号，否则将有如下报错。将序列中的星号删除即可。</p><p>InterProScan自带的blast+中rpsblast的编译环境与本机环境不同。通过替换这支程序来解决。下载ncbi提供的已编译版本，使用其中的rpsblast替换InterProScan自带的rpsblast即可。</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-comment"># backup original version</span><br><span class="hljs-built_in">cp</span> bin/blast/ncbi-blast-2.6.0+/rpsblast bin/blast/ncbi-blast-2.6.0+/rpsblast.bak<br><br><span class="hljs-comment"># copy the new version to the binary folder</span><br><span class="hljs-built_in">cp</span> ncbi-blast-2.6.0+/bin/rpsblast bin/blast/ncbi-blast-2.6.0+/rpsblast<br></code></pre></td></tr></table></figure><h2 id="5-运行"><a href="#5-运行" class="headerlink" title="5. 运行"></a>5. 运行</h2><p>一次运行同时实现多个信息注释</p><ul><li>InterPro注释</li><li>Pfam数据库注释(可以通过hmmscan搜索pfam数据库完成)</li><li>GO注释(可以基于NR和Pfam等数据库，然后BLAST2GO完成,)</li><li>Reactome通路注释，不同于KEGG</li></ul><p>命令如下</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs stylus">./interproscan-<span class="hljs-number">5.29</span>-<span class="hljs-number">68.0</span>/interproscan<span class="hljs-selector-class">.sh</span> -appl Pfam  -f TSV -<span class="hljs-selector-tag">i</span> sample<span class="hljs-selector-class">.fa</span> -cpu <span class="hljs-number">50</span> -<span class="hljs-selector-tag">b</span> sample -goterms -iprlookup -pa<br></code></pre></td></tr></table></figure><p><code>-appl</code>告诉软件要执行哪些数据分析，勾选的越多，分析速度越慢，Pfam就行。</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br></pre></td><td class="code"><pre><code class="hljs sh">software/interproscan-5.56-89.0/interproscan.sh<br>31/05/2022 11:39:27:267 Welcome to InterProScan-5.56-89.0<br>31/05/2022 11:39:27:269 Running InterProScan v5 <span class="hljs-keyword">in</span> STANDALONE mode... on Linux<br>usage: java -XX:+UseParallelGC -XX:ParallelGCThreads=2 -XX:+AggressiveOpts -XX:+UseFastAccessorMethods -Xms128M<br>            -Xmx2048M -jar interproscan-5.jar<br><br><br>Please give us your feedback by sending an email to<br><br>interhelp@ebi.ac.uk<br><br>-appl,--applications &lt;ANALYSES&gt;     Optional, <span class="hljs-string">&#x27;comma separated list&#x27;</span> of analyses.  Default: all available analysis<br><br>-b,--output-file-base &lt;OUTPUT-FILE-BASE&gt;     Optional, <span class="hljs-string">&#x27;base output filename&#x27;</span> (relative or absolute path). Note that this option, the --output-dir (-d) option and the --outfile (-o) option are mutually exclusive.  The appropriate file extension <span class="hljs-keyword">for</span> the output format(s) will be appended automatically. By default the input file path/name will be used.<br><br>-d,--output-dir &lt;OUTPUT-DIR&gt;     Optional, output directory.  Note that this option, the --outfile (-o) option and the --output-file-base (-b) option are mutually exclusive. The output filename(s) are the same as the input filename, with the appropriate file extension(s) <span class="hljs-keyword">for</span> the output format(s) appended automatically .<br><br>-o,--outfile &lt;EXPLICIT_OUTPUT_FILENAME&gt; Optional explicit output file name (relative or absolute path).  Note that this option, the --output-dir (-d) option and the --output-file-base (-b) option are mutually exclusive. If this option is given, you MUST specify a single output format using the -f option.  The output file name will not be modified. Note that specifying an output file name using this option OVERWRITES ANY EXISTING FILE.<br><br>-cpu,--cpu &lt;CPU&gt;     Optional, number of cores <span class="hljs-keyword">for</span> inteproscan.<br><br>-dp,--disable-precalc     Optional.  Disables use of the precalculated match lookup service.  All match calculations will be <span class="hljs-string">&#x27;run locally&#x27;</span>.<br><br>-dra,--disable-residue-annot     Optional, excludes sites from the XML, JSON output<br><br>-etra,--enable-tsv-residue-annot     Optional, includes sites <span class="hljs-keyword">in</span> TSV output<br><br>-exclappl,--excl-applications &lt;EXC-ANALYSES&gt;     Optional, comma separated list of <span class="hljs-string">&#x27;analyses you want to exclude&#x27;</span>.<br><br>-f,--formats &lt;OUTPUT-FORMATS&gt;     Optional, case-insensitive, comma separated <span class="hljs-string">&#x27;list of output formats&#x27;</span>. Supported formats are <span class="hljs-string">&#x27;TSV, XML, JSON, GFF3, HTML and SVG&#x27;</span>. <span class="hljs-string">&#x27;Default for protein sequences are TSV, XML and GFF3&#x27;</span>, or <span class="hljs-string">&#x27;for nucleotide sequences GFF3 and XML&#x27;</span>.<br><br>-iprlookup,--iprlookup     Also include <span class="hljs-string">&#x27;lookup of corresponding InterPro annotation in the TSV and GFF3 output formats&#x27;</span>.<br><br>-goterms,--goterms     Optional, <span class="hljs-string">&#x27;switch on lookup of corresponding Gene Ontology annotation (IMPLIES -iprlookup option)&#x27;</span><br><br>-pa,--pathways Optional, switch on <span class="hljs-string">&#x27;lookup of corresponding Pathway annotation (IMPLIES -iprlookup option)&#x27;</span><br><br>-<span class="hljs-built_in">help</span>,--<span class="hljs-built_in">help</span>     Optional, display <span class="hljs-built_in">help</span> information<br><br>-i,--input &lt;INPUT-FILE-PATH&gt;     Optional, path to fasta file that should be loaded on Master startup. Alternatively, <span class="hljs-keyword">in</span> CONVERT mode, the InterProScan 5 XML file to convert.<br><br>-incldepappl,--incl-dep-applications &lt;INC-DEP-ANALYSES&gt;   Optional, comma separated list of deprecated analyses that you want included.  If this option is not <span class="hljs-built_in">set</span>, deprecated analyses will not run.<br><br>-ms,--minsize &lt;MINIMUM-SIZE&gt;     Optional, <span class="hljs-string">&#x27;minimum nucleotide size of ORF to report[100aa?]&#x27;</span>. Will only be considered <span class="hljs-keyword">if</span> n is specified as a sequence <span class="hljs-built_in">type</span>. Please be aware of the fact that <span class="hljs-keyword">if</span> you specify a too short value it might be that the analysis takes a very long time!<br><br>-t,--seqtype &lt;SEQUENCE-TYPE&gt;     Optional, the <span class="hljs-built_in">type</span> of the input sequences (dna/rna (n) or protein (p)).  The <span class="hljs-string">&#x27;default sequence type is protein&#x27;</span>. Optional, specify temporary file directory (relative or absolute path). The <span class="hljs-string">&#x27;default location is temp/&#x27;</span>.<br><br>-verbose,--verbose Optional, display more ‘verbose冗长’ <span class="hljs-built_in">log</span> output<br><br>-version,--version     Optional, display version number<br><br>-vl,--verbose-level &lt;VERBOSE-LEVEL&gt;     Optional, display <span class="hljs-string">&#x27;verbose log output at level specified&#x27;</span>.<br><br>-vtsv,--output-tsv-version     Optional, includes a TSV version file along with any TSV <br>output (when TSV output requested)<br><br>Copyright © EMBL European Bioinformatics Institute, Hinxton, Cambridge, UK. (http://www.ebi.ac.uk) The InterProScan software itself is provided under the Apache License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.html). Third party components (e.g. member database binaries and models) are subject to separate licensing - please see the individual member database websites <span class="hljs-keyword">for</span> details.<br><br><span class="hljs-string">&#x27;Available analyses&#x27;</span>:<br><span class="hljs-string">&#x27;TIGRFAM (15.0)&#x27;</span> : TIGRFAMs are <span class="hljs-string">&#x27;protein families&#x27;</span> based on <span class="hljs-string">&#x27;hidden Markov models (HMMs)&#x27;</span>.<br><br><span class="hljs-string">&#x27;SFLD (4)&#x27;</span> : SFLD is a database of <span class="hljs-string">&#x27;protein families&#x27;</span> based on <span class="hljs-string">&#x27;hidden Markov models (HMMs)&#x27;</span>.<br><br><span class="hljs-string">&#x27;√SUPERFAMILY (1.75)&#x27;</span> : SUPERFAMILY is a database of <span class="hljs-string">&#x27;structural and functional annotations&#x27;</span> <span class="hljs-keyword">for</span> <span class="hljs-string">&#x27;all proteins and genomes&#x27;</span>.<br><br><span class="hljs-string">&#x27;√PANTHER (15.0)&#x27;</span> : The PANTHER (<span class="hljs-string">&#x27;Protein ANalysis THrough Evolutionary Relationships&#x27;</span>) Classification System is a unique resource that <span class="hljs-string">&#x27;classifies genes by their functions, using published scientific experimental evidence and evolutionary relationships to predict function&#x27;</span> even <span class="hljs-keyword">in</span> the absence of direct experimental evidence.<br><br><span class="hljs-string">&#x27;√Gene3D (4.3.0)&#x27;</span> : <span class="hljs-string">&#x27;Structural assignment&#x27;</span> <span class="hljs-keyword">for</span> whole genes and genomes using the <span class="hljs-string">&#x27;CATH domain structure database&#x27;</span>.<br><br>Hamap (2021_04) : High-quality Automated and Manual Annotation of <span class="hljs-string">&#x27;Microbial Proteomes&#x27;</span>.<br><br>Coils (2.2.1) : Prediction of coiled coil regions? <span class="hljs-keyword">in</span> proteins.<br><br><span class="hljs-string">&#x27;ProSiteProfiles (2022_01)&#x27;</span>: PROSITE consists of documentation entries describing <span class="hljs-string">&#x27;protein domains, families and functional sites&#x27;</span> as well as <span class="hljs-string">&#x27;associated patterns and profiles&#x27;</span> to identify them.<br><br><span class="hljs-string">&#x27;√SMART (7.1)&#x27;</span> : SMART allows the identification and analysis of <span class="hljs-string">&#x27;domain architectures&#x27;</span> based on <span class="hljs-string">&#x27;hidden Markov models&#x27;</span> (HMMs). <br><br><span class="hljs-string">&#x27;CDD (3.18)&#x27;</span> : CDD predicts protein <span class="hljs-string">&#x27;domains and families&#x27;</span> based on <span class="hljs-string">&#x27;a collection of well-annotated multiple sequence alignment models&#x27;</span>.<br><br><span class="hljs-string">&#x27;√PRINTS (42.0)&#x27;</span> : A compendium of <span class="hljs-string">&#x27;protein fingerprints&#x27;</span> - a fingerprint is a group of <span class="hljs-string">&#x27;conserved motifs&#x27;</span> used to characterise a protein family.<br><br>PIRSR (2021_05) : PIRSR is a database of protein families based on hidden Markov models (HMMs) and Site Rules.<br><br>ProSitePatterns (2022_01) : PROSITE consists of documentation entries describing <span class="hljs-string">&#x27;protein domains, families and functional&#x27;</span> sites as well as associated patterns and profiles to identify them.<br><br>AntiFam (7.0) : AntiFam is a resource of profile-HMMs designed to identify spurious protein predictions.<br><br><span class="hljs-string">&#x27;√Pfam (34.0)&#x27;</span> : A <span class="hljs-string">&#x27;large collection of protein families&#x27;</span>, each represented by <span class="hljs-string">&#x27;multiple sequence alignments and hidden Markov models (HMMs)&#x27;</span>.<br><br>MobiDBLite (2.0) : Prediction of intrinsically disordered regions <span class="hljs-keyword">in</span> proteins.<br><br><span class="hljs-string">&#x27;PIRSF (3.10)&#x27;</span> : The PIRSF concept is used as a guiding principle to <span class="hljs-string">&#x27;provide comprehensive and non-overlapping clustering of UniProtKB sequences into a hierarchical order&#x27;</span> to reflect their evolutionary relationships.<br><br><span class="hljs-string">&#x27;Deactivated analyses&#x27;</span>:<br>SignalP_GRAM_NEGATIVE (4.1) : Analysis SignalP_GRAM_NEGATIVE is deactivated, because the resources expected at the following paths <span class="hljs-keyword">do</span> not exist: bin/signalp/4.1/signalp<br><br>TMHMM (2.0c) : Analysis TMHMM is deactivated, because the resources expected at the following paths <span class="hljs-keyword">do</span> not exist: bin/tmhmm/2.0c/decodeanhmm, data/tmhmm/2.0c/TMHMM2.0c.model<br><br>SignalP_EUK (4.1) : Analysis SignalP_EUK is deactivated, because the resources expected at the following paths <span class="hljs-keyword">do</span> not exist: bin/signalp/4.1/signalp<br><br>Phobius (1.01) : Analysis Phobius is deactivated, because the resources expected at the following paths <span class="hljs-keyword">do</span> not exist: bin/phobius/1.01/phobius.pl<br><br>SignalP_GRAM_POSITIVE (4.1) : Analysis SignalP_GRAM_POSITIVE is deactivated, because the resources expected at the following paths <span class="hljs-keyword">do</span> not exist: bin/signalp/4.1/signalp<br></code></pre></td></tr></table></figure><p>IF8-PlantBio 杜鹃属和海南冀鹏科植物：<strong>Pfam</strong>, <strong>PRINTS</strong>, <strong>SMART</strong>, ProDom and PROSITE</p><p>IF8-PlantBio 常绿杜鹃基因组：TIGRFAM, Phobius, SignalP, <strong>SUPERFAMILY</strong>, <strong>PANTHER</strong>, <strong>Gene3D</strong>, ProSite, Coils, <strong>PRINTS</strong>, <strong>SMART</strong>, <strong>Pfam</strong>, PIRSF, TMHMM and GO. </p><p>IF3.6-frontierInPlantSci 牛油果树：<strong>PFAM</strong>, <strong>Gene3D</strong>, <strong>PANTHER</strong>, <strong>CDD</strong>, <strong>SUPERFAMILY</strong>, ProSite, and GO</p><p>IF3.4-GBE 叶蝉基因组：<strong>Pfam</strong>,  <strong>Superfamily</strong> , <strong>Gene3D</strong>, <strong>SMART</strong>, <strong>CDD</strong></p><p>ProSiteProfiles, ProSitePatterns</p><p>-iprlookup,–iprlookup     Also include ‘lookup of corresponding <strong>InterPro</strong> annotation in the TSV and GFF3 output formats’.</p><p>-goterms,–goterms     Optional, ‘switch on lookup of corresponding <strong>Gene Ontology</strong> annotation (IMPLIES -iprlookup option)’</p><p>-pa,–pathways Optional, switch on ‘lookup of corresponding <strong>Pathway</strong> annotation (IMPLIES -iprlookup option)’</p><p>-vl</p><p>Pfam,PRINTS,SMART,SUPERFAMILY,PANTHER,Gene3D,CDD,ProSiteProfiles?ProSitePatterns?</p>]]></content>
    
    
    <categories>
      
      <category>Software</category>
      
    </categories>
    
    
    <tags>
      
      <tag>FuncAnno</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【FuncAnno】【BLAST】</title>
    <link href="/GeekFocus/2022/06/05/2022-06-05-FuncAnno-BLASTP/"/>
    <url>/GeekFocus/2022/06/05/2022-06-05-FuncAnno-BLASTP/</url>
    
    <content type="html"><![CDATA[<p>NCBI BLAST+</p><span id="more"></span><h1 id="BLAST"><a href="#BLAST" class="headerlink" title="BLAST"></a>BLAST</h1><h2 id="nr-nt"><a href="#nr-nt" class="headerlink" title="nr nt"></a>nr nt</h2><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs awk">wget -c ftp:<span class="hljs-regexp">//</span>ftp.ncbi.nlm.nih.gov<span class="hljs-regexp">/blast/</span>db/nt*<br>wget -c ftp:<span class="hljs-regexp">//</span>ftp.ncbi.nlm.nih.gov<span class="hljs-regexp">/blast/</span>db/nr*<br></code></pre></td></tr></table></figure><figure class="highlight stata"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs stata">awk &#x27;&#123;<span class="hljs-keyword">if</span>(NR%4 == 1)&#123;<span class="hljs-keyword">print</span> <span class="hljs-string">&quot;&gt;&quot;</span> <span class="hljs-built_in">substr</span>(<span class="hljs-variable">$0</span>, 2)&#125;&#125;&#123;<span class="hljs-keyword">if</span>(NR%4 == 2)&#123;<span class="hljs-keyword">print</span>&#125;&#125;&#x27; <span class="hljs-keyword">test</span>.fastq &gt; <span class="hljs-keyword">test</span>.fasta<br>blastn -<span class="hljs-keyword">query</span> <span class="hljs-keyword">test</span>.fasta -<span class="hljs-keyword">out</span> <span class="hljs-keyword">test</span>.result -<span class="hljs-keyword">db</span> ./nt_db/nt <br>## 输出一条最优比对结果<br>blastn -<span class="hljs-keyword">query</span> test1.fa -<span class="hljs-keyword">out</span> test1.align -<span class="hljs-keyword">db</span> ./nt_db_NCBI/nt -outfmt 6 -subject_besthit -num_threads 4<br></code></pre></td></tr></table></figure><h2 id="BLASTP-Functional-Annotation"><a href="#BLASTP-Functional-Annotation" class="headerlink" title="BLASTP Functional Annotation"></a>BLASTP Functional Annotation</h2><p>用BLASTP检索相关数据库，四步：下载数据库，构建BLASTP索引，数据库检索，结果整理。其中结果整理需要根据BLASTP的输出格式调整。</p><p>Nr的NCBI收集的最全的蛋白序列数据库，但是无论是用NCBI的BLAST还是用速度比较快DIAMOND对nr进行搜索，没有利用好物种本身的信息。因此在RefSeq上下载对应物种的蛋白序列, 用BLASTP进行注释即可。</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-comment"># download</span><br>wget -4  -nd -np -r 1 -A *.faa.gz ftp://ftp.ncbi.nlm.nih.gov/refseq/release/plant/<br><span class="hljs-comment">#mkdir -p ~/db/RefSeq</span><br><span class="hljs-comment">#zcat *.gz &gt; ~/db/RefSeq/plant.protein.faa</span><br>zcat *.gz &gt; plant.protein.faa<br><br><span class="hljs-comment"># build index</span><br><span class="hljs-comment">#~/opt/biosoft/ncbi-blast-2.7.1+/bin/makeblastdb -in plant.protein.faa -dbtype prot -parse_seqids -title RefSeq_plant -out plant</span><br>makeblastdb -<span class="hljs-keyword">in</span> plant.protein.faa -dbtype prot -parse_seqids -title RefSeq_plant -out RefSeq_plant_blastpdb/RefSeq_plant &gt; RefSeq_plant-builddb.log 2&gt;&amp;1 &amp;<br><span class="hljs-comment">#-out database_name</span><br><span class="hljs-comment">#-title database_title</span><br><br><span class="hljs-comment"># search</span><br>~/opt/biosoft/ncbi-blast-2.7.1+/bin/blastp -query protein.fa -out RefSeq_plant_blastp.xml -db ~/db/RefSeq/uniprot_sprot.fasta -evalue 1e-5 -outfmt 5 -num_threads 50 &amp;<br></code></pre></td></tr></table></figure><p><a href="http://www.uniprot.org/downloads">Swiss-Prot</a>里收集了目前可信度最高的蛋白序列，一共有55w条记录，数据量较小</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-comment"># download</span><br><span class="hljs-comment">#wget -4 -q ftp://ftp.uniprot.org/pub/databases/uniprot/current_release/knowledgebase/complete/uniprot_sprot.fasta.gz</span><br>gzip -d uniprot_sprot.fasta.gz<br><span class="hljs-comment"># builid index</span><br><span class="hljs-comment">#~/opt/biosoft/ncbi-blast-2.7.1+/bin/makeblastdb -in uniprot_sprot.fasta -dbtype prot -title swiss_prot -parse_seqids</span><br>makeblastdb -<span class="hljs-keyword">in</span> uniprot-reviewed_yes.fasta -dbtype prot -title swiss_prot -parse_seqids -out swiss_prot_blastpdb/swiss_prot &gt; uniprot-swiss-builddb.log 2&gt;&amp;1 &amp;<br><br><span class="hljs-comment"># search</span><br>~/opt/biosoft/ncbi-blast-2.7.1+/bin/blastp -query protein.fa -out swiss_prot.xml -db ~/db/swiss_prot/uniprot_sprot.fasta -evalue 1e-5 -outfmt 5 -num_threads 50 &amp;<br></code></pre></td></tr></table></figure><p>关于结果整理，已经有很多人写了脚本，比如说我搜索BLAST XML to tab，找到<a href="https://github.com/peterjc/galaxy_blast/blob/master/tools/ncbi_blast_plus/blastxml_to_tabular.py">https://github.com/peterjc/galaxy_blast/blob/master/tools/ncbi_blast_plus/blastxml_to_tabular.py</a></p><h2 id="BLAST-输出"><a href="#BLAST-输出" class="headerlink" title="BLAST 输出"></a>BLAST 输出</h2><h3 id="1-pairwise格式"><a href="#1-pairwise格式" class="headerlink" title="1. pairwise格式"></a>1. pairwise格式</h3><p>默认，会输出查询序列ID；库序列概况；具体配对信息pairwise。适合query序列较少</p><h3 id="2-blast-tab-ourfmt-6"><a href="#2-blast-tab-ourfmt-6" class="headerlink" title="2. blast tab, -ourfmt 6"></a>2. blast tab, -ourfmt 6</h3><p>blast+ 一般设置输出格式为 -outfmt 6 或者 7 （后者包含表头）</p><p>可在excel中查看，以HSP（高度相似片段）为单位，比对结果不直观。</p><h3 id="3-ASN"><a href="#3-ASN" class="headerlink" title="3. ASN"></a>3. ASN</h3><p>ASN格式类似JSON，是NCBI自定义格式，存储信息全面，可直接使用Blast软件转换为其他格式。</p><h3 id="4-XML"><a href="#4-XML" class="headerlink" title="4. XML"></a>4. XML</h3><ul><li>相比于Pairwise和ASN，XML更容易使用程序解析</li><li>相比于Tab，XML信息更全面</li></ul><blockquote><p>序列少建议Pairwise，其他建议XML？</p></blockquote><h3 id="5-XML转化BLAST-Tab"><a href="#5-XML转化BLAST-Tab" class="headerlink" title="5. XML转化BLAST Tab"></a>5. XML转化BLAST Tab</h3><p>TBtools</p><h3 id="6-scripts"><a href="#6-scripts" class="headerlink" title="6. scripts"></a>6. scripts</h3><p>blast xml to table</p><p><a href="https://github.com/peterjc/galaxy_blast/tree/master/tools">https://github.com/peterjc/galaxy_blast/tree/master/tools</a>  58stars</p><p><a href="https://github.com/peterjc/galaxy_blast/blob/master/tools/ncbi_blast_plus/blastxml_to_tabular.py">https://github.com/peterjc/galaxy_blast/blob/master/tools/ncbi_blast_plus/blastxml_to_tabular.py</a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br><span class="line">335</span><br><span class="line">336</span><br><span class="line">337</span><br><span class="line">338</span><br><span class="line">339</span><br><span class="line">340</span><br><span class="line">341</span><br><span class="line">342</span><br><span class="line">343</span><br><span class="line">344</span><br><span class="line">345</span><br><span class="line">346</span><br><span class="line">347</span><br><span class="line">348</span><br><span class="line">349</span><br><span class="line">350</span><br><span class="line">351</span><br><span class="line">352</span><br><span class="line">353</span><br><span class="line">354</span><br><span class="line">355</span><br><span class="line">356</span><br><span class="line">357</span><br><span class="line">358</span><br><span class="line">359</span><br><span class="line">360</span><br><span class="line">361</span><br><span class="line">362</span><br><span class="line">363</span><br><span class="line">364</span><br><span class="line">365</span><br><span class="line">366</span><br><span class="line">367</span><br><span class="line">368</span><br><span class="line">369</span><br><span class="line">370</span><br><span class="line">371</span><br><span class="line">372</span><br><span class="line">373</span><br><span class="line">374</span><br><span class="line">375</span><br><span class="line">376</span><br><span class="line">377</span><br><span class="line">378</span><br><span class="line">379</span><br><span class="line">380</span><br><span class="line">381</span><br><span class="line">382</span><br><span class="line">383</span><br><span class="line">384</span><br><span class="line">385</span><br><span class="line">386</span><br><span class="line">387</span><br><span class="line">388</span><br><span class="line">389</span><br><span class="line">390</span><br><span class="line">391</span><br><span class="line">392</span><br><span class="line">393</span><br><span class="line">394</span><br><span class="line">395</span><br><span class="line">396</span><br><span class="line">397</span><br><span class="line">398</span><br><span class="line">399</span><br><span class="line">400</span><br><span class="line">401</span><br><span class="line">402</span><br><span class="line">403</span><br><span class="line">404</span><br><span class="line">405</span><br><span class="line">406</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#!/usr/bin/env python</span><br><span class="hljs-string">&quot;&quot;&quot;Convert a BLAST XML file to tabular output.</span><br><span class="hljs-string">Designed to convert BLAST XML files into tabular BLAST output (either</span><br><span class="hljs-string">std for standard 12 columns, or ext for the extended 25 columns offered</span><br><span class="hljs-string">in the Galaxy BLAST+ wrappers).</span><br><span class="hljs-string">The 12 columns output are &#x27;qseqid sseqid pident length mismatch gapopen qstart</span><br><span class="hljs-string">qend sstart send evalue bitscore&#x27; or &#x27;std&#x27; at the BLAST+ command line, which</span><br><span class="hljs-string">mean:</span><br><span class="hljs-string">====== ========= ============================================</span><br><span class="hljs-string">Column NCBI name Description</span><br><span class="hljs-string">------ --------- --------------------------------------------</span><br><span class="hljs-string">     1 qseqid    Query Seq-id (ID of your sequence)</span><br><span class="hljs-string">     2 sseqid    Subject Seq-id (ID of the database hit)</span><br><span class="hljs-string">     3 pident    Percentage of identical matches</span><br><span class="hljs-string">     4 length    Alignment length</span><br><span class="hljs-string">     5 mismatch  Number of mismatches</span><br><span class="hljs-string">     6 gapopen   Number of gap openings</span><br><span class="hljs-string">     7 qstart    Start of alignment in query</span><br><span class="hljs-string">     8 qend      End of alignment in query</span><br><span class="hljs-string">     9 sstart    Start of alignment in subject (database hit)</span><br><span class="hljs-string">    10 send      End of alignment in subject (database hit)</span><br><span class="hljs-string">    11 evalue    Expectation value (E-value)</span><br><span class="hljs-string">    12 bitscore  Bit score</span><br><span class="hljs-string">====== ========= ============================================</span><br><span class="hljs-string">The additional columns offered in the Galaxy BLAST+ wrappers are:</span><br><span class="hljs-string">====== ============= ===========================================</span><br><span class="hljs-string">Column NCBI name     Description</span><br><span class="hljs-string">------ ------------- -------------------------------------------</span><br><span class="hljs-string">    13 sallseqid     All subject Seq-id(s), separated by &#x27;;&#x27;</span><br><span class="hljs-string">    14 score         Raw score</span><br><span class="hljs-string">    15 nident        Number of identical matches</span><br><span class="hljs-string">    16 positive      Number of positive-scoring matches</span><br><span class="hljs-string">    17 gaps          Total number of gaps</span><br><span class="hljs-string">    18 ppos          Percentage of positive-scoring matches</span><br><span class="hljs-string">    19 qframe        Query frame</span><br><span class="hljs-string">    20 sframe        Subject frame</span><br><span class="hljs-string">    21 qseq          Aligned part of query sequence</span><br><span class="hljs-string">    22 sseq          Aligned part of subject sequence</span><br><span class="hljs-string">    23 qlen          Query sequence length</span><br><span class="hljs-string">    24 slen          Subject sequence length</span><br><span class="hljs-string">    25 salltitles    All subject titles, separated by &#x27;&amp;lt;&amp;gt;&#x27;</span><br><span class="hljs-string">====== ============= ===========================================</span><br><span class="hljs-string">Most of these fields are given explicitly in the XML file, others some like</span><br><span class="hljs-string">the percentage identity and the number of gap openings must be calculated.</span><br><span class="hljs-string">Be aware that the sequence in the extended tabular output or XML direct from</span><br><span class="hljs-string">BLAST+ may or may not use XXXX masking on regions of low complexity. This</span><br><span class="hljs-string">can throw the off the calculation of percentage identity and gap openings.</span><br><span class="hljs-string">[In fact, both BLAST 2.2.24+ and 2.2.25+ have a subtle bug in this regard,</span><br><span class="hljs-string">with these numbers changing depending on whether or not the low complexity</span><br><span class="hljs-string">filter is used.]</span><br><span class="hljs-string">This script attempts to produce identical output to what BLAST+ would have done.</span><br><span class="hljs-string">However, check this with &quot;diff -b ...&quot; since BLAST+ sometimes includes an extra</span><br><span class="hljs-string">space character (probably a bug).</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br><br><span class="hljs-keyword">from</span> __future__ <span class="hljs-keyword">import</span> print_function<br><br><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">import</span> re<br><span class="hljs-keyword">import</span> sys<br><br><span class="hljs-keyword">from</span> optparse <span class="hljs-keyword">import</span> OptionParser<br><br><span class="hljs-keyword">if</span> <span class="hljs-string">&quot;-v&quot;</span> <span class="hljs-keyword">in</span> sys.argv <span class="hljs-keyword">or</span> <span class="hljs-string">&quot;--version&quot;</span> <span class="hljs-keyword">in</span> sys.argv:<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;v0.2.01&quot;</span>)<br>    sys.exit(<span class="hljs-number">0</span>)<br><br><span class="hljs-keyword">if</span> sys.version_info[:<span class="hljs-number">2</span>] &gt;= (<span class="hljs-number">2</span>, <span class="hljs-number">5</span>):<br>    <span class="hljs-keyword">try</span>:<br>        <span class="hljs-keyword">from</span> xml.etree <span class="hljs-keyword">import</span> cElementTree <span class="hljs-keyword">as</span> ElementTree<br>    <span class="hljs-keyword">except</span> ImportError:<br>        <span class="hljs-keyword">from</span> xml.etree <span class="hljs-keyword">import</span> ElementTree <span class="hljs-keyword">as</span> ElementTree<br><span class="hljs-keyword">else</span>:<br>    <span class="hljs-keyword">from</span> galaxy <span class="hljs-keyword">import</span> eggs  <span class="hljs-comment"># noqa - ignore flake8 F401</span><br>    <span class="hljs-keyword">import</span> pkg_resources<br><br>    pkg_resources.require(<span class="hljs-string">&quot;elementtree&quot;</span>)<br>    <span class="hljs-keyword">from</span> elementtree <span class="hljs-keyword">import</span> ElementTree<br><br><span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(sys.argv) == <span class="hljs-number">4</span> <span class="hljs-keyword">and</span> sys.argv[<span class="hljs-number">3</span>] <span class="hljs-keyword">in</span> [<span class="hljs-string">&quot;std&quot;</span>, <span class="hljs-string">&quot;x22&quot;</span>, <span class="hljs-string">&quot;ext&quot;</span>]:<br>    <span class="hljs-comment"># False positive if user really has a BLAST XML file called &#x27;std&#x27; or &#x27;ext&#x27;...</span><br>    sys.exit(<br>        <span class="hljs-string">&quot;&quot;&quot;ERROR: The script API has changed, sorry.</span><br><span class="hljs-string">Instead of the old style:</span><br><span class="hljs-string">$ python blastxml_to_tabular.py input.xml output.tabular std</span><br><span class="hljs-string">Please use:</span><br><span class="hljs-string">$ python blastxml_to_tabular.py -o output.tabular -c std input.xml</span><br><span class="hljs-string">For more information, use:</span><br><span class="hljs-string">$ python blastxml_to_tabular.py -h</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br>    )<br><br>usage = <span class="hljs-string">&quot;&quot;&quot;usage: %prog [options] blastxml[,...]</span><br><span class="hljs-string">Convert one (or more) BLAST XML files into a single tabular file.</span><br><span class="hljs-string">The columns option can be &#x27;std&#x27; (standard 12 columns), &#x27;ext&#x27;</span><br><span class="hljs-string">(extended 25 columns), or a list of BLAST+ column names like</span><br><span class="hljs-string">&#x27;qseqid,sseqid,pident&#x27; (space or comma separated).</span><br><span class="hljs-string">Note if using a list of column names, currently ONLY the 25</span><br><span class="hljs-string">extended column names are supported.</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br>parser = OptionParser(usage=usage)<br>parser.add_option(<br>    <span class="hljs-string">&quot;-o&quot;</span>,<br>    <span class="hljs-string">&quot;--output&quot;</span>,<br>    dest=<span class="hljs-string">&quot;output&quot;</span>,<br>    default=<span class="hljs-literal">None</span>,<br>    <span class="hljs-built_in">help</span>=<span class="hljs-string">&quot;output filename (defaults to stdout)&quot;</span>,<br>    metavar=<span class="hljs-string">&quot;FILE&quot;</span>,<br>)<br>parser.add_option(<br>    <span class="hljs-string">&quot;-c&quot;</span>,<br>    <span class="hljs-string">&quot;--columns&quot;</span>,<br>    dest=<span class="hljs-string">&quot;columns&quot;</span>,<br>    default=<span class="hljs-string">&quot;std&quot;</span>,<br>    <span class="hljs-built_in">help</span>=<span class="hljs-string">&quot;[std|ext|col1,col2,...] standard 12 columns, &quot;</span><br>    <span class="hljs-string">&quot;extended 25 columns, or list of column names&quot;</span>,<br>)<br>(options, args) = parser.parse_args()<br><br>colnames = (<br>    <span class="hljs-string">&quot;qseqid,sseqid,pident,length,mismatch,gapopen,qstart,qend,&quot;</span><br>    <span class="hljs-string">&quot;sstart,send,evalue,bitscore,sallseqid,score,nident,positive,&quot;</span><br>    <span class="hljs-string">&quot;gaps,ppos,qframe,sframe,qseq,sseq,qlen,slen,salltitles&quot;</span><br>).split(<span class="hljs-string">&quot;,&quot;</span>)<br><br><span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(args) &lt; <span class="hljs-number">1</span>:<br>    sys.exit(<span class="hljs-string">&quot;ERROR: No BLASTXML input files given; run with --help to see options.&quot;</span>)<br><br>out_fmt = options.columns<br><span class="hljs-keyword">if</span> out_fmt == <span class="hljs-string">&quot;std&quot;</span>:<br>    extended = <span class="hljs-literal">False</span><br>    cols = <span class="hljs-literal">None</span><br><span class="hljs-keyword">elif</span> out_fmt == <span class="hljs-string">&quot;x22&quot;</span>:<br>    sys.exit(<span class="hljs-string">&quot;Format argument x22 has been replaced with ext (extended 25 columns)&quot;</span>)<br><span class="hljs-keyword">elif</span> out_fmt == <span class="hljs-string">&quot;ext&quot;</span>:<br>    extended = <span class="hljs-literal">True</span><br>    cols = <span class="hljs-literal">None</span><br><span class="hljs-keyword">else</span>:<br>    cols = out_fmt.replace(<span class="hljs-string">&quot; &quot;</span>, <span class="hljs-string">&quot;,&quot;</span>).split(<span class="hljs-string">&quot;,&quot;</span>)  <span class="hljs-comment"># Allow space or comma separated</span><br>    <span class="hljs-comment"># Remove any blank entries due to trailing comma,</span><br>    <span class="hljs-comment"># or annoying &quot;None&quot; dummy value from Galaxy if no columns</span><br>    cols = [c <span class="hljs-keyword">for</span> c <span class="hljs-keyword">in</span> cols <span class="hljs-keyword">if</span> c <span class="hljs-keyword">and</span> c != <span class="hljs-string">&quot;None&quot;</span>]<br>    extra = <span class="hljs-built_in">set</span>(cols).difference(colnames)<br>    <span class="hljs-keyword">if</span> extra:<br>        sys.exit(<span class="hljs-string">&quot;These are not recognised column names: %s&quot;</span> % <span class="hljs-string">&quot;,&quot;</span>.join(<span class="hljs-built_in">sorted</span>(extra)))<br>    <span class="hljs-keyword">del</span> extra<br>    <span class="hljs-keyword">assert</span> <span class="hljs-built_in">set</span>(colnames).issuperset(cols), cols<br>    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> cols:<br>        sys.exit(<span class="hljs-string">&quot;No columns selected!&quot;</span>)<br>    extended = (<br>        <span class="hljs-built_in">max</span>(colnames.index(c) <span class="hljs-keyword">for</span> c <span class="hljs-keyword">in</span> cols) &gt;= <span class="hljs-number">12</span><br>    )  <span class="hljs-comment"># Do we need any higher columns?</span><br><span class="hljs-keyword">del</span> out_fmt<br><br><span class="hljs-keyword">for</span> in_file <span class="hljs-keyword">in</span> args:<br>    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> os.path.isfile(in_file):<br>        sys.exit(<span class="hljs-string">&quot;Input BLAST XML file not found: %s&quot;</span> % in_file)<br><br><br>re_default_query_id = re.<span class="hljs-built_in">compile</span>(<span class="hljs-string">r&quot;^Query_\d+$&quot;</span>)<br><span class="hljs-keyword">assert</span> re_default_query_id.match(<span class="hljs-string">r&quot;Query_101&quot;</span>)<br><span class="hljs-keyword">assert</span> <span class="hljs-keyword">not</span> re_default_query_id.match(<span class="hljs-string">r&quot;Query_101a&quot;</span>)<br><span class="hljs-keyword">assert</span> <span class="hljs-keyword">not</span> re_default_query_id.match(<span class="hljs-string">r&quot;MyQuery_101&quot;</span>)<br>re_default_subject_id = re.<span class="hljs-built_in">compile</span>(<span class="hljs-string">r&quot;^Subject_\d+$&quot;</span>)<br><span class="hljs-keyword">assert</span> re_default_subject_id.match(<span class="hljs-string">r&quot;Subject_1&quot;</span>)<br><span class="hljs-keyword">assert</span> <span class="hljs-keyword">not</span> re_default_subject_id.match(<span class="hljs-string">r&quot;Subject_&quot;</span>)<br><span class="hljs-keyword">assert</span> <span class="hljs-keyword">not</span> re_default_subject_id.match(<span class="hljs-string">r&quot;Subject_12a&quot;</span>)<br><span class="hljs-keyword">assert</span> <span class="hljs-keyword">not</span> re_default_subject_id.match(<span class="hljs-string">r&quot;TheSubject_1&quot;</span>)<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">convert</span>(<span class="hljs-params">blastxml_filename, output_handle</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;Convert BLAST XML input from a file to tabular on given handle.&quot;&quot;&quot;</span><br>    blast_program = <span class="hljs-literal">None</span><br>    <span class="hljs-comment"># get an iterable</span><br>    <span class="hljs-keyword">try</span>:<br>        context = ElementTree.iterparse(blastxml_filename, events=(<span class="hljs-string">&quot;start&quot;</span>, <span class="hljs-string">&quot;end&quot;</span>))<br>    <span class="hljs-keyword">except</span> Exception:<br>        sys.exit(<span class="hljs-string">&quot;Invalid data format.&quot;</span>)<br>    <span class="hljs-comment"># turn it into an iterator</span><br>    context = <span class="hljs-built_in">iter</span>(context)<br>    <span class="hljs-comment"># get the root element</span><br>    <span class="hljs-keyword">try</span>:<br>        event, root = <span class="hljs-built_in">next</span>(context)<br>    <span class="hljs-keyword">except</span> Exception:<br>        sys.exit(<span class="hljs-string">&quot;Invalid data format.&quot;</span>)<br>    <span class="hljs-keyword">for</span> event, elem <span class="hljs-keyword">in</span> context:<br>        <span class="hljs-keyword">if</span> event == <span class="hljs-string">&quot;end&quot;</span> <span class="hljs-keyword">and</span> elem.tag == <span class="hljs-string">&quot;BlastOutput_program&quot;</span>:<br>            blast_program = elem.text<br>        <span class="hljs-comment"># for every &lt;Iteration&gt; tag</span><br>        <span class="hljs-keyword">if</span> event == <span class="hljs-string">&quot;end&quot;</span> <span class="hljs-keyword">and</span> elem.tag == <span class="hljs-string">&quot;Iteration&quot;</span>:<br>            <span class="hljs-comment"># Expecting either this, from BLAST 2.2.25+ using FASTA vs FASTA</span><br>            <span class="hljs-comment"># &lt;Iteration_query-ID&gt;sp|Q9BS26|ERP44_HUMAN&lt;/Iteration_query-ID&gt;</span><br>            <span class="hljs-comment"># &lt;Iteration_query-def&gt;Endoplasmic reticulum resident protein 44</span><br>            <span class="hljs-comment"># OS=Homo sapiens GN=ERP44 PE=1 SV=1&lt;/Iteration_query-def&gt;</span><br>            <span class="hljs-comment"># &lt;Iteration_query-len&gt;406&lt;/Iteration_query-len&gt;</span><br>            <span class="hljs-comment"># &lt;Iteration_hits&gt;&lt;/Iteration_hits&gt;</span><br>            <span class="hljs-comment">#</span><br>            <span class="hljs-comment"># Or, from BLAST 2.2.24+ run online</span><br>            <span class="hljs-comment"># &lt;Iteration_query-ID&gt;Query_1&lt;/Iteration_query-ID&gt;</span><br>            <span class="hljs-comment"># &lt;Iteration_query-def&gt;Sample&lt;/Iteration_query-def&gt;</span><br>            <span class="hljs-comment"># &lt;Iteration_query-len&gt;516&lt;/Iteration_query-len&gt;</span><br>            <span class="hljs-comment"># &lt;Iteration_hits&gt;...</span><br>            qseqid = elem.findtext(<span class="hljs-string">&quot;Iteration_query-ID&quot;</span>)<br>            <span class="hljs-keyword">if</span> re_default_query_id.match(qseqid):<br>                <span class="hljs-comment"># Place holder ID, take the first word of the query definition</span><br>                qseqid = elem.findtext(<span class="hljs-string">&quot;Iteration_query-def&quot;</span>).split(<span class="hljs-literal">None</span>, <span class="hljs-number">1</span>)[<span class="hljs-number">0</span>]<br>            qlen = <span class="hljs-built_in">int</span>(elem.findtext(<span class="hljs-string">&quot;Iteration_query-len&quot;</span>))<br><br>            <span class="hljs-comment"># for every &lt;Hit&gt; within &lt;Iteration&gt;</span><br>            <span class="hljs-keyword">for</span> hit <span class="hljs-keyword">in</span> elem.findall(<span class="hljs-string">&quot;Iteration_hits/Hit&quot;</span>):<br>                <span class="hljs-comment"># Expecting either this,</span><br>                <span class="hljs-comment"># &lt;Hit_id&gt;gi|3024260|sp|P56514.1|OPSD_BUFBU&lt;/Hit_id&gt;</span><br>                <span class="hljs-comment"># &lt;Hit_def&gt;RecName: Full=Rhodopsin&lt;/Hit_def&gt;</span><br>                <span class="hljs-comment"># &lt;Hit_accession&gt;P56514&lt;/Hit_accession&gt;</span><br>                <span class="hljs-comment"># or,</span><br>                <span class="hljs-comment"># &lt;Hit_id&gt;Subject_1&lt;/Hit_id&gt;</span><br>                <span class="hljs-comment"># &lt;Hit_def&gt;gi|57163783|ref|NP_001009242.1|</span><br>                <span class="hljs-comment"># rhodopsin [Felis catus]&lt;/Hit_def&gt;</span><br>                <span class="hljs-comment"># &lt;Hit_accession&gt;Subject_1&lt;/Hit_accession&gt;</span><br>                <span class="hljs-comment">#</span><br>                <span class="hljs-comment"># apparently depending on the parse_deflines switch</span><br>                <span class="hljs-comment">#</span><br>                <span class="hljs-comment"># Or, with a local database not using -parse_seqids can get this,</span><br>                <span class="hljs-comment"># &lt;Hit_id&gt;gnl|BL_ORD_ID|2&lt;/Hit_id&gt;</span><br>                <span class="hljs-comment"># &lt;Hit_def&gt;chrIII gi|240255695|ref|NC_003074.8| Arabidopsis</span><br>                <span class="hljs-comment"># thaliana chromosome 3, complete sequence&lt;/Hit_def&gt;</span><br>                <span class="hljs-comment"># &lt;Hit_accession&gt;2&lt;/Hit_accession&gt;</span><br>                sseqid = hit.findtext(<span class="hljs-string">&quot;Hit_id&quot;</span>).split(<span class="hljs-literal">None</span>, <span class="hljs-number">1</span>)[<span class="hljs-number">0</span>]<br>                hit_def = sseqid + <span class="hljs-string">&quot; &quot;</span> + hit.findtext(<span class="hljs-string">&quot;Hit_def&quot;</span>)<br>                <span class="hljs-keyword">if</span> re_default_subject_id.match(sseqid) <span class="hljs-keyword">and</span> sseqid == hit.findtext(<br>                    <span class="hljs-string">&quot;Hit_accession&quot;</span><br>                ):<br>                    <span class="hljs-comment"># Place holder ID, take the first word of the subject definition</span><br>                    hit_def = hit.findtext(<span class="hljs-string">&quot;Hit_def&quot;</span>)<br>                    sseqid = hit_def.split(<span class="hljs-literal">None</span>, <span class="hljs-number">1</span>)[<span class="hljs-number">0</span>]<br>                <span class="hljs-keyword">if</span> sseqid.startswith(<br>                    <span class="hljs-string">&quot;gnl|BL_ORD_ID|&quot;</span><br>                ) <span class="hljs-keyword">and</span> sseqid == <span class="hljs-string">&quot;gnl|BL_ORD_ID|&quot;</span> + hit.findtext(<span class="hljs-string">&quot;Hit_accession&quot;</span>):<br>                    <span class="hljs-comment"># Alternative place holder ID, again take the first word of hit_def</span><br>                    hit_def = hit.findtext(<span class="hljs-string">&quot;Hit_def&quot;</span>)<br>                    sseqid = hit_def.split(<span class="hljs-literal">None</span>, <span class="hljs-number">1</span>)[<span class="hljs-number">0</span>]<br>                <span class="hljs-comment"># for every &lt;Hsp&gt; within &lt;Hit&gt;</span><br>                <span class="hljs-keyword">for</span> hsp <span class="hljs-keyword">in</span> hit.findall(<span class="hljs-string">&quot;Hit_hsps/Hsp&quot;</span>):<br>                    nident = hsp.findtext(<span class="hljs-string">&quot;Hsp_identity&quot;</span>)<br>                    length = hsp.findtext(<span class="hljs-string">&quot;Hsp_align-len&quot;</span>)<br>                    <span class="hljs-comment"># As of NCBI BLAST+ 2.4.0 this is given to 3dp (not 2dp)</span><br>                    pident = <span class="hljs-string">&quot;%0.3f&quot;</span> % (<span class="hljs-number">100</span> * <span class="hljs-built_in">float</span>(nident) / <span class="hljs-built_in">float</span>(length))<br><br>                    q_seq = hsp.findtext(<span class="hljs-string">&quot;Hsp_qseq&quot;</span>)<br>                    h_seq = hsp.findtext(<span class="hljs-string">&quot;Hsp_hseq&quot;</span>)<br>                    m_seq = hsp.findtext(<span class="hljs-string">&quot;Hsp_midline&quot;</span>)<br>                    <span class="hljs-keyword">assert</span> <span class="hljs-built_in">len</span>(q_seq) == <span class="hljs-built_in">len</span>(h_seq) == <span class="hljs-built_in">len</span>(m_seq) == <span class="hljs-built_in">int</span>(length)<br>                    gapopen = <span class="hljs-built_in">str</span>(<br>                        <span class="hljs-built_in">len</span>(q_seq.replace(<span class="hljs-string">&quot;-&quot;</span>, <span class="hljs-string">&quot; &quot;</span>).split())<br>                        - <span class="hljs-number">1</span><br>                        + <span class="hljs-built_in">len</span>(h_seq.replace(<span class="hljs-string">&quot;-&quot;</span>, <span class="hljs-string">&quot; &quot;</span>).split())<br>                        - <span class="hljs-number">1</span><br>                    )<br><br>                    mismatch = (<br>                        m_seq.count(<span class="hljs-string">&quot; &quot;</span>)<br>                        + m_seq.count(<span class="hljs-string">&quot;+&quot;</span>)<br>                        - q_seq.count(<span class="hljs-string">&quot;-&quot;</span>)<br>                        - h_seq.count(<span class="hljs-string">&quot;-&quot;</span>)<br>                    )<br>                    <span class="hljs-comment"># TODO - Remove this alternative mismatch calculation and test</span><br>                    <span class="hljs-comment"># once satisifed there are no problems</span><br>                    expected_mismatch = <span class="hljs-built_in">len</span>(q_seq) - <span class="hljs-built_in">sum</span>(<br>                        <span class="hljs-number">1</span><br>                        <span class="hljs-keyword">for</span> q, h <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(q_seq, h_seq)<br>                        <span class="hljs-keyword">if</span> q == h <span class="hljs-keyword">or</span> q == <span class="hljs-string">&quot;-&quot;</span> <span class="hljs-keyword">or</span> h == <span class="hljs-string">&quot;-&quot;</span><br>                    )<br>                    xx = <span class="hljs-built_in">sum</span>(<span class="hljs-number">1</span> <span class="hljs-keyword">for</span> q, h <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(q_seq, h_seq) <span class="hljs-keyword">if</span> q == <span class="hljs-string">&quot;X&quot;</span> <span class="hljs-keyword">and</span> h == <span class="hljs-string">&quot;X&quot;</span>)<br>                    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> (<br>                        expected_mismatch - q_seq.count(<span class="hljs-string">&quot;X&quot;</span>)<br>                        &lt;= <span class="hljs-built_in">int</span>(mismatch)<br>                        &lt;= expected_mismatch + xx<br>                    ):<br>                        sys.exit(<br>                            <span class="hljs-string">&quot;%s vs %s mismatches, expected %i &lt;= %i &lt;= %i&quot;</span><br>                            % (<br>                                qseqid,<br>                                sseqid,<br>                                expected_mismatch - q_seq.count(<span class="hljs-string">&quot;X&quot;</span>),<br>                                <span class="hljs-built_in">int</span>(mismatch),<br>                                expected_mismatch,<br>                            )<br>                        )<br><br>                    <span class="hljs-comment"># TODO - Remove this alternative identity calculation and test</span><br>                    <span class="hljs-comment"># once satisifed there are no problems</span><br>                    expected_identity = <span class="hljs-built_in">sum</span>(<span class="hljs-number">1</span> <span class="hljs-keyword">for</span> q, h <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(q_seq, h_seq) <span class="hljs-keyword">if</span> q == h)<br>                    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> (<br>                        expected_identity - xx<br>                        &lt;= <span class="hljs-built_in">int</span>(nident)<br>                        &lt;= expected_identity + q_seq.count(<span class="hljs-string">&quot;X&quot;</span>)<br>                    ):<br>                        sys.exit(<br>                            <span class="hljs-string">&quot;%s vs %s identities, expected %i &lt;= %i &lt;= %i&quot;</span><br>                            % (<br>                                qseqid,<br>                                sseqid,<br>                                expected_identity,<br>                                <span class="hljs-built_in">int</span>(nident),<br>                                expected_identity + q_seq.count(<span class="hljs-string">&quot;X&quot;</span>),<br>                            )<br>                        )<br><br>                    evalue = hsp.findtext(<span class="hljs-string">&quot;Hsp_evalue&quot;</span>)<br>                    <span class="hljs-keyword">if</span> evalue == <span class="hljs-string">&quot;0&quot;</span>:<br>                        evalue = <span class="hljs-string">&quot;0.0&quot;</span><br>                    <span class="hljs-keyword">else</span>:<br>                        evalue = <span class="hljs-string">&quot;%0.0e&quot;</span> % <span class="hljs-built_in">float</span>(evalue)<br><br>                    bitscore = <span class="hljs-built_in">float</span>(hsp.findtext(<span class="hljs-string">&quot;Hsp_bit-score&quot;</span>))<br>                    <span class="hljs-keyword">if</span> bitscore &lt; <span class="hljs-number">100</span>:<br>                        <span class="hljs-comment"># Seems to show one decimal place for lower scores</span><br>                        bitscore = <span class="hljs-string">&quot;%0.1f&quot;</span> % bitscore<br>                    <span class="hljs-keyword">else</span>:<br>                        <span class="hljs-comment"># Note BLAST does not round to nearest int, it truncates</span><br>                        bitscore = <span class="hljs-string">&quot;%i&quot;</span> % bitscore<br><br>                    values = [<br>                        qseqid,<br>                        sseqid,<br>                        pident,<br>                        length,  <span class="hljs-comment"># hsp.findtext(&quot;Hsp_align-len&quot;)</span><br>                        <span class="hljs-built_in">str</span>(mismatch),<br>                        gapopen,<br>                        hsp.findtext(<span class="hljs-string">&quot;Hsp_query-from&quot;</span>),  <span class="hljs-comment"># qstart,</span><br>                        hsp.findtext(<span class="hljs-string">&quot;Hsp_query-to&quot;</span>),  <span class="hljs-comment"># qend,</span><br>                        hsp.findtext(<span class="hljs-string">&quot;Hsp_hit-from&quot;</span>),  <span class="hljs-comment"># sstart,</span><br>                        hsp.findtext(<span class="hljs-string">&quot;Hsp_hit-to&quot;</span>),  <span class="hljs-comment"># send,</span><br>                        evalue,  <span class="hljs-comment"># hsp.findtext(&quot;Hsp_evalue&quot;) in scientific notation</span><br>                        bitscore,  <span class="hljs-comment"># hsp.findtext(&quot;Hsp_bit-score&quot;) rounded</span><br>                    ]<br><br>                    <span class="hljs-keyword">if</span> extended:<br>                        <span class="hljs-keyword">try</span>:<br>                            sallseqid = <span class="hljs-string">&quot;;&quot;</span>.join(<br>                                name.split(<span class="hljs-literal">None</span>, <span class="hljs-number">1</span>)[<span class="hljs-number">0</span>] <span class="hljs-keyword">for</span> name <span class="hljs-keyword">in</span> hit_def.split(<span class="hljs-string">&quot; &gt;&quot;</span>)<br>                            )<br>                            salltitles = <span class="hljs-string">&quot;&lt;&gt;&quot;</span>.join(<br>                                name.split(<span class="hljs-literal">None</span>, <span class="hljs-number">1</span>)[<span class="hljs-number">1</span>] <span class="hljs-keyword">for</span> name <span class="hljs-keyword">in</span> hit_def.split(<span class="hljs-string">&quot; &gt;&quot;</span>)<br>                            )<br>                        <span class="hljs-keyword">except</span> IndexError <span class="hljs-keyword">as</span> e:<br>                            sys.exit(<br>                                <span class="hljs-string">&quot;Problem splitting multuple hits?\n%r\n--&gt; %s&quot;</span><br>                                % (hit_def, e)<br>                            )<br>                        <span class="hljs-comment"># print(hit_def, &quot;--&gt;&quot;, sallseqid)</span><br>                        positive = hsp.findtext(<span class="hljs-string">&quot;Hsp_positive&quot;</span>)<br>                        ppos = <span class="hljs-string">&quot;%0.2f&quot;</span> % (<span class="hljs-number">100</span> * <span class="hljs-built_in">float</span>(positive) / <span class="hljs-built_in">float</span>(length))<br>                        qframe = hsp.findtext(<span class="hljs-string">&quot;Hsp_query-frame&quot;</span>)<br>                        sframe = hsp.findtext(<span class="hljs-string">&quot;Hsp_hit-frame&quot;</span>)<br>                        <span class="hljs-keyword">if</span> blast_program == <span class="hljs-string">&quot;blastp&quot;</span>:<br>                            <span class="hljs-comment"># Probably a bug in BLASTP that they use 0 or 1</span><br>                            <span class="hljs-comment"># depending on format</span><br>                            <span class="hljs-keyword">if</span> qframe == <span class="hljs-string">&quot;0&quot;</span>:<br>                                qframe = <span class="hljs-string">&quot;1&quot;</span><br>                            <span class="hljs-keyword">if</span> sframe == <span class="hljs-string">&quot;0&quot;</span>:<br>                                sframe = <span class="hljs-string">&quot;1&quot;</span><br>                        slen = <span class="hljs-built_in">int</span>(hit.findtext(<span class="hljs-string">&quot;Hit_len&quot;</span>))<br>                        values.extend(<br>                            [<br>                                sallseqid,<br>                                hsp.findtext(<span class="hljs-string">&quot;Hsp_score&quot;</span>),  <span class="hljs-comment"># score,</span><br>                                nident,<br>                                positive,<br>                                hsp.findtext(<span class="hljs-string">&quot;Hsp_gaps&quot;</span>),  <span class="hljs-comment"># gaps,</span><br>                                ppos,<br>                                qframe,<br>                                sframe,<br>                                <span class="hljs-comment"># NOTE - for blastp, XML shows original seq,</span><br>                                <span class="hljs-comment"># tabular uses XXX masking</span><br>                                q_seq,<br>                                h_seq,<br>                                <span class="hljs-built_in">str</span>(qlen),<br>                                <span class="hljs-built_in">str</span>(slen),<br>                                salltitles,<br>                            ]<br>                        )<br>                    <span class="hljs-keyword">if</span> cols:<br>                        <span class="hljs-comment"># Only a subset of the columns are needed</span><br>                        values = [values[colnames.index(c)] <span class="hljs-keyword">for</span> c <span class="hljs-keyword">in</span> cols]<br>                    <span class="hljs-comment"># print(&quot;\t&quot;.join(values))</span><br>                    output_handle.write(<span class="hljs-string">&quot;\t&quot;</span>.join(values) + <span class="hljs-string">&quot;\n&quot;</span>)<br>            <span class="hljs-comment"># prevents ElementTree from growing large datastructure</span><br>            root.clear()<br>            elem.clear()<br><br><br><span class="hljs-keyword">if</span> options.output:<br>    outfile = <span class="hljs-built_in">open</span>(options.output, <span class="hljs-string">&quot;w&quot;</span>)<br><span class="hljs-keyword">else</span>:<br>    outfile = sys.stdout<br><br><span class="hljs-keyword">for</span> in_file <span class="hljs-keyword">in</span> args:<br>    blast_program = <span class="hljs-literal">None</span><br>    convert(in_file, outfile)<br><br><span class="hljs-keyword">if</span> options.output:<br>    outfile.close()<br><span class="hljs-keyword">else</span>:<br>    <span class="hljs-comment"># Using stdout</span><br>    <span class="hljs-keyword">pass</span><br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>Software</category>
      
    </categories>
    
    
    <tags>
      
      <tag>FuncAnno</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【FuncAnno】【eggNOG-mapper】</title>
    <link href="/GeekFocus/2022/06/05/2022-06-05-FuncAnno-eggNOG/"/>
    <url>/GeekFocus/2022/06/05/2022-06-05-FuncAnno-eggNOG/</url>
    
    <content type="html"><![CDATA[<p>eggNOG(evolutionary genealogy of genes: Non-supervised Orthologous Groups)</p><span id="more"></span><h1 id="Install"><a href="#Install" class="headerlink" title="Install"></a>Install</h1><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs sh">github download<br>Download error on https://pypi.org/simple/: [Errno -3] Temporary failure <span class="hljs-keyword">in</span> name resolution -- Some packages may not be found!<br>No <span class="hljs-built_in">local</span> packages or working download links found <span class="hljs-keyword">for</span> xlsxwriter==1.4.3<br>error: Could not find suitable distribution <span class="hljs-keyword">for</span> Requirement.parse(<span class="hljs-string">&#x27;xlsxwriter==1.4.3&#x27;</span>)<br><br>loginal1 (loginal2 no internet)<br><span class="hljs-comment">#pip install xlsxwriter failed</span><br>pip install xlsxwriter==1.4.3<br>eggnog-mapper 2.1.7 requires biopython==1.76, <span class="hljs-built_in">which</span> is not installed.<br>eggnog-mapper 2.1.7 requires psutil==5.7.0, but you have psutil 5.8.0 <span class="hljs-built_in">which</span> is incompatible.<br><br>error: Could not find suitable distribution <span class="hljs-keyword">for</span> Requirement.parse(<span class="hljs-string">&#x27;psutil==5.7.0&#x27;</span>)<br>pip install psutil==5.7.0<br>pip install biopython==1.76<br><br>fat<br>python setup.py install<br>Using /xtdisk/xueyb_group/wangchenA/miniconda3/lib/python3.9/site-packages<br>Finished processing dependencies <span class="hljs-keyword">for</span> eggnog-mapper==2.1.7<br><br>download db <br>http://eggnog5.embl.de/download/emapperdb-5.0.2/<br>http://eggnog5.embl.de/<span class="hljs-comment">#/app/downloads</span><br><span class="hljs-built_in">mv</span> to data<br>unzip<br><br><span class="hljs-built_in">export</span> PATH=/home/user/eggnog-mapper:/home/user/eggnog-mapper/eggnogmapper/bin:<span class="hljs-string">&quot;<span class="hljs-variable">$PATH</span>&quot;</span><br><span class="hljs-built_in">export</span> EGGNOG_DATA_DIR=/home/user/eggnog-mapper-data<br></code></pre></td></tr></table></figure><h1 id="github"><a href="#github" class="headerlink" title="github"></a>github</h1><h2 id="eggNOG-mapper-v2-1-5-to-v2-1-7"><a href="#eggNOG-mapper-v2-1-5-to-v2-1-7" class="headerlink" title="eggNOG mapper v2.1.5 to v2.1.7"></a>eggNOG mapper v2.1.5 to v2.1.7</h2><p><a href="https://github.com/eggnogdb/eggnog-mapper/wiki/eggNOG-mapper-v2.1.5-to-v2.1.7#Installation">https://github.com/eggnogdb/eggnog-mapper/wiki/eggNOG-mapper-v2.1.5-to-v2.1.7#Installation</a></p><p>overview</p><p><strong>EggNOG-mapper</strong> (a.k.a. <code>emapper.py</code> ) is a tool for fast functional annotation of novel sequences. It uses <font color="blue">precomputed orthologous groups (OGs)</font> and <font color="blue">phylogenies</font> from the <font color="blue">eggNOG db</font> (<a href="http://eggnogdb.embl.de/">http://eggnogdb.embl.de/</a>) to transfer functional information from fine-grained orthologs only. </p><p>Common uses of eggNOG-mapper include the annotation of <strong>novel genomes</strong>, <strong>transcriptomes</strong> or even <strong>metagenomic</strong> gene catalogs. </p><p>The use of orthology predictions for functional annotation permits a <font color="blue">higher precision[fewer results]</font> than <font color="blue">traditional homology searches</font> (i.e. BLAST searches), as it avoids transferring annotations from close paralogs (duplicate genes with a higher chance of being involved in functional divergence). </p><p>Benchmarks comparing <font color="red"><strong>different</strong></font> eggNOG-mapper options against <font color="red"><strong>BLAST and InterProScan</strong></font> are available at <a href="https://github.com/jhcepas/emapper-benchmark/blob/master/benchmark_analysis.ipynb">https://github.com/jhcepas/emapper-benchmark/blob/master/benchmark_analysis.ipynb</a>. </p><p>EggNOG-mapper is also available as a public online resource: <a href="http://eggnog-mapper.embl.de/">http://eggnog-mapper.embl.de</a></p><h2 id="storage-requirements"><a href="#storage-requirements" class="headerlink" title="storage requirements"></a>storage requirements</h2><ul><li>~40 GB for the eggNOG annotation databases (<em>eggnog.db</em> and <em>eggnog.taxa.db</em>)</li><li>~9 GB for Diamond database of eggNOG sequences (required if using <font color="red"><strong>-m diamond, which is the default search mode</strong></font>).</li><li><del>11 GB for MMseqs2 database of eggNOG sequences (</del>86 GB if MMseqs2 index is created) (required if using <code>-m mmseqs</code>).</li><li>~3 GB for PFAM database (required if using <code>--pfam_realign</code> options for realignment of queries to <font color="red">PFAM domains</font>).</li><li>The size of eggNOG diamond&#x2F;mmseqs databases created with <code>create_dbs.py</code> is highly variable, depending on the size of the chosen taxonomic groups.</li></ul><p>Databases for specific taxonomic ranges can be downloaded (for HMMER) or created (for Diamond and MMseqs2). The size of these databases is highly variable. For the size of HMMER databases, check <a href="http://eggnog5.embl.de/#/app/downloads">http://eggnog5.embl.de/#/app/downloads</a>. For Diamond and MMseqs2 databases, DB size will depend on the number of proteins which are from those taxonomic ranges. Also, these proteins need to be downloaded to create the databases, and can be removed afterwards.</p><h2 id="download-eggnog-data-py"><a href="#download-eggnog-data-py" class="headerlink" title="download_eggnog_data.py"></a>download_eggnog_data.py</h2><ul><li>The <code>-P</code> flag is required to download the PFAM database. you may wish to download the PFAM database to be able to run PFAM realignemnts with <code>--pfam_realign realign</code> or <code>--pfam_realign denovo</code>.</li><li>The <code>-M</code> flag is required to download the MMseqs2 database. The whole MMseqs2 database includes eggNOG proteins which do not belong to any eggNOG Orthologous Group (OG), whereas the Diamond database only includes those which belong to an OG. Also, note that no MMseqs2 index is provided. To create it, you could use the <code>mmseqs createindex &quot;$EGGNOG_DATA_DIR&quot;/mmseqs tmp</code> command (see <a href="https://mmseqs.com/latest/userguide.pdf">https://mmseqs.com/latest/userguide.pdf</a> for more details).</li><li>The <code>-H -d taxID</code> flag is required to download a HMMER database for a given <em>taxID</em> (check list of databases at <a href="http://eggnog5.embl.de/#/app/downloads">http://eggnog5.embl.de/#/app/downloads</a>).</li></ul><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs sh">./download_eggnog_data.py -H -d euk<br>Skipping eggnog.db database (already present). Use -f to force download<br>Skipping eggnog.taxa.db database (already present). Use -f to force download<br>Skipping diamond database (or already present). Use -f to force download<br>Skipping Pfam database (or already present). Use -P and -f to force download<br>Skipping MMseqs2 database (or already present). Use -M and -f to force download<br>Download HMMER database of tax ID euk? [y,n] <br><br></code></pre></td></tr></table></figure><h2 id="option-tools"><a href="#option-tools" class="headerlink" title="option tools"></a>option tools</h2><p>all of them are actually included, bundled, along with eggNOG-mapper. </p><ul><li>Prodigal: required if using <code>--itype genome</code> or <code>--itype metagenome</code> along with the option <code>--genepred prodigal</code>. Current bundled version is V2.6.3: February, 2016.</li><li>Diamond: required to run the search steps with <code>-m diamond</code>. Current bundled version is 2.0.11.</li><li>MMseqs2: required to run the search steps with <code>-m mmseqs</code>. </li><li>HMMER: required to run the search steps with <code>-m hmmer</code>, to run the HMMER based scripts (<code>hmm_mapper.py</code>, <code>hmm_server.py</code>, <code>hmm_worker.py</code>), and to perform realignments to PFAM with <code>--pfam_realign realign</code> or <code>--pfam_realign denovo</code>. Current bundled version is HMMER 3.1b2 (February 2015).</li></ul><p>first search in PATH, then use bundled ones.</p><h2 id="Basic-usage"><a href="#Basic-usage" class="headerlink" title="Basic usage"></a>Basic usage</h2><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sh">emapper.py -i FASTA_FILE_PROTEINS -o <span class="hljs-built_in">test</span><br></code></pre></td></tr></table></figure><p>This basic example will run a <font color="red"><strong>diamond blastp search</strong></font>, and for those queries with hits to eggNOG proteins, will carry out functional annotation.</p><p>- Run <font color="blue">search and annotation</font>, using <font color="blue">Diamond in blastx</font> mode</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs stylus">emapper<span class="hljs-selector-class">.py</span> -m diamond <span class="hljs-attr">--itype</span> CDS -<span class="hljs-selector-tag">i</span> FASTA_FILE_NTS -o test<br></code></pre></td></tr></table></figure><p>- Run<font color="blue"> search and annotation</font>, using <font color="blue">MMseqs after translating input CDS to proteins</font>. Add the search and annotation results to the attributes of an existing GFF file (<em>GFF decoration</em>), using the <em>GeneID</em> field to link features from the GFF to the annotation results.</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs stylus">emapper<span class="hljs-selector-class">.py</span> -m mmseqs <span class="hljs-attr">--itype</span> CDS <span class="hljs-attr">--translate</span> -<span class="hljs-selector-tag">i</span> FASTA_FILE_CDS -o test \<br><span class="hljs-attr">--decorate_gff</span> MY_GFF_FILE <span class="hljs-attr">--decorate_gff_ID_field</span> GeneID<br></code></pre></td></tr></table></figure><p>- Run <strong>search</strong> and <strong>annotation</strong> for <strong>assembled contigs</strong>, using <strong>MMseqs2 “blastx”</strong> hits for <strong>gene prediction</strong></p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs stylus">emapper<span class="hljs-selector-class">.py</span> -m mmseqs <span class="hljs-attr">--itype</span> metagenome -<span class="hljs-selector-tag">i</span> FASTA_FILE_NTS -o test<br></code></pre></td></tr></table></figure><p>- Run <strong>search</strong> and <strong>annotation</strong> for a <strong>genome</strong>, using <strong>Diamond search</strong> on proteins <strong>predicted by Prodigal</strong>, changing the output directory.</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs stylus">emapper<span class="hljs-selector-class">.py</span> -m diamond <span class="hljs-attr">--itype</span> genome <span class="hljs-attr">--genepred</span> prodigal \<br>-<span class="hljs-selector-tag">i</span> FASTA_FILE_NTS -o test <span class="hljs-attr">--output_dir</span> /home/me/mydir<br></code></pre></td></tr></table></figure><p>- Run gene prediction using a genome to train Prodigal</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs stylus">emapper<span class="hljs-selector-class">.py</span> -m mmseqs <span class="hljs-attr">--itype</span> genome <span class="hljs-attr">--genepred</span> prodigal -<span class="hljs-selector-tag">i</span> FASTA_FILE_NTS -o test \<br><span class="hljs-attr">--training_genome</span> FASTA_FILE <span class="hljs-attr">--training_file</span> OUT_TRAIN_FILE<br></code></pre></td></tr></table></figure><p>- Perform a 2-step (search + annotation) run, using Diamond in <em>more-sensitive</em> mode and loading the annotation DB into memory (–dbmem; requires ~44 GB free mem)</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs stylus">emapper<span class="hljs-selector-class">.py</span> -m diamond <span class="hljs-attr">--sensmode</span> more-sensitive <span class="hljs-attr">--no_annot</span> -<span class="hljs-selector-tag">i</span> FASTA_FILE_PROTS -o test<br><br>emapper<span class="hljs-selector-class">.py</span> -m no_search <span class="hljs-attr">--annotate_hits_file</span> test<span class="hljs-selector-class">.emapper</span><span class="hljs-selector-class">.seed_orthologs</span> -o test_annot_1 <span class="hljs-attr">--dbmem</span><br></code></pre></td></tr></table></figure><p>- Repeat the annotation step, using specific taxa as target and reporting the one-to-one orthologs found</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs stylus">emapper<span class="hljs-selector-class">.py</span> -m no_search <span class="hljs-attr">--annotate_hits_file</span> test<span class="hljs-selector-class">.emapper</span><span class="hljs-selector-class">.seed_orthologs</span> -o test_annot_2 <span class="hljs-attr">--dbmem</span> \<br><span class="hljs-attr">--report_orthologs</span> <span class="hljs-attr">--target_orthologs</span> one2one <span class="hljs-attr">--target_taxa</span> <span class="hljs-number">72274</span>,<span class="hljs-number">1123487</span><br></code></pre></td></tr></table></figure><p>- Use <strong>HMMER</strong> to search a database of bacterial proteins, using current directory for temporary files, and using a “scratch” directory to write output on a different hard drive than the one used to read. Once emapper.py finishes, output files in the scratch dir will be moved to the actual output dir, and the scratch dir will be removed.</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs stylus">emapper<span class="hljs-selector-class">.py</span> -m hmmer -d bact -<span class="hljs-selector-tag">i</span> FASTA_FILE_PROTS -o test <span class="hljs-attr">--scratch_dir</span> /scratch/test <span class="hljs-attr">--temp_dir</span> .<br></code></pre></td></tr></table></figure><p>- Perform a <strong>Diamond search,</strong> and annotation also realigning queries to the <strong>PFAM domains found on the Orthologous Groups</strong></p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs stylus">emapper<span class="hljs-selector-class">.py</span> -<span class="hljs-selector-tag">i</span> FASTA_FILE_PROTS -o test <span class="hljs-attr">--pfam_realign</span> realign<br></code></pre></td></tr></table></figure><p>- Perform a <strong>Diamond search</strong>, and annotation also realigning queries to the whole PFAM database</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs stylus">emapper<span class="hljs-selector-class">.py</span> -<span class="hljs-selector-tag">i</span> FASTA_FILE_PROTS -o test <span class="hljs-attr">--pfam_realign</span> denovo<br></code></pre></td></tr></table></figure><p>- Perform a Diamond search and annotation, constraining the Orthologous Groups from which to retrieve annotations to the <em>Bacteria</em> taxon:</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs stylus">emapper<span class="hljs-selector-class">.py</span> -<span class="hljs-selector-tag">i</span> FASTA_FILE_PROTS -o test <span class="hljs-attr">--tax_scope</span> Bacteria<br></code></pre></td></tr></table></figure><p>- Perform a Diamond search and annotation, constraining the Orthologous Groups from which to retrieve annotations to a predefined tax scope (defined in the file <code>eggnogmapper/annotation/tax_scopes/bacteria</code>) for Bacteria and its descendants. The difference with the previous example is that here the <em>bacteria</em> file used as tax scope contains a list of taxa instead of only <em>Bacteria</em>. If several OGs intersect with the scope, for a given protein, the narrowest will be used to transfer annotations to the query:</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs stylus">emapper<span class="hljs-selector-class">.py</span> -<span class="hljs-selector-tag">i</span> FASTA_FILE_PROTS -o test <span class="hljs-attr">--tax_scope</span> bacteria<br></code></pre></td></tr></table></figure><p>- Perform a Diamond search and annotation, constraining the Orthologous Groups from which to retrieve annotations to the <em>Gammaproteobacteria</em> tax scope. Also, from those OGs, force to retrieve annotations at the <em>Bacteria</em> level:</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs stylus">emapper<span class="hljs-selector-class">.py</span> -<span class="hljs-selector-tag">i</span> FASTA_FILE_PROTS -o test <span class="hljs-attr">--tax_scope</span> Gammaproteobacteria <span class="hljs-attr">--tax_scope_mode</span> Bacteria<br></code></pre></td></tr></table></figure><h1 id="文档1"><a href="#文档1" class="headerlink" title="文档1"></a>文档1</h1><h2 id="同源"><a href="#同源" class="headerlink" title="同源"></a>同源</h2><p><strong>同源（Homologs</strong>）：来源于共同祖先的相似序列为同源序列。相似序列有两种，来源于共同祖先可以叫同源，不来源于共同祖先尽管相似也不能叫同源。第二种情况概率虽低但存在，所以<strong>相似序列并不一定是同源序列</strong>。同源又分为三种，<strong>直系同源</strong>，<strong>旁系同源</strong>和<strong>异同源</strong>。同源只是对性质的一种判定，只能定性描述，不能定量。</p><p><strong>直系同源（Orthologs）</strong>是指来自于不同物种的由垂直家系，也就是物种形成，进化而来的基因，并且典型的保留与原始基因相同的功能。随着进化分支，一个基因进入了不同的物种，并保留了原有功能。这时，不同物种中的这个基因就属于直系同源。 <strong>Orthologous genes</strong> <em>(or orthologs) are a particular class of homologous genes. They are found in different species and have diverged following the speciation of the species hosting them. Therefore, orthologous genes in different species derive from a common ancestral gene found in the ancestor of those species.</em></p><p><strong>旁系同源（Paralogs）</strong>是指在同一物种中的来源于<strong>基因复制</strong>的基因，可能会进化出新的但与原功能相关的功能。</p><p><strong>异同源（Xenologs）</strong>是指通过水平基因转移，来源于<strong>共生或病毒侵染</strong>所产生的相似基因。异同源的产生不是垂直进化而来的，也不是平行复制产生的，而是由于<strong>原核生物与真核生物的接触</strong>，比如病毒感染，在跨度巨大的物种间跳跃转移产生的。</p><p><strong>为什么说旁系同源没有共进化信息呢</strong>，在进化起源上，直系同源是强调在不同基因组中的垂直传递，旁系同源则是在同一基因组中的横向加倍；在功能上，<strong>直系同源要求功能高度相似</strong>，而<strong>旁系同源在定义上对功能上没有严格要求，可能相似，但也可能并不相似</strong>(尽管结构上具一定程度的相似)，甚至于没有功能(如基因家族中的假基因)。</p><p>即 <strong>co-evolution 是在不同物种的同源序列，某一个位点发生了某种变化，为了维持之前的形状和功能，相应的位点也发生了相应的变化，这就是共进化。即直系同源可以得到共进化信息，但是旁系同源直接连原始的形状和功能都不在乎了，失去了或者说没有那么保守，那么旁系同源序列自然就体现不出来共进化信息。</strong></p><h2 id="eggNOG-Mapper介绍"><a href="#eggNOG-Mapper介绍" class="headerlink" title="eggNOG-Mapper介绍"></a>eggNOG-Mapper介绍</h2><p>通常功能注释的思路都是基于序列相似性找直系同源基因，常用方法是BLAST+BLAST2GO， 或InterProScan。eggNOG-mapper认为这种方法不够可靠，毕竟有可能找到的是旁系同源基因。对多个工具的整体评估发现<font color="red">eggNOG(evolutionary genealogy of genes: Non-supervised Orthologous Groups)</font>在区分旁系同源基因和直系同源基因上较优，基于eggNOG数据库开发<code>eggNOG-mapper</code>工具，用于对新序列功能注释。</p><p><code>eggNOG-mapper</code>算法：</p><p>第一步：<font color="red">序列比对</font>。首先，每条蛋白序列用HMMER3在整理的eggNOG库中搜索。由于每个HMM匹配都和一个功能注释的eggNOG OG对应，这一步就提供初步的注释信息。之后，每条蛋白序列用<code>phmmer</code>在最佳匹配的HMM对应的一组eggNOG蛋白中进一步搜索。最后，每条序列的<font color="red">最佳匹配结果以 <strong>seed ortholog</strong> 形式存放</font>，用于获取其他直系同源基因。目前eggNOG HMM数据库中拥有1,911,745个OG，覆盖了1,678种细菌,115种古细菌，238种真核物种以及352种病毒。除HMMER3外，还可用DIAMOND直接对所有的eggNOG蛋白序列进行搜索，它的速度更快，适合类似于宏基因组这类大数据集，或者是已有物种和eggNOG所收集的物种比较近。当然服务器性能强大的话，还是有限选择HMMER3.</p><p><img src="/GeekFocus/2022-06-05-FuncAnno-eggNOG/1.png" alt="2"></p><p><img src="/GeekFocus/./1.png"></p><p><strong>step1: 序列比对</strong></p><p>第二步：推测直系同源基因。每个用于检索的蛋白序列的最佳匹配序列会对应eggNOG的一个蛋白, 这些蛋白基于预分析的eggNOG进化树数据库会提取一组更加精细的直系同源基因。这一步还会根据bit-screo或E-value对结果进行一次过来，<strong>剔除</strong>同源性不高的结果</p><p><img src="/GeekFocus/2022-06-05-FuncAnno-eggNOG/2.png" alt="2"></p><p><img src="/GeekFocus/./2.png" alt="2"></p><p><strong>step2: 推测直系同源基因</strong></p><p>第三步：功能注释。用于搜索的蛋白序列对应的直系同源基因的功能描述就是最终的注释结果。比如说GO, KEGG, COG等。</p><p><img src="/GeekFocus/2022-06-05-FuncAnno-eggNOG/3.png" alt="2"></p><p><img src="/GeekFocus/./3.png" alt="2"></p><p><strong>step3: 功能注释</strong></p><h2 id="具体用法"><a href="#具体用法" class="headerlink" title="具体用法"></a>具体用法</h2><p><code>eggnog-mapper</code>用法简单，需提供蛋白序列作为输入</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">python emapper.py -i <span class="hljs-built_in">test</span>/p53.fa --output p53_maNOG -d euk<br>python emapper.py -i <span class="hljs-built_in">test</span>/p53.fa --output p53_maNOG -d maNOG<br>python emapper.py -i <span class="hljs-built_in">test</span>/p53.fa --output p53_maNOG -d maNOG --usemem --cpu 10<br></code></pre></td></tr></table></figure><p><code>eggnog-mapper</code>默认是以HMMER进行序列搜索，尽管可以通过<code>-m diamond</code>更改成DIAMOND，但结果中就会缺少一些信息列。HMM的搜索参数，有<code>--hmm_maxhits</code>, <code>--hmm_evalue</code>, <code>--hmm_score</code>, <code>--hmm_qcov</code>和<code>--Z</code>, 一般默认。</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sh">-d/--database <span class="hljs-comment">#`表示搜索数据库的类型，既可以是&quot;euk, bact, arch&quot; 三大类的其中一种，也可以是&quot;eggnog-mapper/data/OG_fasta&quot;中的小类，例如&quot;maNOG&quot;表示的就是哺乳动物的NOG。此外也可以是自定义HMM数据库， `-d /path/to/pfam.hmm</span><br></code></pre></td></tr></table></figure><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs sh">-m MODE <span class="hljs-comment">#how input queries will be searched against eggNOG sequences. Default is -m diamond</span><br><span class="hljs-comment">#diamond, hmmer(HMMER), mmseqs(MMseqs2), diff options</span><br>--usemem <span class="hljs-comment">#内存</span><br>--cpu <span class="hljs-comment">#线程</span><br>--output <span class="hljs-comment"># 输出文件前缀,默认输出在当前文件夹</span><br>--output_dir <span class="hljs-comment"># 输出文件路径</span><br>--resume <span class="hljs-comment">#任务重启后跳过之前已经完成部分</span><br>--override <span class="hljs-comment"># 覆盖原先输出结果</span><br><span class="hljs-comment">#--other</span><br>--list_taxa <span class="hljs-comment">#List available taxonomic names and IDs for OGs and exit，These are valid tax names and IDs for --tax_scope/--tax_scope_mode</span><br>--itype INPUT_TYPE <span class="hljs-comment">#Type of sequences in the input (-i) file. Default is --itype proteins. All INPUT_TYPE options are shown the next table:CDS，genome，metagenome</span><br><br></code></pre></td></tr></table></figure><ul><li><code>-m MODE</code></li><li>how input queries will be searched against eggNOG sequences. Default is -m diamond. All MODE options are shown in the next table:</li></ul><table><thead><tr><th><em>MODE</em></th><th>description</th><th>Notes</th></tr></thead><tbody><tr><td><em>diamond</em></td><td>search queries against eggNOG sequences using Diamond.</td><td>Requires <code>-i FILE</code>.</td></tr><tr><td><em>hmmer</em></td><td>search sequences&#x2F;hmm against sequences&#x2F;hmm using HMMER.</td><td>Requires <code>-i FILE</code> and <code>-d DB_NAME</code>.</td></tr><tr><td><em>mmseqs</em></td><td>search queries against eggNOG sequences using MMseqs2.</td><td>Requires <code>-i FILE</code>.</td></tr><tr><td><em>cache</em></td><td>annotate queries using a previously annotated file (<code>-c</code>) which includes md5 hashes of the annotated sequences.</td><td>Requires <code>-i FILE</code> and <code>-c FILE</code>.</td></tr><tr><td><em>no_search</em></td><td>skip search stage. Annotate an existing <em>emapper.seed_orthologs</em> file.</td><td>Requires <code>--annotate_hits_table FILE</code>, unless <code>--no_annot</code> is used.</td></tr></tbody></table><ul><li>Common search options; diamond search options; MMseqs2 search options; HMMER search options</li></ul><h2 id="结果解读"><a href="#结果解读" class="headerlink" title="结果解读"></a>结果解读</h2><p>eggnog-mapper会生成三个文件，</p><ul><li><code>[project_name].emapper.hmm_hits</code>: 记录每个用于搜索序列对应的所有的显著性的eggNOG Orthologous Groups(OG). 所有标记为”-“则表明该序列未找到可能的OG . A file with the results from the search phase, from HMMER, Diamond or MMseqs2.</li><li><code>[project_name].emapper.seed_orthologs</code>: 记录每个用于搜索序列对的的最佳的OG，也就是<code>[project_name].emapper.hmm_hits</code>里选择得分最高的结果。之后会从eggNOG中提取更精细的直系同源关系(orthology relationships). A file with the results from parsing the hits. Each row links a query with a seed ortholog. This file has the same format independently of which searcher was used, except that it can be in short format (4 fields), or full.</li><li><code>[project_name].emapper.annotations</code>: 该文件提供了最终的注释结果。大部分需要的内容都可以通过写脚本从从提取，一共有13列。A file with the results from the annotation phase. Therefore, each row represents the annotation reported  for a given query.</li></ul><h2 id="annotation-files"><a href="#annotation-files" class="headerlink" title="annotation files"></a>annotation files</h2><p><code>[project_name].emapper.annotations</code>每一列对应的记录如下：</p><ol><li><code>query_name</code>: 检索的基因名或者其他ID</li><li><code>sedd_eggNOG_ortholog</code>: eggNOG中最佳的蛋白匹配</li><li><code>seed_orholog_evalue</code>: 最佳匹配的e-value</li><li><code>seed_ortolog_evalu</code>: 最佳匹配的bit-score</li><li><code>predicted_gene_name</code>: 预测的基因名，特别指的是类似AP2有一定含义的基因名，而不是AT2G17950这类编号</li><li><code>GO_term</code>: 推测的GO的词条， 未必最新</li><li><code>KEGG_KO</code>: 推测的KEGG KO词条， 未必最新</li><li><code>BiGG_Reactions</code>: BiGG代谢反应的预测结果</li><li><code>Annotation_tax_scope</code>: 对该序列在分类范围的注释</li><li><code>Matching_OGs</code>: 匹配的eggNOG Orthologous Groups</li><li><code>best_OG|evalue|score</code>: 最佳匹配的OG(HMM模式才有)</li><li><code>COG functional categories</code>: 从最佳匹配的OG中推测出的COG功能分类</li><li><code>eggNOG_HMM_model_annotation</code>: 从最佳匹配的OG中推测出eggNOG功能描述</li></ol><p>如果打算做富集分析，用命令行的cut&#x2F;awk提取对应的列，过滤掉其中未注释的部分。</p>]]></content>
    
    
    <categories>
      
      <category>Software</category>
      
    </categories>
    
    
    <tags>
      
      <tag>FuncAnno</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Hello World</title>
    <link href="/GeekFocus/2022/06/05/hello-world/"/>
    <url>/GeekFocus/2022/06/05/hello-world/</url>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo new <span class="hljs-string">&quot;My New Post&quot;</span><br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo server<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo generate<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo deploy<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>Database</title>
    <link href="/GeekFocus/2022/05/29/2022-05-29-BioDatabase/"/>
    <url>/GeekFocus/2022/05/29/2022-05-29-BioDatabase/</url>
    
    <content type="html"><![CDATA[<span id="more"></span><h1 id="一、核酸数据库"><a href="#一、核酸数据库" class="headerlink" title="一、核酸数据库"></a>一、核酸数据库</h1><h2 id="NCBI"><a href="#NCBI" class="headerlink" title="NCBI"></a><strong>NCBI</strong></h2><p>NCBI (National Center for Biotechnology Information）是美国国立生物技术信息中心构建的生信数据库，目前最全面的数据库。</p><h2 id="EMBL"><a href="#EMBL" class="headerlink" title="EMBL"></a>EMBL</h2><p>欧洲分子生物学实验室EMBL（The European Molecular Biology Laboratory），目前蛋白质信息最全部的数据库UniProt就是他家开发的。 </p><h2 id="DDBJ"><a href="#DDBJ" class="headerlink" title="DDBJ"></a>DDBJ</h2><p>DDBJ (DNA Data Bank of Japan)，于1984年建立，是世界三大DNA 数据库之一，与NCBI的GenBank，EMBL的EBI数据库共同组成国际DNA数据库 。该数据库最为常用的就是他家的KEGG通路数据库。</p><h2 id="CNGB"><a href="#CNGB" class="headerlink" title="CNGB"></a>CNGB</h2><p>中国国家数据库（China National GeneBank）位于深圳大鹏新区，是继世界三大数据库之后的全球第四大国家级数据库。它是中国首个，也是唯一一个国家基因库，相对于全球另外三个基因库而言，国家基因库样品保存的规模、存储量和可访问的数据量皆是全球最大。 </p><h2 id="BIGD"><a href="#BIGD" class="headerlink" title="BIGD"></a>BIGD</h2><p>中国国家基因组科学数据中心 生命与健康大数据中心 (National Genomics Data Center BIG Data Center)，由北京基因组研究所管理。</p><h1 id="二、蛋白质数据库"><a href="#二、蛋白质数据库" class="headerlink" title="二、蛋白质数据库"></a>二、蛋白质数据库</h1><h2 id="nr"><a href="#nr" class="headerlink" title="nr"></a>nr</h2><p>目前有很多数据库都存储蛋白序列，比如NCBI Refseq, protein, swissprot 等，在各个数据库之间，或在某个数据库内，蛋白序列有大量冗余；为方便使用，ncbi 构建nr 库， 全称是 <font color="red"><strong>RefSeq non-redundant proteins</strong></font></p><p>Non-redundant protein sequences from  <font color="red"><strong>GenPept,  Swissprot, PIR, PDF, PDB, and NCBI RefSeq</strong></font></p><p>完整的nr 数据库的蛋白序列和预先构建好的blast 索引可以从ncbi 的ftp 服务器上下载得到，地址如下：</p><p><a href="https://ftp.ncbi.nlm.nih.gov/blast/db/FASTA/">https://ftp.ncbi.nlm.nih.gov/blast/db/FASTA/</a></p><p>通常情况下，直接下载构建好的blast 索引，因为</p><ol><li>整个nr 的蛋白序列非常大，大概30G 左右，<strong>构建索引费时</strong>；</li></ol><p>2）ncbi 的blast索引，加入每条序列的种水平taxid，便于得到序列对应的物种注释信息；<strong>官方索引更优</strong></p><p>3） 使用blastdbcmd 命令可以从索引中还原出原始的nr 序列；</p><p>对于NCBI ftp 的数据，可以用aspera  进行下载， 速度非常快</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sh">ascp -i ~/asperaweb_id_dsa.openssh  -QTr -l6000m  anonftp@ftp-private.ncbi.nlm.nih.gov:/blast/db/FASTA/nr..tar.gz ./<br></code></pre></td></tr></table></figure><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs sh">wget -c ftp://ftp.ncbi.nlm.nih.gov/blast/db/nt*<br>wget -c ftp://ftp.ncbi.nlm.nih.gov/blast/db/nr*<br></code></pre></td></tr></table></figure><p>由于nr 库较大，所以 ncbi 把 nr 库分成了很多小份的fasta 序列，建立索引</p><p>对于nr 的序列而言，其标识符中包含了很多的信息</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sh">&gt;XP_642131.1 hypothetical protein DDB_G0277827 [Dictyostelium discoideum AX4]P54670.1 RecName: Full=Calfumirin-1; Short=CAF-1BAA06266.1 calfumirin-1 [Dictyostelium discoideum AX2]EAL68086.1 hypothetical protein DDB_G0277827 [Dictyostelium discoideum AX4]<br></code></pre></td></tr></table></figure><p>首先是1个蛋白序列的编号，后面是这条序列对应的详细信息，方括号内是物种名称； 由于nr 库是非冗余的，这里的 <font color="red">每一条蛋白序列可以理解为 一个聚类的group 中的代表序列，第一条是该代表序列本身的信息，后面几条是属于这个group 下的其他序列的信息</font>；</p><p>这里有两种情况，</p><p>1） 这一个group 中所有的蛋白序列都来源于同一个物种；</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">WP_003131952</span>.<span class="hljs-number">1</span> <span class="hljs-number">30</span>S ribosomal protein S18<span class="hljs-meta"> [Lactococcus lactis]</span><br></code></pre></td></tr></table></figure><p>2） 这一个group 中所有的蛋白序列都来源于多个物种；</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">WP_000184067</span>.<span class="hljs-number">1</span> MULTISPECIES: MbtH family protein<span class="hljs-meta"> [Bacillus]</span><br></code></pre></td></tr></table></figure><p> <font color="red"><strong>唯一不同的是，当来源于多个物种时，会在前面加上 MULTISPECIES 关键字</strong></font></p><p>对于nr 中的序列，其标识符有两种：</p><p>1）  <font color="red"><strong>WP 开头 ：真实存在的蛋白序列</strong></font></p><p>2） <font color="red"><strong>XP 开头： 理论上的蛋白序列（计算机软件预测的结果）</strong></font></p><p>通常情况下，比对nr 库有两种用途：</p><p>1）<strong>蛋白质功能注释</strong>： 需要输出蛋白质的描述信息</p><p>对于这个需求，nr 库里包含了这些信息，所以比较简单，直接blast 比对，在输出结果中输出这个信息就可以了</p><p>2） <strong>物种注释</strong>：输出蛋白对应的物种信息</p><p>在序列中有明确的 species 水平的注释，但是还需要phylum 等水平的注释，这时候就需要借助Taxonomy 数据库，把物种注释信息补充完整。</p><h2 id="Transporter-Classfication-DB转运蛋白分类库"><a href="#Transporter-Classfication-DB转运蛋白分类库" class="headerlink" title="Transporter Classfication DB转运蛋白分类库"></a>Transporter Classfication DB转运蛋白分类库</h2><p><a href="https://www.tcdb.org/">https://www.tcdb.org</a></p><p><a href="http://www.tcdb.org/download.php">http://www.tcdb.org/download.php</a></p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs sh">makeblastdb error<br><span class="hljs-comment">#error</span><br><span class="hljs-comment">#No volumes were created.</span><br><span class="hljs-comment">#BLAST Database creation error: Could not construct seq-id from &#x27;gnl|TC-DB|1CN3_F|1.A.83.1.5&#x27;</span><br><br><br><span class="hljs-built_in">cat</span> TCDB_transport.pro.fasta | seqkit <span class="hljs-built_in">seq</span> -m 100 &gt; TCDB_transport.100aa.fasta<br><span class="hljs-comment">#[WARN] you may switch on flag -g/--remove-gaps to remove spaces</span><br><span class="hljs-comment">#still error</span><br><br><span class="hljs-comment">#BLAST Database creation error: Near line 6001, the local id is too long. Its length is 51 but the maximum allowed local id length is 50. Please find and correct all local ids that are too long</span><br><span class="hljs-comment">#parse_seqids is the id lenth parameter</span><br><span class="hljs-comment">#remove parse_seqids</span><br></code></pre></td></tr></table></figure><p>TCDB是对膜转运蛋白（Membrane Transport Protein）进行分类的一个数据库，它制定了一套转运蛋白分类系统（Transporter Classification）, 简称TC System, 类似于对酶进行分类的EC系统，只不过TC系统同时提供了功能和进化信息；</p><p>TCDB对于每一个转运蛋白家族，提供了一个TC Nmuber, TC Number 由小数点分隔的5为数字或者字母构成</p><p><a href="http://www.tcdb.org/browse.php">http://www.tcdb.org/browse.php</a>  第一级分类</p><ul><li><strong>Channels&#x2F;Proes</strong></li><li><strong>Electrochemical Potential-driven Transporters</strong></li><li><strong>Primary Active Transporters</strong></li><li><strong>Group Translocators</strong></li><li><strong>Transmembrane Electron Carriers</strong></li><li><strong>Accessory Factors Involved in Transport</strong></li><li><strong>Incompletely Characterized Transport Systems</strong></li></ul><p>点击 TCDB FsatA Sequences 超链接，下载所有的序列，下载下来的序列内容如下：</p><figure class="highlight coq"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs coq">&gt;gnl|<span class="hljs-type">TC</span>-DB|<span class="hljs-type">1001796365</span>|<span class="hljs-type">4</span>.F<span class="hljs-number">.1</span><span class="hljs-number">.1</span><span class="hljs-number">.5</span> CDP-alcohol phosphatidyltransferase [Marinobacter excellens]<br>MDSIRPATFQIPAAVRELGWAALLLFFVLLSVHEWFSPPGWFGLLAILIFATQGALILTR<br>WPARQNFGWANRTTLLRSILVVSLVAWAPFLPAADSSALWIYGVACLIALILDGVDGKVA<br>RATNSNSEFGARFDMELDALFIFGLCVATMAIGKAGPWVLMLALMRYAFLAASHFLTWLN<br>QPLPDSFRRKTVCVWQVVTLMIAILPPTPTGFAGTTLAMALALLGWSFALDVRWLYQRRH<br>YHEN<br></code></pre></td></tr></table></figure><p>序列标识符中，</p><ul><li>1001796365 代表该蛋白质序列在GeneBank 数据库中的编号</li><li>4.F.1.1.5 是TC Number, 代表该蛋白质所属的转运蛋白家族</li><li>CDP-alcohol phosphatidyltransferase 是对该转运蛋白家族功能的具体描述</li><li>[Marinobacter excellens] 是该蛋白序列的来源物种</li></ul><p>有了fasta序列之后，对序列进行TCDB的功能注释</p><p>TCDB还提供了TCID 与其他数据库的关联</p><h2 id="蛋白质信息库Human-protein-atlas"><a href="#蛋白质信息库Human-protein-atlas" class="headerlink" title="蛋白质信息库Human protein atlas"></a>蛋白质信息库Human protein atlas</h2><ul><li><a href="https://link.zhihu.com/?target=http://www.proteinatlas.org/">Human protein atlas</a><br>人体蛋白在细胞、组织、病理条件下的表达 ，荧光染色和表达信息使得网站很炫也很实用。</li></ul><h2 id="蛋白序列数据库"><a href="#蛋白序列数据库" class="headerlink" title="蛋白序列数据库"></a>蛋白序列数据库</h2><h3 id="Pfam"><a href="#Pfam" class="headerlink" title="Pfam"></a>Pfam</h3><p>Pfam是蛋白质家族的数据库，包括使用隐马尔可夫模型生成的注释和多序列比对。 </p><hr><h3 id="SwissProt"><a href="#SwissProt" class="headerlink" title="SwissProt"></a>SwissProt</h3><p>手动注释的非冗余蛋白序列数据库</p><hr><h3 id="UniProt"><a href="#UniProt" class="headerlink" title="UniProt"></a>UniProt</h3><p>Uniprot （<em>Universal Protein</em> ）是包含蛋白质序列，功能信息，研究论文索引的蛋白质数据库，整合了包括EBI（ European Bioinformatics Institute），SIB（the Swiss Institute of Bioinformatics），PIR（Protein Information Resource）三大数据库的资源。</p><ul><li><p>EBI（ European Bioinformatics Institute）：欧洲生物信息学研究所（EMBL-EBI）是欧洲生命科学旗舰实验室EMBL的一部分。位于英国剑桥欣克斯顿的惠康基因组校园内，是世界上基因组学领域最强地带之一。</p></li><li><p>SIB（the Swiss Institute of Bioinformatics）：瑞士日内瓦的SIB维护着ExPASy（专家蛋白质分析系统）服务器，这里包含有蛋白质组学工具和数据库的主要资源。</p></li><li><p>PIR（Protein Information Resource）：PIR由美国国家生物医学研究基金会（NBRF）于1984年成立，旨在协助研究人员识别和解释蛋白质序列信息。</p></li></ul><p>UniProt主要子库</p><table><thead><tr><th>数据库名</th><th>全名</th><th>用途</th></tr></thead><tbody><tr><td>UniProtKB&#x2F;Swiss-Prot</td><td>protein knowledgebas（review）</td><td>高质量，手工注释，非冗余</td></tr><tr><td>UniProtKB&#x2F;TrEMBL</td><td>protein knowledgebas（unreview）</td><td>自动翻译蛋白序列，预测序列，未验证的数据库</td></tr><tr><td>UniParc</td><td>Sequence</td><td>非冗余蛋白质序列数据库</td></tr><tr><td>UniRef</td><td>Sequence cluster</td><td>聚类序列减少数据库，加快搜索的速度</td></tr><tr><td>Proteomes</td><td>Protein sets from fully sequenced genomes</td><td>为全测序基因组物种提供蛋白质信息</td></tr></tbody></table><p>通过EMBL，GenBank，DDBJ等公共数据库得到原始数据，处理后存入UniParc的非冗余蛋白质序列数据库。UniProt作为数据仓库，再分别给UniProtKB，Proteomes，UNIRef提供可靠的数据集。其中在UniProtKB数据库中Swiss-Prot是由TrEMBL经过手动注释后得到的高质量非冗余数据库，也是我们今后常用的蛋白质数据库之一。</p><p><img src="/GeekFocus/2022-05-29-BioDatabase/1.png" alt="img"></p><p><img src="/GeekFocus/./1.png" alt="img"></p><p><strong>UniProtKB&#x2F;Swiss-Prot</strong></p><p>高质量的、手工注释的、非冗余的数据集</p><p>Swiss-Prot旨在提供与高水平注释（例如，蛋白质功能，其域结构，翻译后修饰，变体等的描述）相关的可靠蛋白质序列，最小程度的冗余和高水平与其他数据库的集成级别。注释主要来自文献中的研究成果和E-value校验过计算分析结果，有质量保证的数据才被加入该数据库 。</p><p>Swiss-Prot由Amos Bairoch博士在1986年创建，由瑞士生物信息学研究所开发，随后由欧洲生物信息学研究所的Rolf Apweiler开发。也是说EBI和SIB共同制作了Swiss-Prot和TrEMBL数据库。</p><p>Swiss-Prot条目的注释中使用了一系列序列分析工具。包括手动评估，计算机预测，并选择结果包含在相应的条目中。这些预测包括翻译后修饰，跨膜结构域和拓扑，信号肽，结构域识别和蛋白质家族分类。</p><p>来自相同基因和相同物种的序列合并到相同的数据库条目中。确定序列之间的差异包含：可变剪接，自然变异，错误的起始位点，错误的外显子边界，移码，未识别的冲突。</p><p>注释会用相关出版物通过搜索数据库（例如PubMed）进行识别。阅读每篇论文的全文，然后提取信息并将其添加到条目中。科学文献中的注释包括但不限于：</p><ul><li>蛋白质和基因名称</li><li>功能</li><li>特定于酶的信息，例如催化活性，辅因子和催化残基</li><li>亚细胞定位</li><li>蛋白质相互作用</li><li>表达方式</li><li>重要域和站点的位置和角色</li><li>离子，底物和辅因子结合位点</li><li>通过自然遗传变异，RNA编辑，替代剪接，蛋白水解加工和翻译后修饰产生的蛋白质变异形式</li></ul><img src="2022-05-29-BioDatabase/2.png" alt="img" style="zoom:50%;" /><img src="./1.png" alt="img" style="zoom:50%;" /><p>&lt;1&gt;：这里输入基因名，UniProt ID，或者感兴趣的关键字</p><p>&lt;2&gt;：筛选：<strong>Reviewed</strong>：存储在Swiss-Prot数据库中经过验证的蛋白数据，<strong>Unreviewed</strong>：存储在TrEMBL数据库中没有经过验证的蛋白数据</p><p>&lt;3&gt;：筛选某个物种，点击就好切换到该物种</p><p>&lt;4&gt;：通过基因名或蛋白名来筛选</p><p>&lt;5&gt;：依次是Unprot ID，该蛋白数据库命名，蛋白质名，基因名，物种，序列长</p><p>&lt;6&gt;：如果需要Blast来查看某个蛋白有哪些序列相似的蛋白序列，先选中感兴趣蛋白前的方框，点击<code>Blast</code></p><p>&lt;7&gt;：如果需要多序列比对，先选中感兴趣蛋白前的方框，点击<code>Align</code></p><p>&lt;8&gt;：如果要下载信息，先选中感兴趣蛋白前的方框，点击<code>Download</code>下载。这里不选择序列，默认会下载全部序列</p><p>下载到的序列：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs sh"> &gt;sp|Q01860|PO5F1_HUMAN POU domain, class 5, transcription <span class="hljs-built_in">factor</span> 1 OS=Homo sapiens OX=9606 GN=POU5F1 PE=1 SV=1<br>  MAGHLASDFAFSPPPGGGGDGPGGPEPGWVDPRTWLSFQGPPGGPGIGPGVGPGSEVWGI<br><span class="hljs-comment">#sp：Swiss-Prot数据库的简称，也就是上面说的验证后的蛋白数据库</span><br><span class="hljs-comment">#Q01860：UniProt ID号</span><br><span class="hljs-comment">#PO5F1_HUMAN：是UniProt 的登录名</span><br><span class="hljs-comment">#POU domain, class 5, transcription factor 1：蛋白质名称</span><br><span class="hljs-comment">#OS=Homo sapiens：OS是Organism简称，Homo sapiens为人的拉丁文分类命名，也就是这是人的蛋白质</span><br><span class="hljs-comment">#OX=9606：Organism Taxonomy，也就是物种分类数据库Taxonomy ID</span><br><span class="hljs-comment">#GN=POU5F1：Gene name，基因名为POU5F1</span><br><span class="hljs-comment">#PE=1：Protein Existence，蛋白质可靠性，对应5个数字，数字越小越可靠：</span><br><span class="hljs-comment">#1：Experimental evidence at protein level</span><br><span class="hljs-comment">#2：Experimental evidence at tranlevel</span><br><span class="hljs-comment">#3：Protein inferred from homology</span><br><span class="hljs-comment">#4：Protein predicted</span><br><span class="hljs-comment">#5：Protein uncertain</span><br><span class="hljs-comment">#SV=1：Sequence Version，序列版本号</span><br></code></pre></td></tr></table></figure><p><strong>UniProtKB&#x2F;TrEMBL</strong></p><p>在认识到序列数据的生成速度超过了Swiss-Prot的注释能力时，为了给不在Swiss-Prot中的那些蛋白质提供自动注释，UniProt创建了TrEMBL（翻译的EMBL核苷酸序列数据库）。在三大核酸数据库（EMBL-Bank&#x2F;GenBank&#x2F;DDBJ）中注释的编码序列都会被自动翻译并加入该数据库中。它也有来自PDB数据库的序列，以及Ensembl、Refeq和CCDS基因预测的序列。之前提到的PIR组织制作了蛋白质序列数据库（PIR-PSD）。</p><p><strong>UniParc</strong></p><p>UniProt Archive（UniParc）包含来自主要公共可用蛋白质序列数据库的所有蛋白质序列的非冗余数据集。蛋白质可能存在于几个不同的来源数据库中，并且在同一数据库中存在多个副本。 为了避免冗余，UniParc仅将每个唯一序列存储一次。 相同序列被合并，无论它们来自相同还是不同物种。 每个序列都有一个稳定且唯一的标识符（UPI），从而可以从不同的来源数据库中识别相同的蛋白质。</p><p>UniParc仅包含蛋白质序列，没有注释。 UniParc条目中的数据库交叉引用允许从源数据库检索有关该蛋白质的更多信息。 当源数据库中的序列发生更改时，UniParc将跟踪这些更改，并记录所有更改的历史记录。</p><p><strong>UniRef</strong></p><p>UniProt Reference Clusters（UniRef）：聚类序列可显著减小数据库大小，从而加快序列搜索的速度。用于计算的蛋白质序列来自UniProtKB和部分UniParc记录的序列。UniRef100序列将相同的序列和序列片段（来自任何生物）合并到一个UniRef条目中，用于显示代表性蛋白质的序列。 使用CD-HIT算法对UniRef100序列进行聚类，并构建UniRef90和UniRef50。UniRef90和UniRef50分别代表每个簇由与最长序列分别具有至少90％或50％序列同一性的序列组成。</p><hr><h3 id="InterPro"><a href="#InterPro" class="headerlink" title="InterPro"></a>InterPro</h3><p><a href="http://www.ebi.ac.uk/interpro/">http://www.ebi.ac.uk/interpro/</a></p><p>通过整合多个蛋白相关数据库，提供了一个方便的对蛋白序列进行功能注释的平台，包括对蛋白质家族、结构域、功能位点的预测 </p><p>以上这些数据库是整合在一个网站中的，他们间的关系可以参考这篇：</p><hr><h3 id="PIR"><a href="#PIR" class="headerlink" title="PIR"></a>PIR</h3><p><a href="http://www.proteininformationresource.org/">www.proteininformationresource.org/</a></p><hr><h3 id="Antibodies"><a href="#Antibodies" class="headerlink" title="Antibodies"></a>Antibodies</h3><p><a href="http://www.bioinf.org.uk/abs/">www.bioinf.org.uk/abs/</a></p><hr><h3 id="BRENDA"><a href="#BRENDA" class="headerlink" title="BRENDA"></a>BRENDA</h3><hr><h3 id="HPRD"><a href="#HPRD" class="headerlink" title="HPRD"></a>HPRD</h3><p><a href="http://www.hprd.org/">www.hprd.org/</a></p><hr><h3 id="iProClass"><a href="#iProClass" class="headerlink" title="iProClass"></a>iProClass</h3><p>pir.georgetown.edu&#x2F;iproclass&#x2F;</p><hr><h3 id="PRF"><a href="#PRF" class="headerlink" title="PRF"></a>PRF</h3><p><a href="http://www.prf.or.jp/">www.prf.or.jp/</a></p><hr><h3 id="REBASE"><a href="#REBASE" class="headerlink" title="REBASE"></a>REBASE</h3><p>rebase.neb.com&#x2F;rebase&#x2F;rebase.html</p><hr><h2 id="蛋白质结构数据库"><a href="#蛋白质结构数据库" class="headerlink" title="蛋白质结构数据库"></a>蛋白质结构数据库</h2><h3 id="PDB"><a href="#PDB" class="headerlink" title="PDB"></a>PDB</h3><p><a href="http://www.rcsb.org/">www.rcsb.org/</a><br>通过实验测定的结构，最常用的蛋白质三维结构数据库</p><hr><h3 id="SCOP"><a href="#SCOP" class="headerlink" title="SCOP"></a>SCOP</h3><p>scop.mrc-lmb.cam.ac.uk&#x2F;scop&#x2F;</p><hr><h3 id="CATH"><a href="#CATH" class="headerlink" title="CATH"></a>CATH</h3><p><a href="http://www.cathdb.info/">www.cathdb.info/</a></p><hr><h3 id="PSI"><a href="#PSI" class="headerlink" title="PSI"></a>PSI</h3><p><a href="http://www.uwstructuralgenomics.org/">www.uwstructuralgenomics.org/</a></p><hr><h2 id="蛋白组数据库"><a href="#蛋白组数据库" class="headerlink" title="蛋白组数据库"></a>蛋白组数据库</h2><h3 id="PRIDE"><a href="#PRIDE" class="headerlink" title="PRIDE"></a>PRIDE</h3><p><a href="http://www.ebi.ac.uk/pride/archive/">www.ebi.ac.uk/pride/archive/</a></p><h2 id="蛋白质功能域数据库"><a href="#蛋白质功能域数据库" class="headerlink" title="蛋白质功能域数据库"></a><strong>蛋白质功能域数据库</strong></h2><h3 id="PROSITE最全面"><a href="#PROSITE最全面" class="headerlink" title="PROSITE最全面"></a>PROSITE最全面</h3><p>prosite.expasy.org</p><hr><h3 id="Pfam最专业"><a href="#Pfam最专业" class="headerlink" title="Pfam最专业"></a>Pfam最专业</h3><p>pfam.xfam.org</p><hr><h3 id="ProDom"><a href="#ProDom" class="headerlink" title="ProDom"></a>ProDom</h3><p>prodom.prabi.fr</p><hr><h3 id="CCD"><a href="#CCD" class="headerlink" title="CCD"></a>CCD</h3><p><a href="http://www.ncbi.nlm.nih.gov/Structure/cdd/cdd.shtm">www.ncbi.nlm.nih.gov/Structure/cdd/cdd.shtm</a></p><hr><h3 id="Prints"><a href="#Prints" class="headerlink" title="Prints"></a>Prints</h3><p><a href="http://www.bioinf.man.ac.uk/dbbrowser/PRINTS/index.php">www.bioinf.man.ac.uk/dbbrowser/PRINTS/index.php</a></p><hr><h3 id="SMART"><a href="#SMART" class="headerlink" title="SMART"></a>SMART</h3><hr><h3 id="TIGRFAM"><a href="#TIGRFAM" class="headerlink" title="TIGRFAM"></a>TIGRFAM</h3><p><a href="http://www.tigr.org/TIGRFAMs/">www.tigr.org/TIGRFAMs/</a></p><hr><h2 id="蛋白互作数据库"><a href="#蛋白互作数据库" class="headerlink" title="蛋白互作数据库"></a><strong>蛋白互作数据库</strong></h2><h3 id="STRING"><a href="#STRING" class="headerlink" title="STRING"></a>STRING</h3><p>string-db.org</p><h3 id="DIP"><a href="#DIP" class="headerlink" title="DIP"></a>DIP</h3><p>dip.doe-mbi.ucla.edu&#x2F;dip&#x2F;Main.cgi 实验验证的蛋白相互作用数据库</p><h3 id="BioGRID"><a href="#BioGRID" class="headerlink" title="BioGRID"></a>BioGRID</h3><p>thebiogrid.org</p><h3 id="IntAct"><a href="#IntAct" class="headerlink" title="IntAct"></a>IntAct</h3><h1 id="三-非编码RNA数据库"><a href="#三-非编码RNA数据库" class="headerlink" title="三. 非编码RNA数据库"></a>三. 非编码RNA数据库</h1><h2 id="非编码小RNA数据库"><a href="#非编码小RNA数据库" class="headerlink" title="非编码小RNA数据库"></a><strong>非编码小RNA数据库</strong></h2><h3 id="miRBase"><a href="#miRBase" class="headerlink" title="miRBase"></a>miRBase</h3><p><a href="http://www.mirbase.org/">www.mirbase.org/</a></p><h3 id="piRNAbank"><a href="#piRNAbank" class="headerlink" title="piRNAbank"></a>piRNAbank</h3><p>pirnabank.ibab.ac.in&#x2F;</p><h3 id="piRNAbank-1"><a href="#piRNAbank-1" class="headerlink" title="piRNAbank"></a>piRNAbank</h3><p>gtrnadb.ucsc.edu&#x2F;</p><h3 id="SILVA"><a href="#SILVA" class="headerlink" title="SILVA"></a>SILVA</h3><p><a href="http://www.arb-silva.de/">www.arb-silva.de/</a></p><h2 id="长非编码RNA数据库"><a href="#长非编码RNA数据库" class="headerlink" title="长非编码RNA数据库"></a><strong>长非编码RNA数据库</strong></h2><ul><li><a href="https://link.zhihu.com/?target=http://www.lncrnadb.org/">LncRNAdb</a> 真核生物长非编码RNA数据库</li><li><a href="https://link.zhihu.com/?target=http://lncrna.big.ac.cn/index.php/Main_Page">LncRNAwiki</a> 人类长非编码RNA数据库</li></ul><h2 id="非编码RNA家族数据库"><a href="#非编码RNA家族数据库" class="headerlink" title="非编码RNA家族数据库"></a><strong>非编码RNA家族数据库</strong></h2><h3 id="Rfam"><a href="#Rfam" class="headerlink" title="Rfam"></a>Rfam</h3><p>rfam.xfam.org  类似于Pfam的RNA家族注释数据库</p><h2 id="非编码RNA序列数据库"><a href="#非编码RNA序列数据库" class="headerlink" title="非编码RNA序列数据库"></a><strong>非编码RNA序列数据库</strong></h2><p>RNAcentral</p><h1 id="四-代谢数据库"><a href="#四-代谢数据库" class="headerlink" title="四. 代谢数据库"></a>四. <strong>代谢数据库</strong></h1><h3 id="MapMan"><a href="#MapMan" class="headerlink" title="MapMan"></a>MapMan</h3><p>mapman.gabipd.org 一个功能强大的代谢途径查看和编辑软件</p><h2 id="代谢通路数据库"><a href="#代谢通路数据库" class="headerlink" title="代谢通路数据库"></a>代谢通路数据库</h2><h3 id="KEGG"><a href="#KEGG" class="headerlink" title="KEGG"></a>KEGG</h3><p><a href="https://zhuanlan.zhihu.com/p/96008506">https://zhuanlan.zhihu.com/p/96008506</a></p><p><strong>1. 介绍</strong></p><p>1995年开发的KEGG数据库，全称为 Kyoto Encyclopedia of Genes and Genomes（京都基因与基因组百科全书）。拥有多个子数据库，包含基因组，生化反应，生化物质，疾病与药物，以及最常用PATHWAY通路信息。</p><img src="2022-05-29-BioDatabase/3.png" alt="img" style="zoom:50%;" /><img src="./3.png" alt="img" style="zoom:50%;" /><p><strong>2. KEGG的数据库构成</strong></p><img src="2022-05-29-BioDatabase/4.png" alt="img" style="zoom:50%;" /><img src="./4.png" alt="img" style="zoom:50%;" /><p><font color="red"><strong>3. KEGG PATHWAY 数据库</strong></font></p><p>所有子数据库中最重要也最常用的是<strong>KEGG PATHWAY</strong>，包括大量由科研人员根据已有文献，手动绘制的KEGG通路图，代表代谢过程，环境信息过程，细胞过程，生物系统，人类疾病和药物开发。</p><p>每个通路都由一个五位数字标识，后跟以下任意一个：map，ko，ec，rn和三字母或四字母生物代码，它们分别代表五种通路类型：</p><ul><li><strong>map编号</strong>：代表reference pathway，根据已有的知识绘制的、概括的、详尽的具有一般参考意义的代谢图。 <font color="blue">一个点</font>同时表示一个基因，这个基因编码的酶或这个酶参加的反应 </li><li><strong>org编号</strong>：<font color="blue">物种特异性通路</font>，这里就是将K编号基因（直系同源基因，后面介绍）换为每个物种中对应的基因</li><li><strong>ko编号</strong>：KO通路中的点表示<font color="blue">直系同源基因 </font></li><li><strong>ec编号</strong>：EC通路中的<font color="blue">点表示相关的酶 </font></li><li><strong>rn编号</strong>：化学反应通路中的点只表示该点参与的某个反应、反应物及反应类型</li></ul><p>在了解每种通路之前先学会在KEGG中切换每种通路类型</p><p><a href="https://www.kegg.jp/kegg-bin/show_pathway?org_name=map&amp;mapno=00020&amp;mapscale=&amp;show_description=hide">https://www.kegg.jp/kegg-bin/show_pathway?org_name=map&amp;mapno=00020&amp;mapscale=&amp;show_description=hide</a></p><p>进入<a href="https://www.kegg.jp/kegg-bin/show_pathway?org_name=map&mapno=00020&mapscale=&show_description=hide">TCA循环</a> ，点击<code>change pathway type</code> 按钮：</p><img src="2022-05-29-BioDatabase/5.png" alt="img" style="zoom:50%;" /><img src="./5.png" alt="img" style="zoom:50%;" /><p><strong>3.1 参考通路图 (map)</strong></p><p>以 <a href="https://link.zhihu.com/?target=https://www.kegg.jp/kegg-bin/show_pathway?org_name=map&mapno=00020&mapscale=&show_description=hide">TCA循环</a> 的通路图为例，进入参考通路图(Reference pathway)。这是原始版本的通路，也是后续几种通路图的”模板”。每个白框可以代表直系同源基因，酶，反应，也可以点击链接至KO，ENZYME和REACTION详细信息。</p><p>形状，箭头，线段的意义</p><img src="2022-05-29-BioDatabase/6.png" alt="img" style="zoom:50%;" /><img src="./6.png" alt="img" style="zoom:50%;" /><p><strong>3.2 物种特异性通路 (org)</strong></p><p>选择人的物种名<code>Homo sapiens (human)</code>，点击<code>Go</code>。可以看到与Reference pathway 图（map00020）不同的是有物种特异性基因被标注为绿色，而且通路编号为<code>hsa00020</code></p><p>点击绿色基因，会进入<code>Gene</code>详细信息</p><p><strong>3.3 直系同源物通路 (ko)</strong></p><p>选择ko，蓝色框超链接到从原始版本中选择的KO条目</p><p>进入<code>PCK</code>的直系同源基因信息</p><p><strong>3.4 酶通路 (ec)</strong></p><p>选择ec，蓝色框超链接到从原始版本中选择的ENZYME条目</p><p><strong>3.5 反应通路 (reaction)</strong></p><p>选择rn，蓝色框超链接到从原始版本中选择的反应条目</p><p><strong>4. KEGG ORTHOLOGY（KO）数据库</strong></p><p>KEGG ORTHOLOGY （KO）数据库是构建Pathway和Module的基础，相当于KEGG数据库构建的基石，理解KO数据库的构成对于使用及了解KEGG至关重要。</p><p>KEGG的开发者根据不同生物之间基因和基因组的保守和变异，引入<font color="blue">直系同源物（KO）</font>的概念，使得KEGG通路图，BRITE层次结构和KEGG模块的参考数据集可以广泛应用于任何细胞生物。</p><p><strong>4.1 KO号</strong>：表示<strong>不分物种的通路</strong>，相当于所有物种的这一通路的并集，比如<code>ko00020</code>代表的 <a href="https://link.zhihu.com/?target=https://www.kegg.jp/kegg-bin/show_pathway?ko00020">TCA 循环</a> (下图所示)，下图的每个圆角矩形也代表着一个KO通路。</p><p><strong>4.2 K号</strong>：表示<strong>基因</strong>，每个号代表的是所有物种的一个同源基因，比如上图中的<code>K01596</code>代表的是 <a href="https://link.zhihu.com/?target=https://www.kegg.jp/dbget-bin/www_bget?K01596">PCK</a>。</p><p>进入K01596的<a href="https://link.zhihu.com/?target=https://www.kegg.jp/dbget-bin/www_bget?K01596">详细页面</a>，我们会看到它代表的是一个基因列表，这些基因具有一个功能却来自于不同的物种。</p><p><strong>4.3 C号</strong>：表示<strong>化合物</strong></p><hr><h3 id="GO"><a href="#GO" class="headerlink" title="GO"></a>GO</h3><p><a href="https://zhuanlan.zhihu.com/p/99789859">https://zhuanlan.zhihu.com/p/99789859</a></p><p><strong>1. 介绍</strong></p><p>读懂基因本体论（Gene Ontology）前，先看看什么是本体论：</p><p>本体论（Ontology ）是探究世界的本原或基质的哲学理论 。</p><p>本体论通常处理的问题：存在哪些本质，如何将这些本质分组，在层次结构内关联以及如何根据相似性和差异进行细分 。</p><p>基因本体论（Gene Ontology）包含生物学领域知识体系本质的表示形式，本体通常由一组类（或术语或概念）组成，它们之间具有关系。 基因本体论（GO）从三个方面（GO domains）描述了我们对生物学领域的了解：</p><p><strong>1.1 分子功能（Molecular Function，MF ）</strong></p><p><strong>单个的基因产物（包括蛋白质和RNA）或多个基因产物的复合物在分子水平上的活动</strong>，比如<font color="red"><strong>“催化”，“转运”</strong></font></p><p>此处描述只表示活动，而不指定执行功能的实体（分子或复合物），动作发生的地点，时间或背景</p><p>广义上例子是<font color="blue">催化活性和转运蛋白活性</font>。具体例子是<font color="blue">腺苷酸环化酶活性或Toll样受体结合</font></p><p><font color="blue">为避免基因产物名与其分子功能混淆，GO分子功能通常<strong>附加“活性（activity）”一词</strong>。如蛋白激酶（protein kinase）具有GO分子功能：蛋白激酶活性（ protein kinase activity）</font></p><p><strong>1.2. 细胞组分（Cellular Component ，CC）</strong>**</p><p><strong>基因产物在执行功能时所处的细胞结构位置</strong>，比如线粒体，核糖体</p><p>需要注意：细胞组分是<font color="blue">细胞解刨结构</font>，不指代过程</p><p><strong>1.3. 生物过程（Biological Process ，BP）</strong>**</p><p><strong>通过多种分子活动完成的生物学过程</strong></p><p>广义上的例子是<font color="red"><strong>DNA修复或信号转导</strong></font>。更加具体的例子是<font color="blue">嘧啶核苷生物合成过程或葡萄糖跨膜转运</font></p><p>需要注意：<font color="blue">生物学过程不等同于通路</font>。目前GO没有表示完整的通路信息所需的动力学或依赖性的描述信息</p><p>举例，在基因本体论GO的角度来解释一个基因：</p><p>基因产物：细胞色素C（cytochrome c）</p><p>分子功能：氧化还原酶活性</p><p>细胞组分：线粒体基质</p><p>生物过程：氧化磷酸化</p><hr><ul><li><a href="https://link.zhihu.com/?target=https://www.ncbi.nlm.nih.gov/biosystems">NCBI BioSystems</a></li><li><a href="https://link.zhihu.com/?target=http://imp.princeton.edu/">IMP</a></li><li><a href="https://link.zhihu.com/?target=https://www.plantcyc.org/">plantCyc</a></li><li><a href="https://zhuanlan.zhihu.com/p/79626339/">MANET</a></li><li><a href="https://zhuanlan.zhihu.com/p/79626339/">MetaNetX</a></li></ul><h2 id="代谢组学常用数据库"><a href="#代谢组学常用数据库" class="headerlink" title="代谢组学常用数据库"></a><strong>代谢组学常用数据库</strong></h2><ul><li><a href="https://link.zhihu.com/?target=https://www.ebi.ac.uk/metabolights/">MataboLights</a></li><li><a href="https://link.zhihu.com/?target=http://www.hmdb.ca/">HMDB</a></li><li><a href="https://link.zhihu.com/?target=http://www.ymdb.ca/">YMDB</a></li><li><a href="https://link.zhihu.com/?target=http://ecmdb.ca/">ECMDB</a></li></ul><h2 id="表型数据库"><a href="#表型数据库" class="headerlink" title="表型数据库"></a><strong>表型数据库</strong></h2><ul><li><a href="https://link.zhihu.com/?target=http://www.planteome.org/">Planteome</a></li><li><a href="https://link.zhihu.com/?target=https://www.ncbi.nlm.nih.gov/gap/">dbGaP</a></li><li><a href="https://link.zhihu.com/?target=https://www.plant-phenotyping.org/">IPPN</a></li></ul><h1 id="五-序列比对"><a href="#五-序列比对" class="headerlink" title="五. 序列比对"></a>五. 序列比对</h1><h2 id="序列与数据库比对"><a href="#序列与数据库比对" class="headerlink" title="序列与数据库比对"></a><strong>序列与数据库比对</strong></h2><h3 id="Blast"><a href="#Blast" class="headerlink" title="Blast"></a>Blast</h3><p>blast.ncbi.nlm.nih.gov&#x2F;Blast.cgi</p><hr><h2 id="多序列间比对"><a href="#多序列间比对" class="headerlink" title="多序列间比对"></a><strong>多序列间比对</strong></h2><h3 id="Clustal"><a href="#Clustal" class="headerlink" title="Clustal"></a>Clustal</h3><h2 id="序列进化树分析"><a href="#序列进化树分析" class="headerlink" title="序列进化树分析"></a><strong>序列进化树分析</strong></h2><h3 id="MEGA"><a href="#MEGA" class="headerlink" title="MEGA"></a>MEGA</h3><p><a href="https://zhuanlan.zhihu.com/p/141835886">https://zhuanlan.zhihu.com/p/141835886</a></p><p><a href="https://zhuanlan.zhihu.com/p/36598434">https://zhuanlan.zhihu.com/p/36598434</a></p><h1 id="六-基因分析"><a href="#六-基因分析" class="headerlink" title="六. 基因分析"></a>六. 基因分析</h1><h2 id="基因信息"><a href="#基因信息" class="headerlink" title="基因信息"></a>基因信息</h2><p><a href="https://link.zhihu.com/?target=https://www.genecards.org/">GeneCard</a></p><p><a href="https://link.zhihu.com/?target=https://en.wikipedia.org/wiki/Wikipedia:Gene_Wiki">Gene Wiki</a></p><h2 id="基因注释"><a href="#基因注释" class="headerlink" title="基因注释"></a><strong>基因注释</strong></h2><ul><li><a href="https://link.zhihu.com/?target=https://blast.ncbi.nlm.nih.gov/Blast.cgi">Blast</a></li><li><a href="https://link.zhihu.com/?target=http://www.ebi.ac.uk/interpro/">Interproscan</a></li><li><a href="https://link.zhihu.com/?target=http://wego.genomics.org.cn/">WEGO</a></li><li><a href="https://link.zhihu.com/?target=https://www.genome.jp/tools/kaas/">KAAS</a></li></ul><h2 id="基因功能预测"><a href="#基因功能预测" class="headerlink" title="基因功能预测"></a><strong>基因功能预测</strong></h2><ul><li><a href="https://link.zhihu.com/?target=http://linux1.softberry.com/berry.phtml?topic=fgenesh&group=programs&subgroup=gfind">FGENESH</a></li><li><a href="https://link.zhihu.com/?target=http://bioinf.uni-greifswald.de/augustus/submission.php">AUGUSTUS</a></li><li><a href="https://link.zhihu.com/?target=http://argonaute.mit.edu/GENSCAN.html">GENESCAN</a></li><li><a href="https://link.zhihu.com/?target=http://topaz.gatech.edu/GeneMark/">GeneMark</a></li><li><a href="https://link.zhihu.com/?target=http://ccb.jhu.edu/software/glimmer/index.shtml">Glimmer</a></li></ul><h2 id="基因结构预测"><a href="#基因结构预测" class="headerlink" title="基因结构预测"></a><strong>基因结构预测</strong></h2><ul><li><a href="https://link.zhihu.com/?target=http://wormweb.org/exonintron">Exon-Intron Graphic Maker</a> 根据候选基因的外显子和内含子等信息绘制基因结构</li><li><a href="https://link.zhihu.com/?target=https://blast.ncbi.nlm.nih.gov/Blast.cgi?PROGRAM=blastp&PAGE_TYPE=BlastSearch&LINK_LOC=blasthome">Blastp</a> 可在线获取蛋白结构域的注释和位置信息</li></ul><h2 id="同源基因分析"><a href="#同源基因分析" class="headerlink" title="同源基因分析"></a><strong>同源基因分析</strong></h2><p>OrthoDB是直系同源物的综合目录</p><h2 id="亚细胞定位预测"><a href="#亚细胞定位预测" class="headerlink" title="亚细胞定位预测"></a><strong>亚细胞定位预测</strong></h2><p>PSORT Prediction</p><h2 id="启动子分析"><a href="#启动子分析" class="headerlink" title="启动子分析"></a><strong>启动子分析</strong></h2><p>Plantcare</p><h2 id="调控目的基因的miRNA预测"><a href="#调控目的基因的miRNA预测" class="headerlink" title="调控目的基因的miRNA预测"></a><strong>调控目的基因的miRNA预测</strong></h2><p>psRNAtarget</p><h2 id="表达分析"><a href="#表达分析" class="headerlink" title="表达分析"></a><strong>表达分析</strong></h2><ul><li><a href="https://link.zhihu.com/?target=https://www.ebi.ac.uk/arrayexpress%3E/">ArrayExpress</a><br>数据来自EMBL的高通量功能基因组学实验的数据；</li><li><a href="https://link.zhihu.com/?target=http://bar.utoronto.ca/">BAR</a><br>在分析基因功能时，通常会参考基因的表达模式，即基因在植物不同组织不同发育时期的表达丰度变化。通过在线分析网站BAR对候基因进行表达分析。 是一个植物生信分析资源网站，用该网站分析基因表达时，不仅可以获得基因表达模式的热图，还可以获得可视化的电子荧光图片，直观呈现基因在植物组织中的表达位置。</li></ul><h2 id="基因结构绘制"><a href="#基因结构绘制" class="headerlink" title="基因结构绘制"></a><strong>基因结构绘制</strong></h2><ul><li><a href="https://link.zhihu.com/?target=http://gsds.cbi.pku.edu.cn/">GSDS</a><br>Gene Structure Display Server，基于基因组注释文件绘制序列基因结构等功能</li></ul><h1 id="七-蛋白质分析"><a href="#七-蛋白质分析" class="headerlink" title="七. 蛋白质分析"></a>七. <strong>蛋白质分析</strong></h1><h3 id="1-蛋白二级三级结构预测及绘图"><a href="#1-蛋白二级三级结构预测及绘图" class="headerlink" title="1. 蛋白二级三级结构预测及绘图"></a><strong>1. 蛋白二级三级结构预测及绘图</strong></h3><ul><li><a href="https://link.zhihu.com/?target=http://www.biogem.org/tool/chou-fasman/">CFSSP</a></li><li><a href="https://link.zhihu.com/?target=https://npsa-prabi.ibcp.fr/cgi-bin/npsa_automat.pl?page=npsa_sopma.html">SOPMA</a></li><li><a href="https://link.zhihu.com/?target=https://www.predictprotein.org/">PredictProtein</a></li><li><a href="https://link.zhihu.com/?target=https://swissmodel.expasy.org/interactive">SWISS-MODEL</a></li></ul><h3 id="2-蛋白特性分析"><a href="#2-蛋白特性分析" class="headerlink" title="2.蛋白特性分析"></a><strong>2.蛋白特性分析</strong></h3><ul><li><a href="https://link.zhihu.com/?target=http://web.expasy.org/protparam/">ProtParam</a><br>蛋白特性分析是指蛋白的一些物理和化学参数，如分子量、等电点、氨基酸和原子组成、消光系数、半衰期、不稳定系数、脂肪族氨基酸指数、亲水性。这些参数，有助于进行蛋白的相关生化实验。比如在体外体系（大肠杆菌、酵母等）表达和纯化目的蛋白时，需要考虑蛋白的分子量、等电点、消光系数、不稳定系数和亲水性等。在酶活实验中，也需要根据这些参数优化实验体系。</li></ul><h3 id="3-蛋白亲疏水性分析"><a href="#3-蛋白亲疏水性分析" class="headerlink" title="3.蛋白亲疏水性分析"></a><strong>3.蛋白亲疏水性分析</strong></h3><ul><li><a href="https://link.zhihu.com/?target=https://web.expasy.org/protscale/">Protscale</a><br>蛋白氨基酸的亲疏水性主要由其侧链基团R，如果R只是H或是C、H两元素组成的话，都是疏水的，如果含有极性侧链基团，如-OH、-SH、-COOH、-NH2 等，则就是极性的（亲水的）。疏水性氨基酸有酪氨酸、色氨酸、苯丙氨酸、缬氨酸、亮氨酸、异亮氨酸、丙氨酸和蛋氨酸（甲硫氨酸）。疏水性氨基酸在蛋白质内部，在保持蛋白质的三级结构上，酶和基质、抗体和抗原间的相互作用等各种非共价键的分子结合方面，具有重要作用。</li></ul><h3 id="4-跨膜结构分析"><a href="#4-跨膜结构分析" class="headerlink" title="4.跨膜结构分析"></a><strong>4.跨膜结构分析</strong></h3><ul><li><a href="https://link.zhihu.com/?target=http://www.cbs.dtu.dk/services/TMHMM/">TMHMM</a><br>蛋白的跨膜结构分析对于预测蛋白的亚细胞定位密切相关。如果具有跨膜结构，蛋白很可能定位于细胞中与膜相关的结构，如细胞质膜、叶绿体膜或线粒体膜等内膜系统。此外，蛋白跨膜结构分析对于蛋白功能分析也有一定的帮助。比如某蛋白没有跨膜结构，但是亚细胞定位实验显示其可定位于膜相关结构，这说明该蛋白可能通过其他膜定位蛋白招募过去的。</li></ul><h3 id="5-信号肽分析"><a href="#5-信号肽分析" class="headerlink" title="5.信号肽分析"></a><strong>5.信号肽分析</strong></h3><ul><li><a href="https://link.zhihu.com/?target=http://www.cbs.dtu.dk/services/SignalP/">SignalP</a><br>峰信号位置为信号肽切割点，峰之前的序列为信号肽 信号肽是指引导新合成的蛋白质向分泌通路转移的短肽链，常位于蛋白的N-末端，负责把蛋白质引导到不同膜结构的亚细胞器内。编码分泌蛋白的mRNA在翻译时首先合成N末端的信号肽，它被信号肽识别蛋白(SRP)所识别，SRP将核糖体携带至内质网上，内质网膜上的 SPR 受体识别并与之结合。新合成蛋白在信号肽引导下到达内质网内腔，而信号肽则在信号肽酶的作用下被切除。由于它的引导，新生的多肽就能够通过内质网膜进入腔内，最终被分泌到胞外。在宿主菌中表达外源蛋白时，可用信号肽引导外源蛋白定位分泌到胞外，提高蛋白可溶性，在原核表达系统（大肠杆菌、芽孢杆菌等）和真核表达系统（如毕赤酵母）中均有应用。</li></ul><h3 id="6-磷酸化位点分析"><a href="#6-磷酸化位点分析" class="headerlink" title="6.磷酸化位点分析"></a><strong>6.磷酸化位点分析</strong></h3><ul><li><a href="https://link.zhihu.com/?target=http://www.cbs.dtu.dk/services/NetPhos/">NetPhos</a></li><li><a href="https://link.zhihu.com/?target=http://kinasephos2.mbc.nctu.edu.tw/">KinasePhos-2.0</a><br>蛋白质磷酸化指由蛋白质激酶催化的把 ATP 的磷酸基转移到底物蛋白质氨基酸残基（丝氨酸、苏氨酸、酪氨酸）上的过程，或者在信号作用下结合 GTP（通常以 GTP 取代 GDP），是生物体内一种普通的调节方式，在细胞信号转导的过程中起重要作用。在信号达到时通过获得一个或几个磷酸集团而被激活，而在信号减弱时能去除这些集团，从而失去活性。有时某个信号蛋白磷酸化通常造成下游的蛋白依次发生磷酸化，形成磷酸化级联反应。</li></ul><p>ref： <a href="https://zhuanlan.zhihu.com/p/79626339">https://zhuanlan.zhihu.com/p/79626339</a></p>]]></content>
    
    
    <categories>
      
      <category>Biology</category>
      
    </categories>
    
    
    <tags>
      
      <tag>database</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>ncRNA prediction</title>
    <link href="/GeekFocus/2022/05/29/2022-05-29-ncRNA-prediction/"/>
    <url>/GeekFocus/2022/05/29/2022-05-29-ncRNA-prediction/</url>
    
    <content type="html"><![CDATA[<p>ncRNA prediction</p><span id="more"></span><p><a href="http://www.eilersgenomics.com/annotation/rfam_infernal/">http://www.eilersgenomics.com/annotation/rfam_infernal/</a></p><h1 id="tRNAscanSE-2-0-9"><a href="#tRNAscanSE-2-0-9" class="headerlink" title="tRNAscanSE 2.0.9"></a>tRNAscanSE 2.0.9</h1><p><a href="http://trna.ucsc.edu/tRNAscan-SE/">http://trna.ucsc.edu/tRNAscan-SE/</a></p><h2 id="1-tRNAscan-SE-简介"><a href="#1-tRNAscan-SE-简介" class="headerlink" title="1. tRNAscan-SE 简介"></a>1. tRNAscan-SE 简介</h2><p>tRNAscan-SE 能在基因组水平进行 tRNA 扫描。该软件是一个 perl 脚本，整合 tRNAscan、 EufindRNA 和 Cove 这 3 个独立的 tRNA 检测软件。tRNAscan-SE 首先调用 tRNAscan 和 EufindRNA 鉴定基因组序列中的 tRNA 区域，然后调用 Cove 验证。既保证前者的 sensitivities， 又保证后者较低的假阳性概率，同时提高搜索速度。</p><h2 id="2-tRNAscan-SE-本地安装"><a href="#2-tRNAscan-SE-本地安装" class="headerlink" title="2. tRNAscan-SE 本地安装"></a>2. tRNAscan-SE 本地安装</h2><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs sh">./configure --prefix=<span class="hljs-built_in">local</span> &amp;&amp;  make &amp;&amp; make insatll<br><span class="hljs-built_in">echo</span>  <span class="hljs-variable">$PERL5LIB</span><br>-bash: /home/user/perl5/lib/perl5<br><span class="hljs-built_in">which</span> perl<br>/usr/bin/perl<br>no conda . fat or loginal. root perl, <span class="hljs-built_in">local</span> lib<br></code></pre></td></tr></table></figure><h2 id="3-使用与参数"><a href="#3-使用与参数" class="headerlink" title="3. 使用与参数"></a>3. 使用与参数</h2><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs sh">tRNAscan-SE -o tRNA.out -f rRNA.ss -m tRNA.stats genome.fasta<br><span class="hljs-comment">#-E         : search for eukaryotic tRNAs (default)</span><br><span class="hljs-comment">#  -f &lt;file&gt;  : save tRNA secondary structures to &lt;file&gt;将 tRNA 的二级结构结果保存到文件</span><br><span class="hljs-comment">#  -m &lt;file&gt;  : save statistics summary for run in &lt;file&gt;将统计结果保存到文件</span><br></code></pre></td></tr></table></figure><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs sh">-- default: use Infernal &amp; tRNA covariance models with eukaryotic sequences <br>             (use -B, -A, -M, -O or -G to scan other types of sequences)<br></code></pre></td></tr></table></figure><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-comment"># types of sequences</span><br> -B         : search <span class="hljs-keyword">for</span> bacterial tRNAs<br> -A         : search <span class="hljs-keyword">for</span> archaeal tRNAs. 古细菌。该参数选择古细菌特异性的协方差模型，同时稍微放宽 EufindtRNA 的 cutoffs<br> -M &lt;model&gt; : search <span class="hljs-keyword">for</span> mitochondrial tRNAs<br>                options: mammal, vert<br> -O         : search <span class="hljs-keyword">for</span> other organellar tRNAs. 线粒体和叶绿体。该参数仅使用 Cove 进行分析，搜索速度会很慢，同时不能给出 pseudogenes 检测。<br> -G         : use general tRNA model (cytoslic tRNAs from all 3 domains included)古细菌，细菌和真核生物的混合序列。使用 general tRNA 协方差模型。<br></code></pre></td></tr></table></figure><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs sh">-L         : search using the legacy method (tRNAscan, EufindtRNA, and COVE)<br>               use with -E, -B, -A, -O, or -G<br>-I         : search using Infernal (default)<br>               use with -E, -B, -A, -O, or -G<br>-o &lt;file&gt;  : save final results <span class="hljs-keyword">in</span> &lt;file&gt;结果文件<br>-f &lt;file&gt;  : save tRNA secondary structures to &lt;file&gt;将 tRNA 的二级结构结果保存到文件<br>-m &lt;file&gt;  : save statistics summary <span class="hljs-keyword">for</span> run <span class="hljs-keyword">in</span> &lt;file&gt;将统计结果保存到文件<br>             (speed, <span class="hljs-comment"># tRNAs found in each part of search, etc)</span><br>-H         : show both primary and secondary structure components to<br>             covariance model bit scores<br>-q         : quiet mode (credits &amp; run option selections suppressed)<br></code></pre></td></tr></table></figure><h2 id="4-结果说明"><a href="#4-结果说明" class="headerlink" title="4. 结果说明"></a>4. 结果说明</h2><p>真核生物tRNA 由 RNA 聚合酶III 在核内转录生成 pre-tRNA, 再进行加工生成有功能的 tRNA 分子（特别是一些 tRNA 序列还含有内含子）。若 tRNA 存在内含子，则结果文件中第 7 8 列会给出内含子区间，否则其值为 0 。<br>tRNAscan-SE 的结果中, 如果 begin 比 end 的值大，则表示 tRNA 在负义链。</p><p>有些结果中第 5 列为 pseudogene， 这表示其一级或二级结构比较差。</p><p>最后一列是 Cove Score，该分值最低阈值为 20 。该值是一个 log ratio值。ratio 是符合 tRNA 协方差模型概率与随机序列模型概率的比值。</p><p>最后最好是将表格格式结果转换为 GFF3 结果，以利于在基因组上的可视化。</p><h2 id="5-过滤"><a href="#5-过滤" class="headerlink" title="5. 过滤"></a>5. 过滤</h2><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs sh">Usage: EukHighConfidenceFilter [options]<br>Options<br>--result -i &lt;file&gt;         tRNAscan-SE output file used as input<br>--ss -s &lt;file&gt;             tRNAscan-SE secondary structure file used as input<br>--output -o &lt;file path&gt;    Directory <span class="hljs-built_in">where</span> output files will be written<br>--prefix -p &lt;name&gt;         Prefix <span class="hljs-keyword">for</span> output file name<br>--remove -r                Remove filtered tRNA hits (default: filtered tRNA hits are only tagged)<br>--cmscore1 -c1 &lt;num&gt;       Domain-specific model score cutoff <span class="hljs-keyword">for</span> secondary filtering (default = 50; -1 <span class="hljs-keyword">if</span> not used <span class="hljs-keyword">for</span> filtering)<br>--ssscore1 -m1 &lt;num&gt;       Secondary structure score cutoff <span class="hljs-keyword">for</span> secondary filtering (default = 10; -1 <span class="hljs-keyword">if</span> not used <span class="hljs-keyword">for</span> filtering)<br>--isoscore1 -e1 &lt;num&gt;      Isotype-specific model score cutoff <span class="hljs-keyword">for</span> secondary filtering (default = 70; -1 <span class="hljs-keyword">if</span> not used <span class="hljs-keyword">for</span> filtering)<br>--isoscore2 -e2 &lt;num&gt;      Isotype-specific model starting score cutoff <span class="hljs-keyword">for</span> tertiary filtering (default = 70; -1 <span class="hljs-keyword">if</span> not used <span class="hljs-keyword">for</span> filtering)<br>--isomaxscore2 -x &lt;num&gt;    Maximum isotype-specific model score cutoff <span class="hljs-keyword">for</span> tertiary filtering (default = 95)<br>--<span class="hljs-built_in">help</span> -h                  Print this <span class="hljs-built_in">help</span><br><br></code></pre></td></tr></table></figure><h2 id="error"><a href="#error" class="headerlink" title="error"></a>error</h2><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs sh">FATAL: Unable to find /xtdisk/xueyb_group/wangchenA/software/opt/biosoft/tRNAscan-SE/bin/cmsearch executable<br><span class="hljs-comment">#https://bioinformatics.stackexchange.com/questions/4637/trnascan-se-error-fatal-unable-to-find-usr-local-bin-cmsearch-executable</span><br><br>tRNAscan-SE 2.0 requires separate installation of Infernal 1.1.2. The <span class="hljs-built_in">source</span> code and prebuilt binaries can be obtained at http://eddylab.org/infernal/.<br><br>The installation directory of Infernal should be the same as the one <span class="hljs-built_in">where</span> tRNAscan-SE 2.0 is installed.<br><br>When install infernal, run the configure <span class="hljs-built_in">command</span> with the option --prefix &lt;your tRNAscan-SE-2.0 install path&gt;. If you didn<span class="hljs-string">&#x27;t add option --prefix when installing tRNAscan-SE-2.0, then you should install infernal without option --prefix.</span><br></code></pre></td></tr></table></figure><h2 id="error2-still"><a href="#error2-still" class="headerlink" title="error2 still"></a>error2 still</h2><figure class="highlight subunit"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs subunit"><span class="hljs-keyword">Error: </span>This filter requires isotype-specific model scan result in the tRNAscan-SE v2 output file.<br><br></code></pre></td></tr></table></figure><h1 id="Infernal"><a href="#Infernal" class="headerlink" title="Infernal"></a>Infernal</h1><p><a href="http://eddylab.org/infernal/">http://eddylab.org/infernal/</a></p><p>User-guide: <a href="http://eddylab.org/infernal/Userguide.pdf">http://eddylab.org/infernal/Userguide.pdf</a></p><h2 id="1-安装在tRNAscanSE文件夹内"><a href="#1-安装在tRNAscanSE文件夹内" class="headerlink" title="1. 安装在tRNAscanSE文件夹内"></a>1. 安装在tRNAscanSE文件夹内</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">cd</span> tRNAscanSE<br><span class="hljs-built_in">cd</span> infernal<br>./configure --prefix=/path/tRNAscan-SE<br>make<br>make install<br></code></pre></td></tr></table></figure><p>内部再安装</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs awk">cd easel/<br>.<span class="hljs-regexp">/configure --prefix=/</span>path<span class="hljs-regexp">/tRNAscan-SE/</span>bin<br>make<br>make install<br></code></pre></td></tr></table></figure><h2 id="2-数据库下载"><a href="#2-数据库下载" class="headerlink" title="2. 数据库下载"></a>2. 数据库下载</h2><p>Rfam数据库<a href="https://rfam.xfam.org/">https://rfam.xfam.org</a></p><p>The Rfam database is a collection of RNA families, each represented by <strong>multiple sequence alignments,consensus secondary structures and covariance models</strong></p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-built_in">mkdir</span> 00.rd6.ncRNA<br><span class="hljs-built_in">cd</span> 00.rd6.ncRNA/<br><span class="hljs-built_in">mkdir</span> Rfam<br><br><span class="hljs-built_in">mkdir</span> Rfam &amp;&amp; <span class="hljs-built_in">cd</span> Rfam  <br>http://ftp.ebi.ac.uk/pub/databases/Rfam/14.8/<br><br>wget ftp://ftp.ebi.ac.uk/pub/databases/Rfam/14.8/Rfam.cm.gz<br>gunzip Rfam.cm.gz<br>wget ftp://ftp.ebi.ac.uk/pub/databases/Rfam/14.8/Rfam.clanin<br><span class="hljs-comment"># 使用 Infernal的程序cmpress索引Rfam.cm # 大约需要一分钟</span><br>tRNAscan-SE/bin/cmpress Rfam.cm<br><br><span class="hljs-comment">#my</span><br>Working...    <span class="hljs-keyword">done</span>.<br>Pressed and indexed 4094 CMs and p7 HMM filters (4094 names and 4094 accessions).<br>Covariance models and p7 filters pressed into binary file:  Rfam.cm.i1m<br>SSI index <span class="hljs-keyword">for</span> binary covariance model file:                 Rfam.cm.i1i<br>Optimized p7 filter profiles (MSV part)  pressed into:      Rfam.cm.i1f<br>Optimized p7 filter profiles (remainder) pressed into:      Rfam.cm.i1p<br><br><span class="hljs-comment"># 输出为</span><br>Working...    <span class="hljs-keyword">done</span>.<br>Pressed and indexed 3016 CMs and p7 HMM filters (3016 names and 3016 accessions).<br>Covariance models and p7 filters pressed into binary file:  Rfam14.1.cm.i1m<br>SSI index <span class="hljs-keyword">for</span> binary covariance model file:                 Rfam14.1.cm.i1i<br>Optimized p7 filter profiles (MSV part)  pressed into:      Rfam14.1.cm.i1f<br>Optimized p7 filter profiles (remainder) pressed into:      Rfam14.1.cm.i1p<br></code></pre></td></tr></table></figure><h2 id="3-确定待查询的核苷酸序列或基因组的大小，作为后续命令的参数"><a href="#3-确定待查询的核苷酸序列或基因组的大小，作为后续命令的参数" class="headerlink" title="3. 确定待查询的核苷酸序列或基因组的大小，作为后续命令的参数"></a>3. 确定待查询的核苷酸序列或基因组的大小，作为后续命令的参数</h2><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-comment">#esl-seqstat my-genome.fa</span><br>tRNAscan-SE/bin/bin/esl-seqstat my-genome.fa<br></code></pre></td></tr></table></figure><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs sh">Format:              FASTA<br>Alphabet <span class="hljs-built_in">type</span>:       DNA<br>Number of sequences: 7<br>Total <span class="hljs-comment"># residues:    1242924374</span><br>Smallest:            159833148<br>Largest:             221855282<br>Average length:      177560624.0<br>Z=1242924374*2*4094/1000000=10177064<br><br>Format:              FASTA<br>Alphabet <span class="hljs-built_in">type</span>:       DNA<br>Number of sequences: 7<br>Total <span class="hljs-comment"># residues:    1218819104</span><br>Smallest:            156984786<br>Largest:             222281709<br>Average length:      174117008.0<br>Z=1218819104*2*4094/1000000=9979690<br></code></pre></td></tr></table></figure><p>其输出结果中有一行，Total # of residues: 218502668是需要的。考虑到基因组为双链和下一步用到的参数的单位为Million。<br>计算公式为：Z &#x3D; total * 2 * CMmumber&#x2F;106<br>因此还要计算CM database中的模型的数量（Z&#x3D;2636016）<br>在Rfam14.0版本中，使用</p><h2 id="4-Some-user-guide"><a href="#4-Some-user-guide" class="headerlink" title="4. Some user guide"></a>4. Some user guide</h2><p><a href="http://eddylab.org/infernal/Userguide.pdf">http://eddylab.org/infernal/Userguide.pdf</a></p><p>Searching the Rfam CM database with a query sequence**</p><p>The Rfam database <a href="http://rfam.xfam.org/">http://rfam.xfam.org/</a> is <font color="blue">a collection of RNA families</font>, each represented by a CM and multiple sequence alignment used to build that CM. As of December 2020, the current release is 14.3, which includes 3446 families[<font color="blue">v14.8 4094</font>]. The Rfam website allows <font color="blue">web-based searches using <strong>cmscan</strong> of the <strong>Rfam CM database</strong> against <strong>query sequences</strong> that the user can upload</font>. Alternatively, you can perform the same searches by running cmscan locally, as shown in this example. <font color="blue">By searching all of Rfam with your sequence dataset</font>, you will <font color="red"><strong>annotate most known types of structural RNAs with a single command</strong></font>.</p><p>To complete this step of the tutorial you’ll need to download the Rfam 14.3 CM file from here:<a href="ftp://ftp.ebi.ac.uk/pub/databases/Rfam/14.3/Rfam.cm.gz">ftp://ftp.ebi.ac.uk/pub/databases/Rfam/14.3/Rfam.cm.gz</a> and gunzipping it, like this:</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs sh">wget ftp://ftp.ebi.ac.uk/pub/databases/Rfam/14.3/Rfam.cm.gz<br>gunzip Rfam.cm.gz<br>cmpress Rfam.cm<br></code></pre></td></tr></table></figure><p>The next step is to run cmscan. In order to reproduce how Rfam searches are performed (Nawrocki et al., 2015) several command line options are required. Each of these options is explained below. The full command is :</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs sh">cmscan --rfam --cut_ga --nohmmonly --tblout mrum-genome.tblout --<span class="hljs-built_in">fmt</span> 2 \<br>--clanin tutorial/Rfam.14.3.clanin Rfam.cm tutorial/mrum-genome.fa &gt; mrum-genome.cmscan<br></code></pre></td></tr></table></figure><p>This command will take at least several minutes and possibly up to about 30 minutes depending on the number of cores and speed of your computer. 对500M大小的输入序列，48线程，要7小时</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs sh">--rfam Specifies that the filter pipeline run <span class="hljs-keyword">in</span> fast mode, with the same strict filters that are used <span class="hljs-keyword">for</span> Rfam searches and <span class="hljs-keyword">for</span> other sequence databases larger than 20 Gb (see section 4).<br><br>--cutga SpecifiesthatthespecialRfam*GA*(gathering)thresholdsbeusedtodeterminewhichhitsarereported. These thresholds are stored <span class="hljs-keyword">in</span> the Rfam.cm file. Each model has its own GA bit score threshold, <span class="hljs-built_in">which</span> was determined by Rfam curators as the bit score at and above <span class="hljs-built_in">which</span> all hits are believed to be <span class="hljs-literal">true</span> homologs to the model. These determinations were made based on observed hit results against the large Rfamseq database used by Rfam (Nawrocki et al., 2015).<br><br>--nohmmonly All models, even those with zero basepairs, are run <span class="hljs-keyword">in</span> CM mode (not HMM mode). This ensures all GA cutoffs, <span class="hljs-built_in">which</span> were determined <span class="hljs-keyword">in</span> CM mode <span class="hljs-keyword">for</span> each model, are valid.<br><br>--tblout Specifies that a tabular output file should be created, see section 6.<br><br>--<span class="hljs-built_in">fmt</span> 2 The tabular output file will be <span class="hljs-keyword">in</span> format 2, <span class="hljs-built_in">which</span> includes annotation of overlapping hits. See page 61 <span class="hljs-keyword">for</span> a complete description of this format.<br><br>--clanin Clan information should be <span class="hljs-built_in">read</span> from the file tutorial/Rfam.14.3.claninfo. This file lists <span class="hljs-built_in">which</span> models belong to the same clan. Clans are <span class="hljs-built_in">groups</span> of models that are homologous and therefore it is expected that some hits to these models will overlap. For example, the LSU rRNA archaea and LSU rRNA bacteria models are both <span class="hljs-keyword">in</span> the same clan.<br></code></pre></td></tr></table></figure><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs sh">-g Turn on the glocal alignment algorithm, global with respect to the query model and <span class="hljs-built_in">local</span> with respect to the target database. By default, the <span class="hljs-built_in">local</span> alignment algorithm is used <span class="hljs-built_in">which</span> is <span class="hljs-built_in">local</span> with respect to both the target sequence and the model. In <span class="hljs-built_in">local</span> mode, the alignment to span two or more subsequences <span class="hljs-keyword">if</span> necessary (e.g. <span class="hljs-keyword">if</span> the structures of the query model and target sequence are only partially shared), allowing certain large insertions and deletions <span class="hljs-keyword">in</span> the structure to be penalized differently than normal indels. Local mode performs better on empirical benchmarks and is significantly more sensitive <span class="hljs-keyword">for</span> remote homology detection. Empirically, glocal searches <span class="hljs-built_in">return</span> many fewer hits than <span class="hljs-built_in">local</span> searches, so glocal may be desired <span class="hljs-keyword">for</span> some applications.<br>-Z &lt;x&gt; Calculate E-values as <span class="hljs-keyword">if</span> the search space size was &lt;x&gt; megabases (Mb). Without the use of this option, the search space size changes <span class="hljs-keyword">for</span> each query sequence, it is defined as the length of the current query sequence <span class="hljs-built_in">times</span> 2 (because both strands of the sequence will be searched) <span class="hljs-built_in">times</span> the number of CMs <span class="hljs-keyword">in</span> &lt;cmdb&gt;.<br></code></pre></td></tr></table></figure><p>When the cmscan command finishes running, the file mrum-genome.cmscan will contain the standard output of the program. This file will be similar to what we saw in the earlier example of cmscan. The file mrum-genome.tblout has also been created, which is a tabular representation of all hits, one line per hit. Take a look at this file. The first two lines are comment lines (prefixed with # characters) with the labels of each of the 27 columns of data in the file. Each subsequent line has 27 space delimited tokens. The specific meaning of these tokens is described in detail in section 6. Below I’m including the first 24 lines of the file, with columns 3-5, 7-9 and 13-16 removed (replaced with …) so that the text will fit on this page:</p><p>This tabular format includes the target model name, sequence name (in column 3, which is omitted above to save space), clan name, sequence coordinates, bit score, E-value and more. Because the –fmt 2 option was used, this file includes information on which hits overlap with other hits, starting at the column labelled “olp” and ending with “wfrct2”. Hits with the “*” character in the “olp” column do not overlap with any other hits. Those with “ˆ” do overlap with at least one other hit, but none of those overlapping hits have a better score (that occurs higher in the list). Those with “&#x3D;” also overlap with at least one other hit that does have a better score, the index of which is given in the “anyidx” column. For more detailed explanation of these columns, see page 61.</p><p>The top two hits are both to the LSU rRNA archaea model. These are the two copies of LSU rRNA in the <em>Methanobrevibacter ruminantium</em> genome. Hits number 3 and 4 are to the LSU rRNA bacteria model and over- lap with hits 1 and 2 nearly completely (hit 1 is from sequence positions 762872 to 765862 and hit 3 is from sequence positions 762874 to 765862). This overlap is not surprising because the bacterial and archaeal LSU rRNA models are very similar, and so are assigning high scores to the same subsequences. Further, hit 5 is to LSU rRNA eukarya and also overlaps hits 1 and 3. Because these three LSU models are all expected to produce overlapping hits due to their homology, Rfam has grouped them into the same <em>clan</em>, note the “CL00112” value in the “clan name” column for all three hits. This clan information was provided in the rfam.14.3.claninfo input file we provided to cmscan by using the –clanin option.</p><p>The “olp” column indicates that hit 1 is the highest scoring of the three overlapping hits because it contains the “ˆ” character. Hits 3 and 5 both have “&#x3D;” in the “olp” column indicating that there is another hit to another model which overlaps these hits and has a better score.</p><p>If you were using these results to produce annotations for the <em>Methanobrevibacter ruminantium</em> genome, you may want to ignore any hits that have higher scoring overlaps. To do this you can just remove any hits with “&#x3D;” in the “olp” column. Alternatively, you can have these hits not printed to the tabular output file by additionally providing the –oskip option to cmscan. You can also modify the overlap annotation behavior with –oclan option which restricts the annotation of overlaps to hits for models within the same clan. Overlapping hits from models that are not in the same clan will not be marked as overlaps, instead they will marked as “*” in the “olp” field.</p><p>For more information on using Infernal for genome annotation see a similar example in the Rfam documentation (<a href="https://rfam.readthedocs.io/en/latest/genome-annotation.html">https://rfam.readthedocs.io/en/latest/genome-annotation.html</a>)</p><h2 id="5-Parameter-amp-Running"><a href="#5-Parameter-amp-Running" class="headerlink" title="5. Parameter &amp; Running"></a>5. Parameter &amp; Running</h2><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sh"><br></code></pre></td></tr></table></figure><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-comment"># Rfam14.1.clanin 为下载的claninfo文件，需提供所在路径</span><br><span class="hljs-comment"># Rfam.cm 下载的cm文件</span><br><span class="hljs-comment">#nep_genome.fa 待查询序列</span><br><span class="hljs-comment"># nep.cmscan 输出结果</span><br><span class="hljs-comment"># nep.tblout 表格形式输出结果</span><br><span class="hljs-comment"># 对500M大小的输入序列，48线程，需要7个小时，最好放入后台</span><br>cmscan -Z 2636016 --cut_ga --rfam --nohmmonly --tblout mep_genome.tblout --<span class="hljs-built_in">fmt</span> 2 --cpu 24 --clanin Rfam14.1.clanin Rfam.cm nep_genome.fa &gt; nep.cmscan<br></code></pre></td></tr></table></figure><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-comment">#official</span><br>cmscan --rfam --cut_ga --nohmmonly --tblout mrum-genome.tblout --<span class="hljs-built_in">fmt</span> 2 \<br>--clanin tutorial/Rfam.14.3.clanin Rfam.cm tutorial/mrum-genome.fa &gt; mrum-genome.cmscan<br></code></pre></td></tr></table></figure><h2 id="6-输出结果"><a href="#6-输出结果" class="headerlink" title="6. 输出结果"></a>6. 输出结果</h2><p>nep.tblout</p><figure class="highlight tap"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs tap"><span class="hljs-comment">#idx target name          accession query name           accession clan name mdl mdl from   mdl to seq from   seq to strand trunc pass   gc  bias  score   E-value inc olp anyidx afrct1 afrct2 winidx wfrct1 wfrct2 description of target</span><br><span class="hljs-comment">#--- -------------------- --------- -------------------- --------- --------- --- -------- -------- -------- -------- ------ ----- ---- ---- ----- ------ --------- --- --- ------ ------ ------ ------ ------ ------ ---------------------</span><br>1    mir-7                RF00053   contig_1000          -         -          cm       <span class="hljs-number"> 1 </span>     <span class="hljs-number"> 88 </span>  <span class="hljs-number"> 51272 </span>  <span class="hljs-number"> 51359 </span>     +    no   <span class="hljs-number"> 1 </span>0.38   0.0   58.2   1.9e-06  !   *       -      -      -      -      -      - mir-7 microRNA precursor<br>2    MIR1122              RF00906   contig_1000          -         -          cm       <span class="hljs-number"> 1 </span>    <span class="hljs-number"> 135 </span> <span class="hljs-number"> 137126 </span> <span class="hljs-number"> 137273 </span>     +    no   <span class="hljs-number"> 1 </span>0.20  26.4   37.6       4.1  ?   *       -      -      -      -      -      - microRNA MIR1122<br>1    tRNA                 RF00005   contig_10006         -         CL00001    cm       <span class="hljs-number"> 1 </span>     <span class="hljs-number"> 71 </span>    <span class="hljs-number"> 616 </span>    <span class="hljs-number"> 707 </span>     +    no   <span class="hljs-number"> 1 </span>0.53   0.0   49.7   0.00039  !   *       -      -      -      -      -      - tRNA<br>1    sno_ZL1              RF02723   contig_10010         -         -          cm      <span class="hljs-number"> 36 </span>    <span class="hljs-number"> 107 </span> <span class="hljs-number"> 101457 </span> <span class="hljs-number"> 101528 </span>     +    no   <span class="hljs-number"> 1 </span>0.28   0.1   31.7       3.2  ?   *       -      -      -      -      -      - Small nucleolar RNA ZL1<br>1    Histone3             RF00032   contig_10016         -         -          cm       <span class="hljs-number"> 1 </span>     <span class="hljs-number"> 46 </span> <span class="hljs-number"> 104440 </span> <span class="hljs-number"> 104394 </span>     -    no   <span class="hljs-number"> 1 </span>0.30   0.0   33.2     0.044  ?   *       -      -      -      -      -      - Histone 3&#x27; UTR stem-loop<br>1    LSU_rRNA_bacteria    RF02541   contig_10019         -         CL00112    cm       <span class="hljs-number"> 1 </span>   <span class="hljs-number"> 2925 </span>  <span class="hljs-number"> 51575 </span>  <span class="hljs-number"> 54339 </span>     +    no   <span class="hljs-number"> 1 </span>0.44  53.8 2654.9        <span class="hljs-number"> 0 </span> !   ^       -      -      -      -      -      - Bacterial large subunit ribosomal RNA<br>2    LSU_rRNA_archaea     RF02540   contig_10019         -         CL00112    cm       <span class="hljs-number"> 1 </span>   <span class="hljs-number"> 2990 </span>  <span class="hljs-number"> 51574 </span>  <span class="hljs-number"> 54338 </span>     +    no   <span class="hljs-number"> 1 </span>0.44  54.3 1799.6        <span class="hljs-number"> 0 </span> !   =      <span class="hljs-number"> 1 </span> 1.000  1.000      &quot;      &quot;      &quot; Archaeal large subunit ribosomal RNA<br><span class="hljs-comment">## 每一行有27列，比较关键的是`target name`, `accession`, `query name`, `seq from`, `seq to`, `strand`, `E-value`, `score`。</span><br>`olp`列表示查询序列的重叠信息，`*`表示同一条链上，不存在与此查询序列重叠的序列也在Rfam数据库有匹配，这是需要保留的查询序列。`^`表示同一条链上，不存在比此查询序列与Rfam数据库匹配更好的序列，也需要保留。`=`表示同一条链上，存在比此查询序列与Rfam数据库匹配更好的序列，应忽略。<br><span class="hljs-comment">## 可通过下面的命令获取最终结果。</span><br>​```bash<br>grep -v &#x27;=&#x27; nep.tblout &gt;nep .deoverlapped.tblout<br></code></pre></td></tr></table></figure><h2 id="7-结果解析"><a href="#7-结果解析" class="headerlink" title="7. 结果解析"></a>7. 结果解析</h2><p>得到tblout.final，</p><h3 id="1-转换下结果格式"><a href="#1-转换下结果格式" class="headerlink" title="1. 转换下结果格式"></a>1. 转换下结果格式</h3><p>得到tblout.final，转换下结果格式，提取必须得列和非重叠区域或重叠区域中得分高的区域。<br>&#x3D;表示同一条链上，存在比此查询序列与Rfam数据库匹配更好的序列，应忽略。<br>去掉#开头的注释行 提取所需要的列。初始将分隔符设定为制表符。<br>如果是第一行，打印行名称 第3行开始，如果20列不是等号，且不以井号开始，打印2,3,4等列输出</p><figure class="highlight swift"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs swift">awk &#x27;<span class="hljs-type">BEGIN</span>&#123;<span class="hljs-type">OFS</span><span class="hljs-operator">=</span><span class="hljs-string">&quot;<span class="hljs-subst">\t</span>&quot;</span>;&#125;&#123;<span class="hljs-keyword">if</span>(<span class="hljs-type">FNR</span><span class="hljs-operator">==</span><span class="hljs-number">1</span>) print <span class="hljs-string">&quot;target_name<span class="hljs-subst">\t</span>accession<span class="hljs-subst">\t</span>query_name<span class="hljs-subst">\t</span>query_start<span class="hljs-subst">\t</span>query_end<span class="hljs-subst">\t</span>strand<span class="hljs-subst">\t</span>score<span class="hljs-subst">\t</span>Evalue&quot;</span>; <span class="hljs-keyword">if</span>(<span class="hljs-type">FNR</span><span class="hljs-operator">&gt;</span><span class="hljs-number">2</span> <span class="hljs-operator">&amp;&amp;</span> <span class="hljs-variable">$20</span><span class="hljs-operator">!=</span><span class="hljs-string">&quot;=&quot;</span> <span class="hljs-operator">&amp;&amp;</span> <span class="hljs-variable">$0</span><span class="hljs-operator">!~/^</span>#<span class="hljs-operator">/</span>) print <span class="hljs-variable">$2</span>,<span class="hljs-variable">$3</span>,<span class="hljs-variable">$4</span>,<span class="hljs-variable">$10</span>,<span class="hljs-variable">$11</span>,<span class="hljs-variable">$12</span>,<span class="hljs-variable">$17</span>,<span class="hljs-variable">$18</span>; &#125;&#x27; nep.tblout <span class="hljs-operator">&gt;</span>nep_genome.tblout.final.xls<br></code></pre></td></tr></table></figure><h3 id="2-下载Rfam注释"><a href="#2-下载Rfam注释" class="headerlink" title="2. 下载Rfam注释"></a>2. 下载Rfam注释</h3><p><em>首先下载Rfam家族的注释，点击Rfam网址，选择所有复选框，提交，把得到的表格拷贝下来，整理成TAB键分割的格式。将第三列的第二个分号信息提取出来，这就是各ncRNA class</em></p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">cat</span> rfamannotation.txt | awk &#x27;BEGIN &#123;FS=OFS=<span class="hljs-string">&quot;\t&quot;</span>&#125;&#123;split($<span class="hljs-number">3</span>,x,<span class="hljs-string">&quot;;&quot;</span>);class=x[<span class="hljs-number">2</span>];print $<span class="hljs-number">1</span>,$<span class="hljs-number">2</span>,$<span class="hljs-number">3</span>,class&#125;&#x27; &gt; rfam_anno_class.txt<br></code></pre></td></tr></table></figure><h3 id="3-统计ncRNA数量"><a href="#3-统计ncRNA数量" class="headerlink" title="3. 统计ncRNA数量"></a>3. 统计ncRNA数量</h3><p><em>先读文件1，将列2和列4也就是名称和class按关系存入字典a。再读文件2，每一行，用自己的列1也就是名称去查询字典，得到class，存入type变量，并计数</em></p><figure class="highlight stata"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs stata">awk &#x27;BEGIN&#123;OFS=FS=<span class="hljs-string">&quot;\t&quot;</span>&#125;ARGIND==1&#123;a[<span class="hljs-variable">$2</span>]=<span class="hljs-variable">$4</span>;&#125;ARGIND==2&#123;<span class="hljs-keyword">type</span>=a[<span class="hljs-variable">$1</span>]; <span class="hljs-keyword">if</span>(<span class="hljs-keyword">type</span>==<span class="hljs-string">&quot;&quot;</span>) <span class="hljs-keyword">type</span>=<span class="hljs-string">&quot;Others&quot;</span>; <span class="hljs-keyword">count</span>[<span class="hljs-keyword">type</span>]+=1;&#125;END&#123;<span class="hljs-keyword">for</span>(<span class="hljs-keyword">type</span> <span class="hljs-keyword">in</span> <span class="hljs-keyword">count</span>) <span class="hljs-keyword">print</span> <span class="hljs-keyword">type</span>, <span class="hljs-keyword">count</span>[<span class="hljs-keyword">type</span>];&#125;&#x27; rfam_anno_class.txt nep_genome.tblout.final.xls<br></code></pre></td></tr></table></figure><h3 id="4-统计各类型RNA的总长度"><a href="#4-统计各类型RNA的总长度" class="headerlink" title="4. 统计各类型RNA的总长度"></a>4. 统计各类型RNA的总长度</h3><figure class="highlight wasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs wasm">awk &#x27;BEGIN&#123;OFS=FS=<span class="hljs-string">&quot;\t&quot;</span>&#125;ARGIND==<span class="hljs-number">1</span>&#123;a[<span class="hljs-variable">$2</span>]=<span class="hljs-variable">$4</span>;&#125;ARGIND==<span class="hljs-number">2</span>&#123;<span class="hljs-keyword">type</span>=a[<span class="hljs-variable">$1</span>]; <span class="hljs-keyword">if</span><span class="hljs-punctuation">(</span><span class="hljs-keyword">type</span>==<span class="hljs-string">&quot;&quot;</span><span class="hljs-punctuation">)</span> <span class="hljs-keyword">type</span>=<span class="hljs-string">&quot;Others&quot;</span>; <span class="hljs-keyword">if</span><span class="hljs-punctuation">(</span><span class="hljs-variable">$6</span>==<span class="hljs-string">&quot;-&quot;</span><span class="hljs-punctuation">)</span>len[<span class="hljs-keyword">type</span>]+=<span class="hljs-variable">$4</span>-<span class="hljs-variable">$5</span><span class="hljs-number">+1</span>;<span class="hljs-keyword">if</span><span class="hljs-punctuation">(</span><span class="hljs-variable">$6</span>==<span class="hljs-string">&quot;+&quot;</span><span class="hljs-punctuation">)</span>len[<span class="hljs-keyword">type</span>]+=<span class="hljs-variable">$5</span>-<span class="hljs-variable">$4</span><span class="hljs-number">+1</span>&#125;END&#123;for<span class="hljs-punctuation">(</span><span class="hljs-keyword">type</span> in len<span class="hljs-punctuation">)</span> print <span class="hljs-keyword">type</span>, len[<span class="hljs-keyword">type</span>];&#125;&#x27; rfam_anno_class.txt nep_genome.tblout.final.xls<br></code></pre></td></tr></table></figure><p>Ref: <a href="https://www.jianshu.com/p/c072acba6bd6">https://www.jianshu.com/p/c072acba6bd6</a></p>]]></content>
    
    
    <categories>
      
      <category>Software</category>
      
    </categories>
    
    
    <tags>
      
      <tag>annotation</tag>
      
      <tag>ncRNA</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>LTR-RT/LTR REs</title>
    <link href="/GeekFocus/2022/05/25/2022-05-25-LTR/"/>
    <url>/GeekFocus/2022/05/25/2022-05-25-LTR/</url>
    
    <content type="html"><![CDATA[<p>Long terminal repeat-retrotransposons<br>LTR retroelements (LTR REs)</p><span id="more"></span><p><a href="https://bmcgenomics.biomedcentral.com/articles/10.1186/1471-2164-15-626#:~:text=LTR%20retroelements%20%28LTR%20REs%29%20constitute%20a%20major%20group,variability%2C%20thus%20contributing%20to%20genome%20structure%20and%20organization">https://bmcgenomics.biomedcentral.com/articles/10.1186/1471-2164-15-626#:~:text=LTR%20retroelements%20%28LTR%20REs%29%20constitute%20a%20major%20group,variability%2C%20thus%20contributing%20to%20genome%20structure%20and%20organization</a>.</p><p>LTR retroelements (LTR REs) constitute a major group of transposable elements widely distributed in eukaryotic genomes. Through their own mechanism of retrotranscription LTR REs enrich the genomic landscape by providing genetic variability, thus contributing to genome structure and organization. </p><h1 id="长末端重复反转录转座子（LTR-RTs）"><a href="#长末端重复反转录转座子（LTR-RTs）" class="headerlink" title="长末端重复反转录转座子（LTR-RTs）"></a>长末端重复反转录转座子（LTR-RTs）</h1><p>ref: <a href="https://www.cnblogs.com/triple-y/p/14329159.html">https://www.cnblogs.com/triple-y/p/14329159.html</a></p><h2 id="1-定义：LTR与重复序列，转座子的关系"><a href="#1-定义：LTR与重复序列，转座子的关系" class="headerlink" title="1. 定义：LTR与重复序列，转座子的关系"></a>1. 定义：LTR与重复序列，转座子的关系</h2><p>LTR-RTs 是 Long terminal repeat-retrotransposons</p><p>重复序列</p><ul><li>串联重复序列（Tandem repeat）<ul><li>卫星DNA</li><li>微卫星序列</li><li>小卫星序列</li></ul></li><li>散在重复序列（转座子&#x2F;转做元件）<ul><li>反转录转座子（retrotransposon）<ul><li>SINE</li><li>LINE</li><li>LTR-RTs</li></ul></li><li>DNA转座子</li></ul></li></ul><p>重复序列：根据重复区域<font color="blue">是否连续</font>分为串联重复和散在重复（又名转座子、转座元件），前者相连，后者不相连。</p><p>转座元件(transposable elements, TEs) 又称转座子：指在基因组中<font color="blue">移动或复制</font>，<font color="blue">整合到基因组新位点</font>的一段 DNA 序列。根据转座过程<font color="blue">是否形成 RNA 中间体</font>，转座子可分为 DNA 转座子和反转录转座子。<font color="blue"><strong>反转录转座子</strong></font>是以 RNA 为媒介，伴有反转录过程，以<font color="blue"><strong>复制-粘贴</strong></font>方式在基因组的新位置产生一个新拷贝。<font color="blue"><strong>DNA 转座子</strong></font>的转座机制则是<font color="blue"><strong>剪切-粘贴</strong></font>。</p><p>LTR-RTs :是反转座子中的一种，<font color="blue">两侧存在长的末端重复</font>。不含长末端重复的反转座子统称 non-LTR-RTs，主要包含短散在重复(SINE)和长散在重复(LINE)。</p><h2 id="2-LTR分类"><a href="#2-LTR分类" class="headerlink" title="2. LTR分类"></a>2. LTR分类</h2><p>动植物基因组中存在大量转座子，尤其植物基因组。LTR  因其数量多且 LTR 长度巨大，在植物转座子中具有较高含量。玉米基因组 LTR 占基因组含量高达 75% ，山苍子基因组 LTR 占比高达 47%，所以<font color="blue"><strong>基因组 LTR 的鉴定</strong>尤为重要</font>。反转录转座子根据<font color="blue">转座元件结构</font>的<font color="blue"><strong>完整性</strong></font>和<font color="blue"><strong>转座特点</strong></font>可分为<font color="red"><strong>自主元件（编码转座酶）</strong></font>和<font color="red"><strong>非自主元件（自身不编码转座酶）</strong></font>。非自主转座元件需在自主元件的协助下才能发生转座。完整的 LTR-RTs 由两端序列完全一致的末端重复、GAG（衣壳蛋白）和 POL (AP, RT, RH, INT) 构成，后生动物中含 ENV （包膜蛋白）。其中 <font color="blue">POL 包含 AP（天冬氨酸酶）、INT（整合酶）、 RT（逆转录酶）和 RH（核糖核酸酶 H），是 LTR <strong>能否自主转座</strong>的关键蛋白</font>。 LTR 分类见图 ，<font color="red"><strong>高等植物</strong>主要包括 <strong>Ty1&#x2F;Copia</strong>和 <strong>Ty3&#x2F;Gypsy</strong> 两个<strong>超家族</strong></font>，二者差别在于<font color="red"> <strong>INT 位置</strong>不同</font>。</p><p><img src="/GeekFocus/2022-05-25-LTR/1.png" alt="img"></p><p><img src="/GeekFocus/./1.png" alt="img"></p><p>P: 植物  M: 后生动物  F :真菌  O：其他</p><h2 id="3-LTR生物学意义"><a href="#3-LTR生物学意义" class="headerlink" title="3. LTR生物学意义"></a>3. LTR生物学意义</h2><p>研究表明活性 LTR 插入到关键基因内或周边会导致性状改变。2019 NC的《A high-quality apple genome assembly reveals the association of a retrotransposon and red fruit colour》揭示<strong>苹果红皮表型形成与一个 LTR-RT 插入相关</strong>。MdMYB1 有 MdMYB11-1、MdMYB1-2 和 MdMYB1-3 三个等位基因，其中 MdMYB1-1 是控制苹果果皮花青素合成的单一显性基因。相较于黄苹果基因组，在红苹果基因组的 MdMYB1-1 基因启动子上游有一个 LTR-RT（ redTE）插入，经PCR 验证红苹果中存在一段特异序列。redTE 作为一种<strong>增强子</strong>，增强 MdMYB1-1 对光的敏感性，从而累计花青素，形成红色表皮。</p><p><img src="/GeekFocus/2022-05-25-LTR/2.png" alt="img"></p><p>2<img src="/GeekFocus/./2.png" alt="img"></p><p>【苹果红皮 LTR-RT 插入】</p><p>LTR 的扩张和收缩也影响着基因组大小，<a href="https://links.jianshu.com/go?to=http://mp.weixin.qq.com/s?__biz=MzA5NzE1MTYwMw==&mid=2650849497&idx=1&sn=0831fe0dc984fd8b0aaae5bc451f3f35&chksm=8b515fc5bc26d6d35020392d2ea035602916f02a322592cad38d291c947a386f787250f7455c&scene=21%23wechat_redirect">小叶茶文献《Mol Plant 项目文章 | 第一个茶树染色体级别高质量参考基因组发布》</a>中，揭示小叶茶基因组中 LTR 的扩张尤其是非自主 LTR 的扩张是小叶茶基因组庞大的主要原因。</p><h2 id="4-LTR-RTs的结构特征"><a href="#4-LTR-RTs的结构特征" class="headerlink" title="4. LTR-RTs的结构特征"></a>4. LTR-RTs的结构特征</h2><p>典型的 LTR-RTs 的结构有 5 个特征</p><p><img src="/GeekFocus/2022-05-25-LTR/3.png" alt="img"></p><p><img src="/GeekFocus/./3.png" alt="img"></p><p>典型 LTR 的结构特征</p><p>(1) <font color="blue"><strong>TSR（TSD）</strong></font>: 目标重复位点，是 <strong>4~6bp</strong> 的短的重复序列，在 5’LTR and 3’LTR 两侧，是转座子<strong>插入的信号</strong>。</p><p>(2) <font color="blue">5’LTR and 3’LTR</font> :  LTR 两端<strong>序列完全一致</strong>的<strong>末端重复</strong>， <strong>TG..CA box</strong>，<strong>完整 LTR</strong> 均含有此结构。LTR 长度一般在 85~5000bp。</p><p>(3) <font color="blue">PBS(primer binding site)</font> 引物结合位点: 在 5’LTR 的末端，可<strong>与一些 tRNA 3’ 末端互补结合</strong>的一段 <strong>18bp 左右</strong>的序列，是<font color="red"><strong>反转录的第一步</strong></font>。</p><p>(4) <font color="blue">蛋白区域</font>: 长度通常在 1000~15000bp。</p><p><strong>GAG</strong>：衣壳蛋白。</p><p><strong>POL</strong>：包含4中酶，由AP（天冬氨酸酶）、IN（INT,整合酶）、RT（逆转录酶）、RH（核糖核酸酶），LTR <font color="red"><strong>能否自主转座</strong></font>的关键原因。</p><p><strong>ENV</strong>：包膜蛋白，后生动物中存在。</p><p>(5) <font color="blue">PPT</font>：3’LTR 的起始位置短的富含嘌呤的序列，<strong>11~15bp</strong>。</p><p>LTR 千万年进化发展出许多形式</p><ul><li>A : 通常将包含两个相对完整的 LTRs 和已识别的 PPT 和 PBS 位点的元素，且两侧有 TSD 的 LTR 定义为 Intact LTR</li><li>C : 由于 LTR-RTs 两端序列非常相似，LTR-RTs 内可发生重组，导致内部元件消失，形成 solo LTR, solo LTR 的数量表明一个基因组中 LTR 去除的频率和效率</li><li>B : LTR 发生缺失、易位可形成截断的 LTR</li><li>D : LTR 经常插入到其他 LTR 内部区域，形成嵌套 LTR</li><li>因存在突变机制，实际上完整 LTR-RTs （A）只占基因组中所有 LTR-RT 一小部分</li></ul><p><img src="/GeekFocus/2022-05-25-LTR/4.png" alt="img"></p><p><img src="/GeekFocus/./4.png" alt="img"></p><h2 id="5-LTR-RTs鉴定方法"><a href="#5-LTR-RTs鉴定方法" class="headerlink" title="5. LTR-RTs鉴定方法"></a>5. LTR-RTs鉴定方法</h2><p>LTR-RT 鉴定方法三类：从头预测、结构预测、同源比对。</p><p>LTR_STRUC 是一款最早的从头预测 LTR 的软件</p><p>LTR_finder 和 LTRharvest 是目前鉴定 LTR 最敏感的程序，但假阳性高。</p><p>RepeatMasker基于数据库，使用同源方法来预测 LTR，但不同物种 LTR 差异较大，构建物种特有的 LTR 库非常必要。</p><p>2017 年密歇根州立大学 Shujun Ou 团队开发 LTR_retriever用于 LTR 的鉴定，文章 Plant Physiology 。这是一款整合软件，以一个或多个 LTR 预测软件鉴定 LTR 的结果作为输入文件，通过不同模块对 LTR 进行过滤和修正来对预测软件的预测结果进行整合和调整，以得到非冗余精准且完整的物种特异 LTR 库，再使用 RepeatMasker进行预测</p><p><img src="/GeekFocus/2022-05-25-LTR/5.png" alt="img"></p><p><img src="/GeekFocus/./5.png" alt="img"></p><p>图 5-1  LTR_retriever 整合模块</p><p>LTR_retriever 从 sensitivity（敏感性）、specificity（特异性）、accuracy（准确性）、precision（精确度）四个维度对 LTR 鉴定结果进行评估。以真实 LTR 和非 LTR 序列作为参考库进行预测。对预测结果分四类：</p><p>TP：真阳性，真实的 LTR，被准确预测出</p><p>FN：假阴性 ，真实的 LTR，未被准确预测出</p><p>TN：真阴性 ，非 LTR 序列未被预测当成 LTR</p><p>FP：假阴性，非 LTR 序列被当成 LTR</p><p>从下图公式可知敏感性代表对真正 LTR 的检出能力，特异性代表排除非 LTR 序列的能力，精确性代表正确检出的能力，精确度代表检出结果的真阳性率，精确度越高则表明结果越可靠。</p><p><img src="/GeekFocus/2022-05-25-LTR/6.png" alt="img"></p><p><img src="/GeekFocus/./6.png" alt="img"></p><p>鉴定结果评估指标</p><p>LTR_retriever 评估现有软件，结果显示 LTR_retriever 明显优于其他软件，而 Shujun Ou 团队在 2019 发表在 Genome Biology 上的有关<strong>转座子注释</strong>方法中推荐 LTR 的鉴定方法是使用<strong>以 LTR_finder 和 LTRharvest 软件鉴定结果作为 LTR_retriever 的输入文件</strong>。</p><p><img src="/GeekFocus/2022-05-25-LTR/7.png" alt="img"></p><p><img src="/GeekFocus/./7.png" alt="img"></p><p> 不同 LTR 鉴定方法比较</p><h2 id="6-LTR-分析"><a href="#6-LTR-分析" class="headerlink" title="6. LTR 分析"></a>6. LTR 分析</h2><p>公司 LTR 分析流程，先使用 LTR_finder 和 LTRharvest 对 LTR 进行鉴定，再利用 LTR_retriever 整合，构建非冗余精准的物种特异 LTR 数据库后使用同源预测方法注释，再过滤掉假阳性，注释出全面且精确的物种 LTR 序列，包括 intact LTR、solo LTR、LTR 相关序列，非典型 LTR 等。明确 LTR 含量在基因组中的占比，在染色体上的分布情况。</p><hr><h1 id="真核生物中的转座元件-综述"><a href="#真核生物中的转座元件-综述" class="headerlink" title="真核生物中的转座元件 | 综述"></a>真核生物中的转座元件 | 综述</h1><p>ref : <a href="https://zhuanlan.zhihu.com/p/401637411">https://zhuanlan.zhihu.com/p/401637411</a></p><p>Wells, J. N., &amp; Feschotte, C. (2020). A field guide to eukaryotic transposable elements. <em>Annual review of genetics</em>, <em>54</em>, 539-561.</p><p>Chenais et al (2013) Biochimica et Biophysica Acta 1835 (2013) 28–35,Transposable elements and human cancer: A causal relationship?</p><p>Sultana, T., Zamborlini, A., Cristofari, G., &amp; Lesage, P. (2017). Integration site selection by retroviruses and transposable elements in eukaryotes. <em>Nature Reviews Genetics</em>, <em>18</em>(5), 292-308.</p><p>转座元件（TE）可以在宿主基因组上自主移动的DNA序列。长度通常在<font color="blue">100bp-10000bp</font>。和病毒类似，TE也是非常错综复杂并且自私的元件。TE能够<font color="blue">编码具有多种生化功能的蛋白</font>，或还含有<font color="blue">非编码调控序列</font>，这些<font color="blue">蛋白和调控序列</font>对TE转座有重要作用。</p><p>TE和一些类似病毒的<font color="blue">侵入性遗传元件</font>的区别并不十分明确。定义TE为能够在<font color="blue"><strong>生殖系细胞</strong>中进行染色体水平重复移动的遗传元件</font>。通过生殖系细胞的移动能够实现TE的<font color="blue">垂直传递</font>，以此增加TE的频率。这一定义<font color="blue">包含非自主移动元件</font>，比如<font color="blue">短散布核酸元件SINE(LINE?)</font>和<font color="blue">微小倒置重复转座元件MITE</font>，同时也包含<font color="blue">内源性逆转录病毒ERV</font>。但<strong>不包括</strong>生殖系细胞中<strong>来源于病毒</strong>的<strong>不能整合、移动</strong>的<strong>内源性元件</strong>。此外， 虽然定义TE是能够在生殖系细胞中垂直传递的元件，但TE的水平转移也发生。<font color="blue">水平转移是TE长期广泛存在的重要原因之一</font>。</p><p>真核生物除极少数物种，几乎所有真核物种基因组中都发现TE存在。有些物种TE含量可以达到基因组<code>85%</code>，如果把整个基因组比作一片海洋，那么真正属于宿主的基因可能仅仅是这些海洋中的一些小孤岛。<font color="blue">TE含量和物种基因组复杂程度无关</font>，有些复杂的多细胞生物（如针叶树、蝾螈等）含有较多TE，但有些单细胞生物（比如阴道毛滴虫、<em>Anncaliia algerae</em>等）也含有较多TE。</p><p>在1950年，Barbara McClintock 发表最早关于TE的论文《<em>The origin and behavior of mutable loci in maize</em>》，获得1983年诺奖。七十余年过去，TE的研究还存在很多不足。但也认识到TE在物种<font color="blue">进化、分化、适应</font>等方面有重要作用。本文综述了在真核生物中，TE的<font color="blue">分类、进化起源</font>；<font color="blue">不同物种间TE含量的比较</font>；以及<font color="blue">影响TE分布</font>的一些因素。</p><h2 id="1-真核生物中TE的分类"><a href="#1-真核生物中TE的分类" class="headerlink" title="1. 真核生物中TE的分类"></a><strong>1. 真核生物中TE的分类</strong></h2><p>1989年，David Finnegan首次将TE划分为两类：</p><ul><li>Class I：逆转座子</li><li>Class II: DNA转座子</li></ul><p>第一类是以RNA为中介，并且将RNA逆转录为DNA，整合到宿主基因组，<font color="red">复制粘贴</font>。第二类中，<strong>大多数</strong>是以<font color="blue">剪切粘贴</font>机制进行转座，不涉及RNA中介。</p><p>根据TE复制、整合等具体过程的不同，上述两类TE可以进一步分成很多<strong>子类</strong>，或者<strong>目</strong><code>order</code>。再往下分，还可以分为<strong>超家族、家族</strong>等。</p><p><img src="/GeekFocus/2022-05-25-LTR/8.png" alt="img"></p><p><img src="/GeekFocus/./8.png" alt="img"></p><p>【TE的分类和转座实现方式】</p><p><img src="/GeekFocus/2022-05-25-LTR/9.png" alt="img"></p><p><img src="/GeekFocus/./9.png" alt="img"></p><p>【转座实现方式】</p><p>TE家族的划分一般按照<code>80-80-80</code>方法，即如果两个TE插入的序列长度都超过80bp，有超过80%的序列的相似性超过80%，认为这两个TE是来自同一个家族。因为序列相似性比较高，该家族的TE可以用一个共同的序列来表示该家族共同祖先的序列。特别是当该家族的TE在较短时间内经历了爆发，并且这些TE只经历了中性选择时。但是，<font color="blue">有时根据80-80-80原则定义的家族和其共同序列并不能够反映各个TE间真实的进化关系</font></p><p>还有一些TE的分类是根据其能否自主移动划分。能够自主移动的元件通常都会编码一些移动必需的酶。不能自主移动的元件通常不含相应的编码序列，但是它们能够借助其他可移动元件的顺式序列实现自身的移动。<font color="blue">有些TE家族的所有成员都不含有可自主移动的元件，比如MITE</font>。这类TE源于可自主移动的TE，但是其中的自主移动元件在进化过程中被删除了，只剩下了末端倒置重复序列<code>TIR</code></p><p><img src="/GeekFocus/2022-05-25-LTR/10.png" alt="img"></p><p><img src="/GeekFocus/./10.png" alt="img"></p><p>还有<font color="red">一些非自主移动元件（比如<code>SINE</code>）源于非编码基因，比如编码tRNA的基因，其移动需要借助<code>LINE</code>元件的序列</font>。这些必须借助其他家族才能实现自身转座的元件，也被称为TE的寄生元件，或者是<code>超寄生</code>。</p><h3 id="逆转座子"><a href="#逆转座子" class="headerlink" title="逆转座子"></a><strong>逆转座子</strong></h3><p>根据复制、整合机制的不同，可以将逆转座子分为以下三类</p><p>1）<font color="blue">长末端重复元件（LTR）</font>：比如<code>Copia</code>，<code>Gypsy</code></p><p>2）<font color="blue">non-LTR元件</font>：比如<code>L1</code>，<code>R2</code>，<code>Jockey</code></p><p>3）<font color="blue">酪氨酸重组酶YR移动元件</font>：比如<code>DIRS</code></p><p>Non-LTR的结构比较简单，通常只含有2个开放阅读框（<code>ORF1</code>和<code>ORF2</code>）。其中第一个的开放阅读框<code>ORF1</code>在某些non-LTR群组中缺失（如<code>R2</code>元件）。<code>ORF1</code>的功能可能与RNA的识别和转运有关。第二个开放阅读框<code>ORF2</code> 编码有内切酶<code>EN</code>和逆转录酶<code>RT</code>活性。</p><p><img src="/GeekFocus/2022-05-25-LTR/11.png" alt="img"></p><p><img src="/GeekFocus/./11.png" alt="img"></p><p>【non-LTR元件，R2的第一个开放阅读框缺失，L1等元件则含有第一个开放阅读框。EN：核酸内切酶；RT逆转录酶】</p><p><code>L1</code>元件是non-LTR家族的代表。人类基因组有数十万拷贝的L1元件，至少有100个拷贝处于活跃状态。其编码的核酸内切酶能够识别剪切<code>5&#39;-TT/AAAA-3&#39;</code>位点，然后合成RNA，翻译逆转录酶，逆转录，最后将逆转录的cDNA整合到宿主基因组中。但是在这个过程中，逆转录常常会<font color="red"><strong>提前中断</strong></font>，造成5’端截断。因为5’端是L1表达的重要位点，所以其截断往往会造成L1失活。这也是人类中为什么存在大量的L1却只有相对较少的L1具有活性的原因。</p><p>相比于non-LTR，LTR的结构、编码和复制机制比较复杂，并<font color="blue">和很多逆转录病毒类似</font>。<font color="blue">可自主移动的LTR至少含有两个基因</font>：<code>gag</code>和<code>pol</code>；这两个基因编码多聚蛋白，该多聚蛋白能够被<code>pol</code>编码的蛋白酶<code>PR</code>裂解。此外，<code>pol</code>还编码逆转录酶<code>RT</code>，核糖核酸酶H<code>RH</code>，和整合酶<code>IN</code>（下图）。逆转录过程发生在<code>gag</code>形成的病毒样颗粒中，逆转录出的cDNA和整合酶结合，进入细胞核，并整合到宿主基因组中。</p><p><img src="/GeekFocus/2022-05-25-LTR/12.png" alt="img"></p><p><img src="/GeekFocus/./12.png" alt="img"></p><p><font color="blue">逆转录病毒的复制和整合与LTR的转座过程类似。只不过逆转录病毒常常含有<code>env</code>基因。如果逆转录病毒的<code>env</code>基因丢失，那么该逆转录病毒则内源化了</font>。</p><p><font color="blue">对YR逆转座元件的研究较少，其结构上与LTR元件相似，但是它编码了酪氨酸重组酶<code>YR</code>，而非整合酶<code>IN</code></font>。一般认为，YR元件中含有的末端重复序列参与以mRNA为模板的逆转录、单链cDNA的环化、第二条cDNA链的合成，以及最终的整合。</p><h3 id="DNA转座子"><a href="#DNA转座子" class="headerlink" title="DNA转座子"></a><strong>DNA转座子</strong></h3><p>DNA转座子可以分为4类：</p><p>1）<strong>DDE转座酶</strong>介导的剪切粘贴转座：如<code>Tc1/Mariner</code>，<code>P元件</code></p><p>2）<strong>酪氨酸转座酶</strong>转座子，即<code>Cryptons</code></p><p>3）<code>Helitron</code></p><p>4）<code>Mavericks</code>(也即，<code>Polinton</code>)</p><p>其中前两类（DDE和Cryptons）的转座比较简单，结构构成<font color="blue">只有一个开放阅读框，编码重组酶，两端含有短末端倒置重复序列（TIRs）</font>。这一结构和很多<font color="blue">细菌和古生菌</font>的插入序列很相似。</p><p><img src="/GeekFocus/2022-05-25-LTR/13.png" alt="img"></p><p><img src="/GeekFocus/./13.png" alt="img"></p><p>【DDE类转座子结构和转座方式】</p><p>Cryptons在真核生物中分布较少；<font color="blue">DDE类转座子是所有TE中分布最广，种类最多的一类转座元件，其至少包含了17个超家族</font>。甚至可以说，DDE是地球上最古老、最丰富的的基因。</p><p>不同超家族的DDE转座机制略有差异，但是它们的开始过程都是转座酶对TIR序列的识别和剪切（如上图）。<font color="blue">虽然这一个“剪切粘贴”的过程似乎不会增加DDE的拷贝数，但是DDE有一些实现扩增的策略，比如在宿主基因组复制的过程中，DDE可以从已经复制过的位点转座到尚未复制的位点，然后通过宿主基因组的复制，实现自身扩增</font>。此外，在剪切处的双链断裂可以通过同源重组进行修复，<font color="blue">修复的过程也能实现一定的扩增</font>。</p><p><img src="/GeekFocus/2022-05-25-LTR/14.png" alt="img"></p><p><img src="/GeekFocus/./14.png" alt="img"></p><p>【<font color="blue">DNA转座子通过剪切粘贴实现扩增的方式</font>】</p><p><font color="blue">Helitrons</font>也是一类含量非常丰富的DNA转座元件，在黑腹果蝇、线虫、拟南芥等物种中广泛存在。但是对它的研究仅仅有二十余年的历史。它的结果很简单，没有TIR重复序列等经典DNA转座子结构，不能自主移动，没有“剪切粘贴”。</p><p><img src="/GeekFocus/2022-05-25-LTR/15.png" alt="img"></p><p><img src="/GeekFocus/./15.png" alt="img"></p><p>【Helitrons转座子结构】</p><p><code>Helraiser</code>是其中的典型代表，其通过<code>peel-and-paste</code>机制形成环状双链DNA，然后将此环状DNA转座到基因组其他位置。在转座过程中就实现了扩增。但是在玉米中的研究显示，有些Helitron转座子是通过剪切转座的，而非扩增。所以，对Heliton的转座机制还有待进一步研究。</p><p><font color="blue">Mavericks</font>也称之为Polintons，也是一类目前研究尚不完整的DNA转座子。Mavericks转座子的大小约<code>15-20Kb</code>，构成比较复杂，可含有高达20个蛋白编码基因，两端含有400-700bp的TIR重复序列。其在真核生物中也广泛存在，但是其一般在基因组的拷贝数较少（阴道毛滴虫除外，Mavericks可占其基因组的1&#x2F;3）。</p><p>Mavericks和很多双链DNA病毒类似，包括含有<code>pPolB</code>的DNA聚合酶（和腺病毒关系很近），推测其转座过程中可以直接合成DNA，也因此称其为“自我合成型转座子“。Mavericks还含有和DDE类似的整合酶，在整合过程中会形成5-6bp长度的靶标位点重复序列<code>TSD</code>。</p><p>有些研究还显示Mavericks可能还能够合成衣壳样蛋白。这提示，Mavericks转座子可能代表了内源性病毒或者噬病毒体。噬病毒体能够嵌合到较大的双链DNA病毒中。<font color="blue">Mavericks也因此可能是真核物种为了保护自己免受大DNA病毒攻击的一种秘密武器</font>。</p><h2 id="2-转座元件的进化起源"><a href="#2-转座元件的进化起源" class="headerlink" title="2. 转座元件的进化起源"></a><strong>2. 转座元件的进化起源</strong></h2><p>通过进化基因组学研究<strong>各个转座元件的分布和核心蛋白的发生关系</strong>。尽管我们现在有很方便的全基因组测序和很好的TE注释工具，但是<strong>TE序列进化很快</strong>，即便是<strong>最常见最保守的TE蛋白域也很难进行超家族之间的比对</strong>。此外，<strong>TE的进化关系和物种进化关系并不一致</strong>，TE可以进行<strong>物种之间的水平转移</strong>，甚至是在脊椎动物和无脊椎动物之间<strong>长距离转移</strong>。有些TE在进化的过程中可能<strong>丢失或灭绝</strong>。所以，研究转座元件之间的进化关系非常<strong>困难</strong>。</p><p>在过去数十年的研究中，人们发现，<strong>所有主要转座元件的亚纲</strong><code>subclass</code>在<strong>真核生物进化分支中均有分布</strong>。对TE核心蛋白的分析也显示这些亚纲在真核生物进化早期就已经存在。同时<strong>TE的进化是高度模块化的，可以反复获得或者丢失某些蛋白模块</strong>。</p><h3 id="转座元件相关蛋白的进化关系"><a href="#转座元件相关蛋白的进化关系" class="headerlink" title="转座元件相关蛋白的进化关系"></a><strong>转座元件相关蛋白的进化关系</strong></h3><p>尽管各种不同元件的结构非常多样，但是在<font color="blue">复制和转座过程中涉及的蛋白种类却很有限，大概分为5类</font>：</p><ul><li>逆转录酶RT</li><li>整合酶IN</li><li>酪氨酸重组酶YR</li><li>HUH&#x2F;Rep</li><li>DNA合成酶pPolB</li></ul><p>而且，HUH、RT和pPolB的还拥有相同的RNA识别域。<font color="blue">这些转座涉及的酶可能出现在真核生物形成以前</font></p><p>在DDE类转座子中，有至少6超家族的转座酶和细菌插入序列<code>IS</code>编码的蛋白相似，提示，某些DNA转座子超家族的分化早于真核生物的出现。</p><p>除了上述DDE转座子，其他亚纲的转座子和细菌或者古细菌没有同源序列。</p><p>在Helitron转座子中，HUH核酸内切酶涉及的转座也出现在细菌<code>IS91</code>的转座过程，但是它们之间应该是独立进化的。HUH核酸内切酶可能源于病毒或者质粒。同样地，在细菌和古细菌中的酪氨酸重组酶和真核生物中转座中涉及的酪氨酸重组酶也应该是独立进化的。这些转座子应该是在真核生物形成之后出现的。</p><h3 id="嵌合元件和模块进化"><a href="#嵌合元件和模块进化" class="headerlink" title="嵌合元件和模块进化"></a><strong>嵌合元件和模块进化</strong></h3><p>上述只描述了相关转座酶之间的进化关系，具体到转座子本身，很难用一个进化树来表示它们之间的进化关系。因为转座子之间会频繁交换结构单元，形成一个进化关系网，而非进化关系树。此外，还有一些辅助结构域是从宿主基因组上获得的。转座子之间的界限并不像物种之间的界限那么明确。</p><p>比如，根据逆转录酶结构域，class I中的YR逆转座子可以和LTR及逆转录病毒划分为同一类；但是如果根据酪氨酸重组酶结构，YR逆转座子又可划分为class II中，和Crypton属于一类。</p><p>LTR逆转座子是最典型的模块化进化的例子。它从non-LTR和DDE中分别借来了相应的模块，形成了自己独特的转座机制。从进化上看，LTR的形成比non-LTR和DDE要晚，non-LTR和DDE的嵌合形成了LTR。支持这一论断的另一个证据来自核糖核酸酶<code>RNase H</code>结构域，RNase H形成于生命起源的早期，主要作用是降解DNA-RNA复合体中的RNA序列。对LTR、non-LTR和宿主基因组中的RNase H结构域的进化分析显示，LTR的RNase H隶属于non-LTR中的一个分支。如果将宿主基因组的RNase H序列作为树根，那么可以推测出，non-LTR的出现早于LTR。此外，LTR中的<code>gag</code>蛋白和non-LTR中第一个开放阅读框编码的蛋白在序列、位置和功能上都有很多相似之处。最后，LTR中的IN蛋白来自DDE转座子。通过这种模块结构的嵌合，最终形成了LTR转座子。</p><p>除了LTR外，SINE类转座子也是通过嵌合模块的方式形式的。比如在灵长类中，<code>Alu</code>在灵长类中通过两个7SL获得的SINE融合得到。Alu形成之后，迅速扩散，并且占领了灵长类基因组转座子的很大一部分。</p><h2 id="3-转座子在物种间分布的差异"><a href="#3-转座子在物种间分布的差异" class="headerlink" title="3. 转座子在物种间分布的差异"></a><strong>3. 转座子在物种间分布的差异</strong></h2><p>TE的含量在各个物种间的分布差异很大。有些物种的基因组含有很少的TE，而有些物种基因组中则充斥着大量的TE。</p><p><img src="/GeekFocus/2022-05-25-LTR/16.png" alt="img"></p><p><img src="/GeekFocus/./16.png" alt="img"></p><p>【不同物种的基因组大小和TE含量】</p><p>有些研究认为，物种中TE的含量和其物种的有效群体数量相关。有效群体数量越大，自然选择效能越高，因而对TE的选择压力也越大。比如，在有效群体数量很大的果蝇中，TE含量较低，而在有效群体数量较小的脊椎动物中，TE插入受到选择压力较小，可以很快的在群体中固定下来。不过，有些有效群体数量相近的物种， 其TE含量有时也会有很大差异。所以有效群体数量的差异并不足解释TE的分布差异。</p><p>而且各类不同的TE分布差异也很大，比如<font color="red"><strong>LTR在开花植物中分布很多；non-LTR在哺乳动物中分布很多；DNA转座子在斑马鱼和线虫中分布很多</strong></font>。有效群体数量的差异也不足以解释这一现象。</p><h3 id="TE丰度和基因组大小"><a href="#TE丰度和基因组大小" class="headerlink" title="TE丰度和基因组大小"></a><strong>TE丰度和基因组大小</strong></h3><p>除了极少数已知真核生物外（疟原虫、弓形虫、肠脑炎微孢子虫、泰勒原虫），所有的真核生物物种中都含有TE。巧合的是，上述几种例外都是单细胞生物，而且后两者是真核生物中基因组最小的。但是这并不足说明基因组大小和TE丰度有直接关系。另一种单细胞生物，<em>Anncaliia algerae</em>的基因组大小只有23Mb，但是其中有14%都是TE，涵盖了240个TE家族。</p><p>在一些较大的基因组中，比如<font color="blue">蝾螈基因组，其大小有120Gb</font>。这么大的基因组主要是LTR转座元件造成的。植物基因组通常也可以通过转座元件迅速增大。其中涉及的转座元件可能涵盖较多的TE家族，但是个别TE的作用可能会格外显著。比如棕水螅在3600万年前从绿水螅中分化出来，随后其基因组大小从300Mb迅速增大到了1Gb，造成这一现象的原因就是CR1 non-LTR转座子。</p><p>非必要DNA的删除是另一个决定基因组大小和TE丰度的因素。除了转座元件外，蝾螈形成的大基因组和其较低的DNA删除率也有很直接的关系。<font color="red"><strong>在拟南芥和水稻中，异位重组造成的基因组高删除率抵消了转座造成的基因组扩大，维持了拟南芥和水稻的基因组大小稳定</strong></font>。在鸟类和哺乳动物中，也有同样的现象。</p><h3 id="TE多样性"><a href="#TE多样性" class="headerlink" title="TE多样性"></a><strong>TE多样性</strong></h3><p>TE在物种之间的分布，除了丰度不同外，种类分布也存在很大差异。宿主和TE之间的竞争作用会导致TE家族结构的形成，扩大TE的亚家族种类（比如<code>L1</code>）。其他一些转座元件，比如Helitrons可以通过获取宿主DNA的片段形成新的亚家族。</p><p>不管在什么尺度来衡量，真核生物的TE分布都具有很高的多样性。比如在斑马鱼中，其TE丰度和多样性在脊椎模式生物中都是最高的，含有近2000个TE家族，涵盖了所有的亚纲和几乎所有的超家族。其中，DNA转座子特别丰富，含有1000个不同时期形成的DNA转座子家族，这在鱼类中很不寻常。</p><p>但是这并不是说基因组越大，其TE多样性越高。比如云杉是一类裸子植物，其基因组大小20Gb，其中的转座子主要集中在LTR超家族中，含有大量的拷贝数。而且其中的大多数转座子发生在500万-6000万年前。<font color="blue">在水稻和玉米中，所有的转座子都晚于500万年</font>。这说明尽管TE在云杉中的多样性很低，但是很多已经存在基因组中的TE会被缓慢的移除掉。与云杉相反，在很多开花植物中，尽管其基因组很小，但是其TE的多样性却很高。甚至在所有陆生植物中，基因组大小和TE多样性还表现出负相关关系。</p><h2 id="4-影响TE分布的因素"><a href="#4-影响TE分布的因素" class="headerlink" title="4. 影响TE分布的因素"></a><strong>4. 影响TE分布的因素</strong></h2><p>决定一个TE家族结局的直接因素有三个：<font color="red"><strong>1）转座发生率； 2）新TE插入在群体中的固定率；3）TE序列被删除和侵蚀的速率</strong></font></p><p>影响着三个因素的方面很多，可以概括为：TE自身属性，宿主自身属性。</p><p>更广泛地说，TE的命运决定于其自身、宿主和环境三者的相互作用。本部分将重点讨论TE自身因素对其结局命运的影响。</p><h3 id="TE插入偏好"><a href="#TE插入偏好" class="headerlink" title="TE插入偏好"></a><strong>TE插入偏好</strong></h3><p>TE在基因组中插入的位置对TE的结局有重要影响。通过对自然选择压力进入之前的新插入突变的研究来一窥究竟。研究显示：</p><ul><li>TE存在一定的插入偏倚</li><li>TE倾向于在最小化有害作用的基因组中插入</li><li>TE的靶点倾向于有利于自身增殖</li></ul><p>TE的插入过程涉及到核酸酶，所有TE编码的核酸酶（限制性内切换、整合酶、转座酶）都在一定程度上存在特定DNA或者染色体属性的特异性，也就是说，几乎所有的TE插入都不是随机的，而是存在一定靶标特异性的。只有一些高度简并性的核酸酶或者识别短序列模式的核酸酶，比如<code>L1</code>，其在人类细胞中的插入才表现出一定的随机性。</p><p>很多TE插入表现出很强的位点偏倚，倾向于选择那些不会影响细胞功能的基因组位点进行插入。比如LINE家族的一些TE成员（R1，R2）等，它们的插入精确定位于rRNA基因簇中。因为rRNA基因具有大量的拷贝备份，在其中少量基因的位点的插入不会影响到细胞的整体功能。而对这些位点的识别则是通过高度序列特异性的核酸内切酶实现的。特别是很多类似R2的TE，它们在rRNA基因组的插入也表现出位点特异性，使得它们能够同时存在于基因组中，相互之间不受影响。在多细胞生物中，这种高度特意性的rRNA位点插入是普遍存在的，也证明了TE插入位点选择的偏向性。</p><p>基因间的“垃圾”序列为TE的插入和长期存在提供了一个安全的场所。比如在酵母菌中，LTR转座子的插入会避开宿主基因组的基因序列。<code>Copia</code>和<code>Gypsy</code>通过趋同进化，能够选择在Pol-III转录基因序列的上游插入，避免干扰宿主基因表达。<code>Ty5</code>能够通过其整合酶和一些染色质因子的作用实现其在端粒区非表达染色质的特异插入。</p><p>很多TE的插入靶标位于基因5’端的上游，这种靶标选择倾向会给TE自身带来益处。首先在该区域的插入能够避免插入对编码蛋白的干扰，同时这些区域的染色体多以染色质形态存在，有利于TE自身的表达和转座。很多DNA转座子都采用了这种策略来实现自身利益最大化，比如果蝇中的<code>P</code>元件、玉米中的<code>MuDR</code>，大米中的<code>mPing</code>和拟南芥中的<code>VANDAL21</code>等。</p><p>酵母菌中的<code>Tf1</code>逆转座子同样倾向于选择基因的启动子区域插入，该转座子的整合酶和宿主特异性转录因子相互作用，实现插入位点的选择。</p><p>在拟南芥和其他一些植物中，类<code>Copia</code>的逆转座子也进化出了一些机制，实现在宿主非必需基因中插入。这些机制主要是通过识别核小体组蛋白H2A.Z来实现的，该组蛋白不存在于必需基因组中，只存在于和适应环境压力相关的非必需基因中。这也提示，TE非随机插入带来的基因组突变可能也有利于宿主适应外界环境的变化。</p><p>还有一种TE的插入策略比较特殊，它们倾向于选择其他的TE序列作为自己的插入靶点。研究显示有些TE家族会频繁地出现在其他TE家族的序列内。比如在非洲爪蟾中，non-LTR转座子<code>Tx1L</code>几乎只存在于DNA转座子<code>Tx1D</code>中，前者像是后者的一个寄生虫，这种现象可以称之为TE的“超寄生”<code>hyperparasitism</code>.</p><h3 id="影响TE长期存在的因素"><a href="#影响TE长期存在的因素" class="headerlink" title="影响TE长期存在的因素"></a><strong>影响TE长期存在的因素</strong></h3><p>所有的新TE插入都会受到来自宿主水平的自然选择。特别是当TE对宿主产生有害作用时，比如：干扰到宿主基因的表达；TE表达产物对宿主细胞有毒副作用；同家族TE导致的宿主染色体异位重组。</p><p><img src="/GeekFocus/2022-05-25-LTR/17.png" alt="img"></p><p><img src="/GeekFocus/./17.png" alt="img"></p><p>【TE导致的人类疾病】</p><p>虽然有些TE产物确实对宿主有害，比如<code>L1</code>转座中间产物的积累会导致Aicardi-Goutières综合征，但是很多时候毒性并不是主要受选择的因素。目前的研究显示，TE导致的异位重组是限制TE增殖的主要因素。</p><p>序列较长的TE更容易造成异位重组，因而其受到的选择压力也应该更大。实验观测也确实如此，比如LTR和LINE等较长的转座子常常会聚集在低重组区（中心粒周围的异染色质区），在这些区域内，TE受到的选择压力会相对较小。与之相反，一些较短的转座子，比如SINE和MITE，通常富集在基因较多的染色体区域，这些区域通常重组率也比较高。</p><p>第二个导致TE受到选择的因素是其对基因表达的影响。可自主移动的转座子其自身通常会含有启动子和调节序列，如果其插入到基因序列中，那么对宿主基因的表达会产生较大影响。比如，在人类基因组中，<code>L1</code>转座子很少出现在基因序列中，比较老的LTR插入也很少出现在基因序列两侧5kb的的范围内。这都证明了携带启动子的LTR在人类基因组中受到很强的自然选择压力。即便有些插入出现在基因中，也常常是内含子中，而且是内含子的中段部分，以尽量避免对外显子的影响。</p><p>当然，还要说明一点，TE并不一定只给宿主带来坏处，还有可能给宿主带来适应优势，比如果蝇中<code>Doc</code>(non-LTR)的插入导致了Cyp6g1基因表达增加，该基因提高了宿主对DDT等杀虫剂的抗药性。</p><h3 id="TE水平转移"><a href="#TE水平转移" class="headerlink" title="TE水平转移"></a><strong>TE水平转移</strong></h3><p>有性生殖为TE的垂直传递提供了便利，但是TE的水平转移也是其长期存在的重要原因。几乎所有的TE都存在水平转移现象，在某些TE家族会表现的特别明显。对于DDE类型的DNA转座子，其水平转移相对容易，发生率也更高；而相对于non-LTR的逆转座子，其水平转移比较罕见。</p><p>DNA转座子（DDE）容易发生水平转移可能是因为其进化出了一些转座机制，最大程度上减少了宿主特异性。比如，它们会编码一些弱作用的启动子，甚至不编码启动子，这使得它们的转座必须依赖于插入到宿主基因表达调节序列中，利用宿主的启动子实现转座，其中涉及到的很多转录因子也是直接使用宿主提供的。这大大提高了他们在不同宿主中的适应性。此外，有些DNA转座子的转座酶在不同宿主细胞中都能保持较高活性，甚至在非细胞的体外环境也能保持一定的活性。这些因素都降低了DNA转座子宿主的特异性，促使其水平转移更加容易。</p><p>转座中介物的不同也是造成TE发生水平转移差异的原因。比如转座中的DNA中介比RNA中介产物更加稳定，DNA转座子更容易水平转移。有些逆转座子能够形成类似病毒可以的衣壳，这些衣壳会促进这些逆转座子在细胞外的播散。有些转座子可以依赖真正的病毒进行水平转移，比如转座过程中的中介物可以与病毒序列结合或者利用病毒衣壳。中介物产生的位置会影响水平转移，比如有些中介物主要（non-LTR）或者局限(DNA转座子)在细胞核中，那么这些转座子可能很难依赖在细胞质中进行自我复制的病毒（如痘病毒）而进行水平转移；不过它们却可以依赖一些在细胞核中复制的病毒（比如疱疹病毒和杆状病毒）进行水平转移。</p><h3 id="抵御宿主免疫"><a href="#抵御宿主免疫" class="headerlink" title="抵御宿主免疫"></a><strong>抵御宿主免疫</strong></h3><p>宿主也会对TE活动进行抑制，特别是在生殖系细胞中。<code>Piwi</code>(piRNA)在生殖细胞中很活跃，通过RNA干扰，能够抑制TE的活性。比如在黑腹果蝇的卵子形成过程中，<code>I</code>元件在卵母细胞中进行逆转座，但是其RNA中介物仅仅在卵母细胞周围的支持细胞中生成，然后等卵母细胞成熟之后，再通过微管系统从支持细胞转运至卵母细胞中。这么做的目的一方面是周围支持细胞数量较多，能够积累很高浓度的RNA中介物；另一方面也是避免卵母细胞中<code>piRNA</code>的抑制作用。</p><h2 id="5-总结"><a href="#5-总结" class="headerlink" title="5. 总结"></a><strong>5. 总结</strong></h2><p>转座子（TE）几乎存在于所有的物种中，对物种的基因组结构和物种进化有重要的影响。尽管如此，人们对TE的研究还相当欠缺。在发现TE的前60年的时间内，人们主要是通过模式生物和少数农业作物对少数TE进行描述，研究其对表型的影响。最近十余年，测序的进步使得能够更加全面的识别、比较、探究不同TE的调节、转录活性，对TE的研究更加具体详细。人们发现基因组中大部分TE都是失活的转座遗迹，犹如一座座死火山，这些遗迹的累积构成了真核生物基因中的重复序列。</p><p>对TE的研究不能忽视对其转座机制的研究。目前越来越多的研究出现在了基因组进化水平上的研究，却忽略了TE本身的转座机制。</p><p>TE家族之间表现出了很大的差异性，其对宿主基因组造成的影响也很大。在更多的物种中，对TE进行识别和分类也同样重要。同时要注重对转座机制的研究，特别是一些比较<strong>特殊的转座子，比如Helitrons, Marvericks, YR元件</strong>等。</p>]]></content>
    
    
    <categories>
      
      <category>Biology</category>
      
    </categories>
    
    
    <tags>
      
      <tag>annotation</tag>
      
      <tag>LTR</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>RNA-seq【hisat2】</title>
    <link href="/GeekFocus/2022/05/11/2022-05-11-hisat2/"/>
    <url>/GeekFocus/2022/05/11/2022-05-11-hisat2/</url>
    
    <content type="html"><![CDATA[<p>RNA-seq </p><span id="more"></span><h1 id="一-软件比较"><a href="#一-软件比较" class="headerlink" title="一. 软件比较"></a>一. 软件比较</h1><p>tophat2 不更新，速度慢。hisat2同实验室开发</p><p>tophat+cufflinks可替换为：hisat2+stringtie+ballgown</p><blockquote><p>Star的比对速度是tophat的50倍，hisat是star的1.2倍。<br>stringTie的组装速度是cufflinks的25倍，内存消耗不到其一半。<br>Ballgown在差异分析方面比cuffdiff更高的特异性及准确性，时间消耗不到cuffdiff的千分之一<br>Bowtie2+eXpress做质量控制优于tophat2+cufflinks和bowtie2+RSEM<br>Sailfish跳过比对步骤，直接进行kmer计数做QC，特异性及准确性都还行，但速度提高了25倍<br>kallisto同样不需要比对，速度比sailfish提高5倍.</p></blockquote><p>good introduction：<a href="https://cloud.tencent.com/developer/article/1703051">https://cloud.tencent.com/developer/article/1703051</a></p><h1 id="二-hisat2介绍"><a href="#二-hisat2介绍" class="headerlink" title="二.hisat2介绍"></a>二.hisat2介绍</h1><p>Hisat是一种高效的RNA-seq实验比对工具。它使用了基于BWT和Ferragina-manzini (Fm) index 两种算法的索引框架。使用了两类索引去比对，一类是全基因组范围的FM索引来锚定每一个比对，另一类是大量的局部索引对这些比对做快速的扩展。比对原理可阅读文献原文：HISAT: a fast spliced aligner with low memory requirements.</p><p>（一）背景</p><p>自2008年起，RNAseq已经成为研究基因表达、转录本结构、长链非编码RNA确定以及融合转录本的重要手段。随着测序深度的加深和read读长的延长，给比对工作带来很多困难。目前的工具如Tophat2和GSNAP等在对单个转录组实验的比对中耗时几天，而新型的STAR虽然很快，但是会吃掉大量的内存空间，如基于人类基因组的比对需要消耗28G左右，而hisat2是4.3G，小鼠3.8G左右。</p><p>（二）Hisat设计原则</p><p>1.优化了索引建立策略</p><p>hisat应用了基于bowtie2的方法去处理很多低水平的用于构建和查询FM索引的操作。但是与其它比对器不同的是，该软件应用了两类不同的索引类型：代表全基因组的全局FM索引和大量的局部小索引，每个索引代表64000bp。以人类基因组为例，创建了48000个局部索引，每一个覆盖1024bp，最终可以覆盖这个3 billion 的碱基的基因组。这种存在交叉（overlap）的边界可以轻松的比对那些跨区域的read（可变剪切体）。尽管有很多索引，但是hisat会把他们使用合适方法压缩，最终只占4gb左右的内存。</p><p>2.采用了新的比对策略</p><p>RNA-seq产生的reads可能跨长度比较大的内含子，哺乳动物中甚至最长能达到1MB，同时外显子比较短，read也比较短，会有很多read（模拟数据中大概34%）跨两个外显子的情况。为了更好的比对，将跨外显子的reads分成了三类：1）长锚定read，至少有16bp在两个外显子的每一个上 2）中间锚定read，有8-15bp在一个外显子上 3）短锚定read，只有1-7bp在一个外显子上。所以总的reads可以被划分为五类：1）不跨外显子的read 2）长锚定read 3）中间锚定read 4）短锚定read 5）跨两个外显子以上的read。在模拟的数据中，有25%左右的read是长锚定read，这种read在大多数情况下可以被唯一的定位到人的基因组上。5%为中间锚定read，对于这类，很多依赖于全局索引的算法就很难执行下去（需要比对很多次），而hisat，可以先将read中的长片段实现唯一比对，之后再使用局部索引对剩下的小片段进行比对（局部索引可以实现快速检索）。4.2%为短锚定read，因为这些序列特别短，因此只能通过在hisat比对其它read时发现的剪切位点或者用户自己提供的剪切位点来辅助比对。最后还有3%的是跨多个外显子的read，比对策略在hisat的online method中有介绍，文章中没有详解。比对过程中，中间锚定read、短锚定read、跨多个外显子read的比对占总比对时长的30%-60%，而且比对错误率很高！【引用：1】</p><p>官方手册：<a href="https://daehwankimlab.github.io/hisat2/manual/">https://daehwankimlab.github.io/hisat2/manual/</a><br>（三）.HiSat2进行比对的参数设置 【引用：2】</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br></pre></td><td class="code"><pre><code class="hljs sh">HISAT2 version 2.1.0 by Daehwan Kim (infphilo@gmail.com, www.ccb.jhu.edu/people/infphilo)<br>Usage: <br>  hisat2 [options]* -x &lt;ht2-idx&gt; &#123;-1 &lt;m1&gt; -2 &lt;m2&gt; | -U &lt;r&gt;&#125; [-S &lt;sam&gt;]<br><br>  &lt;ht2-idx&gt;  Index filename prefix (minus trailing .X.ht2).<br>             索引文件的前缀<br>  &lt;m1&gt;       Files with <span class="hljs-comment">#1 mates, paired with files in &lt;m2&gt;.</span><br>             Could be gzip<span class="hljs-string">&#x27;ed (extension: .gz) or bzip2&#x27;</span>ed (extension: .bz2).<br>             Paired-end测序的第一个文件，可以是压缩格式的（`.gz`或者`.bz2`）<br>  &lt;m2&gt;       Files with <span class="hljs-comment">#2 mates, paired with files in &lt;m1&gt;.</span><br>             Could be gzip<span class="hljs-string">&#x27;ed (extension: .gz) or bzip2&#x27;</span>ed (extension: .bz2).<br>             Paired-end测序的第二个文件<br>  &lt;r&gt;        Files with unpaired reads.<br>             Could be gzip<span class="hljs-string">&#x27;ed (extension: .gz) or bzip2&#x27;</span>ed (extension: .bz2).<br>             single-end测序的文件<br>  &lt;sam&gt;      File <span class="hljs-keyword">for</span> SAM output (default: stdout)<br>             输出比对的结果（`.sam`）<br><br>  &lt;m1&gt;, &lt;m2&gt;, &lt;r&gt; can be comma-separated lists (no whitespace) and can be<br>  specified many <span class="hljs-built_in">times</span>.  E.g. <span class="hljs-string">&#x27;-U file1.fq,file2.fq -U file3.fq&#x27;</span>.<br>  可以是多个序列文件用逗号分隔<br><br>Options (defaults <span class="hljs-keyword">in</span> parentheses):<br><br> Input:<br>  -q                 query input files are FASTQ .fq/.fastq (default)<br>                     输入检索序列为FASTQG格式<br>  --qseq             query input files are <span class="hljs-keyword">in</span> Illumina<span class="hljs-string">&#x27;s qseq format</span><br><span class="hljs-string">                     输入检索序列是Illumina qseq格式</span><br><span class="hljs-string">  -f                 query input files are (multi-)FASTA .fa/.mfa</span><br><span class="hljs-string">                     输入文件是多个FASTA文件</span><br><span class="hljs-string">  -r                 query input files are raw one-sequence-per-line</span><br><span class="hljs-string">                     输入检索序列是每行一个原始序列</span><br><span class="hljs-string">  -c                 &lt;m1&gt;, &lt;m2&gt;, &lt;r&gt; are sequences themselves, not files</span><br><span class="hljs-string">                     直接输入序列，而不是文件</span><br><span class="hljs-string">  -s/--skip &lt;int&gt;    skip the first &lt;int&gt; reads/pairs in the input (none)</span><br><span class="hljs-string">                     忽略输入序列的前`&lt;int&gt;`个</span><br><span class="hljs-string">  -u/--upto &lt;int&gt;    stop after first &lt;int&gt; reads/pairs (no limit)</span><br><span class="hljs-string">                     只分析输入序列的前`&lt;int&gt;`个</span><br><span class="hljs-string">  -5/--trim5 &lt;int&gt;   trim &lt;int&gt; bases from 5&#x27;</span>/left end of reads (0)<br>                     剪去reads长度为`&lt;int&gt;`的5<span class="hljs-string">&#x27;端序列</span><br><span class="hljs-string">  -3/--trim3 &lt;int&gt;   trim &lt;int&gt; bases from 3&#x27;</span>/right end of reads (0)<br>                     剪去reads长度为`&lt;int&gt;`的3<span class="hljs-string">&#x27;端序列</span><br><span class="hljs-string">  --phred33          qualities are Phred+33 (default)</span><br><span class="hljs-string">                     序列质量打分为Phred+33</span><br><span class="hljs-string">  --phred64          qualities are Phred+64</span><br><span class="hljs-string">                     序列质量打分为Phred+64</span><br><span class="hljs-string">  --int-quals        qualities encoded as space-delimited integers</span><br><span class="hljs-string">                     序列质量打分为用空格分隔的整数</span><br><span class="hljs-string"></span><br><span class="hljs-string"> Alignment:</span><br><span class="hljs-string">  --n-ceil &lt;func&gt;    func for max # non-A/C/G/Ts permitted in aln (L,0,0.15)</span><br><span class="hljs-string">                     允许在比对结果中出现的最多非ACTG的计算函数</span><br><span class="hljs-string">  --ignore-quals     treat all quality values as 30 on Phred scale (off)</span><br><span class="hljs-string">                     将所有质量分值设为30</span><br><span class="hljs-string">  --nofw             do not align forward (original) version of read (off)</span><br><span class="hljs-string">                     不比对前向的read</span><br><span class="hljs-string">  --norc             do not align reverse-complement version of read (off)</span><br><span class="hljs-string">                     不比对后向的read</span><br><span class="hljs-string"></span><br><span class="hljs-string"> Spliced Alignment:</span><br><span class="hljs-string">  --pen-cansplice &lt;int&gt;              penalty for a canonical splice site (0)</span><br><span class="hljs-string">                                     对已知剪接位点的罚分</span><br><span class="hljs-string">  --pen-noncansplice &lt;int&gt;           penalty for a non-canonical splice site (12)</span><br><span class="hljs-string">                                     对新的剪接位点的罚分</span><br><span class="hljs-string">  --pen-canintronlen &lt;func&gt;          penalty for long introns (G,-8,1) with canonical splice sites</span><br><span class="hljs-string">                                     对已知剪接位点中长内含子的罚分</span><br><span class="hljs-string">  --pen-noncanintronlen &lt;func&gt;       penalty for long introns (G,-8,1) with noncanonical splice sites</span><br><span class="hljs-string">                                     对未知剪接位点中长内含子的罚分</span><br><span class="hljs-string">  --min-intronlen &lt;int&gt;              minimum intron length (20)</span><br><span class="hljs-string">                                     最小允许的内含子长度</span><br><span class="hljs-string">  --max-intronlen &lt;int&gt;              maximum intron length (500000)</span><br><span class="hljs-string">                                     最大允许的内含子长度</span><br><span class="hljs-string">  --known-splicesite-infile &lt;path&gt;   provide a list of known splice sites</span><br><span class="hljs-string">                                     提供一个已知的剪接位点列表</span><br><span class="hljs-string">  --novel-splicesite-outfile &lt;path&gt;  report a list of splice sites</span><br><span class="hljs-string">                                     报告新的剪接位点</span><br><span class="hljs-string">  --novel-splicesite-infile &lt;path&gt;   provide a list of novel splice sites</span><br><span class="hljs-string">                                     提供新的剪接位点</span><br><span class="hljs-string">  --no-temp-splicesite               disable the use of splice sites found</span><br><span class="hljs-string">                                     不使用发现的新剪接位点</span><br><span class="hljs-string">  --no-spliced-alignment             disable spliced alignment</span><br><span class="hljs-string">                                     不允许剪接比对</span><br><span class="hljs-string">  --rna-strandness &lt;string&gt;          specify strand-specific information (unstranded)</span><br><span class="hljs-string">                                     指定链特异性的信息</span><br><span class="hljs-string">  --tmo                              reports only those alignments within known transcriptome</span><br><span class="hljs-string">                                     报告只包含已知转录组信息的比对结果</span><br><span class="hljs-string">  --dta                              reports alignments tailored for transcript assemblers</span><br><span class="hljs-string">                                     结果适合用于stringtie进行转录本的拼接</span><br><span class="hljs-string">  --dta-cufflinks                    reports alignments tailored specifically for cufflinks</span><br><span class="hljs-string">                                     结果适合于cufflinks的应用</span><br><span class="hljs-string">  --avoid-pseudogene                 tries to avoid aligning reads to pseudogenes (experimental option)</span><br><span class="hljs-string">                                     避免与假基因的比对</span><br><span class="hljs-string">  --no-templatelen-adjustment        disables template length adjustment for RNA-seq reads</span><br><span class="hljs-string">                                     不允许对reads的模板长度进行调整</span><br><span class="hljs-string"></span><br><span class="hljs-string"> Scoring:</span><br><span class="hljs-string">  --mp &lt;int&gt;,&lt;int&gt;   max and min penalties for mismatch; lower qual = lower penalty &lt;6,2&gt;</span><br><span class="hljs-string">                     不匹配的最大与最小罚分值，低质量对应低罚分</span><br><span class="hljs-string">  --sp &lt;int&gt;,&lt;int&gt;   max and min penalties for soft-clipping; lower qual = lower penalty &lt;2,1&gt;</span><br><span class="hljs-string">                     soft-clipping的最大与最小罚分</span><br><span class="hljs-string">  --no-softclip      no soft-clipping</span><br><span class="hljs-string">                     不考虑Soft-clipping</span><br><span class="hljs-string">  --np &lt;int&gt;         penalty for non-A/C/G/Ts in read/ref (1)</span><br><span class="hljs-string">                     对read或参考序列中出现的非ATCG的罚分</span><br><span class="hljs-string">  --rdg &lt;int&gt;,&lt;int&gt;  read gap open, extend penalties (5,3)</span><br><span class="hljs-string">                     对read的gap-open, gap-extension的罚分</span><br><span class="hljs-string">  --rfg &lt;int&gt;,&lt;int&gt;  reference gap open, extend penalties (5,3)</span><br><span class="hljs-string">                     对参考序列的gap-open,gap-extension的罚分</span><br><span class="hljs-string">  --score-min &lt;func&gt; min acceptable alignment score w/r/t read length</span><br><span class="hljs-string">                     (L,0.0,-0.2)</span><br><span class="hljs-string">                     相对read长度的最小接受比对分值</span><br><span class="hljs-string"></span><br><span class="hljs-string"> Reporting:</span><br><span class="hljs-string">  -k &lt;int&gt; (default: 5) report up to &lt;int&gt; alns per read</span><br><span class="hljs-string">                     对每个read只报告`&lt;int&gt;`个比对结果</span><br><span class="hljs-string"></span><br><span class="hljs-string"> Paired-end:</span><br><span class="hljs-string">  -I/--minins &lt;int&gt;  minimum fragment length (0), only valid with --no-spliced-alignment</span><br><span class="hljs-string">                     paired-end的最小片段长度</span><br><span class="hljs-string">  -X/--maxins &lt;int&gt;  maximum fragment length (500), only valid with --no-spliced-alignment</span><br><span class="hljs-string">                     最大片段长度</span><br><span class="hljs-string">  --fr/--rf/--ff     -1, -2 mates align fw/rev, rev/fw, fw/fw (--fr)</span><br><span class="hljs-string">                     `--fr==fw/rev`，`--rf==rev/fw`, `--ff==fw/fw`</span><br><span class="hljs-string">  --no-mixed         suppress unpaired alignments for paired reads</span><br><span class="hljs-string">                     不输出paired reads的不能匹配的比对结果</span><br><span class="hljs-string">  --no-discordant    suppress discordant alignments for paired reads</span><br><span class="hljs-string">                     不输出paired-reads的不统一的比对结果</span><br><span class="hljs-string"></span><br><span class="hljs-string"> Output:</span><br><span class="hljs-string">  -t/--time          print wall-clock time taken by search phases</span><br><span class="hljs-string">                     输出搜索阶段所花费的wall-clock时间</span><br><span class="hljs-string">  --un &lt;path&gt;           write unpaired reads that didn&#x27;</span>t align to &lt;path&gt;<br>                        输出没有与`&lt;path&gt;`比对的unpaired reads<br>  --al &lt;path&gt;           write unpaired reads that aligned at least once to &lt;path&gt;<br>                        输出至少与`&lt;path&gt;`有一次比对的unpaired reads<br>  --un-conc &lt;path&gt;      write pairs that didn<span class="hljs-string">&#x27;t align concordantly to &lt;path&gt;</span><br><span class="hljs-string">  --al-conc &lt;path&gt;      write pairs that aligned concordantly at least once to &lt;path&gt;</span><br><span class="hljs-string">  (Note: for --un, --al, --un-conc, or --al-conc, add &#x27;</span>-gz<span class="hljs-string">&#x27; to the option name, e.g.</span><br><span class="hljs-string">  --un-gz &lt;path&gt;, to gzip compress output, or add &#x27;</span>-bz2<span class="hljs-string">&#x27; to bzip2 compress output.)</span><br><span class="hljs-string">                    将输出结果进行`gz`或者`bz2`压缩</span><br><span class="hljs-string">  --summary-file     print alignment summary to this file.</span><br><span class="hljs-string">                     将比对的总结输出到文件中</span><br><span class="hljs-string">  --new-summary      print alignment summary in a new style, which is more machine-friendly.</span><br><span class="hljs-string">                     将比对总结以新的形式输出</span><br><span class="hljs-string">  --quiet            print nothing to stderr except serious errors</span><br><span class="hljs-string">                     除了严重错误以外，不将任何结果输出到stderr</span><br><span class="hljs-string">  --met-file &lt;path&gt;  send metrics to file at &lt;path&gt; (off)</span><br><span class="hljs-string">                     将度量值i输出到文件</span><br><span class="hljs-string">  --met-stderr       send metrics to stderr (off)</span><br><span class="hljs-string">                     将度量值输出到stderr</span><br><span class="hljs-string">  --met &lt;int&gt;        report internal counters &amp; metrics every &lt;int&gt; secs (1)</span><br><span class="hljs-string">                     每隔`&lt;int&gt;`秒输出当前的内部计数器和度量值</span><br><span class="hljs-string">  --no-head          supppress header lines, i.e. lines starting with @</span><br><span class="hljs-string">                     不输出header行，也就是所有以`@`开始的行</span><br><span class="hljs-string">  --no-sq            supppress @SQ header lines</span><br><span class="hljs-string">                     不输出`@SQ`行</span><br><span class="hljs-string">  --rg-id &lt;text&gt;     set read group id, reflected in @RG line and RG:Z: opt field</span><br><span class="hljs-string">                     设置`@RG`</span><br><span class="hljs-string">  --rg &lt;text&gt;        add &lt;text&gt; (&quot;lab:value&quot;) to @RG line of SAM header.</span><br><span class="hljs-string">                     Note: @RG line only printed when --rg-id is set.</span><br><span class="hljs-string">                     将`&lt;text&gt;`加到SAM文件的`@RG`行</span><br><span class="hljs-string">  --omit-sec-seq     put &#x27;</span>*<span class="hljs-string">&#x27; in SEQ and QUAL fields for secondary alignments.</span><br><span class="hljs-string">                     将&quot;*&quot;置于SEQ和QUAL两列中，进行二次比对</span><br><span class="hljs-string"></span><br><span class="hljs-string"> Performance:</span><br><span class="hljs-string">  -o/--offrate &lt;int&gt; override offrate of index; must be &gt;= index&#x27;</span>s offrate<br>                     重置索引的`offrate`，该值必须大于原有的`offrate`<br>  -p/--threads &lt;int&gt; number of alignment threads to launch (1)<br>                     比对所用的线程数<br>  --reorder          force SAM output order to match order of input reads<br>                     强制要求SAM输出顺序比对与输入reads一致<br>  --mm               use memory-mapped I/O <span class="hljs-keyword">for</span> index; many <span class="hljs-string">&#x27;hisat2&#x27;</span>s can share<br>                     使用内存映射的I/O作为索引<br><br> Other:<br>  --qc-filter        filter out reads that are bad according to QSEQ filter<br>                     根据QSEQ filter过滤输入的reads<br>  --seed &lt;int&gt;       seed <span class="hljs-keyword">for</span> random number generator (0)<br>                     设置RNG seeds的值<br>  --non-deterministic seed rand. gen. arbitrarily instead of using <span class="hljs-built_in">read</span> attributes<br>                     不根据reads的属性产生随机数<br>  --remove-chrname   remove <span class="hljs-string">&#x27;chr&#x27;</span> from reference names <span class="hljs-keyword">in</span> alignment<br>                     比对结果中的参考序列名称中去除`chr`<br>  --add-chrname      add <span class="hljs-string">&#x27;chr&#x27;</span> to reference names <span class="hljs-keyword">in</span> alignment<br>                     在比对结果的参考序列名称中加入`chr` <br>  --version          <span class="hljs-built_in">print</span> version information and quit<br>                     输出版本信息<br>  -h/--help          <span class="hljs-built_in">print</span> this usage message<br>                     输出帮助信息<br></code></pre></td></tr></table></figure><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs sh"> --dta                              reports alignments tailored <span class="hljs-keyword">for</span> transcript assemblers<br>                                     结果适合用于stringtie进行转录本的拼接<br><span class="hljs-comment">#Cufflinks error: BAM record error: found spliced alignment without XS attribute</span><br>https://www.biostars.org/p/118904/<br>https://bioinformatics.stackexchange.com/questions/4074/hisat2-which-option-should-mention-for-strand-specific-library-read<br>--rna-strandnessSpecify strand-specific information: the default is unstranded. For single-end reads, use F or R. <span class="hljs-string">&#x27;F&#x27;</span> means a <span class="hljs-built_in">read</span> corresponds to a transcript. <span class="hljs-string">&#x27;R&#x27;</span> means a <span class="hljs-built_in">read</span> corresponds to the reverse complemented counterpart of a transcript. For paired-end reads, use either FR or RF. With this option being used, every <span class="hljs-built_in">read</span> alignment will have an XS attribute tag: <span class="hljs-string">&#x27;+&#x27;</span> means a <span class="hljs-built_in">read</span> belongs to a transcript on <span class="hljs-string">&#x27;+&#x27;</span> strand of genome. <span class="hljs-string">&#x27;-&#x27;</span> means a <span class="hljs-built_in">read</span> belongs to a transcript on <span class="hljs-string">&#x27;-&#x27;</span> strand of genome.<br>--fr/--rf/--ffThe upstream/downstream mate orientations <span class="hljs-keyword">for</span> a valid paired-end alignment against the forward reference strand. E.g., <span class="hljs-keyword">if</span> --fr is specified and there is a candidate paired-end alignment <span class="hljs-built_in">where</span> mate 1 appears upstream of the reverse complement of mate 2 and the fragment length constraints (-I and -X) are met, that alignment is valid. Also, <span class="hljs-keyword">if</span> mate 2 appears upstream of the reverse complement of mate 1 and all other constraints are met, that too is valid. --rf likewise requires that an upstream mate1 be reverse-complemented and a downstream mate2 be forward-oriented. --ff requires both an upstream mate 1 and a downstream mate 2 to be forward-oriented. Default: --fr (appropriate <span class="hljs-keyword">for</span> Illumina<span class="hljs-string">&#x27;s Paired-end Sequencing Assay).</span><br><span class="hljs-string"></span><br></code></pre></td></tr></table></figure><blockquote><p><code>--fr</code>&#x2F;<code>--rf</code>&#x2F;<code>--ff</code> should rarely be set, since they refer to the relative orientation of reads and basically everything these days is <code>--fr</code>. Mate-pairs were <code>--rf</code>, but you don’t see those much any more.</p><p><code>--rna-strandedness</code> is a very different option, since it sets how reads are expected to align against genes. Most stranded protocols in use these days follow the dUTP-method, where read #2 in a pair has the same orientation as the transcript from which it arose. So either <code>R</code> or <code>RF</code>would typically be appropriate, unless the library is unstranded. In practice, I expect this is more useful if you plan to run stringTie downstream, since then the <code>XS</code> auxiliary tag is set appropriately.</p></blockquote><p>hisat2可以自己建立index文件，如果没有现成的index的话，那就得自己去建立了，这个就比较麻烦而且耗内存和时间，下面是建立index的一些参数介绍。因为我们的index文件是直接下载的，所以我后面不需要建立index文件，关于这部分，后面有机会介绍。</p><figure class="highlight livecodeserver"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><code class="hljs livecodeserver">HISAT2 <span class="hljs-built_in">version</span> <span class="hljs-number">2.1</span><span class="hljs-number">.0</span> <span class="hljs-keyword">by</span> Daehwan Kim (infphilo@gmail.com, <span class="hljs-keyword">http</span>://www.ccb.jhu.edu/people/infphilo)<br>Usage: hisat2-build [options]* &lt;reference_in&gt; &lt;ht2_index_base&gt;<br>    reference_in            <span class="hljs-literal">comma</span>-separated list <span class="hljs-keyword">of</span> <span class="hljs-built_in">files</span> <span class="hljs-keyword">with</span> ref sequences<br>                            以逗号分隔的参考序列文件的列表<br>    hisat2_index_base       <span class="hljs-built_in">write</span> ht2 data <span class="hljs-built_in">to</span> <span class="hljs-built_in">files</span> <span class="hljs-keyword">with</span> this dir/basename<br>                            输出的索引文件的`basename`<br>Options:<br>    -c                      reference sequences given <span class="hljs-keyword">on</span> <span class="hljs-title">cmd</span> <span class="hljs-title">line</span> (<span class="hljs-title">as</span><br>                            &lt;reference_in&gt;)<br>                            输入的参考序列<br>    <span class="hljs-comment">--large-index           force generated index to be &#x27;large&#x27;, even if ref</span><br>                            has fewer than <span class="hljs-number">4</span> billion nucleotides<br>                            强制要求产生的索引为`large`<br>    -<span class="hljs-keyword">a</span>/<span class="hljs-comment">--noauto             disable automatic -p/--bmax/--dcv memory-fitting</span><br>                            关闭-p/<span class="hljs-comment">--bmax/--dcv等自动内存匹配</span><br>    -p                      <span class="hljs-built_in">number</span> <span class="hljs-keyword">of</span> threads<br>                            线程数<br>    <span class="hljs-comment">--bmax &lt;int&gt;            max bucket sz for blockwise suffix-array builder</span><br>                            逐块后缀数组建立采用的最大bucket size<br>    <span class="hljs-comment">--bmaxdivn &lt;int&gt;        max bucket sz as divisor of ref len (default: 4)</span><br>    <span class="hljs-comment">--dcv &lt;int&gt;             diff-cover period for blockwise (default: 1024)</span><br>    <span class="hljs-comment">--nodc                  disable diff-cover (algorithm becomes quadratic)</span><br>    -r/<span class="hljs-comment">--noref              don&#x27;t build .3/.4.ht2 (packed reference) portion</span><br>    <span class="hljs-number">-3</span>/<span class="hljs-comment">--justref            just build .3/.4.ht2 (packed reference) portion</span><br>    -o/<span class="hljs-comment">--offrate &lt;int&gt;      SA is sampled every 2^offRate BWT chars (default: 5)</span><br>    -t/<span class="hljs-comment">--ftabchars &lt;int&gt;    # of chars consumed in initial lookup (default: 10)</span><br>    <span class="hljs-comment">--localoffrate &lt;int&gt;    SA (local) is sampled every 2^offRate BWT chars (default: 3)</span><br>    <span class="hljs-comment">--localftabchars &lt;int&gt;  # of chars consumed in initial lookup in a local index (default: 6)</span><br>    <span class="hljs-comment">--snp &lt;path&gt;            SNP file name</span><br>    <span class="hljs-comment">--haplotype &lt;path&gt;      haplotype file name</span><br>    <span class="hljs-comment">--ss &lt;path&gt;             Splice site file name</span><br>    <span class="hljs-comment">--exon &lt;path&gt;           Exon file name</span><br>    <span class="hljs-comment">--seed &lt;int&gt;            seed for random number generator</span><br>    -q/<span class="hljs-comment">--quiet              verbose output (for debugging)</span><br>    -h/<span class="hljs-comment">--help               print detailed description of tool and its options</span><br>    <span class="hljs-comment">--usage                 print this usage message</span><br>    <span class="hljs-comment">--version               print version information and quit</span><br></code></pre></td></tr></table></figure><h1 id="三-stringtie2介绍"><a href="#三-stringtie2介绍" class="headerlink" title="三. stringtie2介绍"></a>三. stringtie2介绍</h1><p><a href="https://ccb.jhu.edu/software/stringtie/">https://ccb.jhu.edu/software/stringtie/</a></p><p><a href="https://github.com/gpertea/stringtie">https://github.com/gpertea/stringtie</a></p><p><a href="https://cloud.tencent.com/developer/article/1702981">https://cloud.tencent.com/developer/article/1702981</a></p><p>StringTie 是用于 RNA-seq 的转录本<font color="blue">组装和定量</font>软件，StringTie 是<font color="blue">cufflinks升级版</font>，功能和Cufflinks一样，包括下面两个主要功能：转录本组装和定量；相比Cuffinks, 运行速度更快</p><p>1、Stringtie通过<font color="blue">genome指导组装与从头组装结合</font>的新方法来改善转录组组装。</p><p> 2、Stringtie的输入不仅可以是经过比对的结果，<font color="blue">也可以是Stringtie从头组装read得到的contig</font>，当这两种输入都用到的时候，称之为<font color="blue">stringtie+SR</font>。</p><p> 3、对于很多<font color="blue">使用参考基因组辅助组装</font>的方法，组装的的策略都是<font color="blue">先对read进行cluter</font>，然后建立<font color="blue">graph model</font>推测每个基因<font color="blue">所有可能的isoform</font>，最终通过不同的graph的解析方法得到对转录本的组装结果。</p><p> 4、<font color="blue">cufflinks</font>采用<font color="blue">overlap graph</font>，该模型中<font color="blue">nodes代表fragment</font>，如果两个fragment<font color="blue">存在overlap并存在兼容的剪切模式</font>，则对应的node连接起来。其解析方法为一种保守的算法，<font color="blue">可以产生能够解释所有read的最少的转录本</font>，尽管这种方法很吸引人，但是<font color="red">没有考虑到转录本的丰度</font>并且<font color="blue">某些isoform</font>该方法<font color="blue">无法组装</font>！</p><p> 5、stringtie采用<font color="red"><strong>组装转录本和估计表达量同步进行</strong></font>的方法，不同于cufflinks的先组装后定量的策略。</p><p> 6、首先，stringtie将read聚成cluster，然后采用<font color="blue">splice graph</font>，其中<font color="blue">node代表外显子或外显子的一部分</font>，path将graph中可能的剪切现象连接，最终对每个转录本通过创建一个网络流的方法，利用<font color="blue">最大流算法</font>（maximum flow algorithm）<font color="red">估计转录本的表达量</font>。</p><p> 7、<font color="red">最大流的问题是最优理论中的经典问题</font>，但是目前还没有应用到转录本定量中。</p><p> 8、与其它组装软件相比，stringtie具有很高的<font color="red"><strong>准确性</strong>和<strong>新型isoform发现</strong>能力</font>，其优势在于使用网络流算法，同时stringtie也支持将read从头组装成<font color="blue">更长片段</font>，进一步提高了其组装的正确性。</p><p> 9、其另一个优势在于它的<font color="blue">最优化策略</font>，它<font color="blue">平衡了每次组装中每条转录本的覆盖度</font>，这样可以对组装算法产生一定的限制，因为在组装基因组时，覆盖度是很重要的一个参数因为它需要被用来限制算法，否则组装器可能将重复的片段错误地堆叠到一起，相似地转录组装也是如此，<font color="red"><strong>在isoform中的每一个外显子需要有相似的覆盖度</strong></font>，如果忽略这个参数可能会产生一些保守但是错误的转录本，其中含有大量剪切位点的基因组装起来尤其困难。</p><p>常用的参数及描述：</p><table><thead><tr><th>参数</th><th>–</th></tr></thead><tbody><tr><td>-o [<path/>]&lt;out.gtf&gt;</td><td>设置StringTie组装转录本的输出GTF文件的<strong>全路径和文件名</strong>。默认情况下，StringTie将GTF写入标准输出</td></tr><tr><td>-p <int></td><td>线程数，默认1</td></tr><tr><td>-G &lt;ref_ann.gff&gt;</td><td>使用参考注释基因文件指导组装过程，格式GTF&#x2F;GFF3。-e未设置时输出文件中既包含参考文件转录本，也包含新转录本。选项-B，-b，-e，-C需要此选项</td></tr><tr><td>-l <label></td><td>输出转录本名称的前缀。默认：STRG</td></tr><tr><td>-A &lt;gene_abund.tab&gt;</td><td>输出的gtf统计基因表达量（tab分隔）</td></tr><tr><td>-C &lt;cov_refs.gtf&gt;</td><td>输出所有转录本对应的reads覆盖度的文件，此处的转录本是指参考注释基因文件中提供的转录本。(需要参数 -G).</td></tr><tr><td>-B</td><td>应用该选项，则会输出Ballgown输入表文件（* .ctab），其中包含用-G选项给出的参考转录本的覆盖率数据。（有关这些文件的说明，请参阅Ballgown文档。）如果选项-o 给出输出转录文件的完整路径，则* .ctab文件与输出GTF文件在相同的目录下。</td></tr><tr><td>-b <path></td><td>#指定 *.ctab 文件的输出路径, 而非由-o选项指定的目录。注意: 建议在使用-B&#x2F;-b选项中同时使用-e选项，除非StringTie GTF输出文件中仍需要新的转录本,-B和-b选一个使用就行。</td></tr><tr><td>-e</td><td>限制reads比对的处理，仅估计和输出与用-G选项给出的参考转录本匹配的组装转录本。使用该选项，则会跳过处理与参考转录本不匹配的组装转录本，提速</td></tr><tr><td>-m <int></td><td>预测转录本设置最小长度，默认200</td></tr><tr><td>–merge</td><td>#转录本合并模式。在合并模式下，StringTie将所有样品的GTF&#x2F;GFF文件列表作为输入，并将这些转录本合并&#x2F;组装成非冗余的转录本集合。这种模式被用于新的差异分析流程中，用以生成一个跨多个RNA-Seq样品的全局的、统一的转录本。如果提供了-G选项（参考注释基因组文件），则StringTie将从输入的GTF文件中将参考转录本组装到transfrags中。(个人理解：transfrags可能指的是拼接成更大的转录本片段，tanscript fragments)。在此模式下可以使用以下附加选项：</td></tr><tr><td>-G <guide_gff></td><td>#参考注释基因组文件(GTF&#x2F;GFF3)</td></tr><tr><td>-o <out_gtf></td><td>#指定输出合并的GTF文件的路径和名称 (默认值：标准输出)</td></tr><tr><td>-m <min_len></td><td>#合并文件中，指定允许最小输入转录本的长度 (默认值: 50)</td></tr><tr><td>-c <min_cov></td><td>#合并文件中，指定允许最低输入转录本的覆盖度(默认值: 0)</td></tr><tr><td>-F <min_fpkm></td><td>#合并文件中，指定允许最低输入转录本的FPKM值 (默认值: 0)</td></tr><tr><td>-T <min_tpm></td><td>#合并文件中，指定允许最低输入转录本的TPM值 (默认值: 0)</td></tr><tr><td>-f <min_iso></td><td>#minimum isoform fraction (默认值: 0.01)</td></tr><tr><td>-i</td><td>#合并后，保留含retained introns的转录本 (默认值: 除非有强有力的证据，否则不予保留)</td></tr><tr><td>-l <label></td><td>#输出转录本的名称前缀 (默认值: MSTRG)</td></tr></tbody></table><h1 id="四-stringtie2-使用"><a href="#四-stringtie2-使用" class="headerlink" title="四. stringtie2 使用"></a>四. stringtie2 使用</h1><p><strong>1.单样本转录本组装</strong></p><p>输入文档是BAM.sorted。可以是来源于Tophat或hisat2。此外，还需要gtf注释文件??</p><p>gtf下载 genecode官网：<a href="https://www.gencodegenes.org/">https://www.gencodegenes.org/</a></p><p>单样本组装：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sh">stringtie -p 8 -G /data/mouse_annotation/gencode.mouse.annotation.gtf -o cleandata/stringtiedata/CK-4.gtf cleandata/samtools_bam/CK-4_sort.bam<br></code></pre></td></tr></table></figure><p><strong>2.多样本转录本整合</strong></p><p>stringtie –merge [options] gtf.list :转录组merge模式，在该模式下，Stringtie可以利用输入的一个gtf list并将他们中的转录本进行非冗余的整理。可以在处理多个RNA-seq样本的时候，由于转录组存在时空特异性，可以将每个样本各自的转录组进行非冗余的整合，如果-G提供了参考gtf文件，可以将其一起整合到一个文件中,最终输出成一个完整的gtf文件。</p><p>将文件名的完整路径输入到一个文件中：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sh">find /data/RNAseq/cleandata/stringtiedata/ -name *.gtf &gt; /data/RNAseq/cleandata/stringtiedata/merglist.txt<br></code></pre></td></tr></table></figure><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sh">stringtie --merge -p 8 -G /data/mouse_annotation/gencode.mouse.annotation.gtf -o cleandata/stringtiedata/stringtie_merged.gtf cleandata/stringtiedata/merglist.txt<br></code></pre></td></tr></table></figure><p><strong>3. 使用gffcompare检验数据比对到基因组上的情况(可选)</strong></p><p>程序gffcompare可用于比较、合并、注释和估计一个或多个GFF文件(“查询”文件)的准确性。</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs xml">gffcompare [options]* &#123;-i <span class="hljs-tag">&lt;<span class="hljs-name">input_gtf_list</span>&gt;</span> | <span class="hljs-tag">&lt;<span class="hljs-name">input1.gtf</span>&gt;</span> [<span class="hljs-tag">&lt;<span class="hljs-name">input2.gtf</span>&gt;</span> .. <span class="hljs-tag">&lt;<span class="hljs-name">inputN.gtf</span>&gt;</span>]&#125;<br></code></pre></td></tr></table></figure><p><strong>4.重新组装转录本并估算基因表达丰度</strong></p><p>利用merge得到的gtf重新对各个样本做定量，并创建ballgown可读取文件。</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> CK-4 CK-7 CK-8 HGJ-10 HGJ-6 HGJ-9; <span class="hljs-keyword">do</span> stringtie -e -B -p 8 -G cleandata/stringtiedata/stringtie_merged.gtf  -o cleandata/ballgown/<span class="hljs-variable">$&#123;i&#125;</span>/<span class="hljs-variable">$&#123;i&#125;</span>.gtf cleandata/samtools_bam/<span class="hljs-variable">$&#123;i&#125;</span>_sort.bam; <span class="hljs-keyword">done</span><br></code></pre></td></tr></table></figure><p><strong>5.read count数据输出</strong></p><p>这里需要prepDE.py这个脚本。</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs awk">prepDE.py -i cleandata<span class="hljs-regexp">/ballgown/</span><br></code></pre></td></tr></table></figure><h1 id="五-Trinity"><a href="#五-Trinity" class="headerlink" title="五. Trinity"></a>五. Trinity</h1><p>下载github 最新版</p><p>make plugins</p><ul><li>Inchworm （虫）（C++）</li><li>Chrysalis （蛹）（C++）</li><li>Butterfly （蝶）（Java）</li></ul><h3 id="Trinity组装原理"><a href="#Trinity组装原理" class="headerlink" title="Trinity组装原理"></a>Trinity组装原理</h3><p>Trinity组装依据的算法是de Bruijn Graph,即从打断的文库中提取一定长度的K-mer，然后根据k-1错位相似的方法拼接组装的可能路径，最终确定完整的参考组装转录组。</p><p><img src="/GeekFocus/2022-05-11-hisat2/1.png" alt="img"></p><p><img src="/GeekFocus/./1.png" alt="img"></p><p><strong>Trinity根据该原理，将主要操作步骤分为3个模块，分别形象的命名为虫，蛹，蝶：</strong></p><ul><li>序列延伸 (inchworm) ——虫<ul><li>将 reads切为 k-mers (k bp长度的短片段)</li><li>利用Overlap关系对k-mers进行延伸 (贪婪算法)</li><li>输出所有的序列 (“contigs”)</li></ul></li><li>构建 de Bruijn graph (chrysalis)——蛹<ul><li>聚类所有相似区域大于k-1bp的 contigs</li><li>构图 (区分不同的 “components”)</li><li>将reads比对回 components，进行验证</li></ul></li><li>解图，列举转录本 (butterfly)——蝶<ul><li>拆分graph 为线性序列</li><li>使用reads以及 pairs关系消除错误序列</li></ul></li></ul><img src="2022-05-11-hisat2/2.png" alt="img" style="zoom:50%;" /><p><img src="/GeekFocus/./2.png" alt="img"></p><h3 id="Trinity-组装流程"><a href="#Trinity-组装流程" class="headerlink" title="Trinity 组装流程"></a>Trinity 组装流程</h3><p>Trinity组装流程主要包括以下几个步骤：</p><ul><li>组装前数据的质控</li><li>组装</li><li>组装质量的评估</li><li>下游分析<ul><li>差异分析</li><li>富集分析</li><li>功能分析</li></ul></li></ul><img src="2022-05-11-hisat2/3.png" alt="img" style="zoom:67%;" /><p><img src="/GeekFocus/./3.png" alt="img"></p><h4 id="STEP1-组装前质控"><a href="#STEP1-组装前质控" class="headerlink" title="STEP1: 组装前质控"></a>STEP1: 组装前质控</h4><p>fatqc——trimmamatic等去除低质量的reads等</p><h4 id="STEP2-组装"><a href="#STEP2-组装" class="headerlink" title="STEP2: 组装"></a>STEP2: 组装</h4><p><strong>Trinity 基本命令的含义：</strong></p><ul><li><code>--seqType</code> : [fa&#x2F;fq] 原始数据的格式，可以是fasta或fastq，可以是.gz或不是</li><li><code>--left/--right</code>：针对双端测序，如果是同一样本不同时期的多个文件，可以中间以逗号分隔，没有空格。</li><li><code>--single</code>: 针对单端测序</li><li><code>--SS_lib_type</code>：[RF]—双端链特异测序；</li><li><code>--output</code>：输出文件，命名必须带Trinity</li><li><code>--CPU</code>：组装使用CPU个数</li><li><code>--max_memory</code>：组装所需内存（eg：10G）</li></ul><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-comment">## my_trinity_script.sh</span><br><span class="hljs-comment">#!/bin/bash</span><br>/software/trinityrnaseq-2.2.0/Trinity --seqType fq \<br>--left RNASEQ_data/Sp_ds.left.fq.gz,RNASEQ_data/Sp_hs.left.fq.gz,RNASEQ_data/Sp_log.left.fq.gz,RNASEQ_data/Sp_plat.left.fq.gz \<br>--right RNASEQ_data/Sp_ds.right.fq.gz,RNASEQ_data/Sp_hs.right.fq.gz,RNASEQ_data/Sp_log.right.fq.gz,RNASEQ_data/Sp_plat.right.fq.gz \<br>--CPU  1 \<br>--max_memory 1G<br></code></pre></td></tr></table></figure><p><strong>trinity组装结果</strong></p><p>会自动生成Trinity_out_dir, 其中Trinity.fasta即组装的初步结果</p><p><img src="/GeekFocus/2022-05-11-hisat2/4.png" alt="img"></p><p><img src="/GeekFocus/./4.png" alt="img"></p><p><strong>组装结果统计</strong></p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs awk"><span class="hljs-regexp">/software/</span>trinityrnaseq-<span class="hljs-number">2.2</span>.<span class="hljs-number">0</span><span class="hljs-regexp">/util/</span>TrinityStats.pl trinity_out_dir<span class="hljs-regexp">/Trinity.fasta &gt; ./</span>trinity_out_dir/assembly_report.txt<br></code></pre></td></tr></table></figure><h4 id="STEP3-组装后质量评估"><a href="#STEP3-组装后质量评估" class="headerlink" title="STEP3: 组装后质量评估"></a>STEP3: 组装后质量评估</h4><p><strong>组装质量评估标准</strong></p><ul><li>Unigene数量</li><li>N50</li><li>比对率–比对率大于80%</li><li>注释比率–物种近缘性良好CDS序列相对完整60%以上</li><li>核心蛋白比对率–真核生物中存在一些高度保守区域所编码的蛋白（2748&#x2F;80%以上）</li></ul><p><strong>组装完整性</strong></p><ul><li>N50长度，可以初步评估，但不是越长越好，对应物种考虑</li><li>通过统计Unigene对近缘物种基因覆盖度分布</li></ul><p><strong>组装准确性</strong></p><ul><li>组装长度会影响定量的准确性</li></ul><p><strong>后续定量准确性</strong></p><p><strong>组装冗余度</strong></p><ul><li><p>影响定量准确性的最大因素：<strong>冗余</strong></p></li><li><p>冗余：组装出的Unigene的数量大大超过基因数；</p></li><li><p>冗余的来源：（1）可变剪切；（2）测序错误引入的“新” 转录本；</p></li><li><p>冗余的最大影响：导致多重比对，给定量带来困难</p></li><li><p>减少冗余策略<br>（1）去除低质量的reads;（2）是否有外援污染;（3）使用Normalization参数，降低高丰度基因的reads数据，同时提高组装效率；（4） 后续序列聚类或过滤</p></li><li><p><strong>去冗余方法</strong></p><p>（1）筛选同一基因的最长转录本作为unigene</p><p>（2）软件：TGICL、CAP3通过聚类筛选unigene</p></li></ul><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-comment"># 1.提取最长转录本</span><br>/software/trinityrnaseq-2.2.0/util/misc/get_longest_isoform_seq_per_trinity_gene.pl \ <br>./trinity_out_dir/Trinity.fasta &gt; ./trinity_out_dir/unigene1.fasta<br><br><span class="hljs-comment"># 2.软件聚类去冗余</span><br>cd-hit-est -i ./trinity_out_dir/Trinity.fasta -o  output-cdhit -T 1 -M 1000<br></code></pre></td></tr></table></figure><figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs pgsql"># unigene长度分布<br>perl /software/trinityrnaseq<span class="hljs-number">-2.2</span><span class="hljs-number">.0</span>/util/misc/fasta_seq_length.pl ./trinity_out_dir/Trinity.fasta &gt; ./trinity_out_dir/length.txt<br><span class="hljs-meta">#R画图</span><br>data &lt;- <span class="hljs-keyword">read</span>.<span class="hljs-keyword">table</span>(&quot;length.txt&quot;,<span class="hljs-keyword">header</span>=T)<br>data[,<span class="hljs-number">2</span>][which(<span class="hljs-keyword">as</span>.numeric(data[,<span class="hljs-number">2</span>])&gt;=<span class="hljs-number">2000</span>)]&lt;<span class="hljs-number">-2000</span><br><br>library(ggplot2)<br>pdf(&quot;length_distribution.pdf&quot;,height=<span class="hljs-number">7</span>,width=<span class="hljs-number">10</span>)<br>ggplot(<span class="hljs-keyword">as</span>.data.frame(data), aes(x = <span class="hljs-keyword">as</span>.numeric(data[,<span class="hljs-number">2</span>])))+geom_histogram(binwidth =<span class="hljs-number">100</span>)+<br>xlab(&quot;Transcripts Length Interval&quot;)+<br>ylab(&quot;Number ofTranscripts&quot;)+<br>labs(title=&quot;Transcripts Length Distribution&quot;)+<br>scale_x_continuous(breaks=seq(<span class="hljs-number">100</span>,<span class="hljs-number">2000</span>,<span class="hljs-keyword">by</span>=<span class="hljs-number">100</span>),<br>labels=c(&quot;100&quot;,&quot;200&quot;,&quot;300&quot;,&quot;400&quot;,&quot;500&quot;,&quot;600&quot;,&quot;700&quot;,&quot;800&quot;,&quot;900&quot;,&quot;1000&quot;,&quot;1100&quot;,&quot;1200&quot;,&quot;1<br>300&quot;,&quot;1400&quot;,&quot;1500&quot;,&quot;1600&quot;,&quot;1700&quot;,&quot;1800&quot;,&quot;1900&quot;,&quot;&gt;=2000&quot;))<br>dev.<span class="hljs-keyword">off</span>()<br></code></pre></td></tr></table></figure><h3 id="Trinity组装后下游分析"><a href="#Trinity组装后下游分析" class="headerlink" title="Trinity组装后下游分析"></a>Trinity组装后下游分析</h3><h4 id="STEP4-定量：比对和丰度计算"><a href="#STEP4-定量：比对和丰度计算" class="headerlink" title="STEP4: 定量：比对和丰度计算"></a>STEP4: 定量：比对和丰度计算</h4><p>利用RSEM进行丰度估计，</p><p><img src="/GeekFocus/2022-05-11-hisat2/4.png" alt="img"></p><p><img src="/GeekFocus/./4.png" alt="img"></p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-comment"># 比对reads评估表达量（每个样品运行一次）</span><br><span class="hljs-comment"># Sp_log</span><br>/software/trinityrnaseq-2.2.0/util/align_and_estimate_abundance.pl \<br>--transcripts ./trinity_out_dir/unigene1.fasta --seqType fq \<br>--left RNASEQ_data/Sp_log.left.fq.gz --right RNASEQ_data/Sp_log.right.fq.gz \<br>--est_method RSEM --aln_method bowtie --trinity_mode --prep_reference \<br>--output_dir rsem_Sp_log_outdir<br><span class="hljs-comment"># Sp_ds</span><br>/software/trinityrnaseq-2.2.0/util/align_and_estimate_abundance.pl \<br>--transcripts ./trinity_out_dir/unigene1.fasta --seqType fq \<br>--left RNASEQ_data/Sp_ds.left.fq.gz --right RNASEQ_data/Sp_ds.right.fq.gz \<br>--est_method RSEM --aln_method bowtie --trinity_mode --prep_reference \<br>--output_dir rsem_Sp_ds_outdir<br><br><span class="hljs-comment"># Sp_hs</span><br>/software/trinityrnaseq-2.2.0/util/align_and_estimate_abundance.pl \<br>--transcripts ./trinity_out_dir/unigene1.fasta --seqType fq \<br>--left RNASEQ_data/Sp_hs.left.fq.gz --right RNASEQ_data/Sp_hs.right.fq.gz \<br>--est_method RSEM --aln_method bowtie --trinity_mode --prep_reference \<br>--output_dir rsem_Sp_hs_outdir<br><br><span class="hljs-comment"># Sp_plat</span><br>/software/trinityrnaseq-2.2.0/util/align_and_estimate_abundance.pl \<br>--transcripts ./trinity_out_dir/unigene1.fasta --seqType fq \<br>--left RNASEQ_data/Sp_plat.left.fq.gz --right RNASEQ_data/Sp_plat.right.fq.gz \<br>--est_method RSEM --aln_method bowtie --trinity_mode --prep_reference \<br>--output_dir rsem_Sp_plat_outdir <br></code></pre></td></tr></table></figure><p>参数含义：</p><ul><li><code>--aln_method</code>: 默认是bowtie</li><li><code>--est_method</code>:丰度评估方法，默认是RSEM，更准确，也可选择<code>eXpress</code>, 更快和所需RAM少</li><li><code>--trinity_mode</code>: 参考文件来自trinity，如果不是需要一个gene-isoform 比对文件 <code>--gene_trans_map</code></li></ul><p><strong>查看mapping结果</strong></p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-comment"># ds</span><br>perl /software/trinityrnaseq-2.2.0/util/SAM_nameSorted_to_uniq_count_stats.pl rsem_Sp_ds_outdir/bowtie.bam &gt; rsem_Sp_ds_outdir/mapping.out<br></code></pre></td></tr></table></figure><h4 id="STEP5-差异分析"><a href="#STEP5-差异分析" class="headerlink" title="STEP5: 差异分析"></a>STEP5: 差异分析</h4><p><strong>创建数量矩阵</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs undefined">/software/trinityrnaseq-2.2.0/util/abundance_estimates_to_matrix.pl \<br>--est_method RSEM \<br>--out_prefix Trinity_trans \<br>rsem_Sp_ds_outdir/ds_RSEM.isoforms.results \<br>rsem_Sp_hs_outdir/hs_RSEM.isoforms.results \<br>rsem_Sp_log_outdir/log_RSEM.isoforms.results \<br>rsem_Sp_plat_outdir/plat_RSEM.isoforms.results<br></code></pre></td></tr></table></figure><p><strong>无生物学重复进行差异表达分析</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs undefined">/software/trinityrnaseq-2.2.0/Analysis/DifferentialExpression/run_DE_analysis.pl \<br>--matrix trinity_trans.matrix/Trinity_trans.counts.matrix \<br>--dispersion 0.1 --method edgeR \<br>--output edgeR<br></code></pre></td></tr></table></figure><p><strong>查看差异数</strong></p><figure class="highlight dart"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs dart">sed <span class="hljs-string">&#x27;1,1d&#x27;</span> edgeR/Trinity_trans.counts.matrix.ds_RSEM_vs_hs_RSEM.edgeR.DE_results | awk <span class="hljs-string">&#x27;&#123; if (<span class="hljs-subst">$5</span> &lt;= 0.05) print;&#125;&#x27;</span> &gt; edgeR/ds_hs_DE_num<br><br>sed <span class="hljs-string">&#x27;1,1d&#x27;</span> edgeR/Trinity_trans.counts.matrix.ds_RSEM_vs_log_RSEM.edgeR.DE_results | awk <span class="hljs-string">&#x27;&#123; if (<span class="hljs-subst">$5</span> &lt;= 0.05) print;&#125;&#x27;</span> &gt; edgeR/ds_log_DE_num<br><br>sed <span class="hljs-string">&#x27;1,1d&#x27;</span> edgeR/Trinity_trans.counts.matrix.ds_RSEM_vs_plat_RSEM.edgeR.DE_results | awk <span class="hljs-string">&#x27;&#123; if (<span class="hljs-subst">$5</span> &lt;= 0.05) print;&#125;&#x27;</span> &gt; edgeR/ds_plat_DE_num<br><br>sed <span class="hljs-string">&#x27;1,1d&#x27;</span> edgeR/Trinity_trans.counts.matrix.hs_RSEM_vs_log_RSEM.edgeR.DE_results | awk <span class="hljs-string">&#x27;&#123; if (<span class="hljs-subst">$5</span> &lt;= 0.05) print;&#125;&#x27;</span> &gt; edgeR/hs_log_DE_num<br><br>sed <span class="hljs-string">&#x27;1,1d&#x27;</span> edgeR/Trinity_trans.counts.matrix.hs_RSEM_vs_plat_RSEM.edgeR.DE_results | awk <span class="hljs-string">&#x27;&#123; if (<span class="hljs-subst">$5</span> &lt;= 0.05) print;&#125;&#x27;</span> &gt; edgeR/hs_plat_DE_num<br><br>sed <span class="hljs-string">&#x27;1,1d&#x27;</span> edgeR/Trinity_trans.counts.matrix.log_RSEM_vs_plat_RSEM.edgeR.DE_results | awk <span class="hljs-string">&#x27;&#123; if (<span class="hljs-subst">$5</span> &lt;= 0.05) print;&#125;&#x27;</span> &gt; edgeR/log_plat_DE_num<br></code></pre></td></tr></table></figure><h4 id="STEP6-聚类-x2F-网络分析"><a href="#STEP6-聚类-x2F-网络分析" class="headerlink" title="STEP6: 聚类&#x2F;网络分析"></a>STEP6: 聚类&#x2F;网络分析</h4><p><strong>提取差异表达的序列绘制热图</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 提取差异表达的序列绘制热图</span><br><span class="hljs-built_in">cd</span> edgeR/<br>/software/trinityrnaseq-2.2.0/Analysis/DifferentialExpression/analyze_diff_expr.pl \<br>--matrix ../trinity_trans.matrix/Trinity_trans.TMM.EXPR.matrix -P 1e-3 -C 2<br><br><span class="hljs-comment"># 根据聚类图提取子类</span><br>/software/trinityrnaseq-2.2.0/Analysis/DifferentialExpression/define_clusters_by_cutting_tree.pl \<br>--Ptree 60 -R diffExpr.P1e-3_C2.matrix.RData<br></code></pre></td></tr></table></figure><h3 id="根据聚类图提取子类"><a href="#根据聚类图提取子类" class="headerlink" title="根据聚类图提取子类"></a>根据聚类图提取子类</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 提取差异表达的序列绘制热图</span><br><span class="hljs-built_in">cd</span> edgeR/<br>/software/trinityrnaseq-2.2.0/Analysis/DifferentialExpression/analyze_diff_expr.pl \<br>--matrix ../trinity_trans.matrix/Trinity_trans.TMM.EXPR.matrix -P 1e-3 -C 2<br><br><span class="hljs-comment"># 根据聚类图提取子类</span><br>/software/trinityrnaseq-2.2.0/Analysis/DifferentialExpression/define_clusters_by_cutting_tree.pl \<br>--Ptree 60 -R diffExpr.P1e-3_C2.matrix.RData<br></code></pre></td></tr></table></figure><h4 id="STEP7-功能注释和富集分析"><a href="#STEP7-功能注释和富集分析" class="headerlink" title="STEP7: 功能注释和富集分析"></a>STEP7: 功能注释和富集分析</h4><p>使用TransDecoder-对trinity结果进行注释</p><p><strong>1. 预测ORF (open-reading-frame) ( DNA -&gt; protein sequence)</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">/software/TransDecoder/TransDecoder.LongOrfs -t trinity_out_dir/unigene1.fasta<br><span class="hljs-comment"># </span><br>/software/TransDecoder/TransDecoder.Predict -t trinity_out_dir/unigene1.fasta<br></code></pre></td></tr></table></figure><p><strong>2. 预测基因功能</strong></p>]]></content>
    
    
    <categories>
      
      <category>Software</category>
      
    </categories>
    
    
    <tags>
      
      <tag>RNA-seq</tag>
      
      <tag>mapping</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>BRAKER2</title>
    <link href="/GeekFocus/2022/04/21/2022-04-28-BRAKER/"/>
    <url>/GeekFocus/2022/04/21/2022-04-28-BRAKER/</url>
    
    <content type="html"><![CDATA[<p>BRAKER2</p><span id="more"></span><h1 id="Contents"><a href="#Contents" class="headerlink" title="Contents"></a>Contents</h1><ul><li><a href="https://github.com/Gaius-Augustus/BRAKER#authors-of-braker">Authors</a></li><li><a href="https://github.com/Gaius-Augustus/BRAKER#funding">Funding</a></li><li><a href="https://github.com/Gaius-Augustus/BRAKER#what-is-braker">What is BRAKER?</a></li><li><a href="https://github.com/Gaius-Augustus/BRAKER#keys-to-successful-gene-prediction">Keys to successful gene prediction</a></li><li><a href="https://github.com/Gaius-Augustus/BRAKER#overview-of-modes-for-running-braker">Overview of modes for running BRAKER</a></li><li>Installation<ul><li><a href="https://github.com/Gaius-Augustus/BRAKER#supported-software-versions">Supported software versions</a></li><li>BRAKER<ul><li><a href="https://github.com/Gaius-Augustus/BRAKER#perl-pipeline-dependencies">Perl pipeline dependencies</a></li><li><a href="https://github.com/Gaius-Augustus/BRAKER#braker-components">BRAKER components</a></li><li>Bioinformatics software dependencies<ul><li><a href="https://github.com/Gaius-Augustus/BRAKER#mandatory-tools">Mandatory tools</a></li><li><a href="https://github.com/Gaius-Augustus/BRAKER#optional-tools">Optional tools</a></li></ul></li></ul></li></ul></li><li>Running BRAKER<ul><li>BRAKER pipeline modes<ul><li><a href="https://github.com/Gaius-Augustus/BRAKER#braker-with-rna-seq-data">BRAKER with RNA-Seq data</a></li><li><a href="https://github.com/Gaius-Augustus/BRAKER#braker-with-proteins-of-any-evolutionary-distance">BRAKER with proteins of any evolutionary distance</a></li><li><a href="https://github.com/Gaius-Augustus/BRAKER#braker-with-proteins-of-short-evolutionary-distance">BRAKER with proteins of short evolutionary distance</a></li><li><a href="https://github.com/Gaius-Augustus/BRAKER#braker-with-rna-seq-and-protein-data">BRAKER with RNA-Seq and protein data</a></li><li><a href="https://github.com/Gaius-Augustus/BRAKER#braker-with-short-and-long-read-RNA-Seq-and-protein-data">BRAKER with short and long read RNA-Seq and protein data</a></li></ul></li><li>Description of selected BRAKER command line options<ul><li><a href="https://github.com/Gaius-Augustus/BRAKER#--ab_initio">–ab_initio</a></li><li><a href="https://github.com/Gaius-Augustus/BRAKER#--augustus_args--some_argbla">–augustus_args&#x3D;–some_arg&#x3D;bla</a></li><li><a href="https://github.com/Gaius-Augustus/BRAKER#--coresint">–cores&#x3D;INT</a></li><li><a href="https://github.com/Gaius-Augustus/BRAKER#--fungus">–fungus</a></li><li><a href="https://github.com/Gaius-Augustus/BRAKER#--softmasking">–softmasking</a></li><li><a href="https://github.com/Gaius-Augustus/BRAKER#--useexisting">–useexisting</a></li><li><a href="https://github.com/Gaius-Augustus/BRAKER#--crf">–crf</a></li><li><a href="https://github.com/Gaius-Augustus/BRAKER#--lambdaint">–lambda&#x3D;int</a></li><li><a href="https://github.com/Gaius-Augustus/BRAKER#--utron">–UTR&#x3D;on</a></li><li><a href="https://github.com/Gaius-Augustus/BRAKER#--addutr">–addUTR&#x3D;on</a></li><li><a href="https://github.com/Gaius-Augustus/BRAKER#--stranded-">–stranded&#x3D;+,-,.,…</a></li><li><a href="https://github.com/Gaius-Augustus/BRAKER#--makehub---emailyourmailde">–makehub --email&#x3D;your@mail.de</a></li></ul></li></ul></li><li><a href="https://github.com/Gaius-Augustus/BRAKER#output-of-braker">Output of BRAKER</a></li><li>Example data<ul><li><a href="https://github.com/Gaius-Augustus/BRAKER#data-description">Data description</a></li><li><a href="https://github.com/Gaius-Augustus/BRAKER#testing-braker-with-rna-seq-data">Testing BRAKER with RNA-Seq data</a></li><li><a href="https://github.com/Gaius-Augustus/BRAKER#testing-braker-with-proteins-of-any-evolutionary-distance">Testing BRAKER with proteins of any evolutionary distance</a></li><li><a href="https://github.com/Gaius-Augustus/BRAKER#testing-braker-with-proteins-of-any-evolutionary-distance-and-rna-seq">Testing BRAKER with proteins of any evolutionary distance and RNA-Seq</a></li><li><a href="https://github.com/Gaius-Augustus/BRAKER#testing-braker-with-proteins-of-close-homology">Testing BRAKER with proteins of close homology</a></li><li><a href="https://github.com/Gaius-Augustus/BRAKER#testing-braker-with-proteins-of-close-homology-and-rna-seq-data-rna-seq-supported-training">Testing BRAKER with proteins of close homology and RNA-Seq data (RNA-Seq supported training)</a></li><li><a href="https://github.com/Gaius-Augustus/BRAKER#testing-braker-with-proteins-of-close-homoogy-and-rna-seq-data-rna-seq-and-protein-supported-training">Testing BRAKER with proteins of close homoogy and RNA-Seq data (RNA-Seq and protein supported training)</a></li><li><a href="https://github.com/Gaius-Augustus/BRAKER#testing-braker-with-pre-trained-parameters">Testing BRAKER with pre-trained parameters</a></li><li><a href="https://github.com/Gaius-Augustus/BRAKER#testing-braker-with-genome-sequence">Testing BRAKER with genome sequence</a></li></ul></li><li><a href="https://github.com/Gaius-Augustus/BRAKER#starting-braker-on-the-basis-of-previously-existing-braker-runs">Starting BRAKER on the basis of previously existing BRAKER runs</a></li><li>Bug reporting<ul><li><a href="https://github.com/Gaius-Augustus/BRAKER#reporting-bugs-on-github">Reporting bugs on github</a></li><li><a href="https://github.com/Gaius-Augustus/BRAKER#common-problems">Common problems</a></li></ul></li><li><a href="https://github.com/Gaius-Augustus/BRAKER#citing-braker-and-software-called-by-braker">Citing BRAKER and software called by BRAKER</a></li><li><a href="https://github.com/Gaius-Augustus/BRAKER#license">License</a></li></ul><h1 id="What-is-BRAKER"><a href="#What-is-BRAKER" class="headerlink" title="What is BRAKER?"></a>What is BRAKER?</h1><p>The rapidly growing number of sequenced genomes requires fully automated methods for accurate gene structure annotation. With this goal in mind, we have developed <font color="blue">BRAKER1</font><a href="https://github.com/Gaius-Augustus/BRAKER#f1">R1</a><a href="https://github.com/Gaius-Augustus/BRAKER#f0">R0</a>, a <strong>combination</strong> of <font color="blue">GeneMark-ET</font> <a href="https://github.com/Gaius-Augustus/BRAKER#f2">R2</a> and <font color="blue">AUGUSTUS</font> <a href="https://github.com/Gaius-Augustus/BRAKER#f3">R3, </a><a href="https://github.com/Gaius-Augustus/BRAKER#f4">R4</a>, that uses genomic and RNA-Seq data to automatically generate full gene structure annotations in novel genome.</p><p>However, the quality of RNA-Seq data that is available for annotating a novel genome is variable, and in some cases, RNA-Seq data is not available, at all.</p><p><font color="blue">BRAKER2 is an extension of BRAKER1</font> which allows for <strong>fully automated training</strong> of the gene prediction tools <font color="blue"><strong>GeneMark</strong>-EX</font> <a href="https://github.com/Gaius-Augustus/BRAKER#f14">R14, </a><a href="https://github.com/Gaius-Augustus/BRAKER#f15">R15, </a><a href="https://github.com/Gaius-Augustus/BRAKER#f17">R17, </a><a href="https://github.com/Gaius-Augustus/BRAKER#g1">F1</a> and <font color="blue"><strong>AUGUSTUS</strong></font> from <strong>RNA-Seq and&#x2F;or protein homology</strong> information, and that integrates the extrinsic evidence from RNA-Seq and protein homology information into the <strong>prediction</strong>.</p><p>In contrast to other available methods that rely on protein homology information, BRAKER2 reaches high gene prediction accuracy even in the absence of the annotation of very closely related species and in the absence of RNA-Seq data.</p><p>In this user guide, we will refer to <font color="blue">BRAKER1 and BRAKER2</font> simply as <strong>BRAKER</strong> because they are <font color="blue">executed by the same script</font> (<code>braker.pl</code>).</p><h1 id="Keys-to-successful-gene-prediction"><a href="#Keys-to-successful-gene-prediction" class="headerlink" title="Keys to successful gene prediction"></a>Keys to successful gene prediction</h1><ul><li>Use a high quality genome assembly. If you have a huge number of very short scaffolds in your genome assembly, those short scaffolds will likely increase runtime dramatically but will not increase prediction accuracy. <strong>使用高质量组装</strong>。时间缩短质量提高。</li><li><strong>contig名字简短</strong>。Use simple scaffold names in the genome file (e.g. <code>&gt;contig1</code> will work better than <code>&gt;contig1my custom species namesome putative function /more/information/  and lots of special characters %&amp;!*()&#123;&#125;</code>). Make the scaffold names in all your fasta files simple before running any alignment program.</li><li>In order to predict genes accurately in a novel genome, the <font color="blue">genome should be <strong>masked</strong> for repeats</font>. This will <strong>avoid the prediction</strong> of false positive gene structures <strong>in repetitive and low complexitiy</strong> regions. Repeat masking is <strong>also essential for mapping RNA</strong>-Seq data to a genome with some tools (other RNA-Seq mappers, such as HISAT2, ignore masking information). In case of GeneMark-EX and AUGUSTUS, <strong>softmasking</strong> (i.e. putting repeat regions into lower case letters and all other regions into upper case letters) leads to <font color="blue"><strong>better results than hardmasking</strong></font> (i.e. replacing letters in repetitive regions by the letter <code>N</code> for unknown nucleotide). If the genome is masked, <font color="blue">use the <strong>–softmasking flag</strong> of <strong>braker.pl</strong></font>.</li><li>Many genomes have gene structures that will be predicted accurately with <font color="blue">standard parameters of GeneMark-EX and AUGUSTUS within BRAKER</font>. However, some genomes have clade-specific features, i.e. special branch point model in fungi, or non-standard splice-site patterns. Please read the options section [options] in order to determine whether any of the custom options may improve gene prediction accuracy in the genome of your target species. <strong>大部分genome使用默认参数结果不错。但仍需查看是否有参数可以提高特定物种的预测。</strong></li><li><font color="blue">Always check gene prediction results before further usage!</font> You can e.g. use a genome browser for visual inspection of gene models in context with extrinsic evidence data. BRAKER supports the generation of track data hubs for the UCSC Genome Browser with MakeHub for this purpose.</li></ul><h1 id="Overview-of-modes-for-running-BRAKER"><a href="#Overview-of-modes-for-running-BRAKER" class="headerlink" title="Overview of modes for running BRAKER"></a>Overview of modes for running BRAKER</h1><p>BRAKER mainly features semi-unsupervised, extrinsic evidence data (RNA-Seq and&#x2F;or protein spliced alignment information) supported <strong>training of GeneMark-EX</strong>[F1] and <strong>subsequent training of AUGUSTUS</strong> with integration of extrinsic evidence in the final gene prediction step. However, there are now a number of additional pipelines included in BRAKER. In the following, we give an overview of <font color="blue">possible input files and pipelines</font>:</p><ul><li><font color="red"><strong>Genome file, only</strong></font>. In this mode, <strong>GeneMark-ES</strong> is <strong>trained</strong> on the genome sequence, <strong>alone</strong>. <strong>Long genes predicted by GeneMark-ES</strong> are <font color="blue"><strong>selected</strong></font> for <strong>training AUGUSTUS</strong>. Final predictions by AUGUSTUS are <em>ab initio</em>. This approach will likely yield lower prediction accuracy than all other here described pipelines. (see Figure <a href="https://github.com/Gaius-Augustus/BRAKER#fig1">2</a>)</li></ul><img src="BRAKER/f2.png" alt="braker2-main-a[fig1]" style="zoom:50%;" /><p>Figure 2: BRAKER pipeline A: training GeneMark-ES on genome data, only; <em>ab initio</em> gene prediction withAUGUSTUS. 只用GeneMark-ES预测，选取较长预测结果训练AUGUSTUS</p><ul><li><font color="red"><strong>Genome</strong> and <strong>RNA-Seq</strong> file from the <strong>same</strong> species</font>; this approach is <strong>suitable for</strong> short read RNA-Seq libraries with a <strong>good coverage</strong> of the transcriptome, <strong>important:</strong> this approach <strong>requires</strong> that each <strong>intron</strong> is <strong>covered by many align</strong>ments, i.e. it does not work with assembled transcriptome mappings. In principle, also alignments of long read RNA-Seq data may lead to sufficient data for running BRAKER, but <strong>only if each transcript that will go into training was sequenced and aligned to the genome multiple times.</strong> Please be aware that at the current point in time, BRAKER <font color="blue">does <strong>not officially support</strong> the integration of <strong>long read RNA-Seq</strong></font> data, yet.</li></ul><img src="BRAKER/f3.png" alt="braker2-main-a[fig1]" style="zoom:50%;" /><p>Figure 3: BRAKER pipeline B: training GeneMark-ET supported by RNA-Seq spliced alignment information, prediction with AUGUSTUS with that same spliced alignment information.</p><ul><li><font color="red"><strong>Genome</strong> file and database of <strong>proteins</strong> that may be of <strong>unknown</strong> evolutionary distance to the target species</font> (see Figure <a href="https://github.com/Gaius-Augustus/BRAKER#fig3">4</a>); this approach is particularly suitable if no RNA-Seq data is available. This method will work better with proteins from species that are rather close to the target species, but <strong>accuracy will drop only very little if the reference proteins are more distant from the target species</strong>. <strong>Important:</strong> This approach requires a database of protein families, i.e. many representatives of each protein family must be present in the database. BRAKER has been tested with OrthoDB <a href="https://github.com/Gaius-Augustus/BRAKER#f19">R19</a>, successfully. <font color="red">The ProtHint <a href="https://github.com/Gaius-Augustus/BRAKER#f18">R18</a> <strong>protein mapping pipeline</strong></font> for generating required hints for BRAKER is available for <strong>download</strong> at <a href="https://github.com/gatech-genemark/ProtHint">https://github.com/gatech-genemark/ProtHint</a>, the instructions on <font color="red"><strong>how to prepare</strong> the OrthoDB input proteins</font> are documented at <a href="https://github.com/gatech-genemark/ProtHint#protein-database-preparation">https://github.com/gatech-genemark/ProtHint#protein-database-preparation</a>. You may add proteins of a closely related species to the OrthoDB fasta file in order to incorporate additional evidence into gene prediction.</li></ul><img src="BRAKER/f4.png" alt="braker2-main-a[fig1]" style="zoom:50%;" /><p>Figure 4: <font color="red"><strong>BRAKER pipeline C</strong>: <strong>training GeneMark-EP+</strong> on <strong>protein spliced alignment</strong>, <strong>start and stop information</strong>, prediction with <strong>AUGUSTUS</strong> with that <strong>same information</strong>, in addition <strong>chained CDSpart hints</strong>. Proteins used here can be of any evolutionary distance to the target organism.</font></p><ul><li><font color="red"><strong>Genome</strong> and <strong>RNA</strong>-Seq file from the same species, and <strong>proteins</strong> that may be of <strong>unknown</strong> evolutionary distance to the target species</font> (see figure <a href="https://github.com/Gaius-Augustus/BRAKER#fig4">5</a>); <strong>important:</strong> this approach requires a database of protein families, i.e. many representatives of each protein family must be present in the database, e.g. OrthoDB is suitable. (You may add proteins of a closely related species to the OrthoDB fasta file in order to incorporate additional evidence into gene prediction.)</li></ul><img src="BRAKER/f5.png" alt="braker2-main-a[fig1]" style="zoom:50%;" /><p>Figure 5: <font color="red"><strong>BRAKER pipeline D</strong>: <strong>training</strong> <strong>GeneMark-ETP+</strong> supported by <strong>RNA</strong>-Seq alignment information and information from <strong>proteins</strong></font> (proteins can be of any evolutionary distance). Please be aware that GeneMark-ETP+ is still under development, BRAKER can currently execute a precursor of the mature version. Introns supported by both RNA-Seq and protein alignment information are treated as “true positive introns”, their prediction in gene structures by GeneMark-ETP+ and AUGUSTUS is enforced. <strong>Important:</strong> It is not always best to use all evidence! So far, <font color="blue">we found this approach to work well for <strong>large genomes</strong>, but accuracy on <strong>small and medium sized genomes</strong> is <strong>unstable</strong></font>. Please have a look at the poster from PAG 2020 before running this pipeline.</p><ul><li><font color="red"><strong>Genome</strong> file and file with <strong>proteins</strong> of <strong>short evolutionary distance</strong></font> (see Figure <a href="https://github.com/Gaius-Augustus/BRAKER#fig5">6</a>); this approach is suitable if RNA-Seq data is not available and if the reference species is very closely related. <em>Note:</em> This pipeline is deprecated since pipeline C can also use proteins of closely related species in addition to OrthoDB.</li></ul><img src="BRAKER/f6.png" alt="braker2-main-a[fig1]" style="zoom:50%;" /><p>Figure 6: Additional pipeline B: training AUGUSTUS on the basis of spliced alignment information from <font color="red">proteins of a very closely related species</font> against the target genome.</p><ul><li><font color="red"><strong>Genome</strong> and <strong>RNA</strong>-Seq file and <strong>proteins</strong> of <strong>short evolutionary distance</strong></font> (see Figures <a href="https://github.com/Gaius-Augustus/BRAKER#fig6">6</a> and <a href="https://github.com/Gaius-Augustus/BRAKER#fig7">7</a>). In both cases, GeneMark-ET is trained supported by RNA-Seq data, and the resulting gene predictions are used for training AUGUSTUS. In approach A), protein alignment information is used in the gene prediction step with AUGUSTUS, only. In approach C), protein spliced alignment data is used to complement the training set for AUGUSTUS. The latter approach is in particular suitable if RNA-Seq data does not produce a sufficiently high number of training gene structures for AUGUSTUS, and if a very closely related and already annotated species is available. <em>Note:</em> This pipeline is deprecated since pipeline D can also use proteins of closely related species in addition to OrthoDB.</li></ul><img src="BRAKER/f7.png" alt="braker2-main-a[fig1]" style="zoom:50%;" /><p>Figure 7: Additional pipeline A: training GeneMark-ET supported by RNA-Seq spliced alignment information, prediction with AUGUSTUS with spliced alignment information from RNA-Seq data and with gene features determined by alignments from proteins of a very closely related species against the target genome. <em>Note:</em> This pipeline is deprecated since pipeline C can also use proteins of closely related species in addition to OrthoDB.</p><img src="BRAKER/f8.png" alt="braker2-main-a[fig1]" style="zoom:50%;" /><p>Figure 8: Additional pipeline C: training GeneMark-ET on the basis of RNA-Seq spliced alignment information, training AUGUSTUS on a set of training gene structures compiled from RNA-Seq supported gene structures predicted by GeneMark-ET and spliced alignment of proteins of a very closely related species. <em>Note:</em> This pipeline is deprecated since pipeline D can also use proteins of closely related species in addition to OrthoDB.</p><h1 id="Installation"><a href="#Installation" class="headerlink" title="Installation"></a>Installation</h1><h2 id="Supported-software-versions"><a href="#Supported-software-versions" class="headerlink" title="Supported software versions"></a>Supported software versions</h2><p>At the time of release, this BRAKER version was tested with:</p><ul><li>AUGUSTUS 3.4.0 <a href="https://github.com/Gaius-Augustus/BRAKER#g2">F2</a></li><li>GeneMark-ES&#x2F;ET&#x2F;EP 4.64_lic</li><li>BAMTOOLS 2.5.1<a href="https://github.com/Gaius-Augustus/BRAKER#f5">R5</a></li><li>SAMTOOLS 1.7-4-g93586ed<a href="https://github.com/Gaius-Augustus/BRAKER#f6">R6</a></li><li>ProtHint 2.6.0</li><li>GenomeThreader 1.7.0<a href="https://github.com/Gaius-Augustus/BRAKER#f7">R7</a></li><li>Spaln 2.3.3d <a href="https://github.com/Gaius-Augustus/BRAKER#f8">R8, </a><a href="https://github.com/Gaius-Augustus/BRAKER#f9">R9, </a><a href="https://github.com/Gaius-Augustus/BRAKER#f10">R10, </a><a href="https://github.com/Gaius-Augustus/BRAKER#g3">F3</a></li><li>(Exonerate 2.2.0 <a href="https://github.com/Gaius-Augustus/BRAKER#f11">R11</a>)[F3]</li><li>NCBI BLAST+ 2.2.31+ <a href="https://github.com/Gaius-Augustus/BRAKER#f12">R12, </a><a href="https://github.com/Gaius-Augustus/BRAKER#f13">R13</a></li><li>DIAMOND 0.9.24</li><li>cdbfasta 0.99</li><li>cdbyank 0.981</li><li>GUSHR 1.0.0</li></ul><h2 id="BRAKER"><a href="#BRAKER" class="headerlink" title="BRAKER"></a>BRAKER</h2><h3 id="Perl-pipeline-dependencies"><a href="#Perl-pipeline-dependencies" class="headerlink" title="Perl pipeline dependencies"></a>Perl pipeline dependencies</h3><p>Running BRAKER requires a Linux-system with <code>bash</code> and Perl. Furthermore, BRAKER requires the following CPAN-Perl modules to be installed:</p><ul><li><code>File::Spec::Functions</code></li><li><code>Hash::Merge</code></li><li><code>List::Util</code></li><li><code>MCE::Mutex</code></li><li><code>Module::Load::Conditional</code></li><li><code>Parallel::ForkManager</code></li><li><code>POSIX</code></li><li><code>Scalar::Util::Numeric</code></li><li><code>YAML</code></li><li><code>Math::Utils</code></li><li><code>File::HomeDir</code></li></ul><p>For ProtHint, used when protein input is supplied, also install:</p><ul><li><code>threads</code></li></ul><p>On Ubuntu, for example, install the modules with CPANminus<a href="https://github.com/Gaius-Augustus/BRAKER#g4">F4</a>: <code>sudo cpanm Module::Name</code>, e.g. <code>sudo cpanm Hash::Merge</code>.</p><p>BRAKER also uses a Perl module <code>helpMod.pm</code> that is not available on CPAN. This module is part of the BRAKER release and does not require separate installation.</p><p>If you do not have root permissions on the Linux machine, try setting up an <strong>Anaconda</strong> (<a href="https://www.anaconda.com/distribution/">https://www.anaconda.com/distribution/</a>) environment as follows:</p><figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs cmake">wget https://repo.anaconda.com/archive/Anaconda3-<span class="hljs-number">2018.12</span>-Linux-x86_64.sh<br>bash bin/Anaconda3-<span class="hljs-number">2018.12</span>-Linux-x86_64.sh <span class="hljs-comment"># do not install VS (needs root privileges)</span><br>conda <span class="hljs-keyword">install</span> -c anaconda perl<br>conda <span class="hljs-keyword">install</span> -c bioconda perl-app-cpanminus<br>conda <span class="hljs-keyword">install</span> -c bioconda perl-hash-merge<br>conda <span class="hljs-keyword">install</span> -c bioconda perl-parallel-forkmanager<br>conda <span class="hljs-keyword">install</span> -c bioconda perl-scalar-util-numeric<br>conda <span class="hljs-keyword">install</span> -c bioconda perl-yaml<br>conda <span class="hljs-keyword">install</span> -c bioconda perl-class-data-inheritable<br>conda <span class="hljs-keyword">install</span> -c bioconda perl-exception-class<br>conda <span class="hljs-keyword">install</span> -c bioconda perl-<span class="hljs-keyword">test</span>-pod<br>conda <span class="hljs-keyword">install</span> -c anaconda biopython<br>conda <span class="hljs-keyword">install</span> -c bioconda perl-<span class="hljs-keyword">file</span>-which <span class="hljs-comment"># skip if you are not comparing to reference annotation</span><br>conda <span class="hljs-keyword">install</span> -c bioconda perl-mce<br>conda <span class="hljs-keyword">install</span> -c bioconda perl-threaded<br>conda <span class="hljs-keyword">install</span> -c bioconda perl-<span class="hljs-keyword">list</span>-util<br>conda <span class="hljs-keyword">install</span> -c bioconda perl-<span class="hljs-keyword">math</span>-utils<br>conda <span class="hljs-keyword">install</span> -c bioconda cdbtools<br></code></pre></td></tr></table></figure><p>Subsequently install BRAKER and other software “as usual” while being in your conda environment. <strong>Note:</strong> <strong>There is a bioconda braker package, and a bioconda augustus package</strong>. They work. But <strong>they are usually lagging behind the development code of both tools on github</strong>. We therefore recommend manual installation and usage of lastest sources.</p><h3 id="BRAKER-components"><a href="#BRAKER-components" class="headerlink" title="BRAKER components"></a>BRAKER components</h3><p>BRAKER is a collection of Perl and Python scripts and a Perl module. The main script that will be called in order to run BRAKER is <code>braker.pl</code>. Additional Perl and Python components are:</p><ul><li><code>align2hints.pl</code></li><li><code>filterGenemark.pl</code></li><li><code>filterIntronsFindStrand.pl</code></li><li><code>startAlign.pl</code></li><li><code>helpMod.pm</code></li><li><code>findGenesInIntrons.pl</code></li><li><code>downsample_traingenes.pl</code></li><li><code>ensure_n_training_genes.py</code></li></ul><p>All scripts (files ending with <code>*.pl</code> and <code>*.py</code>) that are part of BRAKER must be executable in order to run BRAKER. This should already be the case if you download BRAKER from GitHub. Executability may be overwritten if you e.g. transfer BRAKER on a USB-stick to another computer. In order to check whether required files are executable, run the following command in the directory that contains BRAKER Perl scripts:</p><figure class="highlight jboss-cli"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs jboss-cli"><span class="hljs-keyword">ls</span> -l *<span class="hljs-string">.pl</span> *<span class="hljs-string">.py</span><br></code></pre></td></tr></table></figure><p>The output should be similar to this:</p><figure class="highlight tap"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs tap">-rwxr-xr-x<span class="hljs-number"> 1 </span>katharina katharina <span class="hljs-number"> 18191 </span>Mai <span class="hljs-number"> 7 </span>10:25 align2hints.pl<br>-rwxr-xr-x<span class="hljs-number"> 1 </span>katharina katharina  <span class="hljs-number"> 6090 </span>Feb<span class="hljs-number"> 19 </span>09:35 braker_cleanup.pl<br>-rwxr-xr-x<span class="hljs-number"> 1 </span>katharina katharina<span class="hljs-number"> 408782 </span>Aug<span class="hljs-number"> 17 </span>18:24 braker.pl<br>-rwxr-xr-x<span class="hljs-number"> 1 </span>katharina katharina  <span class="hljs-number"> 5024 </span>Mai <span class="hljs-number"> 7 </span>10:25 downsample_traingenes.pl<br>-rwxr-xr-x<span class="hljs-number"> 1 </span>katharina katharina  <span class="hljs-number"> 5024 </span>Mai <span class="hljs-number"> 7 </span>10:23 ensure_n_training_genes.py<br>-rwxr-xr-x<span class="hljs-number"> 1 </span>katharina katharina  <span class="hljs-number"> 4542 </span>Apr <span class="hljs-number"> 3 </span><span class="hljs-number"> 2019 </span>filter_augustus_gff.pl<br>-rwxr-xr-x<span class="hljs-number"> 1 </span>katharina katharina <span class="hljs-number"> 30453 </span>Mai <span class="hljs-number"> 7 </span>10:25 filterGenemark.pl<br>-rwxr-xr-x<span class="hljs-number"> 1 </span>katharina katharina  <span class="hljs-number"> 5754 </span>Mai <span class="hljs-number"> 7 </span>10:25 filterIntronsFindStrand.pl<br>-rwxr-xr-x<span class="hljs-number"> 1 </span>katharina katharina  <span class="hljs-number"> 7765 </span>Mai <span class="hljs-number"> 7 </span>10:25 findGenesInIntrons.pl<br>-rwxr-xr-x<span class="hljs-number"> 1 </span>katharina katharina  <span class="hljs-number"> 1664 </span>Feb<span class="hljs-number"> 12 </span><span class="hljs-number"> 2019 </span>gatech_pmp2hints.pl<br>-rwxr-xr-x<span class="hljs-number"> 1 </span>katharina katharina  <span class="hljs-number"> 2250 </span>Jan <span class="hljs-number"> 9 </span>13:55 log_reg_prothints.pl<br>-rwxr-xr-x<span class="hljs-number"> 1 </span>katharina katharina  <span class="hljs-number"> 4679 </span>Jan <span class="hljs-number"> 9 </span>13:55 merge_transcript_sets.pl<br>-rwxr-xr-x<span class="hljs-number"> 1 </span>katharina katharina <span class="hljs-number"> 41674 </span>Mai <span class="hljs-number"> 7 </span>10:25 startAlign.pl<br></code></pre></td></tr></table></figure><p>It is important that the <code>x</code> in <code>-rwxr-xr-x</code> is present for each script. If that is not the case, run</p><figure class="highlight jboss-cli"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs jboss-cli">`chmod a+x *<span class="hljs-string">.pl</span> *<span class="hljs-string">.py</span>`<br></code></pre></td></tr></table></figure><p>in order to change file attributes.</p><p>You may find it helpful to add the directory in which BRAKER perl scripts reside to your <code>$PATH</code> environment variable. For a single bash session, enter:</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs routeros"><span class="hljs-attribute">PATH</span>=/your_path_to_braker/:$PATH<br><span class="hljs-built_in">export</span> PATH<br></code></pre></td></tr></table></figure><p>To make this <code>$PATH</code> modification available to all bash sessions, add the above lines to a startup script (e.g.<code>~/.bashrc</code>).</p><h2 id="Bioinformatics-software-dependencies"><a href="#Bioinformatics-software-dependencies" class="headerlink" title="Bioinformatics software dependencies"></a>Bioinformatics software dependencies</h2><p>BRAKER calls upon various bioinformatics software tools that are not part of BRAKER. Some tools are obligatory, i.e. BRAKER will not run at all if these tools are not present on your system. Other tools are optional. Please install all tools that are required for running BRAKER in the mode of your choice.</p><h3 id="Mandatory-tools"><a href="#Mandatory-tools" class="headerlink" title="Mandatory tools"></a>Mandatory tools</h3><h4 id="GeneMark-EX"><a href="#GeneMark-EX" class="headerlink" title="GeneMark-EX"></a>GeneMark-EX</h4><p>Download GeneMark-EX<a href="https://github.com/Gaius-Augustus/BRAKER#g1">F1</a> from <a href="http://exon.gatech.edu/GeneMark/license_download.cgi">http://exon.gatech.edu/GeneMark/license_download.cgi</a> (the GeneMark-ES&#x2F;ET&#x2F;EP) option. Unpack and install GeneMark-EX as described in GeneMark-EX’s <code>README</code> file.</p><p>If already contained in your <code>$PATH</code> variable, BRAKER will guess the location of <code>gmes_petap.pl</code>, automatically. Otherwise, BRAKER can find GeneMark-EX executables either by locating them in an environment variable <code>GENEMARK_PATH</code>, or by taking a command line argument (<code>--GENEMARK_PATH=/your_path_to_GeneMark-EX/</code>).</p><p>In order to set the environment variable for your current Bash session, type:</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs routeros"><span class="hljs-built_in">export</span> <span class="hljs-attribute">GENEMARK_PATH</span>=/your_path_to_GeneMark-EX/<br></code></pre></td></tr></table></figure><p>Add the above lines to a startup script (e.g. <code>~/.bashrc</code>) in order to make it available to all bash sessions.<a href="https://github.com/Gaius-Augustus/BRAKER#g5">F5</a></p><p><strong>Important:</strong> GeneMark-EX will only run if a valid key file resides in your home directory. The key file will expire after 200 days, which means that you have to download a new GeneMark-EX release and a new key file after 200 days. The key file is downloaded as <code>gm_key.gz</code>. Unpack the key file and move it to a hidden file <strong>in your home directory</strong> as follows:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">cd</span> <span class="hljs-comment"># change to your home directory</span><br>gunzip gm_key_64.gz<br><span class="hljs-built_in">mv</span> gm_key_64 .gm_key<br></code></pre></td></tr></table></figure><p>Perl scripts within GeneMark-EX are configured with default Perl location at <code>/usr/bin/perl</code>.</p><p>If you are running GeneMark-EX in an Anaconda environment (or want to use Perl from the <code>$PATH</code> variable for any other reason), modify the shebang of all GeneMark-EX scripts with the following command located inside GeneMark-EX folder:</p><figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs nginx"><span class="hljs-attribute">perl</span> change_path_in_perl_scripts.pl <span class="hljs-string">&quot;/usr/bin/env perl&quot;</span><br></code></pre></td></tr></table></figure><p>You can check whether GeneMark-EX is installed properly by running the <code>check_install.bash</code> and&#x2F;or executing examples in <code>GeneMark-E-tests</code> directory.</p><figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs pgsql">my<br>./gmes_linux_64/check_install.bash<br>Checking GeneMark-ES installation<br>Checking Perl setup<br><span class="hljs-keyword">All</span> required Perl modules were <span class="hljs-built_in">found</span><br>Checking GeneMark.hmm setup<br>GeneMark.hmm was <span class="hljs-built_in">found</span><br>GeneMark.hmm <span class="hljs-keyword">is</span> <span class="hljs-keyword">set</span><br>GeneMark.hmm <span class="hljs-keyword">is</span> executable<br>Performing GeneMark.hmm test run<br><span class="hljs-keyword">All</span> required components <span class="hljs-keyword">for</span> GeneMark-ES were <span class="hljs-built_in">found</span><br></code></pre></td></tr></table></figure><h4 id="AUGUSTUS"><a href="#AUGUSTUS" class="headerlink" title="AUGUSTUS"></a>AUGUSTUS</h4><p>Download AUGUSTUS from its master branch at <a href="https://github.com/Gaius-Augustus/Augustus">https://github.com/Gaius-Augustus/Augustus</a>. Unpack AUGUSTUS and install AUGUSTUS according to AUGUSTUS <code>README.TXT</code>. <em><strong>Do not use outdated AUGUSTUS versions from other sources, e.g. Debian package or Bioconda package! BRAKER highly depends in particular on an up-to-date Augustus&#x2F;scripts directory, and other sources are often lagging behind.</strong></em></p><p>You should compile AUGUSTUS on your own system in order to avoid problems with versions of libraries used by AUGUSTUS. Compilation instructions are provided in the AUGUSTUS <code>README.TXT</code> file (<code>Augustus/README.txt</code>).</p><p>AUGUSTUS consists of <code>augustus</code>, the gene prediction tool, additional C++ tools located in <code>Augustus/auxprogs</code> and Perl scripts located in <code>Augustus/scripts</code>. Perl scripts must be executable (see instructions in section <a href="https://github.com/Gaius-Augustus/BRAKER#executability">BRAKER components</a>.</p><p>The C++ tool <code>bam2hints</code> is an essential component of BRAKER when run with RNA-Seq. Sources are located in <code>Augustus/auxprogs/bam2hints</code>. Make sure that you compile <code>bam2hints</code> on your system (it should be automatically compiled when AUGUSTUS is compiled, but in case of problems with <code>bam2hints</code>, please read troubleshooting instructions in <code>Augustus/auxprogs/bam2hints/README</code>).</p><p>Since BRAKER is a pipeline that trains AUGUSTUS, i.e. writes species specific parameter files, BRAKER needs writing access to the configuration directory of AUGUSTUS that contains such files (<code>Augustus/config/</code>). If you install AUGUSTUS globally on your system, the <code>config</code> folder will typically not be writable by all users. Either make the directory where <code>config</code> resides recursively writable to users of AUGUSTUS, or copy the <code>config/</code> folder (recursively) to a location where users have writing permission.</p><p>AUGUSTUS will locate the <code>config</code> folder by looking for an environment variable <code>$AUGUSTUS_CONFIG_PATH</code>. If the <code>$AUGUSTUS_CONFIG_PATH</code> environment variable is not set, then BRAKER will look in the path <code>../config</code> relative to the directory in which it finds an AUGUSTUS executable. Alternatively, you can supply the variable as a command line argument to BRAKER (<code>--AUGUSTUS_CONFIG_PATH=/your_path_to_AUGUSTUS/Augustus/config/</code>). We recommend that you export the variable e.g. for your current bash session:</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs awk">export AUGUSTUS_CONFIG_PATH=<span class="hljs-regexp">/your_path_to_AUGUSTUS/</span>Augustus<span class="hljs-regexp">/config/</span><br></code></pre></td></tr></table></figure><p>In order to make the variable available to all Bash sessions, add the above line to a startup script, e.g. <code>~/.bashrc</code>.</p><h5 id="Important"><a href="#Important" class="headerlink" title="Important:"></a>Important:</h5><p>BRAKER expects the entire <code>config</code> directory of AUGUSTUS at <code>$AUGUSTUS_CONFIG_PATH</code>, i.e. the subfolders <code>species</code> with its contents (at least <code>generic</code>) and <code>extrinsic</code>! Providing a writable but empty folder at <code>$AUGUSTUS_CONFIG_PATH</code> will not work for BRAKER. If you need to separate augustus binary and <code>$AUGUSTUS_CONFIG_PATH</code>, we recommend that you recursively copy the un-writable config contents to a writable location.</p><p>If you have a system-wide installation of AUGUSTUS at <code>/usr/bin/augustus</code>, an unwritable copy of <code>config</code> sits at <code>/usr/bin/augustus_config/</code>. The folder <code>/home/yours/</code> is writable to you. Copy with the following command (and additionally set the then required variables):</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs awk">cp -r <span class="hljs-regexp">/usr/</span>bin<span class="hljs-regexp">/Augustus/</span>config<span class="hljs-regexp">/ /</span>home<span class="hljs-regexp">/yours/</span><br>export AUGUSTUS_CONFIG_PATH=<span class="hljs-regexp">/home/y</span>ours/augustus_config<br>export AUGUSTUS_BIN_PATH=<span class="hljs-regexp">/usr/</span>bin<br>export AUGUSTUS_SCRIPTS_PATH=<span class="hljs-regexp">/usr/</span>bin/augustus_scripts<br></code></pre></td></tr></table></figure><h5 id="Modification-of-PATH"><a href="#Modification-of-PATH" class="headerlink" title="Modification of $PATH"></a>Modification of $PATH</h5><p>Adding directories of AUGUSTUS binaries and scripts to your <code>$PATH</code> variable enables your system to locate these tools, automatically. It is not a requirement for running BRAKER to do this, because BRAKER will try to guess them from the location of another environment variable (<code>$AUGUSTUS_CONFIG_PATH</code>), or both directories can be supplied as command line arguments to <code>braker.pl</code>, but we recommend to add them to your <code>$PATH</code> variable. For your current bash session, type:</p><figure class="highlight elixir"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs elixir"><span class="hljs-title class_">PATH</span>=<span class="hljs-symbol">:/your_path_to_augustus/bin/</span><span class="hljs-symbol">:/your_path_to_augustus/scripts/</span><span class="hljs-symbol">:</span><span class="hljs-variable">$PATH</span><br>export <span class="hljs-title class_">PATH</span><br></code></pre></td></tr></table></figure><p>For all your BASH sessions, add the above lines to a startup script (e.g.<code>~/.bashrc</code>).</p><h4 id="Python3"><a href="#Python3" class="headerlink" title="Python3"></a>Python3</h4><p>On Ubuntu, Python3 is usually installed by default, <code>python3</code> will be in your <code>$PATH</code> variable, by default, and BRAKER will automatically locate it. However, you have the option to specify the <code>python3</code> binary location in two other ways:</p><ol><li><p>Export an environment variable <code>$PYTHON3_PATH</code>, e.g. in your <code>~/.bashrc</code> file:</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs awk">export PYTHON3_PATH=<span class="hljs-regexp">/path/</span>to<span class="hljs-regexp">/python3/</span><br></code></pre></td></tr></table></figure></li><li><p>Specify the command line option <code>--PYTHON3_PATH=/path/to/python3/</code> to <code>braker.pl</code>.</p></li></ol><h4 id="Bamtools"><a href="#Bamtools" class="headerlink" title="Bamtools"></a>Bamtools</h4><p>Download BAMTOOLS (e.g. <code>git clone https://github.com/pezmaster31/bamtools.git</code>). Install BAMTOOLS by typing the following in your shell:</p><figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs vim"><span class="hljs-keyword">cd</span> your-bamtools-directory <span class="hljs-built_in">mkdir</span> build <span class="hljs-keyword">cd</span> build cmake .. <span class="hljs-keyword">make</span><br></code></pre></td></tr></table></figure><p>If already in your <code>$PATH</code> variable, BRAKER will find bamtools, automatically. Otherwise, BRAKER can locate the bamtools binary either by using an environment variable <code>$BAMTOOLS_PATH</code>, or by taking a command line argument (<code>--BAMTOOLS_PATH=/your_path_to_bamtools/bin/</code><a href="https://github.com/Gaius-Augustus/BRAKER#g6">F6</a>). In order to set the environment variable e.g. for your current bash session, type:</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs routeros"><span class="hljs-built_in">export</span> <span class="hljs-attribute">BAMTOOLS_PATH</span>=/your_path_to_bamtools/bin/<br></code></pre></td></tr></table></figure><p>Add the above line to a startup script (e.g. <code>~/.bashrc</code>) in order to set the environment variable for all bash sessions.</p><h4 id="NCBI-BLAST-or-DIAMOND"><a href="#NCBI-BLAST-or-DIAMOND" class="headerlink" title="NCBI BLAST+ or DIAMOND"></a>NCBI BLAST+ or DIAMOND</h4><p>You can use either NCBI BLAST+ or DIAMOND for removal of redundant training genes. You do not need both tools. If DIAMOND is present, it will be preferred because it is much faster.</p><p>Obtain and unpack DIAMOND as follows:</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs awk">wget http:<span class="hljs-regexp">//gi</span>thub.com<span class="hljs-regexp">/bbuchfink/</span>diamond<span class="hljs-regexp">/releases/</span>download<span class="hljs-regexp">/v0.9.24/</span>diamond-linux64.tar.gz<br>tar xzf diamond-linux64.tar.gz<br></code></pre></td></tr></table></figure><p>If already in your <code>$PATH</code> variable, BRAKER will find diamond, automatically. Otherwise, BRAKER can locate the diamond binary either by using an environment variable <code>$DIAMOND_PATH</code>, or by taking a command line argument (<code>--DIAMOND_PATH=/your_path_to_diamond</code>). In order to set the environment variable e.g. for your current bash session, type:</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs routeros"><span class="hljs-built_in">export</span> <span class="hljs-attribute">DIAMOND_PATH</span>=/your_path_to_diamond/<br></code></pre></td></tr></table></figure><p>Add the above line to a startup script (e.g. <code>~/.bashrc</code>) in order to set the environment variable for all bash sessions.</p><p>If you decide for BLAST+, install NCBI BLAST+ with <code>sudo apt-get install ncbi-blast+</code>.</p><p>If already in your <code>$PATH</code> variable, BRAKER will find blastp, automatically. Otherwise, BRAKER can locate the blastp binary either by using an environment variable <code>$BLAST_PATH</code>, or by taking a command line argument (<code>--BLAST_PATH=/your_path_to_blast/</code>). In order to set the environment variable e.g. for your current bash session, type:</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs routeros"><span class="hljs-built_in">export</span> <span class="hljs-attribute">BLAST_PATH</span>=/your_path_to_blast/<br></code></pre></td></tr></table></figure><p>Add the above line to a startup script (e.g. <code>~/.bashrc</code>) in order to set the environment variable for all bash sessions.</p><h4 id="ProtHint"><a href="#ProtHint" class="headerlink" title="ProtHint"></a>ProtHint</h4><p>ProtHint is a pipeline for generating hints for GeneMark-EX and AUGUSTUS from proteins of any evolutionary distance. If protein sequences are given on input, BRAKER runs ProtHint automatically. Alternatively, ProtHint can be executed as a separate step during data preparation. ProtHint is available from <a href="https://github.com/gatech-genemark/ProtHint">https://github.com/gatech-genemark/ProtHint</a>. Download as follows:</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs awk">git clone https:<span class="hljs-regexp">//gi</span>thub.com<span class="hljs-regexp">/gatech-genemark/</span>ProtHint.git<br></code></pre></td></tr></table></figure><p>or by getting the latest release from <a href="https://github.com/gatech-genemark/ProtHint/releases">https://github.com/gatech-genemark/ProtHint/releases</a>.</p><p>ProtHint has software requirements of its own. In addition to the Perl modules required by BRAKER, it needs</p><figure class="highlight ebnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs ebnf"><span class="hljs-attribute">threads</span><br></code></pre></td></tr></table></figure><p>You can easily verify ProtHint’s installation by running the test in <a href="https://github.com/gatech-genemark/ProtHint/tree/master/example">https://github.com/gatech-genemark/ProtHint/tree/master/example</a>.</p><p>ProtHint requires DIAMOND and Spaln, both of which come with ProtHint’s installation. ProtHint’s requirement of GeneMark-ES will already be fulfilled if you installed BRAKER dependencies above. For further installation instructions, please check <a href="https://github.com/gatech-genemark/ProtHint">https://github.com/gatech-genemark/ProtHint</a>.</p><p>If already in your <code>$PATH</code> variable, BRAKER will find prothint.py, automatically. Otherwise, BRAKER will try to locate the prothint.py executable by using an environment variable <code>$PROTHINT_PATH</code>. Alternatively, this can be supplied as a command line argument <code>--PROTHINT_PATH=/your/path/to/ProtHint/bin</code>.</p><h3 id="Optional-tools"><a href="#Optional-tools" class="headerlink" title="Optional tools"></a>Optional tools</h3><h4 id="Samtools"><a href="#Samtools" class="headerlink" title="Samtools"></a>Samtools</h4><p>Samtools is not required for running BRAKER if all your files are formatted, correctly (i.e. all sequences should have short and unique fasta names). If you are not sure whether all your files are fomatted correctly, it might be helpful to have Samtools installed because BRAKER can automatically fix certain format issues by using Samtools.</p><p>As a prerequisite for Samtools, download and install <code>htslib</code> (e.g. <code>git clone https://github.com/samtools/htslib.git</code>, follow the <code>htslib</code> documentation for installation).</p><p>Download and install Samtools (e.g. <code>git clone git://github.com/samtools/samtools.git</code>), subsequently follow Samtools documentation for installation).</p><p>If already in your <code>$PATH</code> variable, BRAKER will find samtools, automatically. Otherwise, BRAKER can find Samtools either by taking a command line argument (<code>--SAMTOOLS_PATH=/your_path_to_samtools/</code>), or by using an environment variable <code>$SAMTOOLS_PATH</code>. For exporting the variable, e.g. for your current bash session, type:</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs routeros"><span class="hljs-built_in">export</span> <span class="hljs-attribute">SAMTOOLS_PATH</span>=/your_path_to_samtools/<br></code></pre></td></tr></table></figure><p>Add the above line to a startup script (e.g. <code>~/.bashrc</code>) in order to set the environment variable for all bash sessions.</p><h4 id="Biopython"><a href="#Biopython" class="headerlink" title="Biopython"></a>Biopython</h4><p>If Biopython is installed, BRAKER can generate FASTA-files with coding sequences and protein sequences predicted by AUGUSTUS and generate track data hubs for visualization of a BRAKER run with MakeHub <a href="https://github.com/Gaius-Augustus/BRAKER#f16">R16</a>. These are optional steps. The first can be disabled with the command-line flag <code>--skipGetAnnoFromFasta</code>, the second can be activated by using the command-line options <code>--makehub --email=your@mail.de</code>, Biopython is not required if neither of these optional steps shall be performed.</p><p>On Ubuntu, install Python3 package manager with:</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs routeros">`sudo apt-<span class="hljs-built_in">get</span> install python3-pip`<br></code></pre></td></tr></table></figure><p>Then, install Biopython with:</p><figure class="highlight arcade"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs arcade"><span class="hljs-string">`sudo pip3 install biopython`</span><br></code></pre></td></tr></table></figure><h4 id="cdbfasta"><a href="#cdbfasta" class="headerlink" title="cdbfasta"></a>cdbfasta</h4><p>cdbfasta and cdbyank are required by BRAKER for correcting AUGUSTUS genes with in frame stop codons (spliced stop codons) using the AUGUSTUS script fix_in_frame_stop_codon_genes.py. This can be skipped with <code>--skip_fixing_broken_genes</code>.</p><p>On Ubuntu, install cdbfasta with:</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs routeros">`sudo apt-<span class="hljs-built_in">get</span> install cdbfasta`<br></code></pre></td></tr></table></figure><p>For other systems, you can for example obtain cdbfasta from <a href="https://github.com/gpertea/cdbfasta">https://github.com/gpertea/cdbfasta</a>, e.g.:</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs awk">git clone https:<span class="hljs-regexp">//gi</span>thub.com<span class="hljs-regexp">/gpertea/</span>cdbfasta.git`<br>cd cdbfasta<br>make all<br></code></pre></td></tr></table></figure><p>On Ubuntu, cdbfasta and cdbyank will be in your <code>$PATH</code> variable after installation, and BRAKER will automatically locate them. However, you have the option to specify the <code>cdbfasta</code> and <code>cdbyank</code> binary location in two other ways:</p><ol><li>Export an environment variable <code>$CDBTOOLS_PATH</code>, e.g. in your <code>~/.bashrc</code> file:</li></ol><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs awk">export CDBTOOLS_PATH=<span class="hljs-regexp">/path/</span>to<span class="hljs-regexp">/cdbtools/</span><br></code></pre></td></tr></table></figure><ol><li>Specify the command line option <code>--CDBTOOLS_PATH=/path/to/cdbtools/</code> to <code>braker.pl</code>.</li></ol><h4 id="GenomeThreader"><a href="#GenomeThreader" class="headerlink" title="GenomeThreader"></a>GenomeThreader</h4><p><strong>Note:</strong> Support of GenomeThreader within BRAKER is deprecated.</p><p>This tool is required, only, if you would like to run protein to genome alignments with BRAKER using GenomeThreader. This is a suitable approach only if an annotated species of short evolutionary distance to your target genome is available. Download GenomeThreader from <a href="http://genomethreader.org/">http://genomethreader.org/</a>. Unpack and install according to <code>gth/README</code>.</p><p>BRAKER will try to locate the GenomeThreader executable by using an environment variable <code>$ALIGNMENT_TOOL_PATH</code>. Alternatively, this can be supplied as command line argument (<code>--ALIGNMENT_TOOL_PATH=/your/path/to/gth</code>).</p><h4 id="Spaln"><a href="#Spaln" class="headerlink" title="Spaln"></a>Spaln</h4><p><strong>Note:</strong> Support of stand-alone Spaln (ouside of ProtHint) within BRAKER is deprecated.</p><p>This tool is required if you run ProtHint or if you would like to run protein to genome alignments with BRAKER using Spaln outside of ProtHint. Using Spaln outside of ProtHint is a suitable approach only if an annotated species of short evolutionary distance to your target genome is available. We recommend running Spaln through ProtHint for BRAKER. ProtHint brings along a Spaln binary. If that does not work on your system, download Spaln from <a href="https://github.com/ogotoh/spaln">https://github.com/ogotoh/spaln</a>. Unpack and install according to <code>spaln/doc/SpalnReadMe22.pdf</code>.</p><p>BRAKER will try to locate the Spaln executable by using an environment variable <code>$ALIGNMENT_TOOL_PATH</code>. Alternatively, this can be supplied as command line argument (<code>--ALIGNMENT_TOOL_PATH=/your/path/to/spaln</code>).</p><h4 id="Exonerate"><a href="#Exonerate" class="headerlink" title="Exonerate"></a>Exonerate</h4><p><strong>Note:</strong> Support of Exonerate within BRAKER is deprecated.</p><p>This tool is required, only, if you would like to run protein to genome alignments with BRAKER using Exonerate. This is a suitable approach only if an annotated species of short evolutionary distance to your target genome is available. (We recommend the usage of GenomeThreader instad of Exonerate because Exonerate is comparably slower and has lower specificity than GenomeThreader.) Download Exonerate from <a href="https://github.com/nathanweeks/exonerate">https://github.com/nathanweeks/exonerate</a>. Unpack and install according to <code>exonerate/README</code>. (On Ubuntu, download and install by typing <code>sudo apt-get install exonerate</code>.)</p><p>BRAKER will try to locate the Exonerate executable by using an environment variable <code>$ALIGNMENT_TOOL_PATH</code>. Alternatively, this can be supplied as command line argument (<code>--ALIGNMENT_TOOL_PATH=/your/path/to/exonerate</code>).</p><h4 id="GUSHR"><a href="#GUSHR" class="headerlink" title="GUSHR"></a><font color="red">GUSHR</font></h4><p>This tool is only required if you want either add UTRs (from RNA-Seq data) to predicted genes or if you want to train UTR parameters for AUGUSTUS and predict genes with UTRs. In any case, GUSHR requires the input of RNA-Seq data.</p><p>GUSHR is available for download at <a href="https://github.com/Gaius-Augustus/GUSHR">https://github.com/Gaius-Augustus/GUSHR</a>. Obtain it by typing:</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs awk">git clone https:<span class="hljs-regexp">//gi</span>thub.com<span class="hljs-regexp">/Gaius-Augustus/</span>GUSHR.git<br></code></pre></td></tr></table></figure><p>GUSHR executes a GeMoMa jar file <a href="https://github.com/Gaius-Augustus/BRAKER#f19">R19, </a><a href="https://github.com/Gaius-Augustus/BRAKER#f20">R20, </a><a href="https://github.com/Gaius-Augustus/BRAKER#f21">R21</a>, and this jar file requires Java 1.8. On Ubuntu, you can install Java 1.8 with the following command:</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs routeros">sudo apt-<span class="hljs-built_in">get</span> install openjdk-8-jdk<br></code></pre></td></tr></table></figure><p>If you have several java versions installed on your system, make sure that you enable 1.8 prior running BRAKER with java by running</p><figure class="highlight mipsasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs mipsasm">sudo update-alternatives --<span class="hljs-built_in">config</span> <span class="hljs-keyword">java </span><br></code></pre></td></tr></table></figure><p>and selecting the correct version.</p><h4 id="Tools-from-UCSC"><a href="#Tools-from-UCSC" class="headerlink" title="Tools from UCSC"></a><font color="red">Tools from UCSC</font></h4><p>If you switch <code>--UTR=on</code>, bamToWig.py will require the following tools that can be downloaded from <a href="http://hgdownload.soe.ucsc.edu/admin/exe">http://hgdownload.soe.ucsc.edu/admin/exe</a>:</p><ul><li>twoBitInfo</li><li>faToTwoBit</li></ul><p>It is optional to install these tools into your $PATH. If you don’t, and you switch <code>--UTR=on</code>, bamToWig.py will automatically download them into the working directory.</p><h4 id="MakeHub"><a href="#MakeHub" class="headerlink" title="MakeHub"></a>MakeHub</h4><p>If you wish to automaticaly generate a track data hub of your BRAKER run, the MakeHub software, available at <a href="https://github.com/Gaius-Augustus/MakeHub">https://github.com/Gaius-Augustus/MakeHub</a> is required. Download the software (either by running <code>git clone https://github.com/Gaius-Augustus/MakeHub.git</code>, or by picking a release from <a href="https://github.com/Gaius-Augustus/MakeHub/releases">https://github.com/Gaius-Augustus/MakeHub/releases</a>. Extract the release package if you downloaded a release (e.g. <code>unzip MakeHub.zip</code> or <code>tar -zxvf MakeHub.tar.gz</code>.</p><p>BRAKER will try to locate the make_hub.py script by using an environment variable <code>$MAKEHUB_PATH</code>. Alternatively, this can be supplied as command line argument (<code>--MAKEHUB_PATH=/your/path/to/MakeHub/</code>). BRAKER can also try to guess the location of MakeHub on your system.</p><h1 id="Running-BRAKER"><a href="#Running-BRAKER" class="headerlink" title="Running BRAKER"></a><font color="red">Running BRAKER</font></h1><h2 id="Different-BRAKER-pipeline-modes"><a href="#Different-BRAKER-pipeline-modes" class="headerlink" title="Different BRAKER pipeline modes"></a>Different BRAKER pipeline modes</h2><p>In the following, we describe “typical” BRAKER calls for different input data types. In general, we recommend that you run BRAKER <font color="blue">on genomic sequences that have been <strong>softmasked</strong> for Repeats</font>. If your genome has been softmasked, include the <code>--softmasking</code> flag in your BRAKER call!</p><h3 id="BRAKER-with-RNA-Seq-data"><a href="#BRAKER-with-RNA-Seq-data" class="headerlink" title="BRAKER with RNA-Seq data"></a>BRAKER with <font color="red">RNA-Seq data</font></h3><p>This approach is suitable for genomes of species for which <font color="blue">RNA-Seq libraries with a good coverage</font> of the transcriptome are available. The pipeline is illustrated in Figure <a href="https://github.com/Gaius-Augustus/BRAKER#fig1">2</a>.</p><p>BRAKER can either extract RNA-Seq spliced alignment information from <code>bam</code> files, or it can use such extracted information, directly.</p><p>In order to run BRAKER with RNA-Seq data supplied as <code>bam</code> file(s) (in case of multiple files, separate them by comma), run:</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs routeros">braker.pl <span class="hljs-attribute">--species</span>=yourSpecies <span class="hljs-attribute">--genome</span>=genome.fasta \<br>   <span class="hljs-attribute">--bam</span>=file1.bam,file2.bam<br></code></pre></td></tr></table></figure><p>In order to run BRAKER with <font color="blue">RNA-Seq <strong>spliced alignment information</strong> that has already been extracted</font>, run:</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs routeros">braker.pl <span class="hljs-attribute">--species</span>=yourSpecies <span class="hljs-attribute">--genome</span>=genome.fasta \<br>   <span class="hljs-attribute">--hints</span>=hints1.gff,hints2.gff<br></code></pre></td></tr></table></figure><p>The format of such a hints file must be as follows (tabulator separated file):</p><figure class="highlight tap"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs tap">chrName b2h intron <span class="hljs-number"> 6591 </span>  <span class="hljs-number"> 8003 </span>  <span class="hljs-number"> 1 </span>  +   .   pri=4;src=E<br>chrName b2h intron <span class="hljs-number"> 6136 </span>  <span class="hljs-number"> 9084 </span>  <span class="hljs-number"> 11 </span> +   .   mult=11;pri=4;src=E<br>...<br></code></pre></td></tr></table></figure><p><font color="blue">The source <strong>b2h</strong> in the <strong>second column</strong> and the source tag <strong>src&#x3D;E</strong> in the <strong>last column</strong> are <strong>essential for BRAKER to determine</strong> whether a <strong>hint</strong> has been <strong>generated from RNA-Seq</strong> data.</font></p><h3 id="BRAKER-with-proteins-of-any-evolutionary-distance"><a href="#BRAKER-with-proteins-of-any-evolutionary-distance" class="headerlink" title="BRAKER with proteins of any evolutionary distance"></a>BRAKER with <font color="red">proteins of any evolutionary distance</font></h3><p>This approach is <font color="blue"><strong>suitable for</strong> genomes of species for which <strong>no RNA-Seq libraries</strong></font> are available. A large database of proteins (with possibly longer evolutionary distance to the target species) should be used in this case. This mode is illustrated in figure <a href="https://github.com/Gaius-Augustus/BRAKER#fig8">9</a>.</p><img src="BRAKER/f9.png" alt="braker2-main-a[fig1]" style="zoom:50%;" /><p>Figure 9: BRAKER with proteins of any evolutionary distance. ProtHint protein mapping pipelines is used to generate protein hints. <font color="blue"><strong>ProtHint</strong> automatically <strong>determines</strong> which <strong>alignments</strong> are <strong>from close relatives</strong>, and which are <strong>from rather distant relatives.</strong></font></p><p>For running BRAKER in this mode, type:</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs stylus">braker<span class="hljs-selector-class">.pl</span> <span class="hljs-attr">--genome</span>=genome<span class="hljs-selector-class">.fa</span> <span class="hljs-attr">--prot_seq</span>=proteins<span class="hljs-selector-class">.fa</span> <span class="hljs-attr">--softmasking</span><br></code></pre></td></tr></table></figure><p>We <font color="blue"><strong>recommend</strong> using OrthoDB</font> as basis for <code>proteins.fa</code>. The instructions on <font color="blue"><strong>how to prepare the input OrthoDB proteins</strong></font> are documented here: <a href="https://github.com/gatech-genemark/ProtHint#protein-database-preparation">https://github.com/gatech-genemark/ProtHint#protein-database-preparation</a>.</p><p>You can of course add additional protein sequences to that file, or try with a completely different database. Any database will need several representatives for each protein, though.</p><p>Instead of having BRAKER run ProtHint, you <font color="blue">can also start BRAKER with hints already produced by ProtHint</font>, by providing ProtHint’s <code>prothint_augustus.gff</code> output:</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs stylus">braker<span class="hljs-selector-class">.pl</span> <span class="hljs-attr">--genome</span>=genome<span class="hljs-selector-class">.fa</span> <span class="hljs-attr">--hints</span>=prothint_augustus<span class="hljs-selector-class">.gff</span> <span class="hljs-attr">--softmasking</span><br></code></pre></td></tr></table></figure><p>The format of <code>prothint_augustus.gff</code> in this mode looks like this:</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">2R</span> ProtHint intron <span class="hljs-number">11506230</span> <span class="hljs-number">11506648</span> <span class="hljs-number">4</span> + . src=M;mult=<span class="hljs-number">4</span>;pri=<span class="hljs-number">4</span><br><span class="hljs-attribute">2R</span> ProtHint intron <span class="hljs-number">9563406</span>  <span class="hljs-number">9563473</span>  <span class="hljs-number">1</span> + . grp=<span class="hljs-number">69004</span>_0:<span class="hljs-number">001</span>de1_702_g;src=C;pri=<span class="hljs-number">4</span>;<br><span class="hljs-attribute">2R</span> ProtHint intron <span class="hljs-number">8446312</span>  <span class="hljs-number">8446371</span>  <span class="hljs-number">1</span> + . grp=<span class="hljs-number">43151</span>_0:<span class="hljs-number">001</span>cae_473_g;src=C;pri=<span class="hljs-number">4</span>;<br><span class="hljs-attribute">2R</span> ProtHint intron <span class="hljs-number">8011796</span>  <span class="hljs-number">8011865</span>  <span class="hljs-number">2</span> - . src=P;mult=<span class="hljs-number">1</span>;pri=<span class="hljs-number">4</span>;al_score=<span class="hljs-number">0</span>.<span class="hljs-number">12</span>;<br><span class="hljs-attribute">2R</span> ProtHint start  <span class="hljs-number">234524</span>   <span class="hljs-number">234526</span>   <span class="hljs-number">1</span> + . src=P;mult=<span class="hljs-number">1</span>;pri=<span class="hljs-number">4</span>;al_score=<span class="hljs-number">0</span>.<span class="hljs-number">08</span>;<br></code></pre></td></tr></table></figure><p>The prediction of all hints with <font color="blue"><strong>src&#x3D;M</strong></font> will be enforced. Hints with <font color="blue"><strong>src&#x3D;C</strong></font> are ‘chained evidence’, i.e. they will only be incorporated if all members of the group (grp&#x3D;…) can be incorporated in a single transcript. All other hints have <font color="blue"><strong>src&#x3D;P</strong></font> in the last column. Supported features in column 3 are <code>intron</code>, <code>start</code>, <code>stop</code> and <code>CDSpart</code>.</p><h4 id="Training-and-prediction-of-UTRs-integration-of-coverage-information"><a href="#Training-and-prediction-of-UTRs-integration-of-coverage-information" class="headerlink" title="Training and prediction of UTRs, integration of coverage information"></a>Training and prediction of <font color="red">UTRs</font>, integration of coverage information</h4><p>If RNA-Seq (and only RNA-Seq) data is provided to BRAKER as a bam-file, and <font color="blue">if the genome is <strong>softmasked for repeats</strong></font>, BRAKER can automatically train UTR parameters for AUGUSTUS. After successful training of UTR parameters, BRAKER will automatically predict genes including coverage information form RNA-Seq data. Example call:</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs routeros">braker.pl <span class="hljs-attribute">--species</span>=yourSpecies <span class="hljs-attribute">--genome</span>=genome.fasta \<br>   <span class="hljs-attribute">--bam</span>=file.bam --softmasking <span class="hljs-attribute">--UTR</span>=on<br></code></pre></td></tr></table></figure><p><strong>Warnings:</strong></p><ol><li>This feature is experimental!</li><li>–UTR&#x3D;on is currently not compatible with bamToWig.py as released in AUGUSTUS 3.3.3; it requires the current development code version from the github repository (git clone <a href="https://github.com/Gaius-Augustus/Augustus.git">https://github.com/Gaius-Augustus/Augustus.git</a>).</li><li>–UTR&#x3D;on increases memory consumption of AUGUSTUS. Carefully monitor jobs if your machine was close to maxing RAM without –UTR&#x3D;on! Reducing the number of cores will also reduce RAM consumption.</li><li>UTR prediction sometimes improves coding sequence prediction accuracy, but not always.<font color="red"> <strong>If you try this feature, carefully compare results with and without UTR parameters</strong>, </font>afterwards (e.g. in UCSC Genome Browser).</li></ol><h4 id="Stranded-RNA-Seq-alignments"><a href="#Stranded-RNA-Seq-alignments" class="headerlink" title="Stranded RNA-Seq alignments"></a>Stranded RNA-Seq alignments</h4><p>For running BRAKER without UTR parameters, <strong>it is not very important whether RNA-Seq data was generated by a <em>stranded</em> protocol</strong> (because spliced alignments are ’artificially stranded’ by checking the splice site pattern). <font color="red"><strong>However, for UTR training and prediction, stranded libraries may provide information that is valuable for BRAKER</strong>.</font></p><p>After alignment of the <strong>stranded RNA-Seq libraries</strong>, separate the resulting bam file entries into two files: <strong>one for plus strand mappings, one for minus strand mappings</strong>. Call BRAKER as follows:</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs routeros">braker.pl <span class="hljs-attribute">--species</span>=yourSpecies <span class="hljs-attribute">--genome</span>=genome.fasta \<br>   --softmasking <span class="hljs-attribute">--bam</span>=plus.bam,minus.bam <span class="hljs-attribute">--stranded</span>=+,- \<br>    <span class="hljs-attribute">--UTR</span>=on<br></code></pre></td></tr></table></figure><p>You may additionally include bam files from <strong>unstranded libraries. Those files will not used for generating UTR training examples, but they will be included in the final gene prediction step as unstranded coverage information</strong>, example call:</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs stylus">braker<span class="hljs-selector-class">.pl</span> <span class="hljs-attr">--species</span>=yourSpecies <span class="hljs-attr">--genome</span>=genome<span class="hljs-selector-class">.fasta</span> \<br>   <span class="hljs-attr">--softmasking</span> <span class="hljs-attr">--bam</span>=plus<span class="hljs-selector-class">.bam</span>,minus<span class="hljs-selector-class">.bam</span>,unstranded<span class="hljs-selector-class">.bam</span> \<br>   <span class="hljs-attr">--stranded</span>=+,-,. <span class="hljs-attr">--UTR</span>=on<br></code></pre></td></tr></table></figure><p><strong>Warning:</strong> This feature is experimental and currently has low priority on our maintenance list!</p><h3 id="BRAKER-with-proteins-of-short-evolutionary-distance"><a href="#BRAKER-with-proteins-of-short-evolutionary-distance" class="headerlink" title="BRAKER with proteins of short evolutionary distance"></a>BRAKER with <font color="red">proteins of short evolutionary distance</font></h3><p>This is a deprecated pipeline that was before the only suitable approach if RNA-Seq data for the species of the target genome is not available and if a well annotated and very closely related reference species is available and you don’t want to use the approach for proteins of any evolutionary distance (where we back then weren’t sure how it’d perform on proteins of short evolutionary distance).</p><p>For running BRAKER in this mode, type:</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs routeros">braker.pl <span class="hljs-attribute">--species</span>=yourSpecies <span class="hljs-attribute">--genome</span>=genome.fasta \<br>   <span class="hljs-attribute">--prot_seq</span>=proteins.fa <span class="hljs-attribute">--prg</span>=gth \<br>   <span class="hljs-attribute">--ALIGNMENT_TOOL_PATH</span>=/path/to/gth/binary \<br>   --trainFromGth<br></code></pre></td></tr></table></figure><p><font color="blue">It is possible to generate protein alignments <strong>externally</strong>,</font> prior running BRAKER, itself. The compatible command for running GenomeThreader prior running BRAKER, is:</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs stylus">gth -genomic genome<span class="hljs-selector-class">.fa</span>  -protein protein<span class="hljs-selector-class">.fa</span> -gff3out \<br>   -skipalignmentout -o gth.aln<br></code></pre></td></tr></table></figure><p>In order to use such externally created alignment files, run: <font color="blue"><strong>[aln out]</strong></font></p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs routeros">braker.pl <span class="hljs-attribute">--species</span>=yourSpecies <span class="hljs-attribute">--genome</span>=genome.fasta \<br>   <span class="hljs-attribute">--prot_aln</span>=proteins.aln <span class="hljs-attribute">--prg</span>=gth --trainFromGth<br></code></pre></td></tr></table></figure><p>It is also possible to run BRAKER in this mode using an already prepared hints file. In this case, run: <font color="blue"><strong>[aln trans hint]</strong></font></p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs routeros">braker.pl <span class="hljs-attribute">--species</span>=yourSpecies <span class="hljs-attribute">--genome</span>=genome.fasta \<br>   <span class="hljs-attribute">--hints</span>=hints.gff <span class="hljs-attribute">--prg</span>=gth --trainFromGth<br></code></pre></td></tr></table></figure><p><font color="red"><strong>–prg&#x3D;gth –trainFromGth? if i have aug,rna,pro hints, alos set this???</strong></font></p><p>Format of the hints file should look like this:</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">chrName</span>   gth2h   CDSpart <span class="hljs-number">105984</span>  <span class="hljs-number">106633</span>  .     -    .    src=P;grp=FBpp0285205;pri=<span class="hljs-number">4</span><br><span class="hljs-attribute">chrName</span>   gth2h   start   <span class="hljs-number">106646</span>  <span class="hljs-number">106648</span>  .     -    .    src=P;grp=FBpp0285205;pri=<span class="hljs-number">4</span><br></code></pre></td></tr></table></figure><p>Supported features in column 3 are intron, CDSpart, start, stop.</p><h3 id="BRAKER-with-RNA-Seq-and-protein-data"><a href="#BRAKER-with-RNA-Seq-and-protein-data" class="headerlink" title="BRAKER with RNA-Seq and protein data"></a>BRAKER with <font color="red">RNA-Seq and protein data</font></h3><p>Even though BRAKER supports the combination of RNA-Seq and protein data within the BRAKER pipeline, we strongly recommend to run BRAKER twice (<font color="blue"><strong>1x with RNA-Seq only</strong></font>, <font color="blue"><strong>1x with protein data only</strong></font>) and subsequently combine the results of both runs with <font color="blue"><strong>TSEBRA</strong></font>, the Transcript Selector for BRAKER (<a href="https://github.com/Gaius-Augustus/TSEBRA">https://github.com/Gaius-Augustus/TSEBRA</a>). You find more information on TSEBRA at <a href="https://www.biorxiv.org/content/10.1101/2021.06.07.447316v1">https://www.biorxiv.org/content/10.1101/2021.06.07.447316v1</a></p><p>In the following, we describe that it is possible to combine both data sources with BRAKER, alone, for the sake of completeness.</p><p>The  <font color="blue">native mode</font> for running BRAKER  <font color="blue">with RNA-Seq and protein</font> data is <code>--etpmode</code>. This will  <font color="blue">call GeneMark-ETP</font> (which is currently only available as a premature version by using current state GeneMark-ES&#x2F;ET&#x2F;EP&#x2F;EP+, improvements are to be expected, soon), which will  <font color="blue">use RNA-Seq and protein hints for training GeneMark-ETP</font>. Hints that are  <font color="blue"><strong>supported by both</strong> sources and proteins hints of particularly high quality are enforced in gene prediction with <strong>GeneMark-ETP</strong></font>. Subsequently,  <font color="blue"><strong>AUGUSTUS</strong></font> is trained on GeneMark-ETP predictions and genes with hints are predicted by AUGUSTUS. To call the pipeline in this mode, run:</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs stylus">braker<span class="hljs-selector-class">.pl</span> <span class="hljs-attr">--genome</span>=genome<span class="hljs-selector-class">.fa</span> <span class="hljs-attr">--prot_seq</span>=orthodb<span class="hljs-selector-class">.fa</span> \<br>   <span class="hljs-attr">--hints</span>=rnaseq<span class="hljs-selector-class">.hints</span> <span class="hljs-attr">--etpmode</span> <span class="hljs-attr">--softmasking</span><br></code></pre></td></tr></table></figure><p>You can or course replace the <code>rnaseq.gff</code> hints file by a BAM-file, e.g. <code>--bam=ranseq.bam</code>.</p><p>In addition, the following pipelines can be executed by BRAKER (deprecated pipelines):</p><ul><li>Adding protein data of short evolutionary distance to gene prediction step</li><li>Extending training gene set with proteins of short evolutionary distance</li></ul><h4 id="Adding-protein-data-of-short-evolutionary-distance-to-gene-prediction-step"><a href="#Adding-protein-data-of-short-evolutionary-distance-to-gene-prediction-step" class="headerlink" title="Adding protein data of short evolutionary distance to gene prediction step"></a>Adding protein data of short evolutionary distance to gene prediction step</h4><p>This pipeline is illustrated in Figure <a href="https://github.com/Gaius-Augustus/BRAKER#fig6">7</a>.</p><p>In general, add the options</p><figure class="highlight brainfuck"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs brainfuck"><span class="hljs-literal">--</span><span class="hljs-comment">prot_seq=proteins</span><span class="hljs-string">.</span><span class="hljs-comment">fa</span> <span class="hljs-literal">--</span><span class="hljs-comment">prg=(gth|exonerate|spaln)</span><br></code></pre></td></tr></table></figure><p>to the BRAKER call that is described in section <a href="https://github.com/Gaius-Augustus/BRAKER#braker-with-rna-seq-data">BRAKER with RNA-Seq data</a>.  <font color="blue">Select one protein alignment tool</font> from <font color="blue"> <strong>GenomeThreader</strong> (<code>gth</code>, <strong>recommended</strong>), Spaln (<code>spaln</code>) or Exonerate (<code>exonerate</code>)</font>. Of course, you may also specify the protein information  <font color="blue">as protein alignment files or hints files as</font> described in section <a href="https://github.com/Gaius-Augustus/BRAKER#braker-with-proteins-of-short-evolutionary-distance">BRAKER with proteins of short evolutionary distance</a>). This may result in a call similar to:</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs routeros">braker.pl <span class="hljs-attribute">--species</span>=yourSpecies <span class="hljs-attribute">--genome</span>=genome.fasta \<br>   <span class="hljs-attribute">--bam</span>=file1.bam,file2.bam <span class="hljs-attribute">--prot_seq</span>=proteins.fa \<br>   --prg=(gth|exonerate|spaln)<br></code></pre></td></tr></table></figure><h4 id="Extending-training-gene-set-with-proteins-of-short-evolutionary-distance"><a href="#Extending-training-gene-set-with-proteins-of-short-evolutionary-distance" class="headerlink" title="Extending training gene set with proteins of short evolutionary distance"></a>Extending training gene set with proteins of short evolutionary distance</h4><p> <font color="blue">If the <strong>number of training gene</strong> structures identified by RNA-Seq data, only, seems to be <strong>too small</strong></font>, you may add training gene structures generated by protein alignments with GenomeThreader to the training gene set. This pipeline is illustrated in Figure <a href="https://github.com/Gaius-Augustus/BRAKER#fig7">8</a>.</p><p>In general, add the options</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs routeros"><span class="hljs-attribute">--prot_seq</span>=proteins.fa <span class="hljs-attribute">--prg</span>=gth --gth2traingenes<br></code></pre></td></tr></table></figure><p>to the BRAKER call that is described in section <a href="https://github.com/Gaius-Augustus/BRAKER#braker-with-rna-seq-data">BRAKER with RNA-Seq data</a>. This may result in a call similar to:</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs stylus">braker<span class="hljs-selector-class">.pl</span> <span class="hljs-attr">--species</span>=yourSpecies <span class="hljs-attr">--genome</span>=genome<span class="hljs-selector-class">.fasta</span> \<br>   <span class="hljs-attr">--bam</span>=file1<span class="hljs-selector-class">.bam</span>,file2<span class="hljs-selector-class">.bam</span> <span class="hljs-attr">--prot_seq</span>=proteins<span class="hljs-selector-class">.fa</span> \<br>   <span class="hljs-attr">--prg</span>=gth <span class="hljs-attr">--gth2traingenes</span><br></code></pre></td></tr></table></figure><h4 id="BRAKER-with-short-and-long-read-RNA-Seq-and-protein-data"><a href="#BRAKER-with-short-and-long-read-RNA-Seq-and-protein-data" class="headerlink" title="BRAKER with short and long read RNA-Seq and protein data"></a>BRAKER with short and long read RNA-Seq and protein data</h4><p>A preliminary protocol for integration of assembled subreads from PacBio ccs sequencing in combination with short read Illumina RNA-Seq and protein database is described at <a href="https://github.com/Gaius-Augustus/BRAKER/blob/master/docs/long_reads/long_read_protocol.md">https://github.com/Gaius-Augustus/BRAKER/blob/master/docs/long_reads/long_read_protocol.md</a></p><h2 id="Description-of-selected-BRAKER-command-line-options"><a href="#Description-of-selected-BRAKER-command-line-options" class="headerlink" title="Description of selected BRAKER command line options"></a>Description of selected BRAKER command line options</h2><p>Please run <code>braker.pl --help</code> to obtain a full list of options.</p><h3 id="–epmode"><a href="#–epmode" class="headerlink" title="–epmode"></a>–epmode</h3><p>Run BRAKER in <font color="blue"><strong>EP-mode</strong>, i.e. with proteins of any evolutionary distance as <strong>processed by ProtHint</strong> within BRAKER. This mode is turned on <strong>by default</strong> when <strong>only protein</strong> input is detected</font>. Should be provided with either <strong>–prot_seq&#x3D;orthodb.fa</strong> or protein hints <strong>–hints&#x3D;prothint_augustus.gff</strong>.</p><h3 id="–etpmode"><a href="#–etpmode" class="headerlink" title="–etpmode"></a>–etpmode</h3><p>Run BRAKER in <font color="red"><strong>ETP-mode</strong></font>, i.e. with proteins of any evolutionary distance processed by ProtHint, and with RNA-Seq data. Should to be provided with <code>prot_seq=orthodb.fa</code> and <code>--bam=rnaseq.bam</code>. <font color="blue"><strong>Alternatively, the RNA-Seq and protein hints can be provided as processed hints</strong></font> with the <code>--hints</code> opiton. Please consider using TSEBRA (<a href="https://github.com/Gaius-Augustus/TSEBRA">https://github.com/Gaius-Augustus/TSEBRA</a>) instead of BRAKER in ETP-mode.</p><h3 id="–ab-initio"><a href="#–ab-initio" class="headerlink" title="–ab_initio"></a>–ab_initio</h3><p><strong>Compute AUGUSTUS <em>ab initio</em> predictions in addition</strong> to AUGUSTUS predictions with hints (additional output files: <code>augustus.ab_initio.*</code>. This may be useful for <strong>estimating the quality of training gene parameters</strong> when inspecting predictions in a Browser.</p><h3 id="–augustus-args-x3D-”–some-arg-x3D-bla”"><a href="#–augustus-args-x3D-”–some-arg-x3D-bla”" class="headerlink" title="–augustus_args&#x3D;”–some_arg&#x3D;bla”"></a>–augustus_args&#x3D;”–some_arg&#x3D;bla”</h3><p>One or several command line arguments to be passed to AUGUSTUS, if several arguments are given, separate them by whitespace, i.e. <code>&quot;--first_arg=sth --second_arg=sth&quot;</code>. This may be be useful if you know that gene prediction in your particular species benefits from a particular AUGUSTUS argument during the prediction step.</p><h3 id="–cores-x3D-INT"><a href="#–cores-x3D-INT" class="headerlink" title="–cores&#x3D;INT"></a>–cores&#x3D;INT</h3><p>Specifies the maximum number of cores that can be used during computation. BRAKER has to run some steps on a single core, others can take advantage of multiple cores. If you use more than 8 cores, this will not speed up all parallelized steps, in particular, the time consuming <code>optimize_augustus.pl</code> will not use more than <strong>8 cores</strong>. However, if you don’t mind some cores being idle, using more than 8 cores will speed up other steps.</p><h3 id="–fungus"><a href="#–fungus" class="headerlink" title="–fungus"></a>–fungus</h3><p>GeneMark-EX option: run algorithm with branch point model. Use this option <strong>if you genome is a fungus</strong>.</p><h3 id="–softmasking"><a href="#–softmasking" class="headerlink" title="–softmasking"></a>–softmasking</h3><p>Softmasking option for <strong>soft masked genome</strong> files. (Disabled by default.)</p><h3 id="–useexisting"><a href="#–useexisting" class="headerlink" title="–useexisting"></a>–useexisting</h3><p>【<strong>Use the present config and parameter files if they exist</strong> for ‘species’; will overwrite original parameters if BRAKER performs an AUGUSTUS training.】??</p><h3 id="–crf"><a href="#–crf" class="headerlink" title="–crf"></a>–crf</h3><p>Execute CRF training for AUGUSTUS; resulting parameters are only kept for final predictions if they show higher accuracy than HMM parameters. This increases runtime!</p><h3 id="–lambda-x3D-int"><a href="#–lambda-x3D-int" class="headerlink" title="–lambda&#x3D;int"></a>–lambda&#x3D;int</h3><p>Change the parameter $\lambda$ of the Poisson distribution that is used for downsampling training genes according to their number of introns (only genes with up to 5 introns are downsampled). The default value is $\lambda&#x3D;2$. You might want to set it to 0 for organisms that mainly have single-exon genes. (Generally, single-exon genes contribute less value to increasing AUGUSTUS parameters compared to genes with many exons.)</p><h3 id="–UTR-x3D-on"><a href="#–UTR-x3D-on" class="headerlink" title="–UTR&#x3D;on"></a>–UTR&#x3D;on</h3><p><font color="blue">Generate <strong>UTR training</strong> examples for AUGUSTUS from <strong>RNA-Seq coverage information</strong></font>, train AUGUSTUS UTR parameters and predict genes with AUGUSTUS and UTRs, including coverage information for RNA-Seq as evidence. This flag only works if –softmasking is also enabled. <em>This is an experimental feature!</em></p><p>If you performed a BRAKER run without –UTR&#x3D;on, you can add UTR parameter training and gene prediction with UTR parameters (and only RNA-Seq hints) with the following command:</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs stylus">braker<span class="hljs-selector-class">.pl</span> <span class="hljs-attr">--genome</span>=../genome<span class="hljs-selector-class">.fa</span> <span class="hljs-attr">--addUTR</span>=on <span class="hljs-attr">--softmasking</span> \<br>    <span class="hljs-attr">--bam</span>=../RNAseq<span class="hljs-selector-class">.bam</span> <span class="hljs-attr">--workingdir</span>=<span class="hljs-variable">$wd</span> \<br>    <span class="hljs-attr">--AUGUSTUS_hints_preds</span>=augustus<span class="hljs-selector-class">.hints</span><span class="hljs-selector-class">.gtf</span> \<br>    <span class="hljs-attr">--cores</span>=<span class="hljs-number">8</span> <span class="hljs-attr">--skipAllTraining</span> <span class="hljs-attr">--species</span>=somespecies<br></code></pre></td></tr></table></figure><p><font color="red"><strong>–AUGUSTUS_hints_preds</strong>. Modify <strong>augustus.hints.gtf</strong> to point to the <strong>AUGUSTUS predictions with hints from previous BRAKER run</strong></font>; <strong>modify flaning_DNA value to the flanking region from the log file???</strong> of your previous BRAKER run; modify some_new_working_directory to the location where BRAKER should store results of the additional BRAKER run; modify somespecies to the species name used in your previous BRAKER run.</p><p><font color="red">–AUGUSTUS_hints_preds</font>: only UTR training and prediction is performed if this option is given</p><h3 id="–addUTR-x3D-on"><a href="#–addUTR-x3D-on" class="headerlink" title="–addUTR&#x3D;on"></a>–addUTR&#x3D;on</h3><p>Add UTRs from RNA-Seq converage information to AUGUSTUS gene predictions using GUSHR. No training of UTR parameters and no gene prediction with UTR parameters is performed.</p><p>If you performed a BRAKER run without –addUTR&#x3D;on, you can add UTRs results of a previous BRAKER run with the following command:</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs stylus">braker<span class="hljs-selector-class">.pl</span> <span class="hljs-attr">--genome</span>=../genome<span class="hljs-selector-class">.fa</span> <span class="hljs-attr">--addUTR</span>=on <span class="hljs-attr">--softmasking</span> \<br>    <span class="hljs-attr">--bam</span>=../RNAseq<span class="hljs-selector-class">.bam</span> <span class="hljs-attr">--workingdir</span>=<span class="hljs-variable">$wd</span> \<br>    <span class="hljs-attr">--AUGUSTUS_hints_preds</span>=augustus<span class="hljs-selector-class">.hints</span><span class="hljs-selector-class">.gtf</span> <span class="hljs-attr">--cores</span>=<span class="hljs-number">8</span> \<br>    <span class="hljs-attr">--skipAllTraining</span> <span class="hljs-attr">--species</span>=somespecies<br></code></pre></td></tr></table></figure><p>Modify <code>augustus.hints.gtf</code> to point to the AUGUSTUS predictions with hints from previous BRAKER run; modify some_new_working_directory to the location where BRAKER should store results of the additional BRAKER run; this run will not modify AUGUSTUS parameters. <font color="red"> <strong>We recommend that you specify the original species of the original run with –species&#x3D;somespecies. Otherwise, BRAKER will create an unneeded species parameters directory Sp_</strong></font></p><h3 id="–stranded-x3D-…"><a href="#–stranded-x3D-…" class="headerlink" title="–stranded&#x3D;+,-,.,…"></a>–stranded&#x3D;+,-,.,…</h3><p>If <code>--UTR=on</code> is enabled, strand-separated bam-files can be provided with <code>--bam=plus.bam,minus.bam</code>. In that case, <code>--stranded=...</code> should hold the strands of the bam files (<code>+</code> for plus strand, <code>-</code> for minus strand, <code>.</code> for unstranded). Note that unstranded data will be used in the gene prediction step, only, if the parameter <code>--stranded=...</code> is set. <em>This is an experimental feature! GUSHR currently does not take advantage of stranded data.</em></p><h3 id="–makehub-email-x3D-x79-111-117-x72-64-x6d-x61-105-108-46-100-x65"><a href="#–makehub-email-x3D-x79-111-117-x72-64-x6d-x61-105-108-46-100-x65" class="headerlink" title="–makehub --email&#x3D;&#x79;&#111;&#117;&#x72;&#64;&#x6d;&#x61;&#105;&#108;&#46;&#100;&#x65;"></a>–makehub --email&#x3D;<a href="mailto:&#x79;&#111;&#117;&#x72;&#64;&#x6d;&#x61;&#105;&#108;&#46;&#100;&#x65;">&#x79;&#111;&#117;&#x72;&#64;&#x6d;&#x61;&#105;&#108;&#46;&#100;&#x65;</a></h3><p>If <code>--makehub</code> and <code>--email=your@mail.de</code> (with your valid e-mail adress) are provided, a track data hub for visualizing results with the UCSC Genome Browser will be generated using MakeHub (<a href="https://github.com/Gaius-Augustus/MakeHub">https://github.com/Gaius-Augustus/MakeHub</a>).</p><h3 id="–gc-probability-x3D-DECIMAL"><a href="#–gc-probability-x3D-DECIMAL" class="headerlink" title="–gc_probability&#x3D;DECIMAL"></a>–gc_probability&#x3D;DECIMAL</h3><p>By default, GeneMark-EX uses a probability of 0.001 for predicting the donor splice site pattern GC (instead of GT). It may make sense to increase this value for species where this donor splice site is more common. For example, in the species <em>Emiliania huxleyi</em>, about 50% of donor splice sites have the pattern GC (<a href="https://media.nature.com/original/nature-assets/nature/journal/v499/n7457/extref/nature12221-s2.pdf">https://media.nature.com/original/nature-assets/nature/journal/v499/n7457/extref/nature12221-s2.pdf</a>, page 5).</p><h1 id="Output-of-BRAKER"><a href="#Output-of-BRAKER" class="headerlink" title="Output of BRAKER"></a>Output of BRAKER</h1><p>BRAKER produces several important output files in the working directory.</p><ul><li><font color="red"><strong>augustus.hints.gtf</strong></font>: Genes predicted by AUGUSTUS with hints from given extrinsic evidence. This file will be missing if BRAKER was run with the option <code>--esmode</code>.</li><li><font color="blue"><strong>augustus.hints_utr.gtf</strong></font>: This file may contain different contents depending on how you called BRAKER:<ul><li>If you ran BRAKER with <font color="blue"><strong>–UTR&#x3D;on</strong></font>, then this file will <strong>contain genes predicted by AUGUSTUS with UTR parameters and coverage information from RNA-Seq</strong> data <strong>in GTF</strong> format.</li><li>If you ran BRAKER with <font color="blue"><strong>–addUTR&#x3D;on</strong></font>, then this file will contain genes predicted by AUGUSTUS <strong>without</strong> UTR parameters and without coverage information from RNA-Seq data. Instead, <strong>AUGUSTUS gene predictions with hints will only be extended by UTRs if RNA-Seq coverage allows</strong> it (i.e. no separate AUGUSTUS training or run was performed, UTRs are only added from running GUSHR). Genes in are in GTF format.</li></ul></li></ul><p>This file will only be present if BRAKER was executed with the options <code>--UTR=on</code> or <code>--addUTR=on</code> and a RNA-Seq BAM file.</p><ul><li><font color="blue"><strong>augustus.ab_initio.gtf</strong></font>: <strong>Genes predicted by AUGUSTUS in <em>ab initio</em> mode</strong> in GTF-format. The file will always be present if AUGUSTUS has been run with the option <font color="blue">–esmode</font>. Otherwise, it will only be present if BRAKER was run with the option <font color="blue">–AUGUSTUS_ab_initio</font>.</li><li><font color="blue"><strong>augustus.ab_initio_utr.gtf</strong></font>: This file may contain gene predictions with UTRs if you ran BRAKER with<font color="blue"> –UTR&#x3D;on</font>.</li></ul><p>This file will only be present if BRAKER was executed with the options <code>--UTR=on</code> or <code>--addUTR=on</code> and a RNA-Seq BAM-file, and with the option <code>--AUGUSTUS_ab_initio</code>.</p><ul><li><font color="blue"><em><em>GeneMark-E</em>&#x2F;genemark.gtf</em>*</font>: Genes predicted by GeneMark-ES&#x2F;ET&#x2F;EP&#x2F;EP+ in GTF-format. This file will be missing if BRAKER was executed with proteins of close homology and the option <code>--trainFromGth</code>.</li><li><font color="blue"><strong>braker.gtf</strong></font>: Union of augustus.hints.gtf and reliable GeneMark-EX predictions (genes fully supported by external evidence). In <code>--esmode</code>, this is the union of augustus.ab_initio.gtf and all GeneMark-ES genes. Thus, this set is generally more sensitive (more genes correctly predicted) and can be less specific (more false-positive predictions can be present).</li><li><font color="red"><strong>hintsfile.gff</strong></font>: The extrinsic evidence data extracted from RNAseq.bam and&#x2F;or protein data.</li></ul><p>AUGUSTUS output files may be present with the following name endings and formats:</p><ul><li><font color="red"><strong>GTF</strong>-format is <strong>always produced</strong></font>.</li><li><font color="red"><strong>GFF3</strong></font>-format is produced if the flag <font color="red"><strong>–gff3</strong></font> was specified to BRAKER.</li><li><font color="red">Coding sequences in FASTA-format <strong>augustus.hints.codingseq</strong></font> are produced if the flag <font color="blue">–skipGetAnnoFromFasta was not set</font>.</li><li><font color="red">Protein sequence files in FASTA-format <strong>augustus.hints.aa</strong></font> are produced if the flag <font color="blue">–skipGetAnnoFromFasta was not set.</font></li></ul><p>For details about gtf format, see <a href="http://www.sanger.ac.uk/Software/formats/GFF/">http://www.sanger.ac.uk/Software/formats/GFF/</a>. A GTF-format file contains one line per predicted exon. Example:</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">HS04636</span> AUGUSTUS initial   <span class="hljs-number">966</span> <span class="hljs-number">1017</span> . + <span class="hljs-number">0</span> transcript_id <span class="hljs-string">&quot;g1.1&quot;</span>; gene_id <span class="hljs-string">&quot;g1&quot;</span>;<br><span class="hljs-attribute">HS04636</span> AUGUSTUS internal <span class="hljs-number">1818</span> <span class="hljs-number">1934</span> . + <span class="hljs-number">2</span> transcript_id <span class="hljs-string">&quot;g1.1&quot;</span>; gene_id <span class="hljs-string">&quot;g1&quot;</span>;<br></code></pre></td></tr></table></figure><p>The columns (fields) contain:</p><figure class="highlight armasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs armasm"><span class="hljs-symbol">seqname</span> source feature start <span class="hljs-meta">end</span> score strand frame transcript ID <span class="hljs-keyword">and</span> gene ID<br></code></pre></td></tr></table></figure><p>If the <code>--makehub</code> option was used and MakeHub is available on your system, a hub directory beginning with the name <code>hub_</code> will be created. Copy this directory to a publicly accessible web server. A file <code>hub.txt</code> resides in the directory. Provide the link to that file to the <font color="blue">UCSC Genome Browser for visualizing results</font>.</p><h1 id="Example-data"><a href="#Example-data" class="headerlink" title="Example data"></a>Example data</h1><p>An incomplete example data set is contained in the directory <code>BRAKER/example</code>. In order to complete the data set, please <strong>download the RNA-Seq alignment BAM file</strong> (134 MB) with <code>wget</code>:</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs awk">cd BRAKER/example<br>wget http:<span class="hljs-regexp">//</span>topaz.gatech.edu<span class="hljs-regexp">/GeneMark/</span>Braker/RNAseq.bam<br></code></pre></td></tr></table></figure><p>In case you have trouble accessing that file, there’s also a copy available from another server:</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs awk">cd BRAKER/example<br>wget http:<span class="hljs-regexp">//</span>bioinf.uni-greifswald.de<span class="hljs-regexp">/augustus/</span>datasets/RNAseq.bam<br></code></pre></td></tr></table></figure><p>The example data set was not compiled in order to achieve optimal prediction accuracy, but in order to quickly test pipeline components. The small subset of <strong>the genome used in these test examples is not long enough for BRAKER training</strong> to work well. <font color="blue">Too few genes</font></p><h2 id="Data-description"><a href="#Data-description" class="headerlink" title="Data description"></a>Data description</h2><p>Data corresponds to the last 1,000,000 nucleotides of <em>Arabidopsis thaliana</em>‘s chromosome Chr5, split into 8 artificial contigs.</p><p>RNA-Seq alignments were obtained by <a href="https://github.com/Gaius-Augustus/VARUS">VARUS</a>.</p><p>The protein sequences are a subset of <a href="https://v100.orthodb.org/download/odb10_plants_fasta.tar.gz">OrthoDB v10 plants proteins</a>.</p><p>List of files:</p><ul><li><code>genome.fa</code> - genome file in fasta format</li><li><code>RNAseq.bam</code> - RNA-Seq alignment file in bam format (this file is not a part of this repository, it must be downloaded separately from <a href="http://topaz.gatech.edu/GeneMark/Braker/RNAseq.bam">http://topaz.gatech.edu/GeneMark/Braker/RNAseq.bam</a>)</li><li><code>RNAseq.hints</code> - RNA-Seq hints (<strong>can be used instead of RNAseq.bam as RNA-Seq input to BRAKER</strong>)</li><li><code>proteins.fa</code> - protein sequences in fasta format</li></ul><p><strong>Set $PATH.</strong></p><p>The example data set also contains scripts <code>tests/test*.sh</code> that will execute below listed commands for testing BRAKER with the example data set. You find example <font color="blue"><strong>results of AUGUSTUS and GeneMark-EX</strong></font> in the folder <code>results/test*</code>. Be aware that BRAKER contains several parts where random variables are used, i.e. results that you obtain when running the tests may not be exactly identical. To <strong>compare</strong> your test <strong>results with the reference ones</strong>, you can use the <a href="https://github.com/Gaius-Augustus/BRAKER/blob/master/scripts/compare_intervals_exact.pl">compare_intervals_exact.pl</a> script as follows:</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-comment"># Compare CDS features</span><br>compare_intervals_exact.pl --f1 augustus.hints.gtf --f2 ../../results/test<span class="hljs-variable">$&#123;N&#125;</span>/augustus.hints.gtf --verbose<br><span class="hljs-comment"># Compare transcripts</span><br>compare_intervals_exact.pl --f1 augustus.hints.gtf --f2 ../../results/test<span class="hljs-variable">$&#123;N&#125;</span>/augustus.hints.gtf --trans --verbose<br></code></pre></td></tr></table></figure><p>Several tests use <code>--gm_max_intergenic 10000</code> option to make the test runs faster. <font color="red"><strong>It is not recommended to use this option in real BRAKER runs, the speed increase achieved by adjusting this option is negligible on full-sized genomes.</strong></font></p><h2 id="Testing-BRAKER-with-RNA-Seq-data"><a href="#Testing-BRAKER-with-RNA-Seq-data" class="headerlink" title="Testing BRAKER with RNA-Seq data"></a>Testing BRAKER with RNA-Seq data</h2><p>The following command will run the pipeline according to Figure <a href="https://github.com/Gaius-Augustus/BRAKER#fig2">3</a>:</p><img src="BRAKER/f3.png" alt="braker2-main-a[fig1]" style="zoom:50%;" /><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs stylus">braker<span class="hljs-selector-class">.pl</span> <span class="hljs-attr">--genome</span> genome<span class="hljs-selector-class">.fa</span> <span class="hljs-attr">--bam</span> RNAseq<span class="hljs-selector-class">.bam</span> <span class="hljs-attr">--softmasking</span> <span class="hljs-attr">--cores</span> N<br></code></pre></td></tr></table></figure><p>This test is implemented in <code>test1.sh</code>, expected runtime is ~20 minutes.</p><h2 id="Testing-BRAKER-with-proteins-of-any-evolutionary-distance"><a href="#Testing-BRAKER-with-proteins-of-any-evolutionary-distance" class="headerlink" title="Testing BRAKER with proteins of any evolutionary distance"></a>Testing BRAKER with proteins of any evolutionary distance</h2><p>The following command will run the pipeline according to Figure <a href="https://github.com/Gaius-Augustus/BRAKER#fig3">4</a>: <strong>ProHint</strong></p><img src="BRAKER/f4.png" alt="braker2-main-a[fig1]" style="zoom:50%;" /><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs stylus">braker<span class="hljs-selector-class">.pl</span> <span class="hljs-attr">--genome</span> genome<span class="hljs-selector-class">.fa</span> <span class="hljs-attr">--prot_seq</span> proteins<span class="hljs-selector-class">.fa</span> <span class="hljs-attr">--softmasking</span> <span class="hljs-attr">--cores</span> N<br></code></pre></td></tr></table></figure><p>This test is implemented in <code>test2.sh</code>, expected runtime is ~20 minutes.</p><h2 id="Testing-BRAKER-with-proteins-of-any-evolutionary-distance-and-RNA-Seq"><a href="#Testing-BRAKER-with-proteins-of-any-evolutionary-distance-and-RNA-Seq" class="headerlink" title="Testing BRAKER with proteins of any evolutionary distance and RNA-Seq"></a>Testing BRAKER with proteins of any evolutionary distance and RNA-Seq</h2><p><font color="red"><strong>Please consider using TSEBRA instead of running BRAKER with both RNA-Seq and protein data</strong></font>: <a href="https://github.com/Gaius-Augustus/TSEBRA">https://github.com/Gaius-Augustus/TSEBRA</a></p><p>The following command will run a pipeline that <font color="red">first trains <strong>GeneMark-ETP</strong> with <strong>protein</strong> and <strong>RNA</strong>-Seq hints</font> and subsequently trains AUGUSTUS on the basis of GeneMark-ETP predictions. <strong>AUGUSTUS predictions</strong> are also performed with hints from <strong>both sources</strong>, see Figure <a href="https://github.com/Gaius-Augustus/BRAKER#fig4">5</a>:</p><img src="BRAKER/f5.png" alt="braker2-main-a[fig1]" style="zoom:50%;" /><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs stylus">braker<span class="hljs-selector-class">.pl</span> <span class="hljs-attr">--genome</span> genome<span class="hljs-selector-class">.fa</span> <span class="hljs-attr">--prot_seq</span> proteins<span class="hljs-selector-class">.fa</span> <span class="hljs-attr">--bam</span> ../RNAseq<span class="hljs-selector-class">.bam</span> <span class="hljs-attr">--etpmode</span> <span class="hljs-attr">--softmasking</span> <span class="hljs-attr">--cores</span> N<br></code></pre></td></tr></table></figure><p>This test is implemented in <code>test3.sh</code>, expected runtime is ~20 minutes.</p><p>You can <font color="red"><strong>add UTRs</strong> from RNA-Seq data</font> (<font color="red"><strong>no AUGUSTUS training</strong></font>) to <strong>results of a BRAKER run in ETP-mode</strong> the following way:</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs stylus">braker<span class="hljs-selector-class">.pl</span> <span class="hljs-attr">--genome</span>=../genome<span class="hljs-selector-class">.fa</span> <span class="hljs-attr">--addUTR</span>=on <span class="hljs-attr">--softmasking</span> \<br>    <span class="hljs-attr">--bam</span>=../RNAseq<span class="hljs-selector-class">.bam</span> <span class="hljs-attr">--workingdir</span>=<span class="hljs-variable">$wd</span> \<br>    <span class="hljs-attr">--AUGUSTUS_hints_preds</span>=augustus<span class="hljs-selector-class">.hints</span><span class="hljs-selector-class">.gtf</span> <span class="hljs-attr">--cores</span>=<span class="hljs-number">8</span> \<br>    <span class="hljs-attr">--skipAllTraining</span> <span class="hljs-attr">--species</span>=somespecies<br></code></pre></td></tr></table></figure><p>This is implemented in <code>test3_add_utrs.sh</code>, expected <strong>runtime is ~1 minute.</strong></p><h2 id="Testing-BRAKER-with-proteins-of-close-homology"><a href="#Testing-BRAKER-with-proteins-of-close-homology" class="headerlink" title="Testing BRAKER with proteins of close homology"></a>Testing BRAKER with proteins of close homology</h2><p>The following command will run the pipeline according to Figure <a href="https://github.com/Gaius-Augustus/BRAKER#fig5">6</a>:</p><img src="BRAKER/f6.png" alt="braker2-main-a[fig1]" style="zoom:50%;" /><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs stylus">braker<span class="hljs-selector-class">.pl</span> <span class="hljs-attr">--genome</span> genome<span class="hljs-selector-class">.fa</span> <span class="hljs-attr">--prot_seq</span> proteins<span class="hljs-selector-class">.fa</span> <span class="hljs-attr">--prg</span> gth \<br>    <span class="hljs-attr">--trainFromGth</span> <span class="hljs-attr">--softmasking</span> <span class="hljs-attr">--cores</span> N<br></code></pre></td></tr></table></figure><p>This test is implemented in <code>test4.sh</code>, expected runtime is ~7 minutes. The fast runtime of this test is mostly caused by <font color="red"><strong>generating a low number of training genes [no GeneMark]</strong></font>. Note that this approach <font color="red"> not scale well with increasing genome size and the number of proteins in a protein database</font>. The runtime on a full genome will be much slower than with the command used in <code>test2.sh</code>.</p><h2 id="Testing-BRAKER-with-proteins-of-close-homology-and-RNA-Seq-data-RNA-Seq-supported-training"><a href="#Testing-BRAKER-with-proteins-of-close-homology-and-RNA-Seq-data-RNA-Seq-supported-training" class="headerlink" title="Testing BRAKER with proteins of close homology and RNA-Seq data (RNA-Seq supported training)"></a>Testing BRAKER with proteins of close homology and RNA-Seq data (<font color="red">RNA-Seq supported training</font>)</h2><p><font color="red">Please consider using <strong>TSBERA</strong> instead of running BRAKER with <strong>proteins</strong> and <strong>RNA</strong>-Seq</font>font&gt; data at the same time: <a href="https://github.com/Gaius-Augustus/TSEBRA">https://github.com/Gaius-Augustus/TSEBRA</a></p><p>The following command will run the pipeline according to Figure <a href="https://github.com/Gaius-Augustus/BRAKER#fig6">7</a>:</p><img src="BRAKER/f7.png" alt="braker2-main-a[fig1]" style="zoom:50%;" /><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-comment">#no etp</span><br>braker.pl --genome genome.fa --prot_seq proteins.fa --prg gth \<br>    --bam RNAseq.bam --softmasking --cores N<br></code></pre></td></tr></table></figure><p>This test is implemented in <code>test5.sh</code>, expected runtime is ~20 minutes.</p><h2 id="Testing-BRAKER-with-proteins-of-close-homology-and-RNA-Seq-data-RNA-Seq-and-protein-supported-training"><a href="#Testing-BRAKER-with-proteins-of-close-homology-and-RNA-Seq-data-RNA-Seq-and-protein-supported-training" class="headerlink" title="Testing BRAKER with proteins of close homology and RNA-Seq data (RNA-Seq and protein supported training)"></a>Testing BRAKER with proteins of close homology and RNA-Seq data (<font color="red">RNA-Seq and protein supported training</font>)</h2><p>Please consider using TSBERA instead of running BRAKER with proteins and RNA-Seq data at the same time: <a href="https://github.com/Gaius-Augustus/TSEBRA">https://github.com/Gaius-Augustus/TSEBRA</a></p><p>The following command will run the pipeline according to Figure <a href="https://github.com/Gaius-Augustus/BRAKER#fig7">8</a>:</p><img src="BRAKER/f8.png" alt="braker2-main-a[fig1]" style="zoom:50%;" /><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-comment"># --gth2traingenes</span><br>braker.pl --genome genome.fa --prot_seq prot.fa --prg gth --bam RNAseq.bam \<br>    --gth2traingenes --softmasking --cores N<br></code></pre></td></tr></table></figure><p>This test is implemented in <code>test6.sh</code>, expected runtime is ~20 minutes.</p><h2 id="Testing-BRAKER-with-pre-trained-parameters"><a href="#Testing-BRAKER-with-pre-trained-parameters" class="headerlink" title="Testing BRAKER with pre-trained parameters"></a>Testing BRAKER with pre-trained parameters</h2><p>The training step of all pipelines can be skipped with the option <code>--skipAllTraining</code>. This means, <font color="red"><strong>only AUGUSTUS predictions</strong> will be <strong>performed</strong></font>, using pre-trained, already existing parameters. For example, you can predict genes with the command:</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs stylus">braker<span class="hljs-selector-class">.pl</span> <span class="hljs-attr">--genome</span>=genome<span class="hljs-selector-class">.fa</span> <span class="hljs-attr">--bam</span> RNAseq<span class="hljs-selector-class">.bam</span> <span class="hljs-attr">--species</span>=arabidopsis \<br>    <span class="hljs-attr">--skipAllTraining</span> <span class="hljs-attr">--softmasking</span> <span class="hljs-attr">--cores</span> N<br></code></pre></td></tr></table></figure><p>This test is implemented in <code>test7.sh</code>, expected runtime is ~1 minute.</p><h2 id="Testing-BRAKER-with-genome-sequence"><a href="#Testing-BRAKER-with-genome-sequence" class="headerlink" title="Testing BRAKER with genome sequence"></a>Testing BRAKER with genome sequence</h2><p>The following command will run the pipeline with <strong>no extrinsic evidence</strong>:</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs stylus">braker<span class="hljs-selector-class">.pl</span> <span class="hljs-attr">--genome</span>=genome<span class="hljs-selector-class">.fa</span> <span class="hljs-attr">--esmode</span> <span class="hljs-attr">--softmasking</span> <span class="hljs-attr">--cores</span> N<br></code></pre></td></tr></table></figure><p>This test is implemented in <code>test8.sh</code>, expected runtime is ~20 minutes.</p><h2 id="Testing-BRAKER-with-RNA-Seq-data-and-–UTR-x3D-on"><a href="#Testing-BRAKER-with-RNA-Seq-data-and-–UTR-x3D-on" class="headerlink" title="Testing BRAKER with RNA-Seq data and –UTR&#x3D;on"></a>Testing BRAKER with RNA-Seq data and –UTR&#x3D;on</h2><p>The following command will run BRAKER with <strong><font color="red">training</font> UTR parameters from RNA-Seq coverage data</strong>:</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs stylus">braker<span class="hljs-selector-class">.pl</span> <span class="hljs-attr">--genome</span> genome<span class="hljs-selector-class">.fa</span> <span class="hljs-attr">--bam</span> RNAseq<span class="hljs-selector-class">.bam</span> <span class="hljs-attr">--softmasking</span> <span class="hljs-attr">--UTR</span>=on <span class="hljs-attr">--cores</span> N<br></code></pre></td></tr></table></figure><p>This test is implemented in <code>test9.sh</code>, expected runtime is ~20 minutes.</p><h2 id="Testing-BRAKER-with-RNA-Seq-data-and-–addUTR-x3D-on"><a href="#Testing-BRAKER-with-RNA-Seq-data-and-–addUTR-x3D-on" class="headerlink" title="Testing BRAKER with RNA-Seq data and –addUTR&#x3D;on"></a>Testing BRAKER with RNA-Seq data and –addUTR&#x3D;on</h2><p>The following command will <strong><font color="red">add[ no training]</font> UTRs to augustus.hints.gtf from RNA-Seq coverage data</strong>:</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs stylus">braker<span class="hljs-selector-class">.pl</span> <span class="hljs-attr">--genome</span> genome<span class="hljs-selector-class">.fa</span> <span class="hljs-attr">--bam</span> RNAseq<span class="hljs-selector-class">.bam</span> <span class="hljs-attr">--softmasking</span> <span class="hljs-attr">--addUTR</span>=on <span class="hljs-attr">--cores</span> N<br></code></pre></td></tr></table></figure><p>This test is implemented in <code>test10.sh</code>, expected runtime is ~20 minutes.</p><h1 id="Starting-BRAKER-on-the-basis-of-previously-existing-BRAKER-runs"><a href="#Starting-BRAKER-on-the-basis-of-previously-existing-BRAKER-runs" class="headerlink" title="Starting BRAKER on the basis of previously existing BRAKER runs"></a>Starting BRAKER on the basis of previously existing BRAKER runs</h1><p>There is currently no clean way to restart a failed BRAKER run (after solving some problem). However, it is possible to start a new BRAKER run based on results from a previous run – given that the old run produced the required intermediate results. We will in the following refer to the old working directory with variable <code>$&#123;BRAKER_OLD&#125;</code>, and to the new BRAKER working directory with <code>$&#123;BRAKER_NEW&#125;</code>. The file <code>what-to-cite.txt</code> will always only refer to the software that was actually called by a particular run. You might have to combine the contents of <code>$&#123;BRAKER_NEW&#125;/what-to-cite.txt</code> with <code>$&#123;BRAKER_OLD&#125;/what-to-cite.txt</code> for preparing a publication. The following figure illustrates at which points BRAKER run may be intercepted.</p><img src="BRAKER/f10.png" alt="braker2-main-a[fig1]" style="zoom:50%;" /><p>Figure 10: Points for intercepting a BRAKER run and reusing intermediate results in a new BRAKER run.</p><h2 id="Option-1-starting-BRAKER-with-existing-hints-file-s-before-training-my-opo-hints-file-generated-before-GeneMark-and-Aug"><a href="#Option-1-starting-BRAKER-with-existing-hints-file-s-before-training-my-opo-hints-file-generated-before-GeneMark-and-Aug" class="headerlink" title="Option 1: starting BRAKER with existing hints file(s) before training[my opo:hints file generated before GeneMark and Aug]"></a>Option 1: starting BRAKER with existing hints file(s) before training[my opo:hints file generated before GeneMark and Aug]</h2><p>If you have access to an existing BRAKER output that contains <strong>hintsfiles</strong> that were <strong>generated from</strong> extrinsic data, such as <strong>RNA</strong>-Seq or <strong>protein</strong> sequences, you can <strong>recycle these hints files in a new BRAKER run</strong>. Also, <strong>hints from a separate ProtHint run</strong> can be <strong>directly used in BRAKER</strong>.</p><p>The hints can be given to BRAKER with <font color="red"><strong>–hints ${BRAKER_OLD}&#x2F;hintsfile.gff</strong></font> option. This is illustrated in the test files <code>test1_restart1.sh</code>, <code>test2_restart1.sh</code>, <code>test3_restart1.sh</code>, <code>test5_restart1.sh</code>, and <code>test7_restart1.sh</code>. The other modes (for which this test is missing) cannot be restarted in this way.</p><h2 id="Option-2-starting-BRAKER-after-GeneMark-EX-had-finished-before-training-AUGUSTUS"><a href="#Option-2-starting-BRAKER-after-GeneMark-EX-had-finished-before-training-AUGUSTUS" class="headerlink" title="Option 2: starting BRAKER after GeneMark-EX had finished, before training AUGUSTUS"></a>Option 2: starting BRAKER after GeneMark-EX had finished, before training AUGUSTUS</h2><p>The GeneMark result can be given to BRAKER with <font color="red"><strong>–geneMarkGtf</strong> ${BRAKER_OLD}&#x2F;GeneMark-EX&#x2F;genemark.gtf</font> option. This is illustrated in the test files <code>test1_restart2.sh</code>, <code>test2_restart2.sh</code>, <code>test3_restart2.sh</code>, <code>test5_restart2.sh</code>, and <code>test8_restart2.sh</code>. The other modes (for which this test is missing) cannot be restarted in this way.</p><h2 id="Option-3-starting-BRAKER-after-AUGUSTUS-training"><a href="#Option-3-starting-BRAKER-after-AUGUSTUS-training" class="headerlink" title="Option 3: starting BRAKER after AUGUSTUS training"></a>Option 3: starting BRAKER after AUGUSTUS training</h2><p>The trained species parameters for AGUSTUS can be passed with <font color="red"><strong>–skipAllTraining and –species $speciesName</strong></font> options. This is illustrated in <code>test*_restart3.sh</code> files.</p><p>My opo: each training creat a new dir, can be use again.</p><h1 id="Bug-reporting"><a href="#Bug-reporting" class="headerlink" title="Bug reporting"></a>Bug reporting</h1><p>Before reporting bugs, please check that you are using the most recent versions of GeneMark-EX, AUGUSTUS and BRAKER. Also, check the list of <a href="https://github.com/Gaius-Augustus/BRAKER#common-problems">Common problems</a>, and the Issue list on GitHub before reporting bugs. We do monitor open issues on GitHub. Sometimes, we are unable to help you, immediately, but we try hard to solve your problems.</p><h2 id="Reporting-bugs-on-GitHub"><a href="#Reporting-bugs-on-GitHub" class="headerlink" title="Reporting bugs on GitHub"></a>Reporting bugs on GitHub</h2><p>If you found a bug, please open an issue at <a href="https://github.com/Gaius-Augustus/BRAKER/issues">https://github.com/Gaius-Augustus/BRAKER/issues</a> (or contact <a href="mailto:&#107;&#x61;&#x74;&#104;&#97;&#x72;&#105;&#x6e;&#97;&#46;&#x68;&#111;&#x66;&#x66;&#64;&#117;&#x6e;&#x69;&#x2d;&#x67;&#114;&#101;&#x69;&#102;&#x73;&#119;&#x61;&#108;&#x64;&#x2e;&#100;&#101;">&#107;&#x61;&#x74;&#104;&#97;&#x72;&#105;&#x6e;&#97;&#46;&#x68;&#111;&#x66;&#x66;&#64;&#117;&#x6e;&#x69;&#x2d;&#x67;&#114;&#101;&#x69;&#102;&#x73;&#119;&#x61;&#108;&#x64;&#x2e;&#100;&#101;</a> or <a href="mailto:&#98;&#x72;&#117;&#x6e;&#97;&#x2e;&#x74;&#111;&#109;&#97;&#115;&#x40;&#x67;&#97;&#116;&#101;&#99;&#x68;&#x2e;&#x65;&#100;&#117;">&#98;&#x72;&#117;&#x6e;&#97;&#x2e;&#x74;&#111;&#109;&#97;&#115;&#x40;&#x67;&#97;&#116;&#101;&#99;&#x68;&#x2e;&#x65;&#100;&#117;</a>).</p><p>Information worth mentioning in your bug report:</p><p>Check in <code>braker/yourSpecies/braker.log</code> at which step <code>braker.pl</code> crashed.</p><p>There are a number of other files that might be of interest, depending on where in the pipeline the problem occurred. Some of the following files will not be present if they did not contain any <strong>errors</strong>.</p><ul><li><code>braker/yourSpecies/errors/bam2hints.*.stderr</code> - will give details on a bam2hints crash (<strong>step for converting bam file to intron gff file</strong>)</li><li><code>braker/yourSpecies/hintsfile.gff</code> - is this file empty? If yes, something went wrong during hints generation - does this file contain hints from source “<strong>b2h</strong>” and of type “<strong>intron</strong>”? If not: <strong>GeneMark-ET</strong>(RNA) will not be able to <strong>execute</strong> properly. Conversely, <strong>GeneMark-EP+</strong>(pro) will not be able to execute correctly if hints from the source “<strong>ProtHint</strong>“ are missing.</li><li><code>braker/yourSpecies/(align_gthalign_exoneratealign_spaln)/*err</code> - <strong>errors reported by the alignment tools gth&#x2F;exonerate&#x2F;spaln</strong></li><li><code>braker/yourSpecies/errors/GeneMark-&#123;ET,EP&#125;.stderr</code> - <strong>errors reported by GeneMark-ET&#x2F;EP+</strong></li><li><code>braker/yourSpecies/errors/GeneMark-&#123;ET,EP).stdout</code> - may give clues about the point at <strong>which errors in GeneMark-ET&#x2F;EP+ occured</strong></li><li><code>braker/yourSpecies/GeneMark-&#123;ET,EP&#125;/genemark.gtf</code> - is this file empty? If yes, something went wrong during executing GeneMark-ET&#x2F;EP+ <strong>My is gene mark_hintsfile.gff? no ,in GeneMark-ET</strong></li><li><code>braker/yourSpecies/GeneMark-&#123;ET,EP&#125;/genemark.f.good.gtf</code> - is this file empty? If yes, something went wrong during <font color="red"><strong>filtering GeneMark-ET&#x2F;EP+ genes for training AUGUSTUS no??</strong></font></li><li><code>braker/yourSpecies/genbank.good.gb</code> - try a “grep -c LOCUS genbank.good.gb” to determine the number of training genes for training AUGUSTUS, should not be low. <font color="red"><strong>no??</strong></font></li><li><code>braker/yourSpecies/errors/firstetraining.stderr</code> - contains errors from first iteration of training AUGUSTUS</li><li><code>braker/yourSpecies/errors/secondetraining.stderr</code> - contains errors from second iteration of training AUGUSTUS</li><li><code>braker/yourSpecies/errors/optimize_augustus.stderr</code> - contains errors <strong>optimize_augustus.pl</strong> (<strong>additional training set for AUGUSTUS</strong>)</li><li><code>braker/yourSpecies/errors/augustus*.stderr</code> - contain <strong>AUGUSTUS execution</strong> errors</li><li><code>braker/yourSpecies/startAlign.stderr</code> - if you provided a protein fasta file and <code>--prg</code> option and this file is not empty, something went <strong>wrong</strong> during <strong>protein alignment</strong></li><li><code>braker/yourSpecies/startAlign.stdout</code> - may give clues on at which point protein alignment went wrong</li></ul><h2 id="Common-problems"><a href="#Common-problems" class="headerlink" title="Common problems"></a>Common problems</h2><ul><li><p><em>BRAKER complains that the RNA-Seq file does not correspond to the provided genome file, but I am sure the files correspond to each other!</em></p><p>Please check the headers of the genome FASTA file. If the headers are long and contain whitespaces, some RNA-Seq alignment tools will truncate sequence names in the BAM file. This leads to an error with BRAKER. Solution: shorten&#x2F;simplify FASTA headers in the genome file before running the RNA-Seq alignment and BRAKER.</p></li><li><p><em>There are duplicate Loci in the train.gb file (after using GenomeThreader)!</em></p><p>This issue arises if outdated versions of AUGUSTUS and BRAKER are used. Solution: Please update AUGUSTUS and BRAKER from github (<a href="https://github.com/Gaius-Augustus/Augustus">https://github.com/Gaius-Augustus/Augustus</a>, <a href="https://github.com/Gaius-Augustus/BRAKER">https://github.com/Gaius-Augustus/BRAKER</a>).</p></li><li><p><em>GeneMark fails!</em></p><p>(a) GeneMark requires a valid hidden key file in your home directory (<code>~/.gm_key</code>). The file expires after 200 days. Please check whether you have a valid key file before reporting an issue about this. Also, BRAKER may issue a WARNING that GeneMark is likely going to fail due to limited extrinsic evidence. If you see that warning, please don’t open an issue but try a different approach towards annotating your genome. For example, you can add more evidence data, you can try the protein mapping pipeline approach, you can try running <code>--esmode</code> without extrinsic evidence, …</p><p>(b) GeneMark by default only uses contigs longer than 50k for training. If you have a highly fragmented assembly, this might lead to “no data” for training. You can override the default minimal length by setting the BRAKER argument <code>--min_contig=10000</code>.</p><p>(c) see “[something] failed to execute” below.</p></li><li><p><em>[something] failed to execute!</em></p><p>When providing paths to software to BRAKER, please use absolute, non-abbreviated paths. For example, BRAKER might have problems with <code>--SAMTOOLS_PATH=./samtools/</code> or <code>--SAMTOOLS_PATH=~/samtools/</code>. Please use <code>SAMTOOLS_PATH=/full/absolute/path/to/samtools/</code>, instead. This applies to all path specifications as command line options to <code>braker.pl</code>. Relative paths and absolute paths will not pose problems if you export a bash variable, instead, or if you append the location of tools to your $PATH variable.</p></li><li><p><em>BRAKER cannot find the Augustus script XYZ…</em></p><p>Update Augustus from github with <code>git clone https://github.com/Gaius-Augustus/Augustus.git</code>. Do not use Augustus from other sources. BRAKER is highly dependent on an up-to-date Augustus. Augustus releases happen rather rarely, updates to the Augustus scripts folder occur rather frequently.</p></li><li><p><em>Does BRAKER depend on Python3?</em></p><p>It does. The python scripts employed by BRAKER are not compatible with Python2.</p></li><li><p><em>Why does BRAKER predict more genes than I expected?</em></p><p>If transposable elements (or similar) have not been masked appropriately, AUGUSTUS tends to predict those elements as protein coding genes. This can lead to a huge number genes. You can check whether this is the case for your project by BLASTing (or DIAMONDing) the predicted protein sequences against themselves (all vs. all) and counting how many of the proteins have a high number of high quality matches. You can use the output of this analysis to divide your gene set into two groups: the protein coding genes that you want to find and the repetitive elements that were additionally predicted.</p></li><li><p><em>I am running BRAKER in Anaconda and something fails…</em></p><p>Update AUGUSTUS and BRAKER from github with <code>git clone https://github.com/Gaius-Augustus/Augustus.git</code> and <code>git clone https://github.com/Gaius-Augustus/BRAKER.git</code>. The Anaconda installation is great, but it relies on releases of AUGUSTUS and BRAKER - which are often lagging behind. Please use the current GitHub code, instead.</p></li></ul><h1 id="Citing-BRAKER-and-software-called-by-BRAKER"><a href="#Citing-BRAKER-and-software-called-by-BRAKER" class="headerlink" title="Citing BRAKER and software called by BRAKER"></a>Citing BRAKER and software called by BRAKER</h1><p>Since BRAKER is a pipeline that calls several Bioinformatics tools, publication of results obtained by BRAKER requires that not only BRAKER is cited, but also the tools that are called by BRAKER. BRAKER will output a file <code>what-to-cite.txt</code> in the BRAKER working directory, informing you about which exact sources apply to your run.</p><ul><li>Always cite:<ul><li>Bruna, T., Hoff, K.J., Lomsadze, A., Stanke, M., &amp; Borodovsky, M. (2021). BRAKER2: Automatic Eukaryotic Genome Annotation with GeneMark-EP+ and AUGUSTUS Supported by a Protein Database. NAR Genomics and Bioinformatics 3(1):lqaa108, doi: 10.1093&#x2F;nargab&#x2F;lqaa108.</li><li>Hoff, K.J., Lomsadze, A., Borodovsky, M. and Stanke, M. (2019). Whole-Genome Annotation with BRAKER. Methods Mol Biol. 1962:65-95, doi: 10.1007&#x2F;978-1-4939-9173-0_5.</li><li>Hoff, K.J., Lange, S., Lomsadze, A., Borodovsky, M. and Stanke, M. (2016). BRAKER1: unsupervised RNA-Seq-based genome annotation with GeneMark-ET and AUGUSTUS. Bioinformatics, 32(5):767-769.</li><li>Stanke, M., Diekhans, M., Baertsch, R. and Haussler, D. (2008). Using native and syntenically mapped cDNA alignments to improve de novo gene finding. Bioinformatics, doi: 10.1093&#x2F;bioinformatics&#x2F;btn013.</li><li>Stanke. M., Schöffmann, O., Morgenstern, B. and Waack, S. (2006). Gene prediction in eukaryotes with a generalized hidden Markov model that uses hints from external sources. BMC Bioinformatics 7, 62.</li></ul></li><li>If any kind of AUGUSTUS training was performed by BRAKER, check carefully whether you configured BRAKER to use NCBI BLAST or DIAMOND. One of them was used to filter out redundant training gene structures.<ul><li>If you used NCBI BLAST, please cite:<ul><li>Altschul, A.F., Gish, W., Miller, W., Myers, E.W. and Lipman, D.J. (1990). A basic local alignment search tool. J Mol Biol 215:403–410.</li><li>Camacho, C., Coulouris, G., Avagyan, V., Ma, N., Papadopoulos, J., Bealer, K., and Madden, T.L. (2009). Blast+: architecture and applications. BMC bioinformatics, 10(1):421.</li></ul></li><li>If you used DIAMOND, please cite:<ul><li>Buchfink, B., Xie, C., Huson, D.H. (2015). Fast and sensitive protein alignment using DIAMOND. Nature Methods 12:59-60.</li></ul></li></ul></li><li>If BRAKER was executed with a genome file and no extrinsic evidence, cite, then GeneMark-ES was used, cite:<ul><li>Lomsadze, A., Ter-Hovhannisyan, V., Chernoff, Y.O. and Borodovsky, M. (2005). Gene identification in novel eukaryotic genomes by self-training algorithm. Nucleic Acids Research, 33(20):6494–6506.</li><li>Ter-Hovhannisyan, V., Lomsadze, A., Chernoff, Y.O. and Borodovsky, M. (2008). Gene prediction in novel fungal genomes using an ab initio algorithm with unsupervised training. Genome research, pages gr–081612, 2008.</li></ul></li><li>If BRAKER was run with proteins of any phylogenetic distance (–epmode or –etpmode), please cite all tools that are used by the ProtHint pipeline to generate hints:<ul><li>Bruna, T., Lomsadze, A., &amp; Borodovsky, M. (2020). GeneMark-EP+: eukaryotic gene prediction with self-training in the space of genes and proteins. NAR Genomics and Bioinformatics, 2(2), lqaa026.</li><li>Buchfink, B., Xie, C., Huson, D.H. (2015). Fast and sensitive protein alignment using DIAMOND. Nature Methods 12:59-60.</li><li>Lomsadze, A., Ter-Hovhannisyan, V., Chernoff, Y.O. and Borodovsky, M. (2005). Gene identification in novel eukaryotic genomes by self-training algorithm. Nucleic Acids Research, 33(20):6494–6506.</li><li>Iwata, H., and Gotoh, O. (2012). Benchmarking spliced alignment programs including Spaln2, an extended version of Spaln that incorporates additional species-specific features. Nucleic acids research, 40(20), e161-e161.</li><li>Gotoh, O., Morita, M., Nelson, D. R. (2014). Assessment and refinement of eukaryotic gene structure prediction with gene-structure-aware multiple protein sequence alignment. BMC bioinformatics, 15(1), 189.</li></ul></li><li>If BRAKER was executed with RNA-Seq alignments in bam-format, then SAMtools was used, cite:<ul><li>Li, H., Handsaker, B., Wysoker, A., Fennell, T., Ruan, J., Homer, N., Marth, G., Abecasis, G., Durbin, R.; 1000 Genome Project Data Processing Subgroup (2009). The Sequence Alignment&#x2F;Map format and SAMtools. Bioinformatics, 25(16):2078-9.</li><li>Barnett, D.W., Garrison, E.K., Quinlan, A.R., Strömberg, M.P. and Marth G.T. (2011). BamTools: a C++ API and toolkit for analyzing and managing BAM files. Bioinformatics, 27(12):1691-2</li></ul></li><li>If BRAKER used RNA-Seq alignments for generating a training gene set, cite GeneMark-ET:<ul><li>Lomsadze, A., Paul D.B., and Mark B. (2014) Integration of Mapped Rna-Seq Reads into Automatic Training of Eukaryotic Gene Finding Algorithm. Nucleic Acids Research 42(15): e119–e119</li></ul></li><li>If BRAKER was executed with proteins of closely related species, cite GenomeThreader:<ul><li>Gremme, G. (2013). Computational Gene Structure Prediction. PhD thesis, Universität Hamburg.</li></ul></li><li>If BRAKER called MakeHub for creating a track data hub for visualization of BRAKER results with the UCSC Genome Browser, cite:<ul><li>Hoff, K.J. (2019) MakeHub: Fully automated generation of UCSC Genome Browser Assembly Hubs. Genomics, Proteomics and Bioinformatics, in press 2020, preprint on bioarXive, doi: <a href="https://doi.org/10.1101/550145">https://doi.org/10.1101/550145</a>.</li></ul></li><li>If BRAKER called GUSHR for generating UTRs, cite:<ul><li>Keilwagen, J., Hartung, F., Grau, J. (2019) GeMoMa: Homology-based gene prediction utilizing intron position conservation and RNA-seq data. Methods Mol Biol. 1962:161-177, doi: 10.1007&#x2F;978-1-4939-9173-0_9.</li><li>Keilwagen, J., Wenk, M., Erickson, J.L., Schattat, M.H., Grau, J., Hartung F. (2016) Using intron position conservation for homology-based gene prediction. Nucleic Acids Research, 44(9):e89.</li><li>Keilwagen, J., Hartung, F., Paulini, M., Twardziok, S.O., Grau, J. (2018) Combining RNA-seq data and homology-based gene prediction for plants, animals and fungi. BMC Bioinformatics, 19(1):189.</li></ul></li></ul><h1 id="License"><a href="#License" class="headerlink" title="License"></a>License</h1><p>All source code, i.e. <code>scripts/*.pl</code> or <code>scripts/*.py</code> are under the Artistic License (see <a href="http://www.opensource.org/licenses/artistic-license.php">http://www.opensource.org/licenses/artistic-license.php</a>).</p><h1 id=""><a href="#" class="headerlink" title=""></a></h1><hr><h1 id="TSEBRA"><a href="#TSEBRA" class="headerlink" title="TSEBRA"></a>TSEBRA</h1><p><a href="https://github.com/Gaius-Augustus/TSEBRA">https://github.com/Gaius-Augustus/TSEBRA</a></p><h1 id="TSEBRA-Transcript-Selector-for-BRAKER"><a href="#TSEBRA-Transcript-Selector-for-BRAKER" class="headerlink" title="TSEBRA: Transcript Selector for BRAKER"></a>TSEBRA: Transcript Selector for BRAKER</h1><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p><a href="https://doi.org/10.1186/s12859-021-04482-0">TSEBRA</a> is a combiner tool that <font color="blue">selects transcripts from gene predictions</font> based on the support by extrisic evidence in form of <font color="blue">introns and start&#x2F;stop codons</font>. It was developed to combine BRAKER1<a href="https://github.com/Gaius-Augustus/TSEBRA#ref1">1</a> and BRAKER2<a href="https://github.com/Gaius-Augustus/TSEBRA#ref2">2</a>predicitons to increase their accuracies.</p><h2 id="Prerequisites"><a href="#Prerequisites" class="headerlink" title="Prerequisites"></a>Prerequisites</h2><p>Python 3.5.2 or higher is required.</p><h2 id="Installation-1"><a href="#Installation-1" class="headerlink" title="Installation"></a>Installation</h2><p>Download TSEBRA:</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs awk">git clone https:<span class="hljs-regexp">//gi</span>thub.com<span class="hljs-regexp">/Gaius-Augustus/</span>TSEBRA<br></code></pre></td></tr></table></figure><h2 id="Usage"><a href="#Usage" class="headerlink" title="Usage"></a>Usage</h2><p>The main script is <code>./bin/tsebra.py</code>. For usage information run <code>./bin/tsebra.py --help</code>.</p><h2 id="Input-Files"><a href="#Input-Files" class="headerlink" title="Input Files"></a>Input Files</h2><p>TSEBRA takes a list of <font color="blue">gene prediciton files</font>, a list of <font color="blue">hintfiles</font> and a <font color="blue">configuration file</font> as mandatory input.</p><h4 id="1-Gene-Predictions"><a href="#1-Gene-Predictions" class="headerlink" title="1 Gene Predictions"></a>1 Gene Predictions</h4><p>The gene prediction files have to be in <font color="blue">gtf format</font>. This is the standard output format of a BRAKER or AUGUSTUS<a href="https://github.com/Gaius-Augustus/TSEBRA#ref3">3,</a><a href="https://github.com/Gaius-Augustus/TSEBRA#ref4">4</a> gene prediciton.</p><p>Example:</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">2L</span>      AUGUSTUS        gene    <span class="hljs-number">83268</span>   <span class="hljs-number">87026</span>   <span class="hljs-number">0</span>.<span class="hljs-number">88</span>    -       .       g5332<br><span class="hljs-attribute">2L</span>      AUGUSTUS        transcript      <span class="hljs-number">83268</span>   <span class="hljs-number">87026</span>   <span class="hljs-number">0</span>.<span class="hljs-number">88</span>    -       .       g5332.t1<br><span class="hljs-attribute">2L</span>      AUGUSTUS        intron  <span class="hljs-number">84278</span>   <span class="hljs-number">87019</span>   <span class="hljs-number">1</span>       -       .       transcript_id <span class="hljs-string">&quot;file_1_file_1_g5332.t1&quot;</span>; gene_id <span class="hljs-string">&quot;file_1_file_1_g5332&quot;</span>;<br><span class="hljs-attribute">2L</span>      AUGUSTUS        CDS     <span class="hljs-number">87020</span>   <span class="hljs-number">87026</span>   <span class="hljs-number">0</span>.<span class="hljs-number">88</span>    -       <span class="hljs-number">0</span>       transcript_id <span class="hljs-string">&quot;file_1_file_1_g5332.t1&quot;</span>; gene_id <span class="hljs-string">&quot;file_1_file_1_g5332&quot;</span>;<br><span class="hljs-attribute">2L</span>      AUGUSTUS        exon    <span class="hljs-number">87020</span>   <span class="hljs-number">87026</span>   .       -       .       transcript_id <span class="hljs-string">&quot;file_1_file_1_g5332.t1&quot;</span>; gene_id <span class="hljs-string">&quot;file_1_file_1_g5332&quot;</span>;<br></code></pre></td></tr></table></figure><h4 id="2-Hint-Files"><a href="#2-Hint-Files" class="headerlink" title="2 Hint Files"></a>2 Hint Files</h4><p>The hints files have to be in <font color="blue">gff format</font>, the last column must include an attribute for <font color="blue">the source for the hint with <strong>‘src&#x3D;’</strong></font> and can include <font color="blue">the number of hints supporting the gene structure segment with <strong>‘mult&#x3D;’</strong></font>. This is the standard file format of the <code>hintsfile.gff</code> in a BRAKER working directory.</p><p>Example:</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">2L</span>      ProtHint        intron  <span class="hljs-number">279806</span>  <span class="hljs-number">279869</span>  <span class="hljs-number">2</span>       +       .       src=P;mult=<span class="hljs-number">25</span>;pri=<span class="hljs-number">4</span>;al_score=<span class="hljs-number">0</span>.<span class="hljs-number">437399</span>;<br><span class="hljs-attribute">2L</span>      ProtHint        intron  <span class="hljs-number">275252</span>  <span class="hljs-number">275318</span>  <span class="hljs-number">2</span>       -       .       src=P;mult=<span class="hljs-number">19</span>;pri=<span class="hljs-number">4</span>;al_score=<span class="hljs-number">0</span>.<span class="hljs-number">430006</span>;<br><span class="hljs-attribute">2L</span>      ProtHint        stop    <span class="hljs-number">293000</span>  <span class="hljs-number">293002</span>  <span class="hljs-number">1</span>       +       <span class="hljs-number">0</span>       grp=<span class="hljs-number">7220</span>_0:<span class="hljs-number">002</span>b08_g42;src=C;pri=<span class="hljs-number">4</span>;<br><span class="hljs-attribute">2L</span>      ProtHint        intron  <span class="hljs-number">207632</span>  <span class="hljs-number">207710</span>  <span class="hljs-number">1</span>       +       .       grp=<span class="hljs-number">7220</span>_0:<span class="hljs-number">002</span>afa_g26;src=C;pri=<span class="hljs-number">4</span>;<br><span class="hljs-attribute">2L</span>      ProtHint        start   <span class="hljs-number">207512</span>  <span class="hljs-number">207514</span>  <span class="hljs-number">1</span>       +       <span class="hljs-number">0</span>       grp=<span class="hljs-number">7220</span>_0:<span class="hljs-number">002</span>afa_g26;src=C;pri=<span class="hljs-number">4</span>;<br></code></pre></td></tr></table></figure><h4 id="3-Configuration-File"><a href="#3-Configuration-File" class="headerlink" title="3 Configuration File"></a>3 Configuration File</h4><p>The configuration file has to include three different sets of parameter:</p><ol><li><p>Weights for <font color="blue">all sources of hints</font>. The source of a hint is specified by the mandatory ‘src&#x3D;’ attribute in the last column of the <code>hintsfile.gff</code> (see section ‘Hint Files’). See section ‘Transcript scores’ in <a href="https://doi.org/10.1101/2021.06.07.447316">TSEBRA</a> for more information on how these weigths are used.<br>A weight is set to 1, if the weight for a hint source is not specified in the configuration file.</p><ul><li><p><em>Notes on adjusting these parameters: Increase the weight of the hint sources that have the highest quality. For example, if the protein database includes only species that are remotely related to the target species, the hints produced by BRAKER2 might be less accurate than the RNA-seq evidence. Then, you should increase the weight of the source related to the RNA-seq hints.</em></p><figure class="highlight livecodeserver"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs livecodeserver"><span class="hljs-comment"># src weights</span><br>P <span class="hljs-number">0.1</span><br>E <span class="hljs-number">10</span><br>C <span class="hljs-number">5</span><br><span class="hljs-comment"># E设置10，C设置5，8，10没区别？？？</span><br>M <span class="hljs-number">1</span><br><br>E = RNA-seq hints<br>M = manual hints, these are hints that are enforced during <span class="hljs-keyword">the</span> prediction step <span class="hljs-keyword">of</span> BRAKER,   手动强制预测。<br>C = protein hints <span class="hljs-built_in">from</span> proteins <span class="hljs-keyword">with</span> <span class="hljs-keyword">a</span> <span class="hljs-string">&#x27;high&#x27;</span> spliced alignment score.<br>P = protein hints <span class="hljs-built_in">from</span> proteins that have <span class="hljs-keyword">a</span> <span class="hljs-string">&#x27;good&#x27;</span> spliced alignment score, <br>     but that is <span class="hljs-built_in">lower</span> than <span class="hljs-keyword">the</span> score <span class="hljs-built_in">from</span> <span class="hljs-keyword">the</span> ones <span class="hljs-keyword">in</span> <span class="hljs-string">&#x27;C&#x27;</span>. <br></code></pre></td></tr></table></figure></li></ul></li><li><p>Required fractions of <strong>supported introns</strong> or <strong>supported start&#x2F;stop-codons</strong> for a transcript. A transcript is not included in the TSEBRA result if the fractions of introns and start&#x2F;stop codons supported by extrinsic evidence are lower than the thresholds.</p><ul><li><p><em>Notes on adjusting these parameters: The low evidence support thresholds for low evidence support are quite strict in the default configuration file. In this configuration, <strong>only transcripts with very high evidence support are allowed in the TSBERA result</strong>. In some cases, the default setting might be too strict, so that too many transcripts are filtered out. In this case, you should reduce the threshold of ‘intron_support’ (e.g., to 0.2).</em></p></li><li><p>Transcript scores: Likely exon-intron borders are inferred from the alignments to create intron hints. The start and stop codons of the protein alignments are used to create start and stop codon hints, respectively. The transcript scores utilize them to quantify the support of the transcript structure.</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-comment"># Low evidence support</span><br><span class="hljs-attribute">intron_support</span> <span class="hljs-number">0</span>.<span class="hljs-number">75</span><br><span class="hljs-attribute">stasto_support</span> <span class="hljs-number">1</span><br></code></pre></td></tr></table></figure></li></ul></li><li><p>Allowed difference between two overlapping transcripts for the four transcript scores (see section ‘Transcript scores’ in <a href="https://doi.org/10.1101/2021.06.07.447316">TSEBRA</a> for a definition of the different transcript scores and section ‘Pairwise transcript comparison rule’ for more information on how transcripts are compared). TSEBRA compares transcripts via their transcript scores and removes the one with the lower score if their difference exceeds the respective threshold.<br>Note that e_1, e_2 are fractions (e_1, e_2 ∊ [0,1]), and e_3, e_4 can be larger than 1 (e_3, e_4 ≥ 0).</p><ul><li><p><em>Notes on adjusting these parameters: The higher the thresholds are set the less transcripts are filtered by the respective rule. With these thresholds one can adjust the effect of each filtering rule of TSEBRA. As these thresholds are increased, more transcripts are included in the TSEBRA result, in particular, more alternatively spliced isoforms per gene are contained in the result.</em></p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-comment"># Allowed difference for each feature </span><br><span class="hljs-comment"># Values have to be in [0,1]</span><br><span class="hljs-attribute">e_1</span> <span class="hljs-number">0</span><br><span class="hljs-attribute">e_2</span> <span class="hljs-number">0</span>.<span class="hljs-number">5</span><br><span class="hljs-comment"># Values have to be &gt;0</span><br><span class="hljs-attribute">e_3</span> <span class="hljs-number">25</span><br><span class="hljs-attribute">e_4</span> <span class="hljs-number">10</span><br></code></pre></td></tr></table></figure></li></ul></li></ol><p>The name and the value of a parameter are separated by a space, and each parameter is listed in a different line.<br>Example:</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-comment"># src weights</span><br><span class="hljs-attribute">P</span> <span class="hljs-number">0</span>.<span class="hljs-number">1</span><br><span class="hljs-attribute">E</span> <span class="hljs-number">10</span><br><span class="hljs-attribute">C</span> <span class="hljs-number">5</span><br><span class="hljs-attribute">M</span> <span class="hljs-number">1</span><br><span class="hljs-comment"># Low evidence support</span><br><span class="hljs-attribute">intron_support</span> <span class="hljs-number">0</span>.<span class="hljs-number">75</span><br><span class="hljs-attribute">stasto_support</span> <span class="hljs-number">1</span><br><span class="hljs-comment"># Feature differences</span><br><span class="hljs-attribute">e_1</span> <span class="hljs-number">0</span><br><span class="hljs-attribute">e_2</span> <span class="hljs-number">0</span>.<span class="hljs-number">5</span><br><span class="hljs-attribute">e_3</span> <span class="hljs-number">25</span><br><span class="hljs-attribute">e_4</span> <span class="hljs-number">10</span><br></code></pre></td></tr></table></figure><p>Description of evidence sources in default BRAKER1 and BRAKER2 outputs:</p><figure class="highlight livecodeserver"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs livecodeserver">E = RNA-seq hints<br>M = manual hints, these are hints that are enforced during <span class="hljs-keyword">the</span> prediction step <span class="hljs-keyword">of</span> BRAKER,<br>C = protein hints <span class="hljs-built_in">from</span> proteins <span class="hljs-keyword">with</span> <span class="hljs-keyword">a</span> <span class="hljs-string">&#x27;high&#x27;</span> spliced alignment score.<br>P = protein hints <span class="hljs-built_in">from</span> proteins that have <span class="hljs-keyword">a</span> <span class="hljs-string">&#x27;good&#x27;</span> spliced alignment score, <br>     but that is <span class="hljs-built_in">lower</span> than <span class="hljs-keyword">the</span> score <span class="hljs-built_in">from</span> <span class="hljs-keyword">the</span> ones <span class="hljs-keyword">in</span> <span class="hljs-string">&#x27;C&#x27;</span>. <br></code></pre></td></tr></table></figure><h2 id="Use-Case"><a href="#Use-Case" class="headerlink" title="Use Case"></a>Use Case</h2><p>The recommended and most common usage for TSEBRA is to combine the resulting <code>augustus.hints.gtf</code> files of a BRAKER1 and a BRAKER2 run using the hintsfile.gff from both working directories. However, TSEBRA can be applied to any number (&gt;1) of gene predictions and hint files as long as they are in the correct format.</p><p>A common case might be that a user wants to annotate a novel genome with BRAKER and has:</p><ul><li>a novel genome with repeats masked: <code>genome.fasta.masked</code>,</li><li>hints for intron positions from RNA-seq reads<code>rna_seq_hints.gff</code>,</li><li>database of homologous proteins: <code>proteins.fa</code>.</li></ul><ol><li>Run BRAKER1 and BRAKER2 for example with</li></ol><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs routeros"><span class="hljs-comment">### BRAKER1</span><br>braker.pl <span class="hljs-attribute">--genome</span>=genome.fasta.masked <span class="hljs-attribute">--hints</span>=rna_seq_hints.gff \<br>            --softmasking <span class="hljs-attribute">--species</span>=species_name <span class="hljs-attribute">--workingdir</span>=braker1_out<br><span class="hljs-comment">### BRAKER2</span><br>braker.pl <span class="hljs-attribute">--genome</span>=genome.fasta.masked <span class="hljs-attribute">--prot_seq</span>=proteins.fa \<br>    --softmasking <span class="hljs-attribute">--species</span>=species_name --epmode \<br>    <span class="hljs-attribute">--workingdir</span>=braker2_out<br></code></pre></td></tr></table></figure><ol><li>Combine predicitons with TSEBRA</li></ol><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs stylus">./bin/tsebra<span class="hljs-selector-class">.py</span> -g braker1_out/augustus<span class="hljs-selector-class">.hints</span><span class="hljs-selector-class">.gtf</span>,braker2_out/augustus<span class="hljs-selector-class">.hints</span><span class="hljs-selector-class">.gtf</span> -c default<span class="hljs-selector-class">.cfg</span> \<br>    -e braker1_out/hintsfile<span class="hljs-selector-class">.gff</span>,braker2_out/hintsfile<span class="hljs-selector-class">.gff</span> \<br>    -o braker1+<span class="hljs-number">2</span>_combined.gtf<br></code></pre></td></tr></table></figure><p>The combined gene prediciton is <code>braker1+2_combined.gtf</code>.</p><h2 id="Example"><a href="#Example" class="headerlink" title="Example"></a>Example</h2><p>A small example is located at <code>example/</code>. Run <code>./example/run_prevco_example.sh</code> to execute the example and to check if TSEBRA runs properly.</p><h2 id="Other-scripts-in-the-TSEBRA-repository"><a href="#Other-scripts-in-the-TSEBRA-repository" class="headerlink" title="Other scripts in the TSEBRA repository"></a>Other scripts in the TSEBRA repository</h2><h3 id="Renaming-transcripts-from-a-TSEBRA-output"><a href="#Renaming-transcripts-from-a-TSEBRA-output" class="headerlink" title="Renaming transcripts from a TSEBRA output"></a>Renaming transcripts from a TSEBRA output</h3><p>The IDs of the transcripts and genes in the TSEBRA output can be renamed such that the gene and transcript ID match. Genes and transcript are numbered consecutively and for example, the second transcript of gene “g12” has the ID “g12.t2”. If a prefix is set then it will be added before all IDs, for example, the transcript ID is “dmel_g12.t2” if the prefix is set to “dmel”. Additionally, a translation table can be produced that provides the mapping from old to new transcript IDs.</p><p>Example for renaming <code>tsebra_result.gtf</code>:</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs stylus">./bin/rename_gtf<span class="hljs-selector-class">.py</span> <span class="hljs-attr">--gtf</span> tsebra_result<span class="hljs-selector-class">.gtf</span> <span class="hljs-attr">--prefix</span> dmel <span class="hljs-attr">--translation_tab</span> translation<span class="hljs-selector-class">.tab</span> <span class="hljs-attr">--out</span> tsebra_result_renamed.gtf<br></code></pre></td></tr></table></figure><p>The arguments <code>--prefix</code> and <code>--translation_tab</code> are optional.</p><h3 id="Fixing-the-formatting-issue-of-braker-gtf"><a href="#Fixing-the-formatting-issue-of-braker-gtf" class="headerlink" title="Fixing the formatting issue of braker.gtf"></a>Fixing the formatting issue of <code>braker.gtf</code></h3><p>A BRAKER run produces a second complete gene set named <code>braker.gtf</code>, besides the official output <code>augustus.hints.gtf</code>. The <code>braker.gtf</code> is the result of merging <code>augustus.hints.gtf</code> with some ‘high-confidents’ genes from the GeneMark prediction. However, the merging process leads to a formatting issue in <code>braker.gtf</code>. A quick fix for this formatting issue is the script <code>fix_gtf_ids.py</code>, e.g.:</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs stylus">./bin/fix_gtf_ids<span class="hljs-selector-class">.py</span> <span class="hljs-attr">--gtf</span> braker_out/braker<span class="hljs-selector-class">.gtf</span> <span class="hljs-attr">--out</span> braker1_fixed.gtf<br></code></pre></td></tr></table></figure><p>Take note that the <code>braker.gtf</code> and <code>fix_gtf_ids.py</code> haven’t been tested sufficently and there is no guarantee that this gene set is superior to <code>augustus.hints.gtf</code>.</p><h2 id="-1"><a href="#-1" class="headerlink" title=""></a></h2><h1 id="braker问题"><a href="#braker问题" class="headerlink" title="braker问题"></a>braker问题</h1><p>预测结果文件braker.gtf中，转录本和基因ID，前面可能会自动加上file_1_file_1_，如g4417.t1变为file_1_file_1_g4417.t1，导致生成的gff（或者你用其他软件，如augustus转换脚本gtf2gff.pl，实际上你在参数中指定–gff3，流程调用的也是agustus&#x2F;gtf2gff.pl）转化得到的gff3文件中没有基因特征。所以，如果你用的结果是braker.gtf，含有这个问题，必须人为去掉。augustus.hints.*则是正常，目前没发现这个问题。<br><a href="https://www.biostars.org/p/9464353/">https://www.biostars.org/p/9464353/</a></p><p>第二个比较关心的问题是，braker流程出来一堆结果，我到底该用哪个？虽然官网有一些解释，但总有些不能理解。<br>几个比较关键的结果： augustus.hints.* 是AUGUSTUS最终蛋白hints结果。<br>而braker.gtf&#x2F;gff3是 AUGUSTUS和GeneMark-EP+预测（braker流程中的蛋白预测）的并集，因此该结果是高敏感性低特异性（更多基因被预测以及更多假阳性）。<br>总体来说，二者结果是相近的，如果侧重于敏感性，则用braker.gtf结果。否则用augustus。（个人建议还是用augustus的结果，相当于二次预测）<br><a href="https://github.com/Gaius-Augustus/BRAKER/issues/194">https://github.com/Gaius-Augustus/BRAKER/issues/194</a></p>]]></content>
    
    
    <categories>
      
      <category>Software</category>
      
    </categories>
    
    
    <tags>
      
      <tag>annotation</tag>
      
      <tag>Braker2</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>MAKER</title>
    <link href="/GeekFocus/2022/04/10/2022-04-10-MAKER-anno/"/>
    <url>/GeekFocus/2022/04/10/2022-04-10-MAKER-anno/</url>
    
    <content type="html"><![CDATA[<h1 id="Genome-annotation-with-Maker"><a href="#Genome-annotation-with-Maker" class="headerlink" title="Genome annotation with Maker"></a><a href="https://training.galaxyproject.org/training-material/topics/genome-annotation/tutorials/annotation-with-maker/tutorial.html">Genome annotation with Maker</a></h1><span id="more"></span><p>Maker is able to annotate both prokaryotes and eukaryotes. It works by <strong>aligning as many evidences as possible along the genome sequence</strong>, and then reconciliating all these signals to determine probable gene structures.</p><p>The evidences can be <strong>transcript or protein sequences</strong> from the <font color="red"><strong>same (or closely related) organism</strong></font>. These sequences can come from <strong>public databases</strong> (like NR or GenBank) or from your <strong>own experimental data</strong> (transcriptome assembly from an RNASeq experiment for example). Maker is also able to <strong>take into account repeated elements</strong>.</p><p>Maker uses <strong>ab-initio predictors</strong> (like <a href="http://bioinf.uni-greifswald.de/augustus/">Augustus</a> or <a href="https://github.com/KorfLab/SNAP">SNAP</a>) to improve its predictions: these software tools are able to make gene structure predictions by analysing only the genome sequence with a <strong>statistical model</strong>.</p><p>In this tutorial you will learn <strong>how to perform a genome annotation</strong>, and <strong>how to evaluate its quality</strong>. You will see how training ab-initio predictors is an important step to produce good results. Finally, you will learn how to use the <a href="http://jbrowse.org/">JBrowse</a> genome browser to visualise the results.</p><p>More information about Maker can be found <a href="http://www.yandell-lab.org/software/maker.html">here</a>.</p><p>This tutorial was inspired by the MAKER Tutorial for <a href="http://weatherby.genetics.utah.edu/MAKER/wiki/index.php/MAKER_Tutorial_for_WGS_Assembly_and_Annotation_Winter_School_2018">WGS Assembly and Annotation Winter School 2018</a>, don’t hesitate to consult it for more information on Maker, and on how to run it with command line.</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-comment">#install</span><br>不是maker/src/bin/maker<br>注意maker/bin/maker<br>不用conda perl [系统perl]<br><br>tar xf maker-2.31.10.tgz<br><span class="hljs-built_in">cd</span> maker/src<br>perl Build.PL   检查依赖的库<br>./Build installdeps<br>./Build installexes<br>./Build install<br>./Build status<br><span class="hljs-built_in">mkdir</span> test01<br><span class="hljs-built_in">cp</span> data/dpp* test01<br><span class="hljs-built_in">cd</span> test01<br>maker -CPL<br><span class="hljs-comment">#MPICC 多线程，所用的computer都需要？？？网络冲突 【已安装</span><br>https://github.com/bioconda/bioconda-recipes/issues/16501<br>ERROR: Could not determine <span class="hljs-keyword">if</span> RepBase is installed<br>！！MASKER checks xxx/RepeatMasker/Libraries/RepeatMaskerLib.embl <span class="hljs-keyword">for</span> Repbase.<br>If you have older versions of Repbase like RMRBSeqs.embl, create symlink <span class="hljs-keyword">in</span> xxx/RepeatMasker/Libraries/. For example, <span class="hljs-built_in">ln</span> -s RMRBSeqs.embl RepeatMaskerLib.embl. But <span class="hljs-keyword">in</span> that <span class="hljs-keyword">case</span>, model_org= should be <span class="hljs-built_in">set</span> to the org that exists <span class="hljs-keyword">in</span> the database, instead of all. CAUTION: I don<span class="hljs-string">&#x27;t know whether the result is reliable enough in this way.</span><br><span class="hljs-string"></span><br><span class="hljs-string">Can&#x27;</span>t locate List/MoreUtils.pm <span class="hljs-keyword">in</span> @INC (@INC contains: <br>conda <span class="hljs-built_in">env</span> install ， no conda <span class="hljs-built_in">env</span> no error？<br>conda install perl-list-moreutils [<span class="hljs-built_in">link</span>](https://www.biostars.org/p/278249/)<br></code></pre></td></tr></table></figure><h2 id="需要的输入文件"><a href="#需要的输入文件" class="headerlink" title="需要的输入文件"></a>需要的输入文件</h2><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs sh">-1. 【genome.fasta】<br>    基因组序列文件。<br>-2. 【inchworm.fasta】<br>    转录组组装结果文件。此文件内容代表转录子序列或 EST 序列。为了增加其准确性，选用了 trinity 中 inchworm 的结果文件，而不是转录组最终的组装结果文件。<br>-3. 【proteins.fasta】<br>    临近物种的蛋白质序列。可以从 NCBI 的 Taxonomy 数据库中下载。<br>-4. 【consensi.fa.classified】<br>    适合本物种的重复序列数据库。该文件是一个fasta文件，其序列代表着本物种的高重复序列。该文件使用 RepeatModeler 制作。<br>-5. 【Augustus hmm files [species]】<br>    适合本物种的 Augustus 的 HMM 文件。该文件以文件夹形式存放在 /opt/biosoft/augustus-3.0.3/config/species/ 目录下。<br>    将 genome.fasta 和 inchworm.fasta 输入 PASA，得到用于 trainning 的基因<br>    然后使用 Augustus 进行 training，得到 HMM 文件。<br>-6. 【Snap hmm file [species.hmm]】<br>    适合本物种的 SNAP 的 HMM 文件。该文件是一个单独的文件。将 genome.fasta 和 inchworm.fasta 输入 PASA，得到用于 trainning 的基因，然后使用 SNAP 进行 training，得到 HMM 文件。<br>-7. 【Genemark_es hmm file [es.mod]】<br>    适合本物种的 Genemark_es 的 HMM 文件。将 genome.fasta 输入 genemark_es 软件进行自我训练得到的 HMM 文件。<br>-8. 【rRNA.fa】<br>    rRNA 的序列文件。该文件使用 RNAmmer 对基因组进行分析得到。<br></code></pre></td></tr></table></figure><p>使用 MAKER 命令得到初始化的 3 个配置文件。</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs stylus">$ maker -CTL<br><br>得到<span class="hljs-number">3</span>个配置文件： maker_exe<span class="hljs-selector-class">.ctl</span>, maker_bopts<span class="hljs-selector-class">.ctl</span> 和 maker_opts.ctl。<br>maker_exe.ctl： 配置 Maker 需要调用的程序的路径；maker_exe<span class="hljs-selector-class">.ctl</span>: 执行程序的路径<br>maker_bopts.ctl： 配置 blast 的各种阈值；maker_bopt<span class="hljs-selector-class">.ctl</span>: BLAST和Exonerat的过滤参数<br>maker_opts.ctl： MAKER 的主要配置文件，配置输入文件的路径，以及 MAKER 的使用流程。<br></code></pre></td></tr></table></figure><h2 id="注释"><a href="#注释" class="headerlink" title="注释"></a>注释</h2><p>先修改 maker_opts.ctl 配置文件，需要修改的内容如下：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs sh">genome=genome.fasta            <span class="hljs-comment"># 基因组序列文件</span><br>est=inchworm.fasta             <span class="hljs-comment"># EST 序列文件</span><br>protein=proteins.fasta         <span class="hljs-comment"># 临近物种的蛋白质序列文件</span><br>model_org=fungi                <span class="hljs-comment"># 选择repebase数据库的物种，对真菌则用fungi，也可以使用 all</span><br>rmlib=consensi.fa.classified   <span class="hljs-comment"># 适合本物种的重复序列数据库</span><br>snaphmm=species.hmm            <span class="hljs-comment"># snap traing 的 HMM 文件</span><br>gmhmm=es.mod                   <span class="hljs-comment"># genemark_es 的 HMM 文件</span><br>augustus_species=species       <span class="hljs-comment"># augustus 的 HMM 文件</span><br>est2genome=1                   <span class="hljs-comment"># 使用 EST 序列进行基因预测</span><br>protein2genome=1               <span class="hljs-comment"># 使用蛋白质序列进行基因预测</span><br>trna=1                         <span class="hljs-comment"># 使用 tRNAscan 进行 tRNA 预测</span><br>snoscan_rrna=rRNA.fa           <span class="hljs-comment"># 【使用 Snoscan 利用 rRNA 序列进行 C/D box 类型的 snoRNAs 预测，不过我加入了这个信息后，maker运行不成功，不知道为什么。】</span><br>correct_est_fusion=1           <span class="hljs-comment"># 进行融合 EST 的校正</span><br></code></pre></td></tr></table></figure><p>并行化运行 maker。基因组序列比较大，MAKER 的计算量大，并行化能极大节约时间？？？</p><p>计算节点有mpicc吗</p><figure class="highlight crystal"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs crystal">mpd &amp;<br><span class="hljs-variable">$ </span>maker                  <span class="hljs-comment"># 不并行化运行</span><br><span class="hljs-variable">$ </span>mpiexec -n <span class="hljs-number">20</span> maker    <span class="hljs-comment"># 使用20个线程并行计算</span><br></code></pre></td></tr></table></figure><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs ini"><span class="hljs-comment">#change</span><br><span class="hljs-attr">genome</span>=dpp_contig.fasta<br><span class="hljs-attr">est</span>=dpp_est.fasta<br><span class="hljs-attr">protein</span>=dpp_protein.fasta<br><span class="hljs-attr">est2genome</span>=<span class="hljs-number">1</span><br></code></pre></td></tr></table></figure><p>当前路径运行程序</p><p>输出结果见”dpp_contig.maker.output”, 重点是”dpp_contig_master_datastore_index.log”文件，由于maker会拆分数据集并行计算，因此该文件记录总体的运行情况，需要关注其中是否有<font color="red">”FAILED”,”RETRY”,”SKIPPED_SAMLL”,”DIED_SIPPED_PERMANET”</font>，因为这意味着有些数据出于某些原因没有运算。</p><p>最后，我们需要将并行运算的结果进行整合，导出GFF文件, 转录本序列和蛋白序列</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs awk">~<span class="hljs-regexp">/opt/</span>biosoft<span class="hljs-regexp">/maker/</span>bin/fasta_merge -d dpp_contig_master_datastore_index.log<br>~<span class="hljs-regexp">/opt/</span>biosoft<span class="hljs-regexp">/maker/</span>bin/gff3_merge -d dpp_contig_master_datastore_index.log<br></code></pre></td></tr></table></figure><p>在该目录下就会出现,<font color="red"> “dpp_contig.all.gff”,“dpp_contig.all.maker.proteins.fasta”,”dpp_contig.all.maker.transcripts.fasta”</font></p><p>其中GFF文件就需要用IGV，JBrowse, Apollo下展示来检查下注释是否正确。</p><hr><p><a href="https://www.jianshu.com/p/fe14cab264a7">https://www.jianshu.com/p/fe14cab264a7</a></p><p><a href="http://weatherby.genetics.utah.edu/MAKER/wiki/index.php/The_MAKER_control_files_explained">http://weatherby.genetics.utah.edu/MAKER/wiki/index.php/The_MAKER_control_files_explained</a></p><h1 id="MAKER配置文件详解"><a href="#MAKER配置文件详解" class="headerlink" title="MAKER配置文件详解"></a>MAKER配置文件详解</h1><p>本文翻译自<a href="https://links.jianshu.com/go?to=http://weatherby.genetics.utah.edu/MAKER/wiki/index.php/The_MAKER_control_files_explained">http://weatherby.genetics.utah.edu/MAKER/wiki/index.php/The_MAKER_control_files_explained</a></p><p>MAKER会生成三个配置文件，如下</p><ul><li>maker_opts.ctl: 控制MAKER分析行为的主要配置文件</li><li>maker_bopts.ctl: BLAST和Exnerate的过滤阈值</li><li>maker_exe.ctl: MAKER运行过程中所依赖软件的路径</li></ul><p>这里主要介绍<code>maker_opts.ctl</code>, 其余配置文件直接看配置文件里面的注释信息即可。</p><p><font color="blue">A minimal input file set for MAKER would generally consist of a F<strong>ASTA file for the genomic</strong> sequence, a <strong>FASTA file of RNA</strong> (ESTs&#x2F;cDNA&#x2F;mRNA transcripts) from <strong>【the organism】</strong>, and a <strong>FASTA file of protein</strong> sequences from <strong>【the same or related organisms】</strong> (or a general protein database).</font></p><h3 id="基因组"><a href="#基因组" class="headerlink" title="基因组"></a>基因组</h3><p>用于设置被注释的基因组序列的位置和物种类型，包括<code>genome</code>和<code>organisam_type</code>两项</p><ul><li>genome: FASTA序列路径</li><li>organism_type: eukaryotic,prokaryotic二选一</li></ul><p>需要注意的是，基因组序列的N50需要超过预期基因长度的中位数，否则注释效果不好。另外最好保证基因组序列只包括A,T,C,G,N, 对于其他类型兼并碱基可以都改成N.</p><h3 id="使用MAKER得到GFF3进行重注释"><a href="#使用MAKER得到GFF3进行重注释" class="headerlink" title="使用MAKER得到GFF3进行重注释"></a>使用MAKER得到GFF3进行重注释</h3><p>这一项基本上我们用不上，它是在当你把MAKER的中间输出文件都删除了，仅保留了输出的GFF3文件时，你可以用之前相同的输入设置重新运行流程得到相同的输出</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment">#-----Re-annotation Using MAKER Derived GFF3</span><br>maker_gff= <span class="hljs-comment">#MAKER derived GFF3 file</span><br>est_pass=0 <span class="hljs-comment">#use ESTs in maker_gff: 1 = yes, 0 = no</span><br>altest_pass=0 <span class="hljs-comment">#use alternate organism ESTs in maker_gff: 1 = yes, 0 = no</span><br>protein_pass=0 <span class="hljs-comment">#use protein alignments in maker_gff: 1 = yes, 0 = no</span><br>rm_pass=0 <span class="hljs-comment">#use repeats in maker_gff: 1 = yes, 0 = no</span><br>model_pass=0 <span class="hljs-comment">#use gene models in maker_gff: 1 = yes, 0 = no</span><br>pred_pass=0 <span class="hljs-comment">#use ab-initio predictions in maker_gff: 1 = yes, 0 = no</span><br>other_pass=0 <span class="hljs-comment">#passthrough anyything else in maker_gff: 1 = yes, 0 = no</span><br></code></pre></td></tr></table></figure><h3 id="EST-x2F-转录本证据"><a href="#EST-x2F-转录本证据" class="headerlink" title="EST&#x2F;转录本证据"></a>EST&#x2F;转录本证据</h3><p>出于历史原因, MAKER还是用EST代表之前<font color="blue">EST数据</font>和目前的<font color="blue">转录组数据</font>。 此处不只是使用EST数据，而是可以使用<font color="blue">组装的mRNA-seq</font>, 组装的<font color="blue">全长cDNA</font>。 预期他们能够正确的组装，并联配到正确的剪切位点(对于FASTA格式，MAKER使用<code>exonerate</code>找到剪切位点）。用途如下:</p><ul><li><font color="red">直接<strong>推断</strong></font>基因模型(est2genome)</li><li>作为预测结果的<strong>支持证据</strong></li><li>修改结果和<strong>增加UTR</strong></li><li>鉴定<strong>可变转录本</strong></li><li>在某些情况下，这些数据和其他证据能帮助MAKER推断<strong>基因边界</strong></li><li>在预测步骤中辅助基因预测工具推断<strong>剪切位点</strong></li></ul><p>设置项如下:</p><ul><li><code>est</code>: EST, 全长cDNA, 组装的mRNA序列，可以通过<font color="blue">逗号分隔多个文件</font>。</li><li><code>altest</code>: 如果真的没有当前物种的转录组数据，也可以使用<font color="blue">同源物种序列</font>。这些序列会通过tblstx进行比对，会消耗大量的运算时间。</li><li><code>est_gff</code>: 预比对的转录本，以<strong>GFF3</strong>格式存放，通常来自于<font color="blue">CuffLinks&#x2F;StringTie的组装结果gtf</font>，或者是上一步的MAKER注释</li><li><code>altest_gff</code>: 和altest一样，只不过是比对后以GFF3存放，基本上也用不到</li></ul><p>Tophat2 + cufflinks 有参转录组组装得到<font color="red"><strong>gtf结果，转化为gff</strong></font>，用于estgff。<font color="red"><strong>转化fa</strong></font>用于est。</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs sh">cufflinks-gffread<br>gffread transcripts.gtf -g reference.fasta -w transcripts.fasta<br>gffread hp1.est.gtf -o- &gt; hp1.est.gff3<br></code></pre></td></tr></table></figure><h3 id="同源蛋白证据"><a href="#同源蛋白证据" class="headerlink" title="同源蛋白证据"></a>同源蛋白证据</h3><p>和之前的转录组数据类似，用途如下</p><ul><li>直接推断基因模型(protein2genome), 仅在它们能够正确的<font color="blue">联配到剪切位点附件</font>。</li><li>作为预测结果的<font color="blue">支持证据</font>(MAKER会检查CDS，保证基因预测结果和蛋白联配是<font color="blue">相同的阅读框</font>)</li><li>某些情况下，用于推断<font color="blue">基因边界</font></li><li>在预测步骤中，<font color="blue">使用从蛋白推断的ORF辅助从头预测软件</font></li></ul><p><strong>建议</strong>使用 <font color="blue">uniprot&#x2F;swiss-prot 或 RefSeq</font>上的NP数据，因为经过人工审查，可信度较高。<font color="blue">不建议用UniProt&#x2F;tremble或者Genbank上的数据</font>，这些数据的可信度较低。你可以挑选几个同源物种的高可信度蛋白。或者使用MAKER注释的其他物种AED小于0.5的转录本产物。</p><p>由于许多注释里包含一些<font color="blue">死亡转座子(dead transposons)或伪基因(pseudogenes)</font>，<font color="blue">因此<strong>不建议</strong>使用临近物种的所有注释蛋白</font>。想象一个比较糟糕的情况，如果有邻近物种的死亡转座子，当构建重复序列屏蔽文库时，发现其中一个条目和该序列匹配。 于是你假设这是一个真实的基因，于是你从屏蔽文库中删除了该条目。当注释基因组的时候，该基因变成了注释集中的一整个基因组家族，但这其实是糟糕的证据和重复序列屏蔽所导致的后果。</p><p>需要设置的就两项：</p><ul><li><code>protein</code>: 以FASTA存放的蛋白序列位置</li><li><code>protein_gff</code>: 以GFF3格式记录的蛋白序列预先比对结果，通常来自于之前MAKER输出</li></ul><h3 id="重复序列重复屏蔽"><a href="#重复序列重复屏蔽" class="headerlink" title="重复序列重复屏蔽"></a>重复序列重复屏蔽</h3><p>通过屏蔽重复序列来避免EST和蛋白比对到重复区域，防止基因预测算法在这些区域预测外显子。由于许多重复序列会编码真实的蛋白(例如反转座子等)，基因预测工具和比对工具会被他们所迷惑(会在一个基因中错误的加上外显子)</p><ul><li><code>model_org</code>: 默认是all, 可以设置成RepeatMasker中<font color="blue">RepBase数据库的其中一个</font></li><li><code>rmlib</code>: <font color="blue">自己构建的重复序列文库</font></li><li><code>repeat_protein</code>: 转座因子的蛋白序列</li><li><code>rm_gff</code>: 以GFF3格式记录的重复序列位置信息</li><li><code>prok_rm</code>: 不需要修改，因为原核生物不需要考虑重复序列</li><li><code>softmask</code>: 不需要修改</li></ul><h3 id="从头基因预测"><a href="#从头基因预测" class="headerlink" title="从头基因预测"></a>从头基因预测</h3><p>如果你需要从MAKER以外获取基因模型，则需要在这一节添加相应的配置。根据可信度高低，MAKER会对这些基因模型采取不同的行为。</p><ul><li>通过软件预测的基因结构可信度低，它们不会影响证据簇(evidence cluster). MAKER会保留预测结果，或者根据EST证据调整外显子，如果有证据支持，那么他们会保留在最终的注释集中。如果有多个注释结果，MAKER会对其进行比较，从中挑选出最优结果。</li><li><code>model_gff</code>提供的基因模型的可信度最高，会影响证据簇。在一些基因边界判定中，MAKER在证据簇的影响下，更倾向于保留之前的基因模型而非替换。它们也会保留名字。MAKER不会修改模型，要么删除要么保留。最后，即便没有证据支持，MAKER还是会保留他们，而不会删除他们，只不过最终的AED会设置为1.</li><li>snaphmm: SNAP的HMM文件路径，允许多个输入，以逗号分隔</li><li>gmhmm: GeneMark的HMM文件文件路径，允许多个输入，以逗号分隔</li><li>augustus_species: Augustus的基因模型命名, 不容易训练，但是效果很好</li><li>fgenesh_par_file: FGENESH的HMM参数文件，收费工具，基本上用不到</li><li>pred_gff: 其他预测工具的输出结果，以GFF3格式保存</li><li>model_gff: 最高可信度的GFF输入</li><li>run_evm&#x3D;0: 是否让MAKER运行EVM，速度会变慢</li><li>est2genome: 让MAKER根据EST推测基因模型</li><li>protein2genome: 让MAKER根据蛋白序列推测基因模型</li><li>trna: 使用tRNAscan分析tRNA #find tRNAs with tRNAscan, 1 &#x3D; yes, 0 &#x3D; no</li><li>snoscan_rrna: Snoscan分析snoRNA所需的rRNA文件&#x3D; #rRNA file to have Snoscan find snoRNAs</li><li>snoscan_meth：Snoscan分析snoRNA所需的O-methylation site 文件</li><li>unmask: 是否在屏蔽序列中进行基因预测，默认是0</li><li>allow_overlap: 允许的基因重叠比例，从0到1，空白表示使用默认值</li></ul><h3 id="其他类型的注释"><a href="#其他类型的注释" class="headerlink" title="其他类型的注释"></a>其他类型的注释</h3><p>这一项功能很简单，就是提供一个GFF文件，在MAKER运行结束后增加里面的信息</p><ul><li><code>other_gff</code>: 其他类型注释的GFF文件路径</li></ul><h3 id="外部程序选项"><a href="#外部程序选项" class="headerlink" title="外部程序选项"></a>外部程序选项</h3><p>这里的两个参数用于影响外部程序，即BLAST的行为</p><ul><li><code>alt_peptide</code>: 对于非标准氨基酸的替换方法，默认是C(cysteine)</li><li><code>cpus</code>: BLAST的线程数，如果使用MPI，该值可以设置的小一些，默认是1.</li></ul><h3 id="MAKER行为选项"><a href="#MAKER行为选项" class="headerlink" title="MAKER行为选项"></a>MAKER行为选项</h3><p>这里的选项用于调整MAKER的行为，使其符合你的基因组特性</p><ul><li><code>mad_dna_len</code>至少要3倍于预期的最大内含子长度。在内存足够的情况下，对于<strong>脊椎动物</strong>可以考虑设置为<code>300000</code>，植物一般没有那么大的内含子</li><li><code>min_contig</code>: 低于该值的contig会被过滤掉，建议设置为10k.</li><li><code>pred_flank</code>: 在基因预测时，将证据簇在两端进行扩展，默认是200 bp. 对于比较紧凑的基因组，降低该值能够避免基因错误合并。对于比较稀疏的基因组，提高该值可以避免外显子缺失。</li><li><code>pred_stats</code>: 默认是0，只计算MAKER预测基因的AED和QI值，设置为1则计算所有从头预测的基因结构。</li><li><code>AED_threashold</code>: 根据AED(0-1)值来过滤输出的基因，默认是1，表示保留所有预测结果。</li><li><code>min_protein</code>: 一些时候，基因预测工具会生成许多短预测结果，而由于一些证据类型（例如mRNA-seq）存在噪音，导致这些预测结果看起来有证据支持，于是保留在最终的输出结果中(AED&gt;1). 通过限制预测蛋白的氨基酸数(amino acides, AA)，可以减少预测结果。</li><li><code>alt_splice</code>: 是否计算可变转录本</li><li><code>always_complete</code>: 这个是MAKER开发者在合作者的要求下加上的参数，用来确保基因模型始终有起始密码子和终止密码子，默认是0</li><li><code>map_forward</code>: 用于保留老版本的GFF文件的信息，映射到新的版本GFF中。</li><li><code>keep_preds</code>: 设置为1时表示保留所有的预测结果，默认是0.</li><li><code>split_hit</code>: 新版本的MAKER(&gt;2.28)不需要考虑该项。因为之前版本拆分后的contig是互不重叠，于是就有可能有外显子被刚好被拆成两端，设置该项可以保留该信息。</li><li><code>single_exon</code>: 如果一个EST只有只有单个外显子，默认情况下MAKER并不会把它当做支持基因模型的证据, 除非还有同源蛋白作为支持。单外显子EST和组装的mRNA-seq转录本通常是RNA制备过程中的基因组序列污染。关闭时会降低MAKER的敏感度(sensitivity), 但是当你打开它的时候，命中的特异性会比整体的准确度(accuracy)差得多。</li><li><code>single_length</code>: 在启用<code>single_exon</code>时，设置该项用于保留一些比较小的序列，但即便注释了也可能不是有功能的蛋白。</li><li><code>correct_est_fusion</code>用来避免因为UTR的重叠导致将基因模型的错误合并，在<strong>真菌基因组</strong>中比较常见。它会检查基因模型的5’ UTR长度是否超过基因长度的一半，如果是的话，那么MAKER会在起始密码位置打断基因，然后在5’UTR区重新预测基因。</li><li><code>tries</code>: 尝试次数，默认是2</li><li><code>clean_try</code>: 重新尝试时，是否删除之前的文件，默认是0，也就是不删除。建议设置为1</li><li><code>clean_up</code>: 删除分析过程中的文件，默认不删除</li><li><code>TMP</code>: 临时文件的目录，默认存放在<code>/tmp</code>下，建议设置一个容量比较大的目录</li></ul><hr><h1 id="maker-内含软件安装"><a href="#maker-内含软件安装" class="headerlink" title="maker 内含软件安装"></a>maker 内含软件安装</h1><h2 id="snoscan"><a href="#snoscan" class="headerlink" title="snoscan"></a>snoscan</h2><p><a href="http://www.chenlianfu.com/?p=2325">http://www.chenlianfu.com/?p=2325</a></p><p><a href="http://lowelab.ucsc.edu/snoscan/">http://lowelab.ucsc.edu/snoscan/</a></p><p><a href="https://iamphioxus.org/2016/01/20/installing-trnascan-se-and-snoscan/">https://iamphioxus.org/2016/01/20/installing-trnascan-se-and-snoscan/</a></p><p>snoRNAs 主要有 2 种不同类型。其中 C&#x2F;D box 类型 snoRNAs 用于指导甲基化修饰(2’O-ribose-methylations)，该甲基化修饰位于核糖体 2′-OH上； H&#x2F;ACA box 类型 snoRNAs 用于指导假尿苷酸化修饰(Pseudouridylation)，即将尿嘧啶转换为假尿嘧啶。</p><p><strong>snoscan</strong>用于鉴定 C&#x2F;D box 类型 snoRNAs； <strong>snoGPS</strong>用于鉴定 H&#x2F;ACA box 类型的 snoRNAs。</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-comment">#wget lowelab.ucsc.edu/software/snoscan.tar.gz</span><br><span class="hljs-comment">#下载最新1.0</span><br>$ tar zxf snoscan.tar.gz -C /opt/biosoft/<br><span class="hljs-built_in">cd</span> snoscan-1.0<br><span class="hljs-built_in">cd</span> squid-1.5.11<br>$ perl -p -i -e <span class="hljs-string">&#x27;s/getline/get_line/g&#x27;</span> sqio.c<span class="hljs-comment">#另一个博客修改为getLine？？？</span><br>$ <span class="hljs-built_in">cd</span> ..<br>$ make<br><span class="hljs-comment">#no conda, fat error </span><br><span class="hljs-comment">#/usr/bin/ld: cannot find -lsquid</span><br><span class="hljs-comment">#collect2: error: ld returned 1 exit status</span><br><span class="hljs-comment">#no fat no conda:ok.</span><br>$ <span class="hljs-built_in">echo</span> <span class="hljs-string">&#x27;PATH=$PATH:/opt/biosoft/snoscan-1.0&#x27;</span> &gt;&gt; ~/.bashrc<br><span class="hljs-comment">#perl -p -i -e &#x27;s#/usr/local/bin/perl#/usr/bin/perl#&#x27; sort-snos</span><br>change sort-snos   <span class="hljs-comment">#!/usr/bin/perl</span><br></code></pre></td></tr></table></figure><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs sh">$ snoscan rRNA.fa genome.fasta -s -o out<br>rRNA.fa      : rRNA序列的fasta格式<br>genome.fasta : 用于搜索 snoRNAs 的基因组序列<br></code></pre></td></tr></table></figure><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs sh">-h<br>    打印帮助信息<br>-m string<br>    指定包含甲基化位点信息的文件。该文件的格式为：<br>        &gt;seq_A<br>        T 5 Verified meth site by TML<br>        C 12  Predicted by snoscan<br>        &gt;My-seq-B<br>        G 1   Partially modified site<br>        A 6   Mapped by Maden<br>    与fasta格式类似，头部是和 genome.fasta 序列名相同；内容部分分3列，以空格或制表符分割，第1列是位点的碱基，第2列是1-based的位点，第3列是60个字符以内的描述。<br>-o string<br>    将结构输出到指定的文件，默认输出到标准输出<br>-s<br>    是否保存 snoRNA 的序列到输出中<br></code></pre></td></tr></table></figure><blockquote><p>snoRNA 指导的 rRNA 的转录后修饰有 2 种： 甲基化(Methylation) 和 假尿苷酸化(Pseudouridylation)。</p><p>snoRNP(small nucleolar ribonucleoprotein): 每个 snoRNA 和至少4个蛋白分子形成复合物，来指导目标RNA的修饰。</p><p>snoRNAs 主要有 2 种不同类型。其中 C&#x2F;D box 类型用于指导甲基化修饰； H&#x2F;ACA box 类型用于指导假尿苷酸化修饰。</p><p>C&#x2F;D box 类型的 snoRNAs 包含 C(RUGAUGA)环 和 D(CUGA)环，分别在 snoRNA 的 5′ 和 3′ 端。</p><p>H&#x2F;ACA box 类型的 snoRNAs 由 2 个发夹结构和 2 个单链区组成，称为 hairpin-hinge-hairpin-tail 结构。结构中包含 H box(ANANNA) 和 ACA box(ACA)。</p></blockquote><h2 id="RNAmmer"><a href="#RNAmmer" class="headerlink" title="RNAmmer"></a>RNAmmer</h2><p><a href="http://www.chenlianfu.com/?p=1979">http://www.chenlianfu.com/?p=1979</a></p><p>Appending installation info to &#x2F;home&#x2F;~&#x2F;perl5&#x2F;lib&#x2F;perl5&#x2F;x86_64-linux-thread-multi&#x2F;perllocal.pod<br>  JV&#x2F;Getopt-Long-2.52.tar.gz</p><p>Appending installation info to &#x2F;home&#x2F;~&#x2F;perl5&#x2F;lib&#x2F;perl5&#x2F;x86_64-linux-thread-multi&#x2F;perllocal.pod<br>  GRANTM&#x2F;XML-Simple-2.25.tar.gz</p><ol><li>perl的Getopt::Long和XML::Simple模块； 2. hmmsearch,需要安装hmmer-2.2g版本，使用最新版本会出错。</li></ol><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs sh">下载并安装hmmer-2.2g失败，查看https://blog.karinlag.no/2013/10/rnammer-install/，提示2.3<br>$ wget： http://hmmer.org/download.html<br>$ tar zxf hmmer-2.3<br><span class="hljs-built_in">mkdir</span> hmmer2.3<br>$ <span class="hljs-built_in">cd</span> hmmer-2.3<br>$ ./configure --prefix=~/opt/biosoft/hmmer2.3<br>$ <span class="hljs-built_in">mkdir</span> -p /opt/biosoft/hmmer-2.3/man/man1/ /opt/biosoft/hmmer-2.3/bin<br>$ make; make install<br><br>安装RNAmmer，该软件需要使用edu邮箱去申请。<br>$ <span class="hljs-built_in">mkdir</span> -p /opt/biosoft/rnammer-1.2<br>$ tar zxf rnammer-1.2.src.tar.Z -C /opt/biosoft/rnammer-1.2<br>修改rnammer中的<span class="hljs-variable">$INSTALL_PATH</span><br>修改rnammer中的<span class="hljs-variable">$HMMSEARCH_BINARY</span><br><br>检测是否正常运行<br>./rnammer -S bac -multi -f rRNA.fasta -h rRNA.hmmreport -xml rRNA.xml -gff rRNA.gff2 example/ecoli.fsa &gt; rnammer.log 2&gt;&amp;1 &amp;<br><span class="hljs-comment">#error：FATAL: POSIX threads support is not compiled into HMMER; --cpu doesn&#x27;t have any effect</span><br><span class="hljs-comment">#依然在官网：https://blog.karinlag.no/2013/10/rnammer-install/</span><br></code></pre></td></tr></table></figure><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs sh">USAGE:<br>$ rnammer [options] sequence.fasta<br>-S  指定输入序列的物种所属的界： arc bac 或 euk<br>-gff  生成的gff文件结果<br>-m  所需要预测的moleculers： <span class="hljs-string">&#x27;tsu&#x27;</span> <span class="hljs-keyword">for</span> 5/8s rRNA, <span class="hljs-string">&#x27;ssu&#x27;</span> <span class="hljs-keyword">for</span> 16/18s rRNA, <span class="hljs-string">&#x27;lsu&#x27;</span> <span class="hljs-keyword">for</span> 23/28s rRNA。如果全部进行预测，则该参数后为 <span class="hljs-string">&#x27;tsu,ssu,lsu&#x27;</span>。<br>-multi  并行运算，预测正反两条链上所有的moleculers。最多并行运行6个计算。使用该参数，则不需要上一个参数。<br>-f  生成的rRNA的fasta结果文件<br>-h  生成的hmm报告结果<br>-gff  生成的rRNA的gff2文件<br>-x  生成的xml结果文件<br></code></pre></td></tr></table></figure><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs sh">$ /opt/biosoft/rnammer-1.2/rnammer -S euk -multi -f rRNA.fasta\<br> -h rRNA.hmmreport -xml rRNA.xml -gff rRNA.gff2 genome.fasta<br> <span class="hljs-comment">#result: rRNA.fasta，rRNA.gff2，rRNA.hmmreport，rRNA.xml</span><br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>Software</category>
      
    </categories>
    
    
    <tags>
      
      <tag>annotation</tag>
      
      <tag>Maker2</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>count, TPM, FPKM, RPKM in RNA-seq</title>
    <link href="/GeekFocus/2022/03/28/2022-03-28-TPM/"/>
    <url>/GeekFocus/2022/03/28/2022-03-28-TPM/</url>
    
    <content type="html"><![CDATA[<p>CUT&amp;RUN CUT&amp;Tag ChIP-seq ATAC-seq</p><span id="more"></span><p><a href="https://hbctraining.github.io/DGE_workshop/lessons/02_DGE_count_normalization.html">https://hbctraining.github.io/DGE_workshop/lessons/02_DGE_count_normalization.html</a></p><p><a href="https://zhuanlan.zhihu.com/p/150300801">https://zhuanlan.zhihu.com/p/150300801</a></p><p><a href="https://haroldpimentel.wordpress.com/2014/05/08/what-the-fpkm-a-review-rna-seq-expression-units/">https://haroldpimentel.wordpress.com/2014/05/08/what-the-fpkm-a-review-rna-seq-expression-units/</a></p>]]></content>
    
    
    <categories>
      
      <category>NGS</category>
      
    </categories>
    
    
    <tags>
      
      <tag>TPM</tag>
      
      <tag>RNA-seq</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【samtools】</title>
    <link href="/GeekFocus/2022/03/26/2022-03-26-samtools/"/>
    <url>/GeekFocus/2022/03/26/2022-03-26-samtools/</url>
    
    <content type="html"><![CDATA[<p>Samtools is a suite of programs for interacting with high-throughput sequencing data. It consists of three separate repositories:</p><ul><li><p><strong>Samtools</strong></p><p>Reading&#x2F;writing&#x2F;editing&#x2F;indexing&#x2F;viewing SAM&#x2F;BAM&#x2F;CRAM format</p></li><li><p><strong>BCFtools</strong></p><p>Reading&#x2F;writing BCF2&#x2F;VCF&#x2F;gVCF files and calling&#x2F;filtering&#x2F;summarising SNP and short indel sequence variants</p></li><li><p><strong>HTSlib</strong></p><p>A C library for reading&#x2F;writing high-throughput sequencing data</p></li></ul><span id="more"></span><p>samtools flags – convert between textual and numeric flag representation.</p><p>Each <em>FLAGS</em> argument may be either an integer (in decimal, hexadecimal, or octal) representing a combination of the listed numeric flag values, or a comma-separated string <em>NAME</em><strong>,</strong>…**,**<em>NAME</em> representing a combination of the flag names listed below.</p><p><strong>FLAGS:</strong></p><table><thead><tr><th></th><th></th><th></th></tr></thead><tbody><tr><td><strong>0x1</strong></td><td>PAIRED</td><td>paired-end (or multiple-segment) sequencing technology</td></tr><tr><td><strong>0x2</strong></td><td>PROPER_PAIR</td><td>each segment properly aligned according to the aligner</td></tr><tr><td><strong>0x4</strong></td><td>UNMAP</td><td>segment unmapped</td></tr><tr><td><strong>0x8</strong></td><td>MUNMAP</td><td>next segment in the template unmapped</td></tr><tr><td><strong>0x10</strong></td><td>REVERSE</td><td>SEQ is reverse complemented</td></tr><tr><td><strong>0x20</strong></td><td>MREVERSE</td><td>SEQ of the next segment in the template is reverse complemented</td></tr><tr><td><strong>0x40</strong></td><td>READ1</td><td>the first segment in the template</td></tr><tr><td><strong>0x80</strong></td><td>READ2</td><td>the last segment in the template</td></tr><tr><td><strong>0x100</strong></td><td>SECONDARY</td><td>secondary alignment</td></tr><tr><td><strong>0x200</strong></td><td>QCFAIL</td><td>not passing quality controls</td></tr><tr><td><strong>0x400</strong></td><td>DUP</td><td>PCR or optical duplicate</td></tr><tr><td><strong>0x800</strong></td><td>SUPPLEMENTARY</td><td>supplementary alignment</td></tr></tbody></table><p> when calc insert size, only calc -f 0x40, reads1 $F[8]?</p><p>Or calc -F 0x4 ,exclude unmapped?</p>]]></content>
    
    
    <categories>
      
      <category>Software</category>
      
    </categories>
    
    
    <tags>
      
      <tag>samtools</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>perl读写</title>
    <link href="/GeekFocus/2022/03/25/2022-03-25-perl/"/>
    <url>/GeekFocus/2022/03/25/2022-03-25-perl/</url>
    
    <content type="html"><![CDATA[<p>命令行 参数 读入。读写</p><span id="more"></span><h2 id="程序名：-0"><a href="#程序名：-0" class="headerlink" title="程序名：$0"></a>程序名：$0</h2><p><code>$0</code>表示当前<strong>正在运行的Perl脚本名</strong>。有3种情况：</p><ol><li>如果执行方式为<code>perl x.pl</code>，则<code>$0</code>的值为<code>x.pl</code>而非perl命令本身</li><li>如果执行方式为<code>./x.pl</code>，则<code>$0</code>的值为<code>./x.pl</code></li><li>如果执行的是<code>perl -e</code>或<code>perl -E</code>一行式perl程序，则<code>$0</code>的值为<code>-e</code>或<code>-E</code></li></ol><h2 id="命令行参数ARGV"><a href="#命令行参数ARGV" class="headerlink" title="命令行参数ARGV"></a>命令行参数ARGV</h2><ul><li>perl将perl命令行的参数列表放进数组ARGV(@ARGV)中。既然是数组，就可以访问($ARGV[n])、遍历，甚至修改数组元素</li><li>ARGV数组分三种情况收集：<ul><li><code>perl x.pl a b c</code>方式运行时，脚本名x.pl之后的<code>a b c</code>才会被收集到ARGV数组</li><li><code>./x.pl a b c</code>方式运行时，<code>a b c</code>才会被收集到ARGV数组</li><li><code>perl -e &#39;xxxxx&#39; a b c</code>方式运行时，<code>a b c</code>才会被收集到ARGV数组</li></ul></li><li>ARGV数组索引从0开始计算，索引0位从脚本名(perl程序名)<strong>之后</strong>的参数开始计算</li><li>默认，这些命令行参数是perl程序的数据输入源，也就是perl会依次将它们当作文件进行读取</li><li>参数是有序的，读取的时候也是有序的</li><li>需要区分ARGV变量和ARGV数组：<ul><li><code>$ARGV</code>表示命令行参数代表的文件列表中，当前被处理的文件名</li><li><code>@ARGV</code>表示命令行参数数组</li><li><code>$ARGV[n]</code>：表示命令行参数数组的元素</li><li><code>ARGV</code>：表示<code>&lt;&gt;</code>当前正在处理的文件句柄</li></ul></li></ul><p>例如，test.plx的内容如下：</p><figure class="highlight nsis"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs nsis"><span class="hljs-number">1</span><br><span class="hljs-number">2</span><br><span class="hljs-number">3</span><br><span class="hljs-number">4</span><br><span class="hljs-number">5</span><br><span class="hljs-number">6</span><br><span class="hljs-number">7</span><br>/usr/bin/perl<br><br><span class="hljs-literal">print</span> <span class="hljs-string">&#x27;<span class="hljs-variable">$ARGV</span>[0] ---&gt; &#x27;</span>,<span class="hljs-variable">$ARGV</span>[<span class="hljs-number">0</span>],<span class="hljs-string">&quot;\n&quot;</span>,<br>      <span class="hljs-string">&#x27;<span class="hljs-variable">$ARGV</span>[1] ---&gt; &#x27;</span>,<span class="hljs-variable">$ARGV</span>[<span class="hljs-number">1</span>],<span class="hljs-string">&quot;\n&quot;</span>,<br>      <span class="hljs-string">&#x27;<span class="hljs-variable">$ARGV</span>[2] ---&gt; &#x27;</span>,<span class="hljs-variable">$ARGV</span>[<span class="hljs-number">2</span>],<span class="hljs-string">&quot;\n&quot;</span>,<br>      <span class="hljs-string">&#x27;<span class="hljs-variable">$ARGV</span>[3] ---&gt; &#x27;</span>,<span class="hljs-variable">$ARGV</span>[<span class="hljs-number">3</span>],<span class="hljs-string">&quot;\n&quot;</span>,<br>      <span class="hljs-string">&#x27;<span class="hljs-variable">$ARGV</span>[4] ---&gt; &#x27;</span>,<span class="hljs-variable">$ARGV</span>[<span class="hljs-number">4</span>],<span class="hljs-string">&quot;\n&quot;</span><span class="hljs-comment">;</span><br></code></pre></td></tr></table></figure><p>执行这个程序：</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs stylus"><span class="hljs-number">1</span><br><span class="hljs-number">2</span><br><span class="hljs-number">3</span><br><span class="hljs-number">4</span><br><span class="hljs-number">5</span><br><span class="hljs-number">6</span><br>shell&gt; ./test<span class="hljs-selector-class">.plx</span> -w <span class="hljs-selector-tag">a</span> <span class="hljs-selector-tag">b</span> c d<br><span class="hljs-variable">$ARGV</span><span class="hljs-selector-attr">[0]</span> ---&gt; -w<br><span class="hljs-variable">$ARGV</span><span class="hljs-selector-attr">[1]</span> ---&gt; <span class="hljs-selector-tag">a</span><br><span class="hljs-variable">$ARGV</span><span class="hljs-selector-attr">[2]</span> ---&gt; <span class="hljs-selector-tag">b</span><br><span class="hljs-variable">$ARGV</span><span class="hljs-selector-attr">[3]</span> ---&gt; c<br><span class="hljs-variable">$ARGV</span><span class="hljs-selector-attr">[4]</span> ---&gt; d<br></code></pre></td></tr></table></figure><p>因为是数组，所以可以修改数组，比如强制指定元素：</p><figure class="highlight perl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs perl"><span class="hljs-number">1</span><br><span class="hljs-number">2</span><br><span class="hljs-number">3</span><br><span class="hljs-number">4</span><br><span class="hljs-number">5</span><br><span class="hljs-number">6</span><br>/usr/bin/perl<br><br>@ARGV=<span class="hljs-string">qw(first second third)</span>;<br><span class="hljs-keyword">print</span> <span class="hljs-string">&#x27;$ARGV[0] ---&gt; &#x27;</span>,$ARGV[<span class="hljs-number">0</span>],<span class="hljs-string">&quot;\n&quot;</span>,<br>      <span class="hljs-string">&#x27;$ARGV[1] ---&gt; &#x27;</span>,$ARGV[<span class="hljs-number">1</span>],<span class="hljs-string">&quot;\n&quot;</span>,<br>      <span class="hljs-string">&#x27;$ARGV[2] ---&gt; &#x27;</span>,$ARGV[<span class="hljs-number">2</span>],<span class="hljs-string">&quot;\n&quot;</span>;<br><span class="hljs-number">1</span><br><span class="hljs-number">2</span><br><span class="hljs-number">3</span><br><span class="hljs-number">4</span><br>shell&gt; ./test.plx a b c d<br>$ARGV[<span class="hljs-number">0</span>] ---&gt; first<br>$ARGV[<span class="hljs-number">1</span>] ---&gt; second<br>$ARGV[<span class="hljs-number">2</span>] ---&gt; third<br></code></pre></td></tr></table></figure><p>例如，读取2个文件(a.log,b.log)的内容：</p><figure class="highlight stata"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs stata">1<br>2<br>3<br>4<br>5<br>/usr/bin/perl<br><br><span class="hljs-keyword">while</span>(&lt;&gt;)&#123;<br>    <span class="hljs-keyword">print</span> <span class="hljs-variable">$_</span>;<br>&#125;<br><span class="hljs-keyword">shell</span>&gt; ./<span class="hljs-keyword">test</span>.plx a.<span class="hljs-keyword">log</span> b.<span class="hljs-keyword">log</span><br></code></pre></td></tr></table></figure><p>如果想读取标准输入，只需使用”-“作为文件参数即可。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_">$ </span><span class="language-bash"><span class="hljs-built_in">echo</span> -e <span class="hljs-string">&quot;abcd\nefg&quot;</span> | ./test.plx a.log - b.log</span><br></code></pre></td></tr></table></figure><p>上面将按先后顺序读取a.log，标准输入(管道左边命令的输出内容)，b.log。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs 整体读入，逐行处理">open(FILE,&quot;&lt;&quot;,&quot;/home/chenmi/.bashrc&quot;)||die&quot;cannot open the file: $!\n&quot;; <br>@linelist=&lt;FILE&gt;; <br>foreach $eachline(@linelist)&#123; <br>       print $eachline; <br>&#125; <br>close FILE; <br></code></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs 逐行读入，边读边处理">open(FILE,&quot;&lt;&quot;,&quot;/home/chenmi/.bashrc&quot;)||die&quot;cannot open the file: $!\n&quot;; <br>while (&lt;FILE&gt;)&#123; <br>       print; <br>&#125; <br>close FILE; <br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>Perl</category>
      
    </categories>
    
    
    <tags>
      
      <tag>perl</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>S-Locus</title>
    <link href="/GeekFocus/2022/03/22/2022-03-22-S-Locus/"/>
    <url>/GeekFocus/2022/03/22/2022-03-22-S-Locus/</url>
    
    <content type="html"><![CDATA[<span id="more"></span><hr><h1 id="Part1-植物S位点自交不亲和机制研究的态势分析2016"><a href="#Part1-植物S位点自交不亲和机制研究的态势分析2016" class="headerlink" title="Part1:植物S位点自交不亲和机制研究的态势分析2016"></a>Part1:<a href="https://manu56.magtech.com.cn/kxgc/article/2016/1673-5668/1673-5668-11-4-9.shtml">植物S位点自交不亲和机制研究的态势分析2016</a></h1><p><strong>植物自交不亲和性</strong>广泛存在于<strong>显花植物</strong>,是<strong>防止近亲繁殖</strong>和<strong>促进开花植物遗传多样性</strong>和<strong>杂种优势</strong>的重要遗传机制。关于自交不亲和机制的研究多集中在<strong>S基因</strong>上。该文结合文献计量的方法,利用Hiscite、Citespace和VosViewer分析了<strong>基于S位点</strong>的植物<strong>自交不亲和机制研究</strong>的年代趋势、重点国家、重要机构、重要作者、研究前沿和研究热点,对<strong>蛋白质磷酸化</strong>、<strong>S-RNase泛素化</strong>和<strong>拟南芥属的演化</strong>作简要论述,并根据目前研究现状提出该领域研究中存在的问题及解决对策,旨在为进一步研究提供重要参考依据。</p><p><strong>1 引言</strong></p><p>自交不亲和性(self-incompatibility, SI)是指具有<strong>完全花</strong>并能形成<strong>正常雌、雄配子</strong>,然而<strong>缺乏自花授粉结实</strong>能力的一种<strong>自交不育</strong>性,<strong>常</strong>存在于<strong>雌雄同株的植物</strong>,自交不亲和现象广泛分布在显花植物中[<a href="https://manu56.magtech.com.cn/kxgc/article/2016/1673-5668/1673-5668-11-4-9.shtml#b1-1673-5668-11-4-9">1</a>]。SI是防止近亲繁殖和促进开花植物遗传多样性和杂种优势的重要遗传机制[<a href="https://manu56.magtech.com.cn/kxgc/article/2016/1673-5668/1673-5668-11-4-9.shtml#b2-1673-5668-11-4-9">2</a>]。基于<strong>花粉识别特异性</strong>的<strong>遗传决定方式</strong>,SI可分为<strong>配子体型自交不亲和性</strong>(<strong>gametophytic</strong> self-incompatibility, GSI)和<strong>孢子体型自交不亲和性</strong>(sporophytic self-incompatibility, SSI) [<a href="https://manu56.magtech.com.cn/kxgc/article/2016/1673-5668/1673-5668-11-4-9.shtml#b3-1673-5668-11-4-9">3</a>]。<font color="red"><strong>GSI</strong>即是<strong>花粉</strong>在<strong>柱头上发芽</strong>后<strong>可侵入柱头</strong>,且能<strong>在花柱组织</strong>中<strong>延伸一定距离</strong>,<strong>之后受到抑制</strong></font>。花粉管与雌性因素的抑制关系发生在单倍体配子体之间,常见于<font color="red"><strong>罂粟科</strong>(Papaveraceae)、<strong>蔷薇科</strong>(Rosaceae)、<strong>茄科</strong>(Solanaceae)<strong>和玄参科</strong>(Scrophulariaceae)</font>的一些植物[<a href="https://manu56.magtech.com.cn/kxgc/article/2016/1673-5668/1673-5668-11-4-9.shtml#b4-1673-5668-11-4-9">4</a>]。<font color="red">此种抑制关系可以发生在<strong>花柱组织中</strong>,也能发生在<strong>花粉管与胚囊组织之间</strong>,有的甚至是<strong>精子已经到达胚囊内,仍然不能与卵细胞结合</strong></font>[<a href="https://manu56.magtech.com.cn/kxgc/article/2016/1673-5668/1673-5668-11-4-9.shtml#b5-1673-5668-11-4-9">5</a>]。<font color="blue"><strong>SSI</strong>即是花粉落到柱头上<strong>不能正常发芽</strong>,或者<strong>发芽之后</strong>在柱头乳突细胞上缠绕而<strong>无法侵入柱头</strong></font>。这种不亲和关系发生在<strong>花粉管与柱头乳突细胞的孢子体之间</strong>,花粉的行为决定于二倍体亲本的基因型,多见于<font color="blue"><strong>油菜</strong>、<strong>拟南芥</strong>等<strong>十字花科</strong></font>(Brassicaceae)植物中[<a href="https://manu56.magtech.com.cn/kxgc/article/2016/1673-5668/1673-5668-11-4-9.shtml#b6-1673-5668-11-4-9">6</a>]。</p><p><font color="red">植物<strong>受粉</strong>过程包括<strong>花粉落到柱头上</strong>、<strong>粘附</strong>、<strong>水合</strong>、<strong>萌发</strong>,<strong>花粉管生长</strong>、<strong>花粉到达胚珠完成受精</strong>作用几个阶段,植物自交不亲和反应的识别可发生在受粉过程的<strong>任何阶段</strong></font>[<a href="https://manu56.magtech.com.cn/kxgc/article/2016/1673-5668/1673-5668-11-4-9.shtml#b7-1673-5668-11-4-9">7</a>]。</p><p>如<font color="green"><strong>拟南芥</strong></font>的识别发生在<font color="green"><strong>花粉水合阶段</strong></font>[<a href="https://manu56.magtech.com.cn/kxgc/article/2016/1673-5668/1673-5668-11-4-9.shtml#b8-1673-5668-11-4-9">8</a>, <a href="https://manu56.magtech.com.cn/kxgc/article/2016/1673-5668/1673-5668-11-4-9.shtml#b9-1673-5668-11-4-9">9</a>];</p><p><font color="green"><strong>罂粟</strong></font>的不亲和反应发生在<font color="green"><strong>花粉萌发阶段</strong></font>[<a href="https://manu56.magtech.com.cn/kxgc/article/2016/1673-5668/1673-5668-11-4-9.shtml#b10-1673-5668-11-4-9">10</a>];</p><p><font color="green"><strong>金鱼草</strong></font>的识别和不亲和反应都发生在<font color="green"><strong>花粉管内部</strong></font>[<a href="https://manu56.magtech.com.cn/kxgc/article/2016/1673-5668/1673-5668-11-4-9.shtml#b11-1673-5668-11-4-9">11</a>]。</p><p>一个基因存在多种等位基因称为复等位基因（multiple allelism）。任何一个杂合二倍体只存在复等位基因中的两个不同的等位基因。人ABO血型系统 IA、IB、i 。其中，IA<strong>和</strong>IB对 i 显性，IA<strong>与</strong>IB共显性。每个人只能有其中的两个基因。</p><p>不论是GSI还是SSI遗传上都是由<font color="darkred"><strong>特定</strong>的<strong>复等位基因</strong>控制</font>,大多数植物的自交不亲和性是由<font color="darkred"><strong>单一</strong>的<strong>复等位基因位点</strong>控制,称为<strong>S位点</strong>(S-locus),S位点具有<strong>高度多态性</strong></font>[<a href="https://manu56.magtech.com.cn/kxgc/article/2016/1673-5668/1673-5668-11-4-9.shtml#b3-1673-5668-11-4-9">3</a>]。<strong>少数植物</strong>的自交不亲和性是由<strong>两个及以上位点控制</strong>的,如<font color="darkred"><strong>禾本科</strong></font>的自交不亲和性由<font color="darkred"><strong>S和Z</strong>两个<strong>互不连锁</strong>的遗传位点<strong>共同</strong>控制</font>[<a href="https://manu56.magtech.com.cn/kxgc/article/2016/1673-5668/1673-5668-11-4-9.shtml#b12-1673-5668-11-4-9">12</a>]。S位点通常包含两类基因：<font color="darkred">决定<strong>花粉识别特异性</strong>的<strong>花粉S基因</strong></font>与<font color="darkred">决定<strong>花柱识别特异性</strong>的<strong>花柱S基因</strong></font>。<font color="red"><strong>蔷薇科、玄参科和茄科</strong>的<strong>花柱</strong>和<strong>花粉决定因子</strong>被鉴定为<strong>S-核酸酶</strong>(S-RNase)和<strong>F-box蛋白</strong></font>[<a href="https://manu56.magtech.com.cn/kxgc/article/2016/1673-5668/1673-5668-11-4-9.shtml#b13-1673-5668-11-4-9">13</a>]。<font color="blue"><strong>十字花科</strong>的<strong>花柱</strong>和<strong>花粉决定因子</strong>为<strong>S位点受体激酶</strong></font> (<strong>S-locus receptor kinase</strong> , <font color="blue">SRK</font>)和<font color="blue"><strong>SCR</strong></font>(<strong>S-locus cysteine-rich</strong>)[<a href="https://manu56.magtech.com.cn/kxgc/article/2016/1673-5668/1673-5668-11-4-9.shtml#b9-1673-5668-11-4-9">9</a>]。而<font color="green"><strong>罂粟科</strong>的<strong>花柱</strong>和<strong>花粉决定因子</strong></font>为<strong>PrsS</strong>(Palaver rhoeas <strong>stigma</strong> S-determinant)和<strong>PrpS</strong>(Papaver rhoeas <strong>pollen</strong> S-determinant),且通过<font color="green"><strong>花粉管胞质自由Ca2+<strong>介导的</strong>信号级联</strong>激活</font>作用来调控[<a href="https://manu56.magtech.com.cn/kxgc/article/2016/1673-5668/1673-5668-11-4-9.shtml#b14-1673-5668-11-4-9">14</a>]。SI是研究有性植物生殖细胞间<strong>信号识别、转导</strong>以及<strong>细胞间相互作用</strong>的一种<strong>理想模型</strong>,在植物<strong>遗传改良</strong>和<strong>作物杂种优势利用</strong>上具有重要价值。</p><p>本文文献信息源自于汤森路透的<em>Web of Science</em>数据库核心合集,通过检索式TS&#x3D; Self-Incompatibilit* and (s-rnase or f-box or S-locus or “s gene”),选取了1990–2016年的全部文献记录共计<strong>1 310条</strong>,数据库更新时间为2016年3月19日,其中2016年文献记录为4条。利用Hiscite、Citespace、Excel、VosViewer软件分析了有关植物S位点自交不亲和机制研究的年代趋势、重点国家、重要机构、重要作者、研究前沿与研究热点,旨在为进一步研究提供参考。</p><p><strong>2 植物S位点自交不亲和机制总体研究现状和发展趋势</strong></p><p><strong>2.1 年度发展趋势</strong></p><p>植物S位点自交不亲和机制年度发文量如<a href="https://manu56.magtech.com.cn/kxgc/article/2016/1673-5668/1673-5668-11-4-9/img_1.png">图1</a>所示。总体而言,植物自交不亲和机制研究领域发文量较少,自1990年开始稳步上升,具有重要意义和广泛前景。</p><p><strong>2.2 国家分析</strong></p><p>结合Histcite软件和<em>Web of Science</em>数据库对文献分布情况进行统计,在这26年内,<em>Web of Science</em>数据库中记录的发文数量前10国家如表1所示。美国342篇,占26.11%。日本占24.58%。中国和英格兰紧随其后,但均不到美国和日本的一半。从引用看,美国论文总被引为15 273次,远超其他国家;日本次之,被引9 483次。二者被引显著高于其他国家。1 310篇,被引≥50的论文总计220篇。<strong>中国</strong>发文量虽较多,但被引次数<strong>≥50</strong>的论文<strong>仅9篇</strong>,仍存在差距。</p><p>国家间合作。苏格兰、英格兰、澳大利亚、加拿大与其他国家合作较多。其中苏格兰与发文量较多的澳大利亚、英格兰、加拿大、法国、葡萄牙、丹麦均有合作。美国与日本有合作,日本与澳大利亚和德国合作相对紧密,而中国仅与葡萄牙一个国家有过合作。</p><p><strong>2.3 机构分析</strong></p><p>康奈尔大学、东北大学、京都大学发文量位居前三。中科院和南农发文量仅次于前5个机构,但是文章被引频次远远落后,存在差距,而2010年至今的发文量跃居前3,说明近年来在该领域加大了研究力度。综合评价,康奈尔大学、东北大学、京都大学、奈良先端科学技术大学院大学和宾州州立大学是植物S位点自交不亲和领域研究的重要机构。</p><p><strong>2.4 重要作者分析</strong></p><p>重要作者分析是分析学科领域发展状况重要环节,通过分析重要作者所发表的科研成果能对该学科领域的主要研究内容有大致了解。而分析<strong>作者分布</strong>及<strong>合作网络</strong>是确定某研究领域<strong>核心作者群</strong>的重要方法。本着发文量、全球总被引、本地总被引3项指标,选取10位重要作者,并统计其作为通讯作者的发文量和近6年的发文量。其中ISOGAI A和HINATA K近6年发文量为零,表明他们曾对该领域做出了巨大的贡献,而其余8位作者持续植物自交不亲和机制研究。</p><p><strong>3 植物S位点自交不亲和机制研究热点及前沿</strong></p><p>植物S位点自交不亲和机制研究相关的3个重要词：<font color="red"><strong>人工合成</strong>(resynthesized)、<strong>激酶</strong>(kinase)、<strong>磷酸化蛋白质组学</strong>(phosphoproteomic)</font>。植物S位点自交不亲和机制研究追溯到1955,自1990年后,涌现大量成果。早期关于S基因的研究集中在人工合成甘蓝型油菜,近年的研究热点为<font color="red">S位点<strong>受体激酶</strong>和<strong>蛋白质磷酸化</strong></font>。前沿相关性较强的词：evolution、brassicaceae、arabidopsis,即十字花科,尤其拟南芥演化是其研究热点。领域研究热点及前沿 3个方面：<font color="red"><strong>蛋白质磷酸化</strong>、<strong>S-RNase泛素化</strong>和<strong>SRK介导的拟南芥属演化</strong></font>。</p><p><strong>3.1 蛋白质磷酸化</strong></p><p>蛋白质磷酸化生物体内广泛存在,发生在SI信号转导早期阶段,在调控<strong>柱头乳突细胞</strong>对<strong>细胞外的信号识别</strong>及<strong>细胞内的信号传递</strong>方面起重要作用[<a href="https://manu56.magtech.com.cn/kxgc/article/2016/1673-5668/1673-5668-11-4-9.shtml#b15-1673-5668-11-4-9">15</a>]。<strong>SRK</strong>的<strong>结构域</strong>通过<strong>胞外域</strong>特异性地<strong>与SCR结合</strong>,引起<strong>胞内激酶域</strong>的<strong>自磷酸化</strong>。<strong>M位点蛋白激酶</strong>(M locus protein kinase, MLPK)是甘蓝的一种非受体蛋白激酶,能够与<strong>SRK</strong>形成<strong>信号复合体</strong>。该信号复合体的磷酸化引起下游组分的<strong>级联</strong>反应,从而导致<strong>自交不亲和</strong>现象的发生[<a href="https://manu56.magtech.com.cn/kxgc/article/2016/1673-5668/1673-5668-11-4-9.shtml#b16-1673-5668-11-4-9">16</a>]。Poulter等[<a href="https://manu56.magtech.com.cn/kxgc/article/2016/1673-5668/1673-5668-11-4-9.shtml#b10-1673-5668-11-4-9">10</a>]也证实可溶性无机焦磷酸酶(soluble inorganic pyrophosphatases)和丝裂原活化蛋白激酶 (mitogen-activated protein kinases, MAPKs)的磷酸化是SI的下游反应。到目前为止,虽然已在SI信号转导通路中鉴定出一些蛋白磷酸酶和蛋白激酶,但还是<strong>未能解释</strong>自交花粉受到抑制从而不亲和的原因,只有对<strong>整个信号通路蛋白质磷酸化途径</strong>有更加全面的认识,才能进一步阐明SI的分子机制[<a href="https://manu56.magtech.com.cn/kxgc/article/2016/1673-5668/1673-5668-11-4-9.shtml#b17-1673-5668-11-4-9">17</a>]。前人对花粉与雌蕊相互作用的研究主要集中在用比较转录组学探讨基因表达情况。然而,在<strong>蛋白质翻译后修饰</strong>的研究较缺乏。Wang等[<a href="https://manu56.magtech.com.cn/kxgc/article/2016/1673-5668/1673-5668-11-4-9.shtml#b18-1673-5668-11-4-9">18</a>, <a href="https://manu56.magtech.com.cn/kxgc/article/2016/1673-5668/1673-5668-11-4-9.shtml#b19-1673-5668-11-4-9">19</a>]对水稻成熟雌蕊一个磷酸化蛋白质组学的剖析为研究植物自交不亲和的细胞信号转导提供参考。</p><p><strong>3.2 S-RNase泛素化</strong></p><p><font color="red"><strong>花柱特异性因子</strong></font>为<font color="red"><strong>S-RNase</strong></font>的<strong>SI</strong>在自然界中<font color="red"><strong>最广泛</strong></font>,相应的<font color="red"><strong>花粉决定因子</strong></font>在<font color="red"><strong>车前科</strong>(Plantaginaceae)和<strong>茄科</strong></font>中被称为<font color="red"><strong>SLF(S-locus F-box)</strong></font>,在<font color="red"><strong>蔷薇科</strong></font>中<font color="red"><strong>类似F-box蛋白</strong>被命名为<strong>SFB</strong></font>(S haplotype-specific F-box protein)[<a href="https://manu56.magtech.com.cn/kxgc/article/2016/1673-5668/1673-5668-11-4-9.shtml#b20-1673-5668-11-4-9">20</a>, <a href="https://manu56.magtech.com.cn/kxgc/article/2016/1673-5668/1673-5668-11-4-9.shtml#b21-1673-5668-11-4-9">21</a>]。Qiao等[<a href="https://manu56.magtech.com.cn/kxgc/article/2016/1673-5668/1673-5668-11-4-9.shtml#b22-1673-5668-11-4-9">22</a>]通过<strong>免疫共沉淀</strong>和<strong>酵母双杂</strong>交实验发现并证明<font color="red"><strong>进入异己花粉管</strong>的<strong>S-RNase</strong>会与<strong>SLF结合</strong>并被<strong>泛素化</strong></font>。<font color="red"><strong>泛素蛋白酶体途径</strong></font>(ubiquitin proteasome pathway)介导的<strong>蛋白降解</strong>是机体调节细胞内蛋白水平与功能的重要机制,大量研究证实<font color="red"><strong>F-box</strong>是<strong>泛素蛋白降解系统</strong>中<strong>泛素蛋白连接酶复合体</strong>(SCF-E3)结合特异性底物的<strong>受体</strong></font>[<a href="https://manu56.magtech.com.cn/kxgc/article/2016/1673-5668/1673-5668-11-4-9.shtml#b23-1673-5668-11-4-9">23</a>, <a href="https://manu56.magtech.com.cn/kxgc/article/2016/1673-5668/1673-5668-11-4-9.shtml#b24-1673-5668-11-4-9">24</a>]。针对SI系统,中科院遗传所薛勇彪课题组提出一个<font color="red"><strong>S-RNase泛素化</strong>介导的<strong>液泡分拣模型</strong></font>[<a href="https://manu56.magtech.com.cn/kxgc/article/2016/1673-5668/1673-5668-11-4-9.shtml#b7-1673-5668-11-4-9">7</a>]：S-RNase通过细胞<font color="red">内吞作用</font>从细胞外基质进入到花粉管后被运输到<font color="red">花粉液泡</font>中。在<strong>自交</strong>花粉管中,<strong>液泡膜</strong>由于某种机制会<strong>被破坏</strong>,<font color="red">S-RNase<strong>被释放</strong>到细胞质中</font>,引起<font color="red"><strong>细胞毒素效应</strong></font>从而<font color="red">抑制花粉管生长</font>;而在<strong>异交</strong>花粉管中,<font color="red">液泡不被破坏</font>,S-RNase不能发挥细胞毒性,因此异交花粉管正常生长。这个模型合理解释了花粉特征的特异性,为进一步研究植物自交不亲和反应的分子机制提供了重要基础。</p><p><strong>3.3 拟南芥属的演化</strong></p><p>S位点受体激酶是以十字花科为代表的SSI反应的核心因子。Stein等[<a href="https://manu56.magtech.com.cn/kxgc/article/2016/1673-5668/1673-5668-11-4-9.shtml#b25-1673-5668-11-4-9">25</a>]首次从甘蓝中鉴定出柱头受体激酶SRK。Nasrallah JB[<a href="https://manu56.magtech.com.cn/kxgc/article/2016/1673-5668/1673-5668-11-4-9.shtml#b26-1673-5668-11-4-9">26</a>]首先发现甘蓝自交不亲和特异性的花粉S基因<em>SCR&#x2F;SP11</em>。在拟南芥中,<em>SCR</em>作为配体与受体SRK相互作用发挥自交不亲和效应。而甘蓝的自交不亲和性由SRK、<em>SCR</em>和S位点糖蛋白(SLG)3个高度多态性的基因共同控制,SLG不是必须的花柱S基因,但它的存在可以增强自交不亲和响应的能力[<a href="https://manu56.magtech.com.cn/kxgc/article/2016/1673-5668/1673-5668-11-4-9.shtml#b27-1673-5668-11-4-9">27</a>, <a href="https://manu56.magtech.com.cn/kxgc/article/2016/1673-5668/1673-5668-11-4-9.shtml#b28-1673-5668-11-4-9">28</a>]。植物交配系统具有高度不稳定的特性,异交和自交之间频繁的转换,但是潜在的遗传原因还不明确。Mable等[<a href="https://manu56.magtech.com.cn/kxgc/article/2016/1673-5668/1673-5668-11-4-9.shtml#b29-1673-5668-11-4-9">29</a>]基于温室条件下的授粉实验发现北美深山南芥中存在SI丢失的现象,并表明可能与SRK扩增的等位基因有关。Tsuchimatsu等[<a href="https://manu56.magtech.com.cn/kxgc/article/2016/1673-5668/1673-5668-11-4-9.shtml#b30-1673-5668-11-4-9">30</a>]在欧洲拟南芥中发现了花粉特异性基因<em>SCR</em>中碱基的突变,进一步描述了拟南芥SI丢失的遗传机制。通过对拟南芥自交不亲和基因系统发育分析可知<em>SCR</em>与SRK存在共进化的关系[<a href="https://manu56.magtech.com.cn/kxgc/article/2016/1673-5668/1673-5668-11-4-9.shtml#b31-1673-5668-11-4-9">31</a>]。拟南芥的祖先具有自交不亲和性,然而在漫长的适应环境的进化过程中逐渐向自交亲和过度。随着全基因组测序的发展,拟南芥属SI的丢失及某些基因的进化将会更加清晰全面的呈现出来。</p><p><strong>6 结论与展望</strong></p><p>美国康奈尔大学的Nasrallah JB和Nasrallah ME、日本奈良先端科学技术大学院大学的Isogai A和Takayama S、日本东北大学的Watanabe M、Nishio T和Hinata K、美国宾州州立大学的Kao TH、日本京都大学的Tao R与日本千叶大学的Sassa H为该领域前10作者。蛋白质磷酸化、S-RNase泛素化和SRK介导的拟南芥属演化是本领域近期或者未来几年的研究前沿热点。</p><p>植物自交不亲和反应可发生在受精前多个阶段,而且在自交不亲和系统中还存有一些重要的**非S因子,与S因子存在着互作关系,**体现出SI具有极其复杂的分子机制。近年来,植物S位点自交不亲和机制研究取得一定进展,但仍然存在诸多问题：</p><p>(1)蛋白质磷酸化与S-RNase泛素化有无互作关系,是如何相互作用的?</p><p> (2)S-RNase进入自交的花粉管后,液泡膜如何被破坏?</p><p>(3)S-RNase进入异交花粉管的细胞便不能发挥细胞毒素效应是否与花粉S因子有关?</p><p>(4)其他自交不亲和植物中是否存在类似的花粉和花柱S因子?</p><p>(5)现阶段普遍认为SI的机理是在花粉管或花粉中诱发细胞程序性死亡,详细机制又是什么?</p><p>要解决这一系列问题,笔者认为需要从以下3个层面进行深入研究：</p><p>(1)在基因层面上,挖掘与SI相关的基因并进行单个甚至多个基因同时作用的功能分析。</p><p>(2)在分子层面上,研究蛋白质体系、蛋白质-核酸体系是如何相互作用的。</p><p>(3)在细胞层面上,探讨S-RNase进入液泡的信号转导途径及其他相关信号通路。</p><p>运用分子遗传学、基因组学、生物信息学、细胞生物学、进化发育生物学等学科的综合手段对自交不亲和信号识别和激活的分子机制作进一步研究。不同种属自交不亲和性机制的阐明对人工打破其生殖障碍、开辟新的作物育种途径具有重要意义。</p><hr><h1 id="part2"><a href="#part2" class="headerlink" title="part2"></a><a href="https://www.cas.cn/kxcb/kpwz/201311/t20131106_3968674.shtml">part2</a></h1><p>自交不亲和性在植物界中广泛分布，超过60%的被子植物都有这种特性，涉及大约320多个科。</p><p>与生物界其它的“识别系统”如<strong>人的主要组织相容性复合体（MHC）</strong>一样，自交不亲和性在遗传上需要标记个体身份的特异性，在<strong>群体中</strong>需有这种<strong>身份标记的多样性</strong>。大多数植物的自交不亲和性是由<strong>单一的复等位基因位点控制</strong>，称为<em>S</em>位点。<strong>S位点</strong>一般包含<strong>两类基因</strong>：<strong>决定花柱识别特异性</strong>的<strong>花柱<em>S</em>基因</strong>和<strong>决定花粉识别特异性</strong>的<strong>花粉<em>S</em>基因</strong>。<strong>不同的花柱<em>S</em>等位基因</strong>与其<font color="red"><strong>紧密连锁</strong>的花粉<em>S</em>等位基因</font>构成<font color="red"><strong>不同的S单倍型</strong></font>。基于花粉识别特异性的遗传决定方式，自交不亲和性分为<strong>孢子体</strong>自交不亲和性和<strong>配子体</strong>自交不亲和性两种类型。孢子体自交不亲和的花粉亲和与否的表型由产生花粉的二倍体亲本（即孢子体）<em>S</em>基因型决定，主要存在于油菜、拟南芥等十字花科植物中。配子体自交不亲和的花粉表型由单倍体花粉（即配子体）自身的<em>S</em>基因型决定，<font color="red">分布<strong>最广泛</strong>的是一种称为<strong>S核酸酶类</strong>的自交不亲和性，主要存在于<strong>茄科、蔷薇科、车前科</strong>等植物中</font>。在<strong>正选择和平衡选择</strong>等作用下，植物自交不亲和性的<font color="red">S单倍型快速进化</font>，在群体中始终维持着<font color="red">低频多态</font>水平。研究发现自然群体中<font color="red"><em>S</em>单倍型的类型可达上百个</font>。 </p><p>　　二十世纪八九十年代，人们逐步利用分子生物学手段研究这种受粉相关性状的基因基础及分子机理。植物受粉从花粉落在柱头上开始，经过<font color="red">粘附、水合、萌发，花粉管生长</font>，直至到达胚珠完成受精作用。在这个过程中，花粉或花粉管细胞携带自身信息，不断感知来自柱头或花柱道细胞的外部信号，当“识别”发生后，迅速作出“生死抉择”。通过不同的信号转导级联反应，“异己花粉”顺利完成受精过程，“自己花粉”的生长则被阻止。植物自交不亲和反应的识别可以发生在受粉过程的不同阶段。<strong>拟南芥</strong>的识别发生在<strong>花粉水合阶段</strong>，<strong>相互作用</strong>的<strong>花柱和花粉因子</strong>分别为<strong>SRK和SCR</strong>。<strong>罂粟</strong>的不亲和反应发生在<strong>花粉萌发阶段</strong>。<strong>金鱼草</strong>的识别和不亲和反应都发生在<strong>花粉管内部</strong>，生长受阻的花粉管停留在<font color="red"><strong>花柱道上部的1&#x2F;3处</strong></font>，其花柱和花粉决定因子分别为<strong>S-RNase</strong>和花粉<strong>SLF&#x2F;SFB</strong>。目前认为植物自交不亲和反应的<font color="red">分子细胞机理是在<strong>花粉或花粉管</strong>中<strong>诱发</strong>了<strong>细胞程序性死亡</strong></font>。 </p><p>　　异交可增加个体遗传杂合度增强适应性。自交亲和迅速占领适宜生境，实现群体扩张。栽培作物大多是自交亲和的纯合品系，呈现均一目的农艺性状，但自交亲和及其纯合效应使作物抗逆性较弱。自交不亲和性作为<strong>种内生殖障碍</strong>，对于<strong>促进种间生殖障碍形成</strong>和<strong>物种分化</strong>意义重大，在<strong>被子植物演化</strong>过程中<strong>多次独立起源</strong>，推测地球上<strong>显花植物的繁盛发达</strong>与其频繁获得这一生殖性状有密切关系。 </p><p>　　植物自交不亲和性不仅是值得深入研究的生物学问题，在生产实践中也有重要应用价值。二十世纪七十年代，我国科学家利用<strong>十字花科自交不亲和</strong>机制育成了<strong>甘蓝型杂交油菜</strong>，大幅度提高油菜产量和品质，在甘蓝、大白菜和萝卜等蔬菜育种中也有很好的应用。 </p><p><img src="/GeekFocus/./1.png" alt="img"></p><hr><h1 id="茄科自交不亲和性花柱因子S-RNase的解毒机制"><a href="#茄科自交不亲和性花柱因子S-RNase的解毒机制" class="headerlink" title="茄科自交不亲和性花柱因子S-RNase的解毒机制"></a><a href="http://pcce.genetics.cas.cn/zhxw/202106/t20210603_642162.html">茄科自交不亲和性花柱因子S-RNase的解毒机制</a></h1><p>　　2021年5月31日在线发表在<em>New Phytologist</em>杂志。 </p><p>​　自交不亲和性广泛存在于显花植物, 种内生殖障碍。前期研究表明，<font color="red">茄科、车前科、蔷薇科和芸香科</font>植物<font color="red">花柱特异表达</font>的可作为一类细胞毒因子<strong>抑制</strong>自己花粉管生长，而在异交授粉后，由于其<font color="red"><strong>被异己花粉泛素化</strong>并通过<strong>蛋白酶体降解</strong></font>，无法发挥细胞毒性，产生异交亲和。然而，<strong>泛素蛋白酶体系统解除细胞毒性的详细机制</strong>并不清楚。 </p><p>　　对茄科植物杂交矮牵牛(<em>Petunia hybrida</em>)自交不亲和性<font color="red">花柱因子<strong>S3</strong>-RNase</font>的泛<strong>素化修饰</strong>进行<strong>生化分析</strong>，发现其主要在<strong>三个较为保守的空间区域</strong>(<strong>I, II和III</strong>)发生<strong>K48类型</strong>的<strong>多聚泛素化</strong>。<font color="red"><strong>区域I</strong>在<strong>未授粉</strong>、<strong>自交</strong>授粉和<strong>异交</strong>授粉花柱中<strong>都被泛素化</strong></font>，表明其在<strong>S3-RNase进入花粉管之前</strong>即可发生，而<font color="red"><strong>区域II和III只在异交授粉花柱中被泛素化</strong></font>。遗传分析表明，<font color="red"><strong>区域II突变</strong>的<strong>S3</strong>-RNase可导致转基因植株的<strong>异交结籽数显著减少</strong></font>，而<font color="red">区域I或III突变</font>时，<font color="red">异交结籽数<strong>减少程度较小</strong></font>，提示<font color="red"><strong>泛素化修饰区域突变</strong>的<strong>S3-RNase</strong>在<strong>花粉管</strong>中发生<strong>积累</strong>并产生<strong>更高</strong>的<strong>细胞毒性</strong></font>。<font color="red">花粉管共培养及降解实验</font>结果显示<font color="red"><strong>区域II突变</strong>后<strong>S3</strong>-RNase在花粉管中的降解速率<strong>显著减慢</strong>，而<strong>区域I和III</strong>突变后减慢程度<strong>较小</strong>，<strong>与异交授粉结果相一致(III why?)</strong></font>，表明<font color="red"><strong>区域II</strong></font>在<strong>异交亲和</strong>反应<strong>S3</strong>-RNase的<font color="red"><strong>泛素化修饰</strong>和<strong>降解</strong>中发挥<strong>主要作用</strong></font>，区域I和III作用较小。进一步研究发现，<font color="reen"><strong>区域II</strong></font>中的<font color="reen"><strong>K154</strong>和<strong>K217</strong></font>在此过程中发挥主要作用，而<strong>苏氨酸位点作用较小</strong>。该研究揭示<strong>S3</strong>-RNase的<strong>泛素化修饰</strong>和<strong>降解</strong>在杂交矮牵牛的<strong>异交亲和</strong>授粉中<font color="red"><strong>分步</strong>进行</font>(图)，为<strong>T2类核酸酶</strong>及<strong>分泌型细胞毒素</strong>稳定性的动态调控机制提供新思路。 </p><p><img src="/GeekFocus/./2.png" alt="img"></p><p>S-RNase的泛素化修饰和降解在杂交矮牵牛的异交亲和授粉中分步进行</p><hr><h1 id="被子植物自交不亲和性起源、丢失和重获的高度动态进化机制"><a href="#被子植物自交不亲和性起源、丢失和重获的高度动态进化机制" class="headerlink" title="被子植物自交不亲和性起源、丢失和重获的高度动态进化机制"></a>被子植物自交不亲和性起源、丢失和重获的高度动态进化机制</h1><p>2021.11.04 plant cell</p><p>陆地生物占地球生物总数85%，其多样性与被子植物的起源和扩张密切相关。<strong>被子植物</strong>约有<strong>20多万种</strong>，是植物界最大的类群，但其形成和扩张的原因仍为未解之谜。现存被子植物中，<strong>约40%<strong>具有自交不亲和性 (Self-incompatibility, SI)。SI是一种</strong>正常可育</strong>的<strong>雌雄同花被子植物</strong>自花授粉后<strong>不能产生合子</strong>的现象，对于促进其异交并增加其多样性至关重要。被子植物在进化过程中，由于受到起伏不定的来自<strong>自交或异交</strong>的<strong>选择压力</strong>，其<strong>SI</strong>会发生<strong>频繁</strong>的<strong>丢失</strong>和<strong>重获</strong>。<strong>真双子叶植物</strong>目前共发现<strong>四类不同分子机制的SI</strong>，包括常见于<font color="red"><strong>车前科、茄科、蔷薇科和芸香科的1类</strong></font>、<font color="blue"><strong>十字花科</strong>的2类(S位点受体激酶花柱SRK花粉SCR)</font>、<font color="green"><strong>罂粟科</strong>的3类(PrsS PrpS 花粉管胞质自由Ca2+介导)</font>和<font color="purple"><strong>报春花科的4类</strong></font>SI。<strong>如此多样的SI机制是如何起源和演化的？四类SI机制的演化关系又是什么？这些问题的阐明将为揭示早期被子植物物种形成和扩张的机制提供关键线索。</strong></p><p><strong>Origin, Loss and Regain of Self-Incompatibility in Angiosperms</strong>。该研究利用<strong>系统基因组演化分析</strong>、<strong>遗传学验证</strong>和<strong>生物学功能研究</strong>揭示了被子植物SI起源、丢失和重获的高度动态进化机制。</p><p>SI通常由<font color="red">包含<strong>紧密连锁</strong>的雌性和雄性<em>S</em>基因的单一复等位的<em>S</em>位点</font>所控制。其中，<strong>1类SI</strong>的<strong>雌性</strong>S基因编码<strong>一个</strong>T2类核酸酶即<strong>S-核酸酶</strong>，而雄性<em>S</em>基因则编码<strong>多个</strong>C端为<strong>FBK或FBA结构域</strong>的<strong>F-box蛋白SLF</strong>。异交授粉时，<font color="red">由于<strong>多个SLF</strong>可<strong>协同识别</strong>并<strong>解除异己S-核酸酶</strong>的<strong>细胞毒性</strong></font>，因而产生异交亲和反应；而在自交授粉时，自己S-核酸酶的毒性由于无法被抑制，最终产生自交不亲和反应。</p><p>该研究首次发现来自<strong>毛茛科、茄科、车前科和蔷薇科</strong>的<strong>多个物种</strong>的<strong>SLF</strong>均能<font color="red"><strong>有效解除</strong>茄科植物<strong>杂交矮牵牛</strong>S-核酸酶的细胞毒性</font>，进而打破其SI，并且这种<font color="red"><strong>跨物种SLF打破SI</strong></font>的概率显著高于种内，表明<font color="red"><strong>祖先SLF</strong>具有<strong>高效</strong></font>解除S-核酸酶毒性的<strong>能力</strong>，而随着逐步<font color="red">进化和选择</font>，<font color="red">SLF的<strong>数量显著扩增</strong></font>，其<font color="red">协同解毒能力也有所增加</font>。进一步对来自种子植物<strong>59个【科】</strong>的物种进行<font color="blue"><strong><em>S</em>位点结构分析</strong></font>，发现编码<strong>雌性</strong>自交不亲和决定因子<strong>T2类核酸酶</strong>和<strong>雄性</strong>自交不亲和决定因子<strong>FBK或FBA结构域蛋白</strong>的<strong>1类<em>S</em>位点</strong>结构在<font color="red"><strong>被子植物起源之初即已产生</strong></font>，表明该类<em>S</em>位点<strong>极其古老</strong>，可能与被子植物的起源和扩张有关。</p><p>随后，通过对真双子叶植物<strong>22个【物种】</strong>的自交不亲和性及<font color="blue"><strong><em>S</em>位点特征进行归纳分析</strong></font>，研究人员系统总结出真双子叶植物SI的<font color="red"><strong>三种丢失</strong>路径和<strong>四种重获</strong>路径</font> (图A)。</p><p>【SI丢失1】：由于<font color="red">全基因组<strong>复制</strong>和1类<em>S</em>位点<strong>重复</strong></font>所导致的1类SI的<font color="green"><strong>丢失</strong></font>最为普遍，例如自交亲和的耧斗菜 (<em>Aquilegia coerulea</em>) 和菜豆 (<em>Phaseolus vulgaris</em>) 均包含<font color="red">2-3个1类<em>S</em>位点</font>。该丢失路径主要基于竞争性相互作用的原理。<strong>竞争性相互作用</strong>是指<strong>四倍体植物</strong>产生的<em>S</em>基因型<strong>杂合的二倍体花粉</strong>可以<strong>打破自交不亲和性</strong>的现象。对于基因组中存在<strong>多个独立的1类<em>S</em>位点</strong>的植物，由于其中<font color="red">一个<em>S</em>位点的SLF可以识别并解除另一个<em>S</em>位点所编码的异己S-核酸酶的细胞毒性</font>，因此该类植物所产生的花粉为<em>S</em><strong>基因型杂合并且亲和</strong>。</p><p>【SI丢失2】：一些物种则通过<font color="red"><strong>删除</strong>或<strong>失活</strong></font>1类<em>S</em>基因从而<font color="green"><strong>丢失</strong></font>了SI，该路径常见于<font color="red">栽培种</font>，例如<strong>自交亲和</strong>的<strong>栽培金鱼草</strong> (<em>Antirrhinum majus</em>) 和<strong>栽培番茄</strong> (<em>Solanum lycopersicum</em>)均<font color="red"><strong>丧失</strong></font>雌性自交<font color="red"><strong>不亲和决定因子S-核酸酶</strong></font>；Inactivation of the S-RNase was only detected in horticulturally selected lines, suggesting this route to self- compatibility (SC) is not favored in natural populations. 失活只存在于栽培种，自然界无</p><p>【SI丢失3】：另一些物种则<font color="red"><strong>完全删除</strong></font>了1类<em>S</em>位点从而<font color="green"><strong>丢失</strong></font>了该类SI机制，例如报春花 (<em>Primula vulgaris</em>)、甘蓝 (<em>Brassica oleracea</em>) 和拟南芥 (<em>Arabidopsis thaliana</em>)。</p><p>尽管如此，为了<strong>避免自交衰退</strong>，促进适应性生存和进化，一些自交亲和的物种通过<font color="red"><strong>失活或删除重复</strong>的1类<em>S</em>位点</font>进而<font color="green"><strong>重新获得</strong></font>了1类SI，例如<strong>自交不亲和的西班牙金鱼草</strong>(<em>A. hispanicum</em>)、<strong>多毛番茄</strong> (<em>S. habrochaites</em>)和<strong>柚子</strong>(<em>Citrus maxima</em>)等；</p><p>而另一些物种则<font color="green"><strong>演化出新的</strong></font>2类十字花科甘蓝 (<em>B. oleracea</em>)、3类罂粟 (<em>Papaver somniferum</em>) 或4类报春花 (<em>P. vulgaris</em>) 的SI (图B)。</p><p><strong>这些结果揭示了SI的起源和进化机制，为深入研究被子植物的起源和扩张提供了一个新的分子进化理论框架。</strong></p><p>在缺乏遗传学数据的情况下，尚不清楚在单子叶中发现的I类T2 RNase和FBK基因是否能赋予- 1型SI。祖先状态分析表明，被子植物共同祖先具有I&#x2F;II类T2 RNases和FBA&#x2F;FBK基因的连锁。真双子叶植物最近的共同祖先（most recent common ancestorMRCA）是否与I&#x2F;II类T2 RNases&#x2F;FBA&#x2F;FBK基因有关联，或者是否有一个亚家族向III类T2 RNases&#x2F;FBA&#x2F;FBK基因进化，目前尚不能确定</p><hr>]]></content>
    
    
    <categories>
      
      <category>Biology</category>
      
    </categories>
    
    
    <tags>
      
      <tag>slocus</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【CUT&amp;Tag-pipeline】</title>
    <link href="/GeekFocus/2022/03/21/2022-03-21-CUTTag/"/>
    <url>/GeekFocus/2022/03/21/2022-03-21-CUTTag/</url>
    
    <content type="html"><![CDATA[<p><strong>CUT&amp;Tag Data Processing and Analysis Tutorial</strong></p><p>Ye Zheng, Kami Ahmad, Steven Henikoff [following NC]</p><p><a href="https://yezhengstat.github.io/CUTTag_tutorial/#223_Intepret_the_quality_check_results">https://yezhengstat.github.io/CUTTag_tutorial/#223_Intepret_the_quality_check_results</a></p><p><a href="https://www.jianshu.com/p/1a23656a0713">https://www.jianshu.com/p/1a23656a0713</a></p><p><a href="https://mp.weixin.qq.com/s?__biz=MzUxNTkzODIzMg==&mid=2247484049&idx=2&sn=b74aa66a9c9e4bd36a8a1d50e2834226&chksm=f9ae4046ced9c950efee443e1f0692e37dbce2b856e4f2f841ecd723affcff9c67c698ebe2fa&scene=21#wechat_redirect">wechat</a></p><span id="more"></span><hr><h1 id="I-Introduction"><a href="#I-Introduction" class="headerlink" title="I. Introduction"></a>I. Introduction</h1><h2 id="1-1-Overview-of-CUT-amp-Tag"><a href="#1-1-Overview-of-CUT-amp-Tag" class="headerlink" title="1.1. Overview of CUT&amp;Tag"></a>1.1. Overview of CUT&amp;Tag</h2><p>All dynamic processes that take place on DNA in the eukaryotic nucleus occur in the context of a chromatin landscape that comprises nucleosomes and their modifications, transcription factors, and chromatin-associated complexes. A variety of chromatin features mark sites of activating and silencing transcriptional regulatory elements and chromatin domains that differ between cell types and change during development.</p><p>The mapping of chromatin features genome-wide has traditionally been performed using chromatin immunoprecipitation (ChIP), in which chromatin is <strong>cross-linked</strong> and <strong>solubilized</strong>, and an <strong>antibody</strong> to a <strong>protein or modification of interest</strong> is used to <strong>immunoprecipitate the bound DNA</strong> (<font color="green"><strong>Fig. 1a</strong></font>). Very little has changed in the way <strong>ChIP</strong> is most generally performed since it was first described <strong>35 years ago</strong>, and remains fraught with <strong>signal-to-noise issues</strong> and <strong>artifacts</strong>. An alternative chromatin profiling strategy is <strong>enzyme tethering in situ</strong> whereby the chromatin protein or modification of interest is targeted by an <strong>antibody or fusion protein</strong>. Then, the underlying DNA is marked or cleaved, and a succession of enzyme-tethering methods have been introduced over the past two decades. <font color="green"><strong>Cleavage Under Targets &amp; Tagmentation (CUT&amp;Tag)</strong></font> is a tethering method that uses a <font color="green"><strong>protein-A-Tn5 (pA-Tn5) transposome fusion protein</strong></font> (<font color="green"><strong>Fig. 1b</strong></font>). In CUT&amp;Tag, permeabilized cells or nuclei are incubated with antibody to a specified chromatin protein, and then <strong>pA-Tn5 loaded with mosaic end adaptors</strong> is successively tethered to antibody-bound sites. Activation of the transposome by adding magnesium ions[<strong>Mg2+</strong>] results in the <strong>integration of the adaptors into nearby DNA</strong>. These are then amplified to generate sequencing libraries. Antibody-tethered Tn5-based methods achieve high sensitivity owing to stringent washing of samples after pA-Tn5 tethering and the high efficiency of adaptor integration. The <font color="green"><strong>improved signal-to-noise</strong></font> relative to ChIP-seq translates to an order-of-magnitude reduction in the amount of sequencing required to map chromatin features, allowing sample pooling (typically up to 90 samples) for paired-end sequencing on Illumina NGS sequencers by barcoded PCR of libraries.</p><p><img src="/GeekFocus/./1.png" alt="Figure 1. Differences between immunoprecipitation and in antibody-targeted chromatin profiling strategies. A. ChIP-seq experimental procedure. B. CUT&amp;Tag experimental procedure. Cells and nuclei are indicated in grey, chromatin as red nucleosomes, and a specific chromatin protein in green."></p><p>Cells and nuclei are indicated in grey, chromatin as red nucleosomes, and a specific chromatin protein in green.</p><h2 id="1-2-Objectives"><a href="#1-2-Objectives" class="headerlink" title="1.2. Objectives"></a>1.2. Objectives</h2><p>This tutorial is designed for processing and analyzing CUT&amp;Tag data following the <a href="https://www.protocols.io/view/bench-top-cut-amp-tag-bcuhiwt6/abstract">Bench top CUT&amp;Tag V.3 protocol</a> <strong>NC</strong>. The illustration data used in <strong>this tutorial</strong> is the profiling of <strong>histone modifications</strong> in the human lymphoma K562 cell line, but the tutorial is <strong>generally applicable to</strong> any chromatin protein, including <strong>transcription factors, RNA polymerase II</strong>, and epitope-tagged proteins.</p><h2 id="1-3-CUT-amp-Tag-data-processing-and-analysis-outline"><a href="#1-3-CUT-amp-Tag-data-processing-and-analysis-outline" class="headerlink" title="1.3 CUT&amp;Tag data processing and analysis outline."></a>1.3 CUT&amp;Tag data processing and analysis outline.</h2><p><img src="/GeekFocus/./2.png" alt="Figure 2. CUT&amp;Tag data processing and analysis."></p><ol start="3"><li><strong>Alignment</strong>: Bowtie2 alignment; Duplicates; Fragment size; Replicate reproducibility</li></ol><blockquote><p>Bowtie2, Samtools, Picard</p></blockquote><ol start="4"><li><strong>Filtering and Conversion</strong>: Sam to bam; bam to bed</li></ol><blockquote><p>Samtools, Bedtools</p></blockquote><ol start="5"><li><strong>Spike-in Calibration?:</strong> Sam to bam; Bam to bed</li></ol><blockquote><p>Bowtie2, Bedtools</p></blockquote><ol start="6"><li><strong>Peak Calling:</strong> SEACR peak calling; Fragment propotion in peak regions(FRiPs)</li></ol><blockquote><p>SEACR, R: chromVAR</p></blockquote><ol start="7"><li>Visualization: Genome browser; Heatmap</li></ol><blockquote><p>IGV, UCSC browser, Deeptools</p></blockquote><ol start="8"><li>Different Analysis</li><li>Additional alternatives</li></ol><h2 id="1-4-Requirements"><a href="#1-4-Requirements" class="headerlink" title="1.4. Requirements"></a>1.4. Requirements</h2><ul><li>R (versions &gt;&#x3D; 3.6)<ul><li>dplyr</li><li>stringr</li><li>ggplot2</li><li>viridis</li><li>GenomicRanges</li><li><strong>chromVAR</strong></li><li>DESeq2</li><li><strong>ggpubr</strong></li><li><strong>corrplot</strong></li><li>ChIPseqSpikeInFree [Optional]</li></ul></li></ul><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs r">library<span class="hljs-punctuation">(</span>dplyr<span class="hljs-punctuation">)</span><br>library<span class="hljs-punctuation">(</span>stringr<span class="hljs-punctuation">)</span><br>library<span class="hljs-punctuation">(</span>ggplot2<span class="hljs-punctuation">)</span><br>library<span class="hljs-punctuation">(</span>viridis<span class="hljs-punctuation">)</span><br>library<span class="hljs-punctuation">(</span>GenomicRanges<span class="hljs-punctuation">)</span><br>library<span class="hljs-punctuation">(</span>chromVAR<span class="hljs-punctuation">)</span> <span class="hljs-comment">## For FRiP analysis and differential analysis</span><br>library<span class="hljs-punctuation">(</span>DESeq2<span class="hljs-punctuation">)</span> <span class="hljs-comment">## For differential analysis section</span><br>library<span class="hljs-punctuation">(</span>ggpubr<span class="hljs-punctuation">)</span> <span class="hljs-comment">## For customizing figures</span><br>library<span class="hljs-punctuation">(</span>corrplot<span class="hljs-punctuation">)</span> <span class="hljs-comment">## For correlation plot</span><br></code></pre></td></tr></table></figure><ul><li>FastQC(version &gt;&#x3D; 0.11.9)</li><li>Bowtie2 (version &gt;&#x3D; 2.3.4.3)</li><li>samtools (version &gt;&#x3D; 1.10)</li><li>bedtools (version &gt;&#x3D; 2.29.1)</li><li>Picard (version &gt;&#x3D; 2.18.29)</li><li><strong>SEACR (version &gt;&#x3D; 1.3)</strong></li><li>deepTools (version &gt;&#x3D; 2.0)</li></ul><h2 id="1-5-Data-Downloading"><a href="#1-5-Data-Downloading" class="headerlink" title="1.5. Data Downloading"></a>1.5. Data Downloading</h2><ol><li>Using <a href="https://www.ncbi.nlm.nih.gov/sra/docs/sradownload/">SRA Toolkit</a></li><li>Download through <a href="file:///Users/yezheng/Downloads/downloading_fastq_GEO.pdf">European Nucleotide Archive</a>. New ENA Browser: <a href="https://www.ebi.ac.uk/ena/browser/view">https://www.ebi.ac.uk/ena/browser/view</a>. We are using this option as illustration.</li></ol><ul><li><strong>H3K27me3</strong>:<ul><li>SH_Hs_K27m3_NX_0918 as replicate 1: GEO accession: GSE145187, SRA entry: SRX8754646</li><li>SH_Hs_K27m3_Xpc_0107 as replicate 2: GEO accession: GSE145187, SRA entry: SRX7713678</li></ul></li><li><strong>H3K4me3</strong>:<ul><li>SH_Hs_K4m3_NX_0918 as replicate 1: GEO accession: GSE145187, SRA entry: SRX7713692</li><li>SH_Hs_K4m3_Xpc_0107 as replicate 2: GEO accession: GSE145187, SRA entry: SRX7713696</li></ul></li><li><strong>IgG</strong>:<ul><li>SH_Hs_IgG_1x_0924 as replicate 1:GEO accession: GSE145187, SRA entry: SRX8468909</li><li>SH_Hs_IgG_20181224 as replicate 2: GEO accession: GSM3680227, SRA entry: SRX5545346</li></ul></li></ul><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-comment">#example</span><br>wget -O <span class="hljs-variable">$projPath</span>/data/IgG_rep2/IgG_rep2_R1_001.fastq.gz ftp://ftp.sra.ebi.ac.uk/vol1/fastq/SRR875/001/SRR8754611/SRR8754611_1.fastq.gz<br>wget -O <span class="hljs-variable">$projPath</span>/data/IgG_rep2/IgG_rep2_R2_001.fastq.gz ftp://ftp.sra.ebi.ac.uk/vol1/fastq/SRR875/001/SRR8754611/SRR8754611_2.fastq.gz<br></code></pre></td></tr></table></figure><hr><h1 id="II-Data-Pre-processing"><a href="#II-Data-Pre-processing" class="headerlink" title="II. Data Pre-processing"></a>II. Data Pre-processing</h1><p>FASTQC</p><p><strong>Per base sequence content fails the FastQC quality check.</strong></p><p><strong>The discordant sequence content at the begining of the reads are common phenomenon for CUT&amp;Tag reads. Failing to pass the Per base seuqnence content does not mean your data failed.</strong></p><ul><li>It can be due to the Tn5 preference.</li><li>What you might be detecting is <font color="green">the 10-bp</font> periodicity that shows up as a sawtooth pattern in the length distribution. If so, <font color="blue"><strong>this is normal and will not affect alignment or peak calling</strong></font>. In any case we do not recommend trimming as the bowtie2 parameters that we list <font color="blue"><strong>will give accurate mapping information without trimming</strong></font>.</li></ul><h2 id="2-2-Merge-technical-replicates-x2F-lanes-if-needed-Optional"><a href="#2-2-Merge-technical-replicates-x2F-lanes-if-needed-Optional" class="headerlink" title="2.2. Merge technical replicates&#x2F;lanes if needed [Optional]"></a>2.2. Merge technical replicates&#x2F;lanes if needed [Optional]</h2><p>Sometimes, samples are often sequenced across <strong>multiple lanes for efficiency</strong> and can be pooled before alignment. <font color="blue">If you want to <strong>check the reproducibility</strong> between sequences of different lanes of the same sample</font>, you can skip this step and <strong>align</strong> each sequencing file (fastq file) <strong>respectively</strong>.</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-comment">#combination of the data</span><br><span class="hljs-built_in">cat</span> <span class="hljs-variable">$&#123;projPath&#125;</span>/data/<span class="hljs-variable">$&#123;histName&#125;</span>/*_R1_*.fastq.gz &gt;<span class="hljs-variable">$&#123;projPath&#125;</span>/fastq/<span class="hljs-variable">$&#123;histName&#125;</span>_R1.fastq.gz<br></code></pre></td></tr></table></figure><hr><h1 id="III-Alignment"><a href="#III-Alignment" class="headerlink" title="III. Alignment"></a>III. Alignment</h1><h2 id="3-1-Bowtie2-alignment-required"><a href="#3-1-Bowtie2-alignment-required" class="headerlink" title="3.1. Bowtie2 alignment [required]"></a>3.1. Bowtie2 alignment [required]</h2><p>The structure of <font color="blue"><strong>CUT&amp;Tag insert libraries</strong></font> with <font color="blue"><strong>Tn5 adapters</strong></font> and <font color="blue"><strong>barcoded PCR primers</strong></font> is shown below:</p><p><img src="/GeekFocus/./3.png" alt="Figure 4. CUT&amp;Tag insert libraries with the sequence of adapters."></p><p>Our standard pipeline is to perform <font color="blue">single-index 25x25 PE Illumina sequencing??</font> on up to 90 pooled samples on a single HiSeq 2500 flowcell, where <font color="blue">each sample</font> has a <font color="blue">unique PCR primer barcode</font>. Amounts for <strong>each library</strong> are adjusted to provide <strong>~5 million</strong> paired-end reads, which provides high-quality profiling for abundant chromatin features with a specific and high-yield antibody. Less abundant features typically require fewer reads, while <strong>lower-quality antibodies</strong> may increase the number of reads needed for generating robust chromatin profiles. A thorough discussion of feature recall and <strong>sequencing depths for CUT&amp;Tag</strong> has been published (Kaya-Okur et al 2020).</p><h3 id="3-1-1-Alignment-to-ref"><a href="#3-1-1-Alignment-to-ref" class="headerlink" title="3.1.1 Alignment to ref."></a>3.1.1 Alignment to <font color="red">ref</font>.</h3><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs sh">bowtie2 \<br>--end-to-end \<br>--very-sensitive \<br><span class="hljs-comment">#runs a little faster, only consider alignment status of pairs per se</span><br>--no-mixed \<br><span class="hljs-comment">#disablelooks for discordant alignments if it cannot find any concordant alignments. </span><br>--no-discordant \<br>--phred33 \<br><span class="hljs-comment">#-I The minimum fragment length for valid paired-end alignments. Default: 0</span><br>-I 10 \<br>-X 700 \<br>-p <span class="hljs-variable">$&#123;cores&#125;</span> \<br>-x <span class="hljs-variable">$&#123;ref&#125;</span> \<br>-1 <span class="hljs-variable">$&#123;projPath&#125;</span>/fastq/<span class="hljs-variable">$&#123;histName&#125;</span>_R1.fastq.gz -2 <span class="hljs-variable">$&#123;projPath&#125;</span>/fastq/<span class="hljs-variable">$&#123;histName&#125;</span>_R2.fastq.gz \<br>-S <span class="hljs-variable">$&#123;projPath&#125;</span>/alignment/sam/<span class="hljs-variable">$&#123;histName&#125;</span>_bowtie2.sam &amp;&gt; <span class="hljs-variable">$&#123;projPath&#125;</span>/alignment/sam/bowtie2_summary/<span class="hljs-variable">$&#123;histName&#125;</span>_bowtie2.txt<br></code></pre></td></tr></table></figure><p><code>--end-to-end --very-sensitive --no-mixed --no-discordant --phred33 -I 10 -X 700</code> for mapping of <strong>inserts 10-700 bp</strong> in length.</p><p><font color="red"><strong>Critical step</strong></font>: There is no need to trim reads from out standard 25x25 PE sequencing?, as adapter sequences will not be included in reads of inserts &gt;25 bp. However, for users <strong>performing longer sequencing</strong>, reads will need to be trimmed by Cutadapt and mapped by <code>--local --very-sensitive --no-mixed --no-discordant --phred33 -I 10 -X 700</code> to ignore any remaining adapter sequence at the 3’ ends of reads during mapping.</p><p><font color="red">–local</font> In this mode, Bowtie 2 does not require that the entire read align from one end to the other. Rather, some characters may be omitted (“soft clipped”) from the ends <strong>in order to achieve the greatest possible alignment score</strong>. The match bonus <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-ma"><code>--ma</code></a>is used in this mode, and the best possible alignment score is equal to the match bonus (<a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-ma"><code>--ma</code></a>) times the length of the read. Specifying <code>--local</code> and one of the presets (e.g. <code>--local --very-fast</code>) is equivalent to specifying the local version of the preset (<code>--very-fast-local</code>). This is mutually exclusive with <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-end-to-end"><code>--end-to-end</code></a>. <code>--end-to-end</code> is the default mode.</p><h3 id="3-1-2-Alignment-to-spike-in-genome-for-spike-in-calibration-optional-x2F-recommended"><a href="#3-1-2-Alignment-to-spike-in-genome-for-spike-in-calibration-optional-x2F-recommended" class="headerlink" title="3.1.2 Alignment to spike-in genome for spike-in calibration [optional&#x2F;recommended]"></a>3.1.2 Alignment to <font color="red">spike-in genome</font> for spike-in calibration [optional&#x2F;recommended]</h3><p>This section is <strong>optional</strong> but <strong>recommended</strong> depending on your experimental protocol.</p><p><font color="red"><strong>E. coli</strong> DNA is <strong>carried along with</strong> bacterially-produced <strong>pA-Tn5 protein</strong></font> and gets tagmented non-specifically during the reaction. <strong>The fraction of total reads that map to the E.coli genome</strong> <font color="blue"><strong>depends on</strong></font> the <strong>yield of epitope-targeted CUT&amp;Tag</strong>, and so <font color="blue"><strong>depends on</strong></font> the <strong>number of cells used and the abundance of that epitope in chromatin</strong>. Since a constant amount of pATn5 is added to CUT&amp;Tag reactions and brings along a fixed amount of E. coli DNA, E. coli reads can be used to <font color="red"><strong>normalize epitope abundance</strong></font> in a set of experiments. More discussion, please see Section V.</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-comment"># download E.coli K12 MG1655</span><br>bowtie2-build ecoli.fa ecoli<br></code></pre></td></tr></table></figure><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-comment">##== linux command ==##</span><br>spikeInRef=/path/to/index/eoli<br>chromSize=<span class="hljs-string">&quot;hg38.chrom.size&quot;</span><br><span class="hljs-comment"># download ecoli K-12 substr.MG1655[INSDC:U00096.3;size:4.64M;]</span><br>bowtie2-build path/to/Ecoli/fasta/Ecoli.fa /path/to/bowtie2Index/Ecoli<br>bowtie2 --end-to-end --very-sensitive --no-overlap --no-dovetail --no-mixed --no-discordant --phred33 -I 10 -X 700 -p <span class="hljs-variable">$&#123;cores&#125;</span> -x <span class="hljs-variable">$&#123;spikeInRef&#125;</span> -1 _R1.fastq.gz -2 _R2.fastq.gz -S _bowtie2_spikeIn.sam &amp;&gt; log_bowtie2_spikeIn.txt<br><br><span class="hljs-comment">#-f output alignments with bits</span><br><span class="hljs-comment">#-F Do not output alignments with any bits set in INT present in the FLAG field. INT can be specified in hex by beginning with 0x&#x27; (i.e. /^0x[0-9A-F]+/) or in octal by beginning with0&#x27; (i.e./^0 [0-7]+/) </span><br><span class="hljs-comment"># FLAGS 0x2 PROPER_PAIR each segment properly aligned according to the aligner</span><br><span class="hljs-comment"># FLAGS 0x4 UNMAP segment unmapped</span><br>seqDepthDouble=`samtools view -F 0x04 _bowtie2_spikeIn.sam | <span class="hljs-built_in">wc</span> -l`<br>seqDepth=$((seqDepthDouble/<span class="hljs-number">2</span>))<br><span class="hljs-built_in">echo</span> <span class="hljs-variable">$seqDepth</span> &gt; _bowtie2_spikeIn.seqDepth<br></code></pre></td></tr></table></figure><ul><li>For spike-in normalization, reads are aligned to the <strong>E. coli genome U00096.3</strong> with two more parameters <code>--no-overlap</code>and <code>--no-dovetail</code>(<code>--end-to-end --very-sensitive --no-overlap --no-dovetail --no-mixed --no-discordant --phred33 -I 10 -X 700</code>) to avoid possible cross-mapping of the experimental genome to that of the carry-over E. coli DNA that is used for calibration.</li></ul><h3 id="3-1-3-Alignment-summary"><a href="#3-1-3-Alignment-summary" class="headerlink" title="3.1.3 Alignment summary"></a>3.1.3 Alignment summary</h3><p>For more detailed parameters explanation, users can refer to the <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml">bowite2 manual</a>.</p><p>Bowtie2 alignment results summary is saved at <code>log</code> .</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">2984630</span> reads; of these:<br>  <span class="hljs-attribute">2984630</span> (<span class="hljs-number">100</span>.<span class="hljs-number">00</span>%) were paired; of these:<br>    <span class="hljs-attribute">125110</span> (<span class="hljs-number">4</span>.<span class="hljs-number">19</span>%) aligned concordantly <span class="hljs-number">0</span> times<br>    <span class="hljs-attribute">2360430</span> (<span class="hljs-number">79</span>.<span class="hljs-number">09</span>%) aligned concordantly exactly <span class="hljs-number">1</span> time<br>    <span class="hljs-attribute">499090</span> (<span class="hljs-number">16</span>.<span class="hljs-number">72</span>%) aligned concordantly &gt;<span class="hljs-number">1</span> times<br><span class="hljs-attribute">95</span>.<span class="hljs-number">81</span>% overall alignment rate<br></code></pre></td></tr></table></figure><ul><li>2984640 is the <strong>sequencing depth?</strong>, i.e., total number of paired reads.</li><li>125110 is the number of read pairs that fail to be mapped.</li><li>2360430 + 499090 is the number of read paris that are successfully mapped.</li><li>95.81% is the overall alignment rate</li></ul><h2 id="3-2-Report-sequencing-mapping-summary-required"><a href="#3-2-Report-sequencing-mapping-summary-required" class="headerlink" title="3.2 Report sequencing mapping summary [required]"></a>3.2 Report sequencing mapping summary [required]</h2><p>Summarize the raw reads and uniquely mapping reads to report the efficiency of alignment. Alignment frequencies are expected to be &gt;80% for high-quality data. <strong>CUT&amp;Tag</strong> data typically has <font color="red"><strong>very low backgrounds</strong></font>, so as few as 1 million mapped fragments can give robust profiles for a histone modification in the human genome. Profiling of less-abundant transcription factors and chromatin proteins may require 10 times as many mapped fragments for downstream analysis.</p><p>We can evaluate the following metrics:</p><ul><li>Sequencing depth</li><li>Alignment rate</li><li>Number of mappable fragments</li><li>Duplication rate</li><li>Unique library size</li><li>Fragment size distribution</li></ul><h3 id="3-2-1-Sequencing-depth"><a href="#3-2-1-Sequencing-depth" class="headerlink" title="3.2.1 Sequencing depth"></a>3.2.1 Sequencing depth</h3><p>code in this part, <font color="red"><strong>no use</strong></font>. Summary all reads, mapped reads, and mapping ratio</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs R"><span class="hljs-comment">##=== R command ===## </span><br><span class="hljs-comment">## Path to the project and histone list</span><br>projPath <span class="hljs-operator">=</span> <span class="hljs-string">&quot;///CUTTag_tutorial&quot;</span><br>sampleList <span class="hljs-operator">=</span> <span class="hljs-built_in">c</span><span class="hljs-punctuation">(</span><span class="hljs-string">&quot;K27me3_rep1&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;K27me3_rep2&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;K4me3_rep1&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;K4me3_rep2&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;IgG_rep1&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;IgG_rep2&quot;</span><span class="hljs-punctuation">)</span><br>histList <span class="hljs-operator">=</span> <span class="hljs-built_in">c</span><span class="hljs-punctuation">(</span><span class="hljs-string">&quot;K27me3&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;K4me3&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;IgG&quot;</span><span class="hljs-punctuation">)</span><br><br><span class="hljs-comment">## Collect the alignment results from the bowtie2 alignment summary files</span><br>alignResult <span class="hljs-operator">=</span> <span class="hljs-built_in">c</span><span class="hljs-punctuation">(</span><span class="hljs-punctuation">)</span><br><span class="hljs-keyword">for</span><span class="hljs-punctuation">(</span>hist <span class="hljs-keyword">in</span> sampleList<span class="hljs-punctuation">)</span><span class="hljs-punctuation">&#123;</span><br>  alignRes <span class="hljs-operator">=</span> read.table<span class="hljs-punctuation">(</span>paste0<span class="hljs-punctuation">(</span>projPath<span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;/alignment/sam/bowtie2_summary/&quot;</span><span class="hljs-punctuation">,</span> hist<span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;_bowtie2.txt&quot;</span><span class="hljs-punctuation">)</span><span class="hljs-punctuation">,</span> header <span class="hljs-operator">=</span> <span class="hljs-literal">FALSE</span><span class="hljs-punctuation">,</span> fill <span class="hljs-operator">=</span> <span class="hljs-literal">TRUE</span><span class="hljs-punctuation">)</span><br>  alignRate <span class="hljs-operator">=</span> substr<span class="hljs-punctuation">(</span>alignRes<span class="hljs-operator">$</span>V1<span class="hljs-punctuation">[</span><span class="hljs-number">6</span><span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span> <span class="hljs-number">1</span><span class="hljs-punctuation">,</span> nchar<span class="hljs-punctuation">(</span><span class="hljs-built_in">as.character</span><span class="hljs-punctuation">(</span>alignRes<span class="hljs-operator">$</span>V1<span class="hljs-punctuation">[</span><span class="hljs-number">6</span><span class="hljs-punctuation">]</span><span class="hljs-punctuation">)</span><span class="hljs-punctuation">)</span><span class="hljs-operator">-</span><span class="hljs-number">1</span><span class="hljs-punctuation">)</span><br>  histInfo <span class="hljs-operator">=</span> strsplit<span class="hljs-punctuation">(</span>hist<span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;_&quot;</span><span class="hljs-punctuation">)</span><span class="hljs-punctuation">[[</span><span class="hljs-number">1</span><span class="hljs-punctuation">]</span><span class="hljs-punctuation">]</span><br>  alignResult <span class="hljs-operator">=</span> data.frame<span class="hljs-punctuation">(</span>Histone <span class="hljs-operator">=</span> histInfo<span class="hljs-punctuation">[</span><span class="hljs-number">1</span><span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span> Replicate <span class="hljs-operator">=</span> histInfo<span class="hljs-punctuation">[</span><span class="hljs-number">2</span><span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span> <br>                           SequencingDepth <span class="hljs-operator">=</span> alignRes<span class="hljs-operator">$</span>V1<span class="hljs-punctuation">[</span><span class="hljs-number">1</span><span class="hljs-punctuation">]</span> <span class="hljs-operator">%&gt;%</span> <span class="hljs-built_in">as.character</span> <span class="hljs-operator">%&gt;%</span> <span class="hljs-built_in">as.numeric</span><span class="hljs-punctuation">,</span> <br>                           MappedFragNum_hg38 <span class="hljs-operator">=</span> alignRes<span class="hljs-operator">$</span>V1<span class="hljs-punctuation">[</span><span class="hljs-number">4</span><span class="hljs-punctuation">]</span> <span class="hljs-operator">%&gt;%</span> <span class="hljs-built_in">as.character</span> <span class="hljs-operator">%&gt;%</span> <span class="hljs-built_in">as.numeric</span> <span class="hljs-operator">+</span> alignRes<span class="hljs-operator">$</span>V1<span class="hljs-punctuation">[</span><span class="hljs-number">5</span><span class="hljs-punctuation">]</span> <span class="hljs-operator">%&gt;%</span> <span class="hljs-built_in">as.character</span> <span class="hljs-operator">%&gt;%</span> <span class="hljs-built_in">as.numeric</span><span class="hljs-punctuation">,</span> <br>                           AlignmentRate_hg38 <span class="hljs-operator">=</span> alignRate <span class="hljs-operator">%&gt;%</span> <span class="hljs-built_in">as.numeric</span><span class="hljs-punctuation">)</span>  <span class="hljs-operator">%&gt;%</span> rbind<span class="hljs-punctuation">(</span>alignResult<span class="hljs-punctuation">,</span> .<span class="hljs-punctuation">)</span><br><span class="hljs-punctuation">&#125;</span><br>alignResult<span class="hljs-operator">$</span>Histone <span class="hljs-operator">=</span> factor<span class="hljs-punctuation">(</span>alignResult<span class="hljs-operator">$</span>Histone<span class="hljs-punctuation">,</span> levels <span class="hljs-operator">=</span> histList<span class="hljs-punctuation">)</span><br>alignResult <span class="hljs-operator">%&gt;%</span> mutate<span class="hljs-punctuation">(</span>AlignmentRate_hg38 <span class="hljs-operator">=</span> paste0<span class="hljs-punctuation">(</span>AlignmentRate_hg38<span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;%&quot;</span><span class="hljs-punctuation">)</span><span class="hljs-punctuation">)</span><br></code></pre></td></tr></table></figure><h3 id="3-2-2-Spike-in-alignment"><a href="#3-2-2-Spike-in-alignment" class="headerlink" title="3.2.2 Spike-in alignment"></a>3.2.2 Spike-in alignment</h3><p>Summary of bowtie2 log file</p><h3 id="3-2-3-Summarize-the-alignment-to-hg38-and-E-coli"><a href="#3-2-3-Summarize-the-alignment-to-hg38-and-E-coli" class="headerlink" title="3.2.3 Summarize the alignment to hg38 and E.coli"></a>3.2.3 Summarize the alignment to hg38 and E.coli</h3><p>Summary of bowtie2 log file(ref and ecoli)</p><h3 id="3-2-4-Visualizing-the-sequencing-depth-and-alignment-results"><a href="#3-2-4-Visualizing-the-sequencing-depth-and-alignment-results" class="headerlink" title="3.2.4 Visualizing the sequencing depth and alignment results"></a>3.2.4 Visualizing the sequencing depth and alignment results</h3><p><font color="red"><strong>No use</strong></font> . barplot learning</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-comment">## Generate sequencing depth boxplot</span><br>fig3A = alignResult %&gt;% ggplot(aes(x = Histone, y = SequencingDepth/1000000, fill = Histone)) +<br>    geom_boxplot() +<br>    geom_jitter(aes(color = Replicate), position = position_jitter(0.15)) +<br>    scale_fill_viridis(discrete = TRUE, begin = 0.1, end = 0.9, option = <span class="hljs-string">&quot;magma&quot;</span>, alpha = 0.8) +<br>    scale_color_viridis(discrete = TRUE, begin = 0.1, end = 0.9) +<br>    theme_bw(base_size = 18) +<br>    ylab(<span class="hljs-string">&quot;Sequencing Depth per Million&quot;</span>) +<br>    xlab(<span class="hljs-string">&quot;&quot;</span>) + <br>    ggtitle(<span class="hljs-string">&quot;A. Sequencing Depth&quot;</span>)<br></code></pre></td></tr></table></figure><p>In a typical <strong>CUT&amp;Tag experiment</strong> targeting the abundant <strong>H3K27me3</strong> histone modification in <strong>65,000</strong> <strong>K562 cells</strong>, the <font color="red"><strong>percentage</strong> of <strong>E. coli</strong> reads range from ~<strong>0.01% to 10%</strong></font>. With <font color="red"><strong>fewer cells</strong> or <strong>less abundant epitopes</strong></font>, E. coli reads can comprise[<strong>more</strong>] as much as 70% or the total mapped reads. For <font color="red"><strong>IgG</strong> controls</font>, the percentage of <strong>E. coli</strong> reads is typically <font color="red"><strong>much higher</strong></font> than that for an abundant histone modification.</p><h2 id="3-3-Remove-duplicates-optional-x2F-required"><a href="#3-3-Remove-duplicates-optional-x2F-required" class="headerlink" title="3.3. Remove duplicates [optional&#x2F;required]"></a>3.3. Remove duplicates [optional&#x2F;required]</h2><p>CUT&amp;Tag integrates adapters into DNA in the vicinity of the antibody-tethered pA-Tn5, and the exact sites of integration are affected by the accessibility of surrounding DNA. For this reason fragments that share exact starting and ending positions are expected to be common, and <font color="red">such ‘duplicates’ <strong>may not be due to duplication during PCR</strong></font>. In practice, we have found that the <font color="red">apparent <strong>duplication rate is low for high quality CUT&amp;Tag datasets</strong></font>, and even the apparent ‘duplicate’ fragments are <strong>likely to be true fragments</strong>. Thus, we <font color="red"><strong>do not recommend removing</strong> the duplicates</font>. In experiments with very small amounts of material or where PCR duplication is suspected, duplicates can be removed. The following commands show how to check the duplication rate using <a href="https://broadinstitute.github.io/picard/">Picard</a>.</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-comment">##== linux command ==##</span><br><span class="hljs-comment">## depending on how you load picard and your server environment, the picardCMD can be different. Adjust accordingly.</span><br>picardCMD=<span class="hljs-string">&quot;java -jar picard.jar&quot;</span><br><span class="hljs-built_in">mkdir</span> -p <span class="hljs-variable">$projPath</span>/alignment/removeDuplicate/picard_summary<br><br><span class="hljs-comment">## Sort by coordinate</span><br><span class="hljs-variable">$picardCMD</span> SortSam I=<span class="hljs-variable">$projPath</span>/alignment/sam/<span class="hljs-variable">$&#123;histName&#125;</span>_bowtie2.sam O=<span class="hljs-variable">$projPath</span>/alignment/sam/<span class="hljs-variable">$&#123;histName&#125;</span>_bowtie2.sorted.sam SORT_ORDER=coordinate<br><br><span class="hljs-comment">## mark duplicates</span><br><span class="hljs-variable">$picardCMD</span> MarkDuplicates I=<span class="hljs-variable">$projPath</span>/alignment/sam/<span class="hljs-variable">$&#123;histName&#125;</span>_bowtie2.sorted.sam O=<span class="hljs-variable">$projPath</span>/alignment/removeDuplicate/<span class="hljs-variable">$&#123;histName&#125;</span>_bowtie2.sorted.dupMarked.sam METRICS_FILE=<span class="hljs-variable">$projPath</span>/alignment/removeDuplicate/picard_summary/<span class="hljs-variable">$&#123;histName&#125;</span>_picard.dupMark.txt<br><br><span class="hljs-comment">## remove duplicates</span><br>picardCMD MarkDuplicates I=<span class="hljs-variable">$projPath</span>/alignment/sam/<span class="hljs-variable">$&#123;histName&#125;</span>_bowtie2.sorted.sam O=<span class="hljs-variable">$projPath</span>/alignment/removeDuplicate/<span class="hljs-variable">$&#123;histName&#125;</span>_bowtie2.sorted.rmDup.sam REMOVE_DUPLICATES=<span class="hljs-literal">true</span> METRICS_FILE=<span class="hljs-variable">$projPath</span>/alignment/removeDuplicate/picard_summary/<span class="hljs-variable">$&#123;histName&#125;</span>_picard.rmDup.txt<br></code></pre></td></tr></table></figure><p>We summarize the apparent duplication rate and calculate the unique library size without duplicates.</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs r"><span class="hljs-comment">##=== R command ===## </span><br><span class="hljs-comment">## Summarize the duplication information from the picard summary outputs.</span><br>library<span class="hljs-punctuation">(</span>magrittr<span class="hljs-punctuation">)</span><br>libry<span class="hljs-punctuation">(</span>dplyr<span class="hljs-punctuation">)</span><br>libry<span class="hljs-punctuation">)</span><span class="hljs-punctuation">(</span>idyverse<br>sampleList <span class="hljs-operator">=</span> <span class="hljs-built_in">c</span><span class="hljs-punctuation">(</span><span class="hljs-string">&quot;K27me3_rep1&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;K27me3_rep2&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;K4me3_rep1&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;K4me3_rep2&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;IgG_rep1&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;IgG_rep2&quot;</span><span class="hljs-punctuation">)</span><br>histList <span class="hljs-operator">=</span> <span class="hljs-built_in">c</span><span class="hljs-punctuation">(</span><span class="hljs-string">&quot;K27me3&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;K4me3&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;IgG&quot;</span><span class="hljs-punctuation">)</span><br><br>dupResult <span class="hljs-operator">=</span> <span class="hljs-built_in">c</span><span class="hljs-punctuation">(</span><span class="hljs-punctuation">)</span><br><span class="hljs-keyword">for</span><span class="hljs-punctuation">(</span>hist <span class="hljs-keyword">in</span> sampleList<span class="hljs-punctuation">)</span><span class="hljs-punctuation">&#123;</span><br>  dupRes <span class="hljs-operator">=</span> read.table<span class="hljs-punctuation">(</span>paste0<span class="hljs-punctuation">(</span>projPath<span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;/alignment/removeDuplicate/picard_summary/&quot;</span><span class="hljs-punctuation">,</span> hist<span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;_picard.rmDup.txt&quot;</span><span class="hljs-punctuation">)</span><span class="hljs-punctuation">,</span> header <span class="hljs-operator">=</span> <span class="hljs-literal">TRUE</span><span class="hljs-punctuation">,</span> fill <span class="hljs-operator">=</span> <span class="hljs-literal">TRUE</span><span class="hljs-punctuation">)</span><br>  <br>  histInfo <span class="hljs-operator">=</span> strsplit<span class="hljs-punctuation">(</span>hist<span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;_&quot;</span><span class="hljs-punctuation">)</span><span class="hljs-punctuation">[[</span><span class="hljs-number">1</span><span class="hljs-punctuation">]</span><span class="hljs-punctuation">]</span><br>  dupResult <span class="hljs-operator">=</span> data.frame<span class="hljs-punctuation">(</span>Histone <span class="hljs-operator">=</span> histInfo<span class="hljs-punctuation">[</span><span class="hljs-number">1</span><span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span> Replicate <span class="hljs-operator">=</span> histInfo<span class="hljs-punctuation">[</span><span class="hljs-number">2</span><span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span> MappedFragNum_hg38 <span class="hljs-operator">=</span> dupRes<span class="hljs-operator">$</span>READ_PAIRS_EXAMINED<span class="hljs-punctuation">[</span><span class="hljs-number">1</span><span class="hljs-punctuation">]</span> <span class="hljs-operator">%&gt;%</span> <span class="hljs-built_in">as.character</span> <span class="hljs-operator">%&gt;%</span> <span class="hljs-built_in">as.numeric</span><span class="hljs-punctuation">,</span> DuplicationRate <span class="hljs-operator">=</span> dupRes<span class="hljs-operator">$</span>PERCENT_DUPLICATION<span class="hljs-punctuation">[</span><span class="hljs-number">1</span><span class="hljs-punctuation">]</span> <span class="hljs-operator">%&gt;%</span> <span class="hljs-built_in">as.character</span> <span class="hljs-operator">%&gt;%</span> <span class="hljs-built_in">as.numeric</span> <span class="hljs-operator">*</span> <span class="hljs-number">100</span><span class="hljs-punctuation">,</span> EstimatedLibrarySize <span class="hljs-operator">=</span> dupRes<span class="hljs-operator">$</span>ESTIMATED_LIBRARY_SIZE<span class="hljs-punctuation">[</span><span class="hljs-number">1</span><span class="hljs-punctuation">]</span> <span class="hljs-operator">%&gt;%</span> <span class="hljs-built_in">as.character</span> <span class="hljs-operator">%&gt;%</span> <span class="hljs-built_in">as.numeric</span><span class="hljs-punctuation">)</span> <span class="hljs-operator">%&gt;%</span> mutate<span class="hljs-punctuation">(</span>UniqueFragNum <span class="hljs-operator">=</span> MappedFragNum_hg38 <span class="hljs-operator">*</span> <span class="hljs-punctuation">(</span><span class="hljs-number">1</span><span class="hljs-operator">-</span>DuplicationRate<span class="hljs-operator">/</span><span class="hljs-number">100</span><span class="hljs-punctuation">)</span><span class="hljs-punctuation">)</span>  <span class="hljs-operator">%&gt;%</span> rbind<span class="hljs-punctuation">(</span>dupResult<span class="hljs-punctuation">,</span> .<span class="hljs-punctuation">)</span><br><span class="hljs-punctuation">&#125;</span><br>dupResult<span class="hljs-operator">$</span>Histone <span class="hljs-operator">=</span> factor<span class="hljs-punctuation">(</span>dupResult<span class="hljs-operator">$</span>Histone<span class="hljs-punctuation">,</span> levels <span class="hljs-operator">=</span> histList<span class="hljs-punctuation">)</span><br>alignDupSummary <span class="hljs-operator">=</span> left_join<span class="hljs-punctuation">(</span>alignSummary<span class="hljs-punctuation">,</span> dupResult<span class="hljs-punctuation">,</span> by <span class="hljs-operator">=</span> <span class="hljs-built_in">c</span><span class="hljs-punctuation">(</span><span class="hljs-string">&quot;Histone&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;Replicate&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;MappedFragNum_hg38&quot;</span><span class="hljs-punctuation">)</span><span class="hljs-punctuation">)</span> <span class="hljs-operator">%&gt;%</span> mutate<span class="hljs-punctuation">(</span>DuplicationRate <span class="hljs-operator">=</span> paste0<span class="hljs-punctuation">(</span>DuplicationRate<span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;%&quot;</span><span class="hljs-punctuation">)</span><span class="hljs-punctuation">)</span><br>alignDupSummary<br></code></pre></td></tr></table></figure><p>计算总reads，比对到ref和ecoli的frag和ratio，计算<strong>duplicationrate，estimatedlibrarysize和uniqueFragNum</strong></p><ul><li>In these example datasets, the <strong>IgG</strong> control samples have <strong>relatively high duplication rates</strong>, since reads in this sample derive from <strong>non-specific tagmentation</strong> in the CUT&amp;Tag reactions. Therefore, <font color="red">it is appropriate to <strong>remove the duplicates</strong> from the <strong>IgG</strong> datasets before downstream analysis</font>.</li><li>The <font color="red"><strong>estimated library size</strong></font> are the estimated <strong>number of unique molecules in the library based on PE duplication</strong> calculated by <strong>Picard</strong>.</li><li>The estimated library sizes is proportional to the <strong>abundance of the targeted epitope</strong> and to the <strong>quality of the antibody</strong> used, while the estimated library sizes of <font color="red">IgG</font> samples are expected to be <font color="red">very low</font>.</li><li><strong>Unique fragment number</strong> is calculated by the MappedFragNum_hg38 * (1-DuplicationRate&#x2F;100).</li></ul><p><font color="red"><strong>no use</strong>, code</font></p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs r"><span class="hljs-comment">##=== R command ===## </span><br><span class="hljs-comment">## generate boxplot figure for the  duplication rate</span><br>fig4A <span class="hljs-operator">=</span> dupResult <span class="hljs-operator">%&gt;%</span> ggplot<span class="hljs-punctuation">(</span>aes<span class="hljs-punctuation">(</span>x <span class="hljs-operator">=</span> Histone<span class="hljs-punctuation">,</span> y <span class="hljs-operator">=</span> DuplicationRate<span class="hljs-punctuation">,</span> fill <span class="hljs-operator">=</span> Histone<span class="hljs-punctuation">)</span><span class="hljs-punctuation">)</span> <span class="hljs-operator">+</span><br>    geom_boxplot<span class="hljs-punctuation">(</span><span class="hljs-punctuation">)</span> <span class="hljs-operator">+</span><br>    geom_jitter<span class="hljs-punctuation">(</span>aes<span class="hljs-punctuation">(</span>color <span class="hljs-operator">=</span> Replicate<span class="hljs-punctuation">)</span><span class="hljs-punctuation">,</span> position <span class="hljs-operator">=</span> position_jitter<span class="hljs-punctuation">(</span><span class="hljs-number">0.15</span><span class="hljs-punctuation">)</span><span class="hljs-punctuation">)</span> <span class="hljs-operator">+</span><br>    scale_fill_viridis<span class="hljs-punctuation">(</span>discrete <span class="hljs-operator">=</span> <span class="hljs-literal">TRUE</span><span class="hljs-punctuation">,</span> begin <span class="hljs-operator">=</span> <span class="hljs-number">0.1</span><span class="hljs-punctuation">,</span> end <span class="hljs-operator">=</span> <span class="hljs-number">0.9</span><span class="hljs-punctuation">,</span> option <span class="hljs-operator">=</span> <span class="hljs-string">&quot;magma&quot;</span><span class="hljs-punctuation">,</span> alpha <span class="hljs-operator">=</span> <span class="hljs-number">0.8</span><span class="hljs-punctuation">)</span> <span class="hljs-operator">+</span><br>    scale_color_viridis<span class="hljs-punctuation">(</span>discrete <span class="hljs-operator">=</span> <span class="hljs-literal">TRUE</span><span class="hljs-punctuation">,</span> begin <span class="hljs-operator">=</span> <span class="hljs-number">0.1</span><span class="hljs-punctuation">,</span> end <span class="hljs-operator">=</span> <span class="hljs-number">0.9</span><span class="hljs-punctuation">)</span> <span class="hljs-operator">+</span><br>    theme_bw<span class="hljs-punctuation">(</span>base_size <span class="hljs-operator">=</span> <span class="hljs-number">18</span><span class="hljs-punctuation">)</span> <span class="hljs-operator">+</span><br>    ylab<span class="hljs-punctuation">(</span><span class="hljs-string">&quot;Duplication Rate (*100%)&quot;</span><span class="hljs-punctuation">)</span> <span class="hljs-operator">+</span><br>    xlab<span class="hljs-punctuation">(</span><span class="hljs-string">&quot;&quot;</span><span class="hljs-punctuation">)</span> <br><span class="hljs-comment">## generate boxplot figure for the  Estimated Library Size</span><br>fig4B <span class="hljs-operator">=</span> dupResult <span class="hljs-operator">%&gt;%</span> ggplot<span class="hljs-punctuation">(</span>aes<span class="hljs-punctuation">(</span>x <span class="hljs-operator">=</span> Histone<span class="hljs-punctuation">,</span> y <span class="hljs-operator">=</span> EstimatedLibrarySize<span class="hljs-punctuation">,</span> fill <span class="hljs-operator">=</span> Histone<span class="hljs-punctuation">)</span><span class="hljs-punctuation">)</span> <span class="hljs-operator">+</span><br>    geom_boxplot<span class="hljs-punctuation">(</span><span class="hljs-punctuation">)</span> <span class="hljs-operator">+</span><br>    geom_jitter<span class="hljs-punctuation">(</span>aes<span class="hljs-punctuation">(</span>color <span class="hljs-operator">=</span> Replicate<span class="hljs-punctuation">)</span><span class="hljs-punctuation">,</span> position <span class="hljs-operator">=</span> position_jitter<span class="hljs-punctuation">(</span><span class="hljs-number">0.15</span><span class="hljs-punctuation">)</span><span class="hljs-punctuation">)</span> <span class="hljs-operator">+</span><br>    scale_fill_viridis<span class="hljs-punctuation">(</span>discrete <span class="hljs-operator">=</span> <span class="hljs-literal">TRUE</span><span class="hljs-punctuation">,</span> begin <span class="hljs-operator">=</span> <span class="hljs-number">0.1</span><span class="hljs-punctuation">,</span> end <span class="hljs-operator">=</span> <span class="hljs-number">0.9</span><span class="hljs-punctuation">,</span> option <span class="hljs-operator">=</span> <span class="hljs-string">&quot;magma&quot;</span><span class="hljs-punctuation">,</span> alpha <span class="hljs-operator">=</span> <span class="hljs-number">0.8</span><span class="hljs-punctuation">)</span> <span class="hljs-operator">+</span><br>    scale_color_viridis<span class="hljs-punctuation">(</span>discrete <span class="hljs-operator">=</span> <span class="hljs-literal">TRUE</span><span class="hljs-punctuation">,</span> begin <span class="hljs-operator">=</span> <span class="hljs-number">0.1</span><span class="hljs-punctuation">,</span> end <span class="hljs-operator">=</span> <span class="hljs-number">0.9</span><span class="hljs-punctuation">)</span> <span class="hljs-operator">+</span><br>    theme_bw<span class="hljs-punctuation">(</span>base_size <span class="hljs-operator">=</span> <span class="hljs-number">18</span><span class="hljs-punctuation">)</span> <span class="hljs-operator">+</span><br>    ylab<span class="hljs-punctuation">(</span><span class="hljs-string">&quot;Estimated Library Size&quot;</span><span class="hljs-punctuation">)</span> <span class="hljs-operator">+</span><br>    xlab<span class="hljs-punctuation">(</span><span class="hljs-string">&quot;&quot;</span><span class="hljs-punctuation">)</span> <br><span class="hljs-comment">## generate boxplot figure for the  Unique Fragments</span><br>fig4C <span class="hljs-operator">=</span> dupResult <span class="hljs-operator">%&gt;%</span> ggplot<span class="hljs-punctuation">(</span>aes<span class="hljs-punctuation">(</span>x <span class="hljs-operator">=</span> Histone<span class="hljs-punctuation">,</span> y <span class="hljs-operator">=</span> UniqueFragNum<span class="hljs-punctuation">,</span> fill <span class="hljs-operator">=</span> Histone<span class="hljs-punctuation">)</span><span class="hljs-punctuation">)</span> <span class="hljs-operator">+</span><br>    geom_boxplot<span class="hljs-punctuation">(</span><span class="hljs-punctuation">)</span> <span class="hljs-operator">+</span><br>    geom_jitter<span class="hljs-punctuation">(</span>aes<span class="hljs-punctuation">(</span>color <span class="hljs-operator">=</span> Replicate<span class="hljs-punctuation">)</span><span class="hljs-punctuation">,</span> position <span class="hljs-operator">=</span> position_jitter<span class="hljs-punctuation">(</span><span class="hljs-number">0.15</span><span class="hljs-punctuation">)</span><span class="hljs-punctuation">)</span> <span class="hljs-operator">+</span><br>    scale_fill_viridis<span class="hljs-punctuation">(</span>discrete <span class="hljs-operator">=</span> <span class="hljs-literal">TRUE</span><span class="hljs-punctuation">,</span> begin <span class="hljs-operator">=</span> <span class="hljs-number">0.1</span><span class="hljs-punctuation">,</span> end <span class="hljs-operator">=</span> <span class="hljs-number">0.9</span><span class="hljs-punctuation">,</span> option <span class="hljs-operator">=</span> <span class="hljs-string">&quot;magma&quot;</span><span class="hljs-punctuation">,</span> alpha <span class="hljs-operator">=</span> <span class="hljs-number">0.8</span><span class="hljs-punctuation">)</span> <span class="hljs-operator">+</span><br>    scale_color_viridis<span class="hljs-punctuation">(</span>discrete <span class="hljs-operator">=</span> <span class="hljs-literal">TRUE</span><span class="hljs-punctuation">,</span> begin <span class="hljs-operator">=</span> <span class="hljs-number">0.1</span><span class="hljs-punctuation">,</span> end <span class="hljs-operator">=</span> <span class="hljs-number">0.9</span><span class="hljs-punctuation">)</span> <span class="hljs-operator">+</span><br>    theme_bw<span class="hljs-punctuation">(</span>base_size <span class="hljs-operator">=</span> <span class="hljs-number">18</span><span class="hljs-punctuation">)</span> <span class="hljs-operator">+</span><br>    ylab<span class="hljs-punctuation">(</span><span class="hljs-string">&quot;# of Unique Fragments&quot;</span><span class="hljs-punctuation">)</span> <span class="hljs-operator">+</span><br>    xlab<span class="hljs-punctuation">(</span><span class="hljs-string">&quot;&quot;</span><span class="hljs-punctuation">)</span><br><br>ggarrange<span class="hljs-punctuation">(</span>fig4A<span class="hljs-punctuation">,</span> fig4B<span class="hljs-punctuation">,</span> fig4C<span class="hljs-punctuation">,</span> ncol <span class="hljs-operator">=</span> <span class="hljs-number">3</span><span class="hljs-punctuation">,</span> common.legend <span class="hljs-operator">=</span> <span class="hljs-literal">TRUE</span><span class="hljs-punctuation">,</span> legend<span class="hljs-operator">=</span><span class="hljs-string">&quot;bottom&quot;</span><span class="hljs-punctuation">)</span><br></code></pre></td></tr></table></figure><h2 id="3-4-Assess-mapped-fragment-size-distribution-Required"><a href="#3-4-Assess-mapped-fragment-size-distribution-Required" class="headerlink" title="3.4. Assess mapped fragment size distribution [Required]"></a>3.4. Assess mapped fragment size distribution [Required]</h2><p>CUT&amp;Tag inserts adapters on either side of chromatin particles in the vicinity of the tethered enzyme, although tagmentation within chromatin particles can also occur. So, CUT&amp;Tag reactions targeting a histone modification predominantly results in fragments that are nucleosomal lengths (~180 bp), or multiples of that length. CUT&amp;Tag targeting transcription factors predominantly produce nucleosome-sized fragments and variable amounts of shorter fragments, from neighboring nucleosomes and the factor-bound site, respectively. Tagmentation of DNA on the surface of nucleosomes also occurs, and plotting fragment lengths with single-basepair resolution reveal a 10-bp sawtooth periodicity, which is typical of successful CUT&amp;Tag experiments.</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs linux">##== linux command ==##<br>mkdir -p $projPath/alignment/sam/fragmentLen<br><br>## Extract the 9th column from the alignment sam file which is the fragment length<br>samtools view -F 0x04 $projPath/alignment/sam/$&#123;histName&#125;_bowtie2.sam | awk -F&#x27;\t&#x27; &#x27;function abs(x)&#123;return ((x &lt; 0.0) ? -x : x)&#125; &#123;print abs($9)&#125;&#x27; | sort | uniq -c | awk -v OFS=&quot;\t&quot; &#x27;&#123;print $2, $1/2&#125;&#x27; &gt;$projPath/alignment/sam/fragmentLen/$&#123;histName&#125;_fragmentLen.txt<br></code></pre></td></tr></table></figure><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs r"><span class="hljs-comment">##=== R command ===## </span><br><span class="hljs-comment">## Collect the fragment size information</span><br>fragLen <span class="hljs-operator">=</span> <span class="hljs-built_in">c</span><span class="hljs-punctuation">(</span><span class="hljs-punctuation">)</span><br><span class="hljs-keyword">for</span><span class="hljs-punctuation">(</span>hist <span class="hljs-keyword">in</span> sampleList<span class="hljs-punctuation">)</span><span class="hljs-punctuation">&#123;</span><br>  <br>  histInfo <span class="hljs-operator">=</span> strsplit<span class="hljs-punctuation">(</span>hist<span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;_&quot;</span><span class="hljs-punctuation">)</span><span class="hljs-punctuation">[[</span><span class="hljs-number">1</span><span class="hljs-punctuation">]</span><span class="hljs-punctuation">]</span><br>  fragLen <span class="hljs-operator">=</span> read.table<span class="hljs-punctuation">(</span>paste0<span class="hljs-punctuation">(</span>projPath<span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;/alignment/sam/fragmentLen/&quot;</span><span class="hljs-punctuation">,</span> hist<span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;_fragmentLen.txt&quot;</span><span class="hljs-punctuation">)</span><span class="hljs-punctuation">,</span> header <span class="hljs-operator">=</span> <span class="hljs-literal">FALSE</span><span class="hljs-punctuation">)</span> <span class="hljs-operator">%&gt;%</span> mutate<span class="hljs-punctuation">(</span>fragLen <span class="hljs-operator">=</span> V1 <span class="hljs-operator">%&gt;%</span> <span class="hljs-built_in">as.numeric</span><span class="hljs-punctuation">,</span> fragCount <span class="hljs-operator">=</span> V2 <span class="hljs-operator">%&gt;%</span> <span class="hljs-built_in">as.numeric</span><span class="hljs-punctuation">,</span> Weight <span class="hljs-operator">=</span> <span class="hljs-built_in">as.numeric</span><span class="hljs-punctuation">(</span>V2<span class="hljs-punctuation">)</span><span class="hljs-operator">/</span><span class="hljs-built_in">sum</span><span class="hljs-punctuation">(</span><span class="hljs-built_in">as.numeric</span><span class="hljs-punctuation">(</span>V2<span class="hljs-punctuation">)</span><span class="hljs-punctuation">)</span><span class="hljs-punctuation">,</span> Histone <span class="hljs-operator">=</span> histInfo<span class="hljs-punctuation">[</span><span class="hljs-number">1</span><span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span> Replicate <span class="hljs-operator">=</span> histInfo<span class="hljs-punctuation">[</span><span class="hljs-number">2</span><span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span> sampleInfo <span class="hljs-operator">=</span> hist<span class="hljs-punctuation">)</span> <span class="hljs-operator">%&gt;%</span> rbind<span class="hljs-punctuation">(</span>fragLen<span class="hljs-punctuation">,</span> .<span class="hljs-punctuation">)</span> <br><span class="hljs-punctuation">&#125;</span><br>fragLen<span class="hljs-operator">$</span>sampleInfo <span class="hljs-operator">=</span> factor<span class="hljs-punctuation">(</span>fragLen<span class="hljs-operator">$</span>sampleInfo<span class="hljs-punctuation">,</span> levels <span class="hljs-operator">=</span> sampleList<span class="hljs-punctuation">)</span><br>fragLen<span class="hljs-operator">$</span>Histone <span class="hljs-operator">=</span> factor<span class="hljs-punctuation">(</span>fragLen<span class="hljs-operator">$</span>Histone<span class="hljs-punctuation">,</span> levels <span class="hljs-operator">=</span> histList<span class="hljs-punctuation">)</span><br><span class="hljs-comment">## Generate the fragment size density plot (violin plot)</span><br>fig5A <span class="hljs-operator">=</span> fragLen <span class="hljs-operator">%&gt;%</span> ggplot<span class="hljs-punctuation">(</span>aes<span class="hljs-punctuation">(</span>x <span class="hljs-operator">=</span> sampleInfo<span class="hljs-punctuation">,</span> y <span class="hljs-operator">=</span> fragLen<span class="hljs-punctuation">,</span> weight <span class="hljs-operator">=</span> Weight<span class="hljs-punctuation">,</span> fill <span class="hljs-operator">=</span> Histone<span class="hljs-punctuation">)</span><span class="hljs-punctuation">)</span> <span class="hljs-operator">+</span><br>    geom_violin<span class="hljs-punctuation">(</span>bw <span class="hljs-operator">=</span> <span class="hljs-number">5</span><span class="hljs-punctuation">)</span> <span class="hljs-operator">+</span><br>    scale_y_continuous<span class="hljs-punctuation">(</span>breaks <span class="hljs-operator">=</span> seq<span class="hljs-punctuation">(</span><span class="hljs-number">0</span><span class="hljs-punctuation">,</span> <span class="hljs-number">800</span><span class="hljs-punctuation">,</span> <span class="hljs-number">50</span><span class="hljs-punctuation">)</span><span class="hljs-punctuation">)</span> <span class="hljs-operator">+</span><br>    scale_fill_viridis<span class="hljs-punctuation">(</span>discrete <span class="hljs-operator">=</span> <span class="hljs-literal">TRUE</span><span class="hljs-punctuation">,</span> begin <span class="hljs-operator">=</span> <span class="hljs-number">0.1</span><span class="hljs-punctuation">,</span> end <span class="hljs-operator">=</span> <span class="hljs-number">0.9</span><span class="hljs-punctuation">,</span> option <span class="hljs-operator">=</span> <span class="hljs-string">&quot;magma&quot;</span><span class="hljs-punctuation">,</span> alpha <span class="hljs-operator">=</span> <span class="hljs-number">0.8</span><span class="hljs-punctuation">)</span> <span class="hljs-operator">+</span><br>    scale_color_viridis<span class="hljs-punctuation">(</span>discrete <span class="hljs-operator">=</span> <span class="hljs-literal">TRUE</span><span class="hljs-punctuation">,</span> begin <span class="hljs-operator">=</span> <span class="hljs-number">0.1</span><span class="hljs-punctuation">,</span> end <span class="hljs-operator">=</span> <span class="hljs-number">0.9</span><span class="hljs-punctuation">)</span> <span class="hljs-operator">+</span><br>    theme_bw<span class="hljs-punctuation">(</span>base_size <span class="hljs-operator">=</span> <span class="hljs-number">20</span><span class="hljs-punctuation">)</span> <span class="hljs-operator">+</span><br>    ggpubr<span class="hljs-operator">::</span>rotate_x_text<span class="hljs-punctuation">(</span>angle <span class="hljs-operator">=</span> <span class="hljs-number">20</span><span class="hljs-punctuation">)</span> <span class="hljs-operator">+</span><br>    ylab<span class="hljs-punctuation">(</span><span class="hljs-string">&quot;Fragment Length&quot;</span><span class="hljs-punctuation">)</span> <span class="hljs-operator">+</span><br>    xlab<span class="hljs-punctuation">(</span><span class="hljs-string">&quot;&quot;</span><span class="hljs-punctuation">)</span><br><br>fig5B <span class="hljs-operator">=</span> fragLen <span class="hljs-operator">%&gt;%</span> ggplot<span class="hljs-punctuation">(</span>aes<span class="hljs-punctuation">(</span>x <span class="hljs-operator">=</span> fragLen<span class="hljs-punctuation">,</span> y <span class="hljs-operator">=</span> fragCount<span class="hljs-punctuation">,</span> color <span class="hljs-operator">=</span> Histone<span class="hljs-punctuation">,</span> group <span class="hljs-operator">=</span> sampleInfo<span class="hljs-punctuation">,</span> linetype <span class="hljs-operator">=</span> Replicate<span class="hljs-punctuation">)</span><span class="hljs-punctuation">)</span> <span class="hljs-operator">+</span><br>  geom_line<span class="hljs-punctuation">(</span>size <span class="hljs-operator">=</span> <span class="hljs-number">1</span><span class="hljs-punctuation">)</span> <span class="hljs-operator">+</span><br>  scale_color_viridis<span class="hljs-punctuation">(</span>discrete <span class="hljs-operator">=</span> <span class="hljs-literal">TRUE</span><span class="hljs-punctuation">,</span> begin <span class="hljs-operator">=</span> <span class="hljs-number">0.1</span><span class="hljs-punctuation">,</span> end <span class="hljs-operator">=</span> <span class="hljs-number">0.9</span><span class="hljs-punctuation">,</span> option <span class="hljs-operator">=</span> <span class="hljs-string">&quot;magma&quot;</span><span class="hljs-punctuation">)</span> <span class="hljs-operator">+</span><br>  theme_bw<span class="hljs-punctuation">(</span>base_size <span class="hljs-operator">=</span> <span class="hljs-number">20</span><span class="hljs-punctuation">)</span> <span class="hljs-operator">+</span><br>  xlab<span class="hljs-punctuation">(</span><span class="hljs-string">&quot;Fragment Length&quot;</span><span class="hljs-punctuation">)</span> <span class="hljs-operator">+</span><br>  ylab<span class="hljs-punctuation">(</span><span class="hljs-string">&quot;Count&quot;</span><span class="hljs-punctuation">)</span> <span class="hljs-operator">+</span><br>  coord_cartesian<span class="hljs-punctuation">(</span>xlim <span class="hljs-operator">=</span> <span class="hljs-built_in">c</span><span class="hljs-punctuation">(</span><span class="hljs-number">0</span><span class="hljs-punctuation">,</span> <span class="hljs-number">500</span><span class="hljs-punctuation">)</span><span class="hljs-punctuation">)</span><br><br>ggarrange<span class="hljs-punctuation">(</span>fig5A<span class="hljs-punctuation">,</span> fig5B<span class="hljs-punctuation">,</span> ncol <span class="hljs-operator">=</span> <span class="hljs-number">2</span><span class="hljs-punctuation">)</span><br></code></pre></td></tr></table></figure><p><img src="/GeekFocus/./4.png"></p><ul><li>The smaller fragments (50-100 bp) can be due to that tethered Tn5 can tagment on the surface of a nucleosome as well as in linker regions(NFR?), so the <strong>small fragments might not be background.</strong></li></ul><h2 id="3-5-Assess-replicate-reproducibility"><a href="#3-5-Assess-replicate-reproducibility" class="headerlink" title="3.5 Assess replicate reproducibility"></a>3.5 Assess replicate reproducibility</h2><p>Data reproducibility between replicates is assessed by <strong>correlation</strong> analysis of <strong>mapped read counts</strong> across the genome. For the simplicity of implementation, we will postpone this analysis after Section IV when the file format has been converted into fragment bed files.</p><hr><h1 id="IV-Alignments-results-filtering-and-file-format-conversion"><a href="#IV-Alignments-results-filtering-and-file-format-conversion" class="headerlink" title="IV. Alignments results filtering and file format conversion"></a>IV. Alignments results filtering and file format conversion</h1><h2 id="4-1-Filtering-mapped-reads-by-the-mapping-quality-filtering-optinal"><a href="#4-1-Filtering-mapped-reads-by-the-mapping-quality-filtering-optinal" class="headerlink" title="4.1 Filtering mapped reads by the mapping quality filtering [optinal]"></a>4.1 Filtering mapped reads by the mapping quality filtering [<font color="red">optinal</font>]</h2><p>Some project may require more stringent filtering on the alignment quality score. This <a href="http://biofinysics.blogspot.com/2014/05/how-does-bowtie2-assign-mapq-scores.html">blog</a> detailedly discussed how does bowtie assign quality score with examples.</p><p>MAPQ(x) &#x3D; -10 * log10(P(x is mapped wrongly)) &#x3D; -10 * log10(p)</p><p>which ranges from 0 to 37, 40 or 42.</p><p><code>samtools view -q minQualityScore</code> will <strong>eliminate</strong> all the alignment results that are below the minQualityScore defined by user.</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-comment">##== linux command ==##</span><br>minQualityScore=2<span class="hljs-comment">#20?30?</span><br>samtools view -q <span class="hljs-variable">$minQualityScore</span> <span class="hljs-variable">$&#123;projPath&#125;</span>/alignment/sam/<span class="hljs-variable">$&#123;histName&#125;</span>_bowtie2.sam &gt;<span class="hljs-variable">$&#123;projPath&#125;</span>/alignment/sam/<span class="hljs-variable">$&#123;histName&#125;</span>_bowtie2.qualityScore<span class="hljs-variable">$minQualityScore</span>.sam<br></code></pre></td></tr></table></figure><ul><li>If you do implement this filtering, please replace the <code>$&#123;histName&#125;_bowtie2.sam</code> in the following steps by this filtered sam file <code>$&#123;histName&#125;_bowtie2.qualityScore$minQualityScore.sam</code>. <font color="red">Use the MAPQ20&#x2F;30 reads</font></li></ul><h2 id="4-2-File-format-conversion-required"><a href="#4-2-File-format-conversion-required" class="headerlink" title="4.2 File format conversion [required]"></a>4.2 File format conversion [required]</h2><p>This section is <strong>required</strong> in preparation for the <font color="red">peak calling</font> and <font color="red">visualization</font> where there are a few filtering and file format conversion that need to be done.</p><p>For example, in MACS2, it has bed(shift extent mode) and pe mode</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-comment">##== linux command ==##</span><br><span class="hljs-comment">## Filter and keep the mapped read pairs</span><br>samtools view -bS -F 0x4 <span class="hljs-variable">$projPath</span>/alignment/sam/<span class="hljs-variable">$&#123;histName&#125;</span>_bowtie2.sam &gt;<span class="hljs-variable">$projPath</span>/alignment/bam/<span class="hljs-variable">$&#123;histName&#125;</span>_bowtie2.mapped.bam<br><br><span class="hljs-comment">## Convert into bed file format</span><br>bedtools bamtobed -i <span class="hljs-variable">$projPath</span>/alignment/bam/<span class="hljs-variable">$&#123;histName&#125;</span>_bowtie2.mapped.bam -bedpe &gt;<span class="hljs-variable">$projPath</span>/alignment/bed/<span class="hljs-variable">$&#123;histName&#125;</span>_bowtie2.bed<br><br><span class="hljs-comment">## Keep the read pairs that are on the same chromosome and fragment length less than 1000bp.</span><br>awk <span class="hljs-string">&#x27;$1==$4 &amp;&amp; $6-$2 &lt; 1000 &#123;print $0&#125;&#x27;</span> <span class="hljs-variable">$projPath</span>/alignment/bed/<span class="hljs-variable">$&#123;histName&#125;</span>_bowtie2.bed &gt;<span class="hljs-variable">$projPath</span>/alignment/bed/<span class="hljs-variable">$&#123;histName&#125;</span>_bowtie2.clean.bed<br><br><span class="hljs-comment">## Only extract the fragment related columns</span><br><span class="hljs-built_in">cut</span> -f 1,2,6 <span class="hljs-variable">$projPath</span>/alignment/bed/<span class="hljs-variable">$&#123;histName&#125;</span>_bowtie2.clean.bed | <span class="hljs-built_in">sort</span> -k1,1 -k2,2n -k3,3n  &gt;<span class="hljs-variable">$projPath</span>/alignment/bed/<span class="hljs-variable">$&#123;histName&#125;</span>_bowtie2.fragments.bed<br></code></pre></td></tr></table></figure><h2 id="4-3-Assess-replicate-reproducibility-continue-section-3-5"><a href="#4-3-Assess-replicate-reproducibility-continue-section-3-5" class="headerlink" title="4.3 Assess replicate reproducibility (continue section 3.5)"></a>4.3 Assess replicate reproducibility (continue section 3.5)</h2><p>To study the reproducibility between replicates and across conditions, the <strong>genome is split into 500 bp bins</strong>, and a <strong>Pearson correlation of the log2-transformed values</strong> of <strong>read counts in each bin</strong> is calculated between replicate datasets. Multiple replicates and IgG control datasets are displayed in a hierarchically clustered correlation matrix.</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-comment">##== linux command ==##</span><br><span class="hljs-comment">## We use the mid point of each fragment to infer which 500bp bins does this fragment belong to.</span><br>binLen=500<br>awk -v w=<span class="hljs-variable">$binLen</span> <span class="hljs-string">&#x27;&#123;print $1, int(($2 + $3)/(2*w))*w + w/2&#125;&#x27;</span> <span class="hljs-variable">$projPath</span>/alignment/bed/<span class="hljs-variable">$&#123;histName&#125;</span>_bowtie2.fragments.bed | <span class="hljs-built_in">sort</span> -k1,1V -k2,2n | <span class="hljs-built_in">uniq</span> -c | awk -v OFS=<span class="hljs-string">&quot;\t&quot;</span> <span class="hljs-string">&#x27;&#123;print $2, $3, $1&#125;&#x27;</span> |  <span class="hljs-built_in">sort</span> -k1,1V -k2,2n  &gt;<span class="hljs-variable">$projPath</span>/alignment/bed/<span class="hljs-variable">$&#123;histName&#125;</span>_bowtie2.fragmentsCount.bin<span class="hljs-variable">$binLen</span>.bed<br></code></pre></td></tr></table></figure><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs r"><span class="hljs-comment">##== R command ==##</span><br>reprod <span class="hljs-operator">=</span> <span class="hljs-built_in">c</span><span class="hljs-punctuation">(</span><span class="hljs-punctuation">)</span><br>fragCount <span class="hljs-operator">=</span> <span class="hljs-literal">NULL</span><br><span class="hljs-keyword">for</span><span class="hljs-punctuation">(</span>hist <span class="hljs-keyword">in</span> sampleList<span class="hljs-punctuation">)</span><span class="hljs-punctuation">&#123;</span><br>  <br>  <span class="hljs-keyword">if</span><span class="hljs-punctuation">(</span><span class="hljs-built_in">is.null</span><span class="hljs-punctuation">(</span>fragCount<span class="hljs-punctuation">)</span><span class="hljs-punctuation">)</span><span class="hljs-punctuation">&#123;</span><br>    <br>    fragCount <span class="hljs-operator">=</span> read.table<span class="hljs-punctuation">(</span>paste0<span class="hljs-punctuation">(</span>projPath<span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;/alignment/bed/&quot;</span><span class="hljs-punctuation">,</span> hist<span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;_bowtie2.fragmentsCount.bin500.bed&quot;</span><span class="hljs-punctuation">)</span><span class="hljs-punctuation">,</span> header <span class="hljs-operator">=</span> <span class="hljs-literal">FALSE</span><span class="hljs-punctuation">)</span> <br>    colnames<span class="hljs-punctuation">(</span>fragCount<span class="hljs-punctuation">)</span> <span class="hljs-operator">=</span> <span class="hljs-built_in">c</span><span class="hljs-punctuation">(</span><span class="hljs-string">&quot;chrom&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;bin&quot;</span><span class="hljs-punctuation">,</span> hist<span class="hljs-punctuation">)</span><br>  <br>  <span class="hljs-punctuation">&#125;</span><span class="hljs-keyword">else</span><span class="hljs-punctuation">&#123;</span><br>    <br>    fragCountTmp <span class="hljs-operator">=</span> read.table<span class="hljs-punctuation">(</span>paste0<span class="hljs-punctuation">(</span>projPath<span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;/alignment/bed/&quot;</span><span class="hljs-punctuation">,</span> hist<span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;_bowtie2.fragmentsCount.bin500.bed&quot;</span><span class="hljs-punctuation">)</span><span class="hljs-punctuation">,</span> header <span class="hljs-operator">=</span> <span class="hljs-literal">FALSE</span><span class="hljs-punctuation">)</span><br>    colnames<span class="hljs-punctuation">(</span>fragCountTmp<span class="hljs-punctuation">)</span> <span class="hljs-operator">=</span> <span class="hljs-built_in">c</span><span class="hljs-punctuation">(</span><span class="hljs-string">&quot;chrom&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;bin&quot;</span><span class="hljs-punctuation">,</span> hist<span class="hljs-punctuation">)</span><br>    fragCount <span class="hljs-operator">=</span> full_join<span class="hljs-punctuation">(</span>fragCount<span class="hljs-punctuation">,</span> fragCountTmp<span class="hljs-punctuation">,</span> by <span class="hljs-operator">=</span> <span class="hljs-built_in">c</span><span class="hljs-punctuation">(</span><span class="hljs-string">&quot;chrom&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;bin&quot;</span><span class="hljs-punctuation">)</span><span class="hljs-punctuation">)</span><br>    <br>  <span class="hljs-punctuation">&#125;</span><br><span class="hljs-punctuation">&#125;</span><br><br>M <span class="hljs-operator">=</span> cor<span class="hljs-punctuation">(</span>fragCount <span class="hljs-operator">%&gt;%</span> select<span class="hljs-punctuation">(</span><span class="hljs-operator">-</span><span class="hljs-built_in">c</span><span class="hljs-punctuation">(</span><span class="hljs-string">&quot;chrom&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;bin&quot;</span><span class="hljs-punctuation">)</span><span class="hljs-punctuation">)</span> <span class="hljs-operator">%&gt;%</span> log2<span class="hljs-punctuation">(</span><span class="hljs-punctuation">)</span><span class="hljs-punctuation">,</span> use <span class="hljs-operator">=</span> <span class="hljs-string">&quot;complete.obs&quot;</span><span class="hljs-punctuation">)</span> <br><br>corrplot<span class="hljs-punctuation">(</span>M<span class="hljs-punctuation">,</span> method <span class="hljs-operator">=</span> <span class="hljs-string">&quot;color&quot;</span><span class="hljs-punctuation">,</span> outline <span class="hljs-operator">=</span> <span class="hljs-built_in">T</span><span class="hljs-punctuation">,</span> addgrid.col <span class="hljs-operator">=</span> <span class="hljs-string">&quot;darkgray&quot;</span><span class="hljs-punctuation">,</span> order<span class="hljs-operator">=</span><span class="hljs-string">&quot;hclust&quot;</span><span class="hljs-punctuation">,</span> addrect <span class="hljs-operator">=</span> <span class="hljs-number">3</span><span class="hljs-punctuation">,</span> rect.col <span class="hljs-operator">=</span> <span class="hljs-string">&quot;black&quot;</span><span class="hljs-punctuation">,</span> rect.lwd <span class="hljs-operator">=</span> <span class="hljs-number">3</span><span class="hljs-punctuation">,</span>cl.pos <span class="hljs-operator">=</span> <span class="hljs-string">&quot;b&quot;</span><span class="hljs-punctuation">,</span> tl.col <span class="hljs-operator">=</span> <span class="hljs-string">&quot;indianred4&quot;</span><span class="hljs-punctuation">,</span> tl.cex <span class="hljs-operator">=</span> <span class="hljs-number">1</span><span class="hljs-punctuation">,</span> cl.cex <span class="hljs-operator">=</span> <span class="hljs-number">1</span><span class="hljs-punctuation">,</span> addCoef.col <span class="hljs-operator">=</span> <span class="hljs-string">&quot;black&quot;</span><span class="hljs-punctuation">,</span> number.digits <span class="hljs-operator">=</span> <span class="hljs-number">2</span><span class="hljs-punctuation">,</span> number.cex <span class="hljs-operator">=</span> <span class="hljs-number">1</span><span class="hljs-punctuation">,</span> col <span class="hljs-operator">=</span> colorRampPalette<span class="hljs-punctuation">(</span><span class="hljs-built_in">c</span><span class="hljs-punctuation">(</span><span class="hljs-string">&quot;midnightblue&quot;</span><span class="hljs-punctuation">,</span><span class="hljs-string">&quot;white&quot;</span><span class="hljs-punctuation">,</span><span class="hljs-string">&quot;darkred&quot;</span><span class="hljs-punctuation">)</span><span class="hljs-punctuation">)</span><span class="hljs-punctuation">(</span><span class="hljs-number">100</span><span class="hljs-punctuation">)</span><span class="hljs-punctuation">)</span><br></code></pre></td></tr></table></figure><p><img src="/GeekFocus/./5.png"></p><hr><h1 id="V-Spike-in-calibration"><a href="#V-Spike-in-calibration" class="headerlink" title="V. Spike-in calibration"></a>V. Spike-in calibration</h1><p>This section is <strong>optional</strong> but <strong>recommended</strong> depending on your experimental protocol. We have shown the alignment to the spike-in genome in Section 3.1.2 and the spike-in alignment summary in Section 3.2.2.</p><p>The underlying assumption is that the ratio of fragments mapped to the primary genome to the E. coli genome is the same for a series of samples, each using the same number of cells. Because of this assumption, we do not normalize between experiments or between batches of purified pATn5, which can have very different amounts of carry-over E. coli DNA. Using a constant C to avoid small fractions in normalized data, we define a scaling factor S as</p><figure class="highlight abnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs abnf"><span class="hljs-attribute">S</span> <span class="hljs-operator">=</span> C / (fragments mapped to E. coli genome)<br></code></pre></td></tr></table></figure><p>Normalized coverage is then calculated as:</p><figure class="highlight abnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs abnf">Normalized coverage <span class="hljs-operator">=</span> (primary_genome_coverage) * S<br></code></pre></td></tr></table></figure><p>The Constant is an arbitrary multiplier, typically 10,000. The resulting file will be comparatively small as a genomic coverage bedgraph file.</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-comment">##== linux command ==##</span><br><span class="hljs-keyword">if</span> [[ <span class="hljs-string">&quot;<span class="hljs-variable">$seqDepth</span>&quot;</span> -gt <span class="hljs-string">&quot;1&quot;</span> ]]; <span class="hljs-keyword">then</span><br>    <br>    <span class="hljs-built_in">mkdir</span> -p <span class="hljs-variable">$projPath</span>/alignment/bedgraph<br><br>    scale_factor=`<span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;10000 / <span class="hljs-variable">$seqDepth</span>&quot;</span> | bc -l`<br>    <span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;Scaling factor for <span class="hljs-variable">$histName</span> is: <span class="hljs-variable">$scale_factor</span>!&quot;</span><br>    bedtools genomecov -<span class="hljs-built_in">bg</span> -scale <span class="hljs-variable">$scale_factor</span> -i <span class="hljs-variable">$projPath</span>/alignment/bed/<span class="hljs-variable">$&#123;histName&#125;</span>_bowtie2.fragments.bed -g <span class="hljs-variable">$chromSize</span> &gt; <span class="hljs-variable">$projPath</span>/alignment/bedgraph/<span class="hljs-variable">$&#123;histName&#125;</span>_bowtie2.fragments.normalized.bedgraph<br>    <br><span class="hljs-keyword">fi</span><br></code></pre></td></tr></table></figure><h2 id="5-1-Scaling-factor"><a href="#5-1-Scaling-factor" class="headerlink" title="5.1 Scaling factor"></a>5.1 Scaling factor</h2><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs r"><span class="hljs-comment">##=== R command ===## </span><br>scaleFactor <span class="hljs-operator">=</span> <span class="hljs-built_in">c</span><span class="hljs-punctuation">(</span><span class="hljs-punctuation">)</span><br>multiplier <span class="hljs-operator">=</span> <span class="hljs-number">10000</span><br><span class="hljs-keyword">for</span><span class="hljs-punctuation">(</span>hist <span class="hljs-keyword">in</span> sampleList<span class="hljs-punctuation">)</span><span class="hljs-punctuation">&#123;</span><br>  spikeDepth <span class="hljs-operator">=</span> read.table<span class="hljs-punctuation">(</span>paste0<span class="hljs-punctuation">(</span>projPath<span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;/alignment/sam/bowtie2_summary/&quot;</span><span class="hljs-punctuation">,</span> hist<span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;_bowtie2_spikeIn.seqDepth&quot;</span><span class="hljs-punctuation">)</span><span class="hljs-punctuation">,</span> header <span class="hljs-operator">=</span> <span class="hljs-literal">FALSE</span><span class="hljs-punctuation">,</span> fill <span class="hljs-operator">=</span> <span class="hljs-literal">TRUE</span><span class="hljs-punctuation">)</span><span class="hljs-operator">$</span>V1<span class="hljs-punctuation">[</span><span class="hljs-number">1</span><span class="hljs-punctuation">]</span><br>  <br>  histInfo <span class="hljs-operator">=</span> strsplit<span class="hljs-punctuation">(</span>hist<span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;_&quot;</span><span class="hljs-punctuation">)</span><span class="hljs-punctuation">[[</span><span class="hljs-number">1</span><span class="hljs-punctuation">]</span><span class="hljs-punctuation">]</span><br>  scaleFactor <span class="hljs-operator">=</span> data.frame<span class="hljs-punctuation">(</span>scaleFactor <span class="hljs-operator">=</span> multiplier<span class="hljs-operator">/</span>spikeDepth<span class="hljs-punctuation">,</span> Histone <span class="hljs-operator">=</span> histInfo<span class="hljs-punctuation">[</span><span class="hljs-number">1</span><span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span> Replicate <span class="hljs-operator">=</span> histInfo<span class="hljs-punctuation">[</span><span class="hljs-number">2</span><span class="hljs-punctuation">]</span><span class="hljs-punctuation">)</span>  <span class="hljs-operator">%&gt;%</span> rbind<span class="hljs-punctuation">(</span>scaleFactor<span class="hljs-punctuation">,</span> .<span class="hljs-punctuation">)</span><br><span class="hljs-punctuation">&#125;</span><br>scaleFactor<span class="hljs-operator">$</span>Histone <span class="hljs-operator">=</span> factor<span class="hljs-punctuation">(</span>scaleFactor<span class="hljs-operator">$</span>Histone<span class="hljs-punctuation">,</span> levels <span class="hljs-operator">=</span> histList<span class="hljs-punctuation">)</span><br>left_join<span class="hljs-punctuation">(</span>alignDupSummary<span class="hljs-punctuation">,</span> scaleFactor<span class="hljs-punctuation">,</span> by <span class="hljs-operator">=</span> <span class="hljs-built_in">c</span><span class="hljs-punctuation">(</span><span class="hljs-string">&quot;Histone&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;Replicate&quot;</span><span class="hljs-punctuation">)</span><span class="hljs-punctuation">)</span><br></code></pre></td></tr></table></figure><p>Histone<br>Replicate<br>SequencingDepth<br>MappedFragNum_hg38<br>AlignmentRate_hg38<br>MappedFragNum_spikeIn<br>AlignmentRate_spikeIn<br><strong>DuplicationRate</strong><br><strong>EstimatedLibrarySize</strong><br><strong>UniqueFragNum</strong><br><strong>scaleFactor</strong></p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs r"><span class="hljs-comment">##=== R command ===##</span><br><span class="hljs-comment">## Generate sequencing depth boxplot</span><br>fig6A <span class="hljs-operator">=</span> scaleFactor <span class="hljs-operator">%&gt;%</span> ggplot<span class="hljs-punctuation">(</span>aes<span class="hljs-punctuation">(</span>x <span class="hljs-operator">=</span> Histone<span class="hljs-punctuation">,</span> y <span class="hljs-operator">=</span> scaleFactor<span class="hljs-punctuation">,</span> fill <span class="hljs-operator">=</span> Histone<span class="hljs-punctuation">)</span><span class="hljs-punctuation">)</span> <span class="hljs-operator">+</span><br>    geom_boxplot<span class="hljs-punctuation">(</span><span class="hljs-punctuation">)</span> <span class="hljs-operator">+</span><br>    geom_jitter<span class="hljs-punctuation">(</span>aes<span class="hljs-punctuation">(</span>color <span class="hljs-operator">=</span> Replicate<span class="hljs-punctuation">)</span><span class="hljs-punctuation">,</span> position <span class="hljs-operator">=</span> position_jitter<span class="hljs-punctuation">(</span><span class="hljs-number">0.15</span><span class="hljs-punctuation">)</span><span class="hljs-punctuation">)</span> <span class="hljs-operator">+</span><br>    scale_fill_viridis<span class="hljs-punctuation">(</span>discrete <span class="hljs-operator">=</span> <span class="hljs-literal">TRUE</span><span class="hljs-punctuation">,</span> begin <span class="hljs-operator">=</span> <span class="hljs-number">0.1</span><span class="hljs-punctuation">,</span> end <span class="hljs-operator">=</span> <span class="hljs-number">0.9</span><span class="hljs-punctuation">,</span> option <span class="hljs-operator">=</span> <span class="hljs-string">&quot;magma&quot;</span><span class="hljs-punctuation">,</span> alpha <span class="hljs-operator">=</span> <span class="hljs-number">0.8</span><span class="hljs-punctuation">)</span> <span class="hljs-operator">+</span><br>    scale_color_viridis<span class="hljs-punctuation">(</span>discrete <span class="hljs-operator">=</span> <span class="hljs-literal">TRUE</span><span class="hljs-punctuation">,</span> begin <span class="hljs-operator">=</span> <span class="hljs-number">0.1</span><span class="hljs-punctuation">,</span> end <span class="hljs-operator">=</span> <span class="hljs-number">0.9</span><span class="hljs-punctuation">)</span> <span class="hljs-operator">+</span><br>    theme_bw<span class="hljs-punctuation">(</span>base_size <span class="hljs-operator">=</span> <span class="hljs-number">20</span><span class="hljs-punctuation">)</span> <span class="hljs-operator">+</span><br>    ylab<span class="hljs-punctuation">(</span><span class="hljs-string">&quot;Spike-in Scalling Factor&quot;</span><span class="hljs-punctuation">)</span> <span class="hljs-operator">+</span><br>    xlab<span class="hljs-punctuation">(</span><span class="hljs-string">&quot;&quot;</span><span class="hljs-punctuation">)</span><br><br>normDepth <span class="hljs-operator">=</span> inner_join<span class="hljs-punctuation">(</span>scaleFactor<span class="hljs-punctuation">,</span> alignResult<span class="hljs-punctuation">,</span> by <span class="hljs-operator">=</span> <span class="hljs-built_in">c</span><span class="hljs-punctuation">(</span><span class="hljs-string">&quot;Histone&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;Replicate&quot;</span><span class="hljs-punctuation">)</span><span class="hljs-punctuation">)</span> <span class="hljs-operator">%&gt;%</span> mutate<span class="hljs-punctuation">(</span>normDepth <span class="hljs-operator">=</span> MappedFragNum_hg38 <span class="hljs-operator">*</span> scaleFactor<span class="hljs-punctuation">)</span><br><br>fig6B <span class="hljs-operator">=</span> normDepth <span class="hljs-operator">%&gt;%</span> ggplot<span class="hljs-punctuation">(</span>aes<span class="hljs-punctuation">(</span>x <span class="hljs-operator">=</span> Histone<span class="hljs-punctuation">,</span> y <span class="hljs-operator">=</span> normDepth<span class="hljs-punctuation">,</span> fill <span class="hljs-operator">=</span> Histone<span class="hljs-punctuation">)</span><span class="hljs-punctuation">)</span> <span class="hljs-operator">+</span><br>    geom_boxplot<span class="hljs-punctuation">(</span><span class="hljs-punctuation">)</span> <span class="hljs-operator">+</span><br>    geom_jitter<span class="hljs-punctuation">(</span>aes<span class="hljs-punctuation">(</span>color <span class="hljs-operator">=</span> Replicate<span class="hljs-punctuation">)</span><span class="hljs-punctuation">,</span> position <span class="hljs-operator">=</span> position_jitter<span class="hljs-punctuation">(</span><span class="hljs-number">0.15</span><span class="hljs-punctuation">)</span><span class="hljs-punctuation">)</span> <span class="hljs-operator">+</span><br>    scale_fill_viridis<span class="hljs-punctuation">(</span>discrete <span class="hljs-operator">=</span> <span class="hljs-literal">TRUE</span><span class="hljs-punctuation">,</span> begin <span class="hljs-operator">=</span> <span class="hljs-number">0.1</span><span class="hljs-punctuation">,</span> end <span class="hljs-operator">=</span> <span class="hljs-number">0.9</span><span class="hljs-punctuation">,</span> option <span class="hljs-operator">=</span> <span class="hljs-string">&quot;magma&quot;</span><span class="hljs-punctuation">,</span> alpha <span class="hljs-operator">=</span> <span class="hljs-number">0.8</span><span class="hljs-punctuation">)</span> <span class="hljs-operator">+</span><br>    scale_color_viridis<span class="hljs-punctuation">(</span>discrete <span class="hljs-operator">=</span> <span class="hljs-literal">TRUE</span><span class="hljs-punctuation">,</span> begin <span class="hljs-operator">=</span> <span class="hljs-number">0.1</span><span class="hljs-punctuation">,</span> end <span class="hljs-operator">=</span> <span class="hljs-number">0.9</span><span class="hljs-punctuation">)</span> <span class="hljs-operator">+</span><br>    theme_bw<span class="hljs-punctuation">(</span>base_size <span class="hljs-operator">=</span> <span class="hljs-number">20</span><span class="hljs-punctuation">)</span> <span class="hljs-operator">+</span><br>    ylab<span class="hljs-punctuation">(</span><span class="hljs-string">&quot;Normalization Fragment Count&quot;</span><span class="hljs-punctuation">)</span> <span class="hljs-operator">+</span><br>    xlab<span class="hljs-punctuation">(</span><span class="hljs-string">&quot;&quot;</span><span class="hljs-punctuation">)</span> <span class="hljs-operator">+</span> <br>    coord_cartesian<span class="hljs-punctuation">(</span>ylim <span class="hljs-operator">=</span> <span class="hljs-built_in">c</span><span class="hljs-punctuation">(</span><span class="hljs-number">1000000</span><span class="hljs-punctuation">,</span> <span class="hljs-number">130000000</span><span class="hljs-punctuation">)</span><span class="hljs-punctuation">)</span><br>ggarrange<span class="hljs-punctuation">(</span>fig6A<span class="hljs-punctuation">,</span> fig6B<span class="hljs-punctuation">,</span> ncol <span class="hljs-operator">=</span> <span class="hljs-number">2</span><span class="hljs-punctuation">,</span> common.legend <span class="hljs-operator">=</span> <span class="hljs-literal">TRUE</span><span class="hljs-punctuation">,</span> legend<span class="hljs-operator">=</span><span class="hljs-string">&quot;bottom&quot;</span><span class="hljs-punctuation">)</span><br></code></pre></td></tr></table></figure><p><img src="/GeekFocus/./6.png"></p><hr><h1 id="VI-Peak-calling"><a href="#VI-Peak-calling" class="headerlink" title="VI. Peak calling"></a>VI. Peak calling</h1><h2 id="6-1-SEACR"><a href="#6-1-SEACR" class="headerlink" title="6.1. SEACR"></a>6.1. SEACR</h2><p>The Sparse Enrichment Analysis for CUT&amp;RUN, <a href="https://github.com/FredHutch/SEACR/">SEACR</a>, package is designed to call peaks and enriched regions from chromatin profiling data <strong>with very low backgrounds</strong> (i.e., regions with no read coverage) that are <strong>typical for CUT&amp;Tag</strong> chromatin profiling experiments. SEACR requires <strong>bedGraph files from paired-end sequencing as input</strong> and defines <strong>peaks</strong> as <strong>contiguous blocks of basepair coverage</strong> that <strong>do not overlap</strong> with <strong>blocks of background signal delineated in the IgG</strong> control dataset. SEACR is effective for calling <strong>both</strong> <strong>narrow</strong> peaks from <strong>factor binding sites</strong> and <strong>broad</strong> domains characteristic of some <strong>histone</strong> modifications. The description of the method is published at <a href="https://epigeneticsandchromatin.biomedcentral.com/articles/10.1186/s13072-019-0287-4">Meers et al. 2019</a>, and the user’s manual is available on <a href="https://github.com/FredHutch/SEACR/">github</a>. Since we have normalized fragment counts with the E. coli read count, we set the normalization option of SEACR to “non”. <strong>Otherwise</strong>, the “<strong>norm</strong>” is <strong>recommended</strong>.</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-comment">##== linux command ==##</span><br>seacr=<span class="hljs-string">&quot;/fh/fast/gottardo_r/yezheng_working/Software/SEACR/SEACR_1.3.sh&quot;</span><br>histControl=<span class="hljs-variable">$2</span><br><span class="hljs-built_in">mkdir</span> -p <span class="hljs-variable">$projPath</span>/peakCalling/SEACR<br><br>bash <span class="hljs-variable">$seacr</span> <span class="hljs-variable">$projPath</span>/alignment/bedgraph/<span class="hljs-variable">$&#123;histName&#125;</span>_bowtie2.fragments.normalized.bedgraph \<br>     <span class="hljs-variable">$projPath</span>/alignment/bedgraph/<span class="hljs-variable">$&#123;histControl&#125;</span>_bowtie2.fragments.normalized.bedgraph \<br>     non stringent <span class="hljs-variable">$projPath</span>/peakCalling/SEACR/<span class="hljs-variable">$&#123;histName&#125;</span>_seacr_control.peaks<br><br>bash <span class="hljs-variable">$seacr</span> <span class="hljs-variable">$projPath</span>/alignment/bedgraph/<span class="hljs-variable">$&#123;histName&#125;</span>_bowtie2.fragments.normalized.bedgraph 0.01 non stringent <span class="hljs-variable">$projPath</span>/peakCalling/SEACR/<span class="hljs-variable">$&#123;histName&#125;</span>_seacr_top0.01.peaks<br></code></pre></td></tr></table></figure><h3 id="6-1-1-Number-of-peaks-called"><a href="#6-1-1-Number-of-peaks-called" class="headerlink" title="6.1.1 Number of peaks called"></a>6.1.1 Number of peaks called</h3><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs r"><span class="hljs-comment">##=== R command ===## </span><br>peakN <span class="hljs-operator">=</span> <span class="hljs-built_in">c</span><span class="hljs-punctuation">(</span><span class="hljs-punctuation">)</span><br>peakWidth <span class="hljs-operator">=</span> <span class="hljs-built_in">c</span><span class="hljs-punctuation">(</span><span class="hljs-punctuation">)</span><br>peakType <span class="hljs-operator">=</span> <span class="hljs-built_in">c</span><span class="hljs-punctuation">(</span><span class="hljs-string">&quot;control&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;top0.01&quot;</span><span class="hljs-punctuation">)</span><br><span class="hljs-keyword">for</span><span class="hljs-punctuation">(</span>hist <span class="hljs-keyword">in</span> sampleList<span class="hljs-punctuation">)</span><span class="hljs-punctuation">&#123;</span><br>  histInfo <span class="hljs-operator">=</span> strsplit<span class="hljs-punctuation">(</span>hist<span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;_&quot;</span><span class="hljs-punctuation">)</span><span class="hljs-punctuation">[[</span><span class="hljs-number">1</span><span class="hljs-punctuation">]</span><span class="hljs-punctuation">]</span><br>  <span class="hljs-keyword">if</span><span class="hljs-punctuation">(</span>histInfo<span class="hljs-punctuation">[</span><span class="hljs-number">1</span><span class="hljs-punctuation">]</span> <span class="hljs-operator">!=</span> <span class="hljs-string">&quot;IgG&quot;</span><span class="hljs-punctuation">)</span><span class="hljs-punctuation">&#123;</span><br>    <span class="hljs-keyword">for</span><span class="hljs-punctuation">(</span>type <span class="hljs-keyword">in</span> peakType<span class="hljs-punctuation">)</span><span class="hljs-punctuation">&#123;</span><br>      peakInfo <span class="hljs-operator">=</span> read.table<span class="hljs-punctuation">(</span>paste0<span class="hljs-punctuation">(</span>projPath<span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;/peakCalling/SEACR/&quot;</span><span class="hljs-punctuation">,</span> hist<span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;_seacr_&quot;</span><span class="hljs-punctuation">,</span> type<span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;.peaks.stringent.bed&quot;</span><span class="hljs-punctuation">)</span><span class="hljs-punctuation">,</span> header <span class="hljs-operator">=</span> <span class="hljs-literal">FALSE</span><span class="hljs-punctuation">,</span> fill <span class="hljs-operator">=</span> <span class="hljs-literal">TRUE</span><span class="hljs-punctuation">)</span>  <span class="hljs-operator">%&gt;%</span> mutate<span class="hljs-punctuation">(</span>width <span class="hljs-operator">=</span> <span class="hljs-built_in">abs</span><span class="hljs-punctuation">(</span>V3<span class="hljs-operator">-</span>V2<span class="hljs-punctuation">)</span><span class="hljs-punctuation">)</span><br>      peakN <span class="hljs-operator">=</span> data.frame<span class="hljs-punctuation">(</span>peakN <span class="hljs-operator">=</span> nrow<span class="hljs-punctuation">(</span>peakInfo<span class="hljs-punctuation">)</span><span class="hljs-punctuation">,</span> peakType <span class="hljs-operator">=</span> type<span class="hljs-punctuation">,</span> Histone <span class="hljs-operator">=</span> histInfo<span class="hljs-punctuation">[</span><span class="hljs-number">1</span><span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span> Replicate <span class="hljs-operator">=</span> histInfo<span class="hljs-punctuation">[</span><span class="hljs-number">2</span><span class="hljs-punctuation">]</span><span class="hljs-punctuation">)</span> <span class="hljs-operator">%&gt;%</span> rbind<span class="hljs-punctuation">(</span>peakN<span class="hljs-punctuation">,</span> .<span class="hljs-punctuation">)</span><br>      peakWidth <span class="hljs-operator">=</span> data.frame<span class="hljs-punctuation">(</span>width <span class="hljs-operator">=</span> peakInfo<span class="hljs-operator">$</span>width<span class="hljs-punctuation">,</span> peakType <span class="hljs-operator">=</span> type<span class="hljs-punctuation">,</span> Histone <span class="hljs-operator">=</span> histInfo<span class="hljs-punctuation">[</span><span class="hljs-number">1</span><span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span> Replicate <span class="hljs-operator">=</span> histInfo<span class="hljs-punctuation">[</span><span class="hljs-number">2</span><span class="hljs-punctuation">]</span><span class="hljs-punctuation">)</span>  <span class="hljs-operator">%&gt;%</span> rbind<span class="hljs-punctuation">(</span>peakWidth<span class="hljs-punctuation">,</span> .<span class="hljs-punctuation">)</span><br>    <span class="hljs-punctuation">&#125;</span><br>  <span class="hljs-punctuation">&#125;</span><br><span class="hljs-punctuation">&#125;</span><br>peakN <span class="hljs-operator">%&gt;%</span> select<span class="hljs-punctuation">(</span>Histone<span class="hljs-punctuation">,</span> Replicate<span class="hljs-punctuation">,</span> peakType<span class="hljs-punctuation">,</span> peakN<span class="hljs-punctuation">)</span><br></code></pre></td></tr></table></figure><table><thead><tr><th align="left">Histone<chr></th><th align="left">Replicate<chr></th><th align="left">peakType<chr></th><th align="right">peakN<int></th></tr></thead><tbody><tr><td align="left">K27me3</td><td align="left">rep1</td><td align="left">control</td><td align="right">144906</td></tr><tr><td align="left">K27me3</td><td align="left">rep1</td><td align="left">top0.01</td><td align="right">5829</td></tr><tr><td align="left">K27me3</td><td align="left">rep2</td><td align="left">control</td><td align="right">74444</td></tr><tr><td align="left">K27me3</td><td align="left">rep2</td><td align="left">top0.01</td><td align="right">9642</td></tr><tr><td align="left">K4me3</td><td align="left">rep1</td><td align="left">control</td><td align="right">8709</td></tr><tr><td align="left">K4me3</td><td align="left">rep1</td><td align="left">top0.01</td><td align="right">878</td></tr></tbody></table><h3 id="6-1-2-Reproducibility-of-the-peak-across-biological-replicates"><a href="#6-1-2-Reproducibility-of-the-peak-across-biological-replicates" class="headerlink" title="6.1.2 Reproducibility of the peak across biological replicates"></a>6.1.2 Reproducibility of the peak across biological replicates</h3><p>Peak calling on replicate datasets is compared to define reproducible peaks. The top 1% of peaks (ranked by total signal in each block) are selected as high-confidence sites.</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs r"><span class="hljs-comment">##=== R command ===## </span><br>histL <span class="hljs-operator">=</span> <span class="hljs-built_in">c</span><span class="hljs-punctuation">(</span><span class="hljs-string">&quot;K27me3&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;K4me3&quot;</span><span class="hljs-punctuation">)</span><br>repL <span class="hljs-operator">=</span> paste0<span class="hljs-punctuation">(</span><span class="hljs-string">&quot;rep&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-number">1</span><span class="hljs-operator">:</span><span class="hljs-number">2</span><span class="hljs-punctuation">)</span><br>peakType <span class="hljs-operator">=</span> <span class="hljs-built_in">c</span><span class="hljs-punctuation">(</span><span class="hljs-string">&quot;control&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;top0.01&quot;</span><span class="hljs-punctuation">)</span><br>peakOverlap <span class="hljs-operator">=</span> <span class="hljs-built_in">c</span><span class="hljs-punctuation">(</span><span class="hljs-punctuation">)</span><br><span class="hljs-keyword">for</span><span class="hljs-punctuation">(</span>type <span class="hljs-keyword">in</span> peakType<span class="hljs-punctuation">)</span><span class="hljs-punctuation">&#123;</span><br>  <span class="hljs-keyword">for</span><span class="hljs-punctuation">(</span>hist <span class="hljs-keyword">in</span> histL<span class="hljs-punctuation">)</span><span class="hljs-punctuation">&#123;</span><br>    overlap.gr <span class="hljs-operator">=</span> GRanges<span class="hljs-punctuation">(</span><span class="hljs-punctuation">)</span><br>    <span class="hljs-keyword">for</span><span class="hljs-punctuation">(</span><span class="hljs-built_in">rep</span> <span class="hljs-keyword">in</span> repL<span class="hljs-punctuation">)</span><span class="hljs-punctuation">&#123;</span><br>      peakInfo <span class="hljs-operator">=</span> read.table<span class="hljs-punctuation">(</span>paste0<span class="hljs-punctuation">(</span>projPath<span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;/peakCalling/SEACR/&quot;</span><span class="hljs-punctuation">,</span> hist<span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;_&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-built_in">rep</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;_seacr_&quot;</span><span class="hljs-punctuation">,</span> type<span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;.peaks.stringent.bed&quot;</span><span class="hljs-punctuation">)</span><span class="hljs-punctuation">,</span> header <span class="hljs-operator">=</span> <span class="hljs-literal">FALSE</span><span class="hljs-punctuation">,</span> fill <span class="hljs-operator">=</span> <span class="hljs-literal">TRUE</span><span class="hljs-punctuation">)</span><br>      peakInfo.gr <span class="hljs-operator">=</span> GRanges<span class="hljs-punctuation">(</span>peakInfo<span class="hljs-operator">$</span>V1<span class="hljs-punctuation">,</span> IRanges<span class="hljs-punctuation">(</span>start <span class="hljs-operator">=</span> peakInfo<span class="hljs-operator">$</span>V2<span class="hljs-punctuation">,</span> end <span class="hljs-operator">=</span> peakInfo<span class="hljs-operator">$</span>V3<span class="hljs-punctuation">)</span><span class="hljs-punctuation">,</span> strand <span class="hljs-operator">=</span> <span class="hljs-string">&quot;*&quot;</span><span class="hljs-punctuation">)</span><br>      <span class="hljs-keyword">if</span><span class="hljs-punctuation">(</span><span class="hljs-built_in">length</span><span class="hljs-punctuation">(</span>overlap.gr<span class="hljs-punctuation">)</span> <span class="hljs-operator">&gt;</span><span class="hljs-number">0</span><span class="hljs-punctuation">)</span><span class="hljs-punctuation">&#123;</span><br>        overlap.gr <span class="hljs-operator">=</span> overlap.gr<span class="hljs-punctuation">[</span>findOverlaps<span class="hljs-punctuation">(</span>overlap.gr<span class="hljs-punctuation">,</span> peakInfo.gr<span class="hljs-punctuation">)</span><span class="hljs-operator">@</span>from<span class="hljs-punctuation">]</span><br>      <span class="hljs-punctuation">&#125;</span><span class="hljs-keyword">else</span><span class="hljs-punctuation">&#123;</span><br>        overlap.gr <span class="hljs-operator">=</span> peakInfo.gr<br>        <br>      <span class="hljs-punctuation">&#125;</span><br>    <span class="hljs-punctuation">&#125;</span><br>    peakOverlap <span class="hljs-operator">=</span> data.frame<span class="hljs-punctuation">(</span>peakReprod <span class="hljs-operator">=</span> <span class="hljs-built_in">length</span><span class="hljs-punctuation">(</span>overlap.gr<span class="hljs-punctuation">)</span><span class="hljs-punctuation">,</span> Histone <span class="hljs-operator">=</span> hist<span class="hljs-punctuation">,</span> peakType <span class="hljs-operator">=</span> type<span class="hljs-punctuation">)</span> <span class="hljs-operator">%&gt;%</span> rbind<span class="hljs-punctuation">(</span>peakOverlap<span class="hljs-punctuation">,</span> .<span class="hljs-punctuation">)</span><br>  <span class="hljs-punctuation">&#125;</span><br><span class="hljs-punctuation">&#125;</span><br><br>peakReprod <span class="hljs-operator">=</span> left_join<span class="hljs-punctuation">(</span>peakN<span class="hljs-punctuation">,</span> peakOverlap<span class="hljs-punctuation">,</span> by <span class="hljs-operator">=</span> <span class="hljs-built_in">c</span><span class="hljs-punctuation">(</span><span class="hljs-string">&quot;Histone&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;peakType&quot;</span><span class="hljs-punctuation">)</span><span class="hljs-punctuation">)</span> <span class="hljs-operator">%&gt;%</span> mutate<span class="hljs-punctuation">(</span>peakReprodRate <span class="hljs-operator">=</span> peakReprod<span class="hljs-operator">/</span>peakN <span class="hljs-operator">*</span> <span class="hljs-number">100</span><span class="hljs-punctuation">)</span><br>peakReprod <span class="hljs-operator">%&gt;%</span> select<span class="hljs-punctuation">(</span>Histone<span class="hljs-punctuation">,</span> Replicate<span class="hljs-punctuation">,</span> peakType<span class="hljs-punctuation">,</span> peakN<span class="hljs-punctuation">,</span> peakReprodNum <span class="hljs-operator">=</span> peakReprod<span class="hljs-punctuation">,</span> peakReprodRate<span class="hljs-punctuation">)</span><br></code></pre></td></tr></table></figure><table><thead><tr><th align="left">Histone<chr></th><th align="left">Replicate<chr></th><th align="left">peakType<chr></th><th align="right">peakN<int></th><th align="right">peakReprodNum<int></th><th align="right">peakReprodRate<dbl></th></tr></thead><tbody><tr><td align="left">K27me3</td><td align="left">rep1</td><td align="left">control</td><td align="right">144906</td><td align="right">71692</td><td align="right">49.47483</td></tr><tr><td align="left">K27me3</td><td align="left">rep1</td><td align="left">top0.01</td><td align="right">5829</td><td align="right">5314</td><td align="right">91.16487</td></tr><tr><td align="left">K27me3</td><td align="left">rep2</td><td align="left">control</td><td align="right">74444</td><td align="right">71692</td><td align="right">96.30326</td></tr><tr><td align="left">K27me3</td><td align="left">rep2</td><td align="left">top0.01</td><td align="right">9642</td><td align="right">5314</td><td align="right">55.11305</td></tr></tbody></table><p>The reproducibility is calculated by</p><figure class="highlight clean"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs clean">`# peaks overlapping rep1 and rep2/# peaks <span class="hljs-keyword">of</span> rep1 or rep2 * <span class="hljs-number">100</span><br></code></pre></td></tr></table></figure><p>Therefore, it is sensitive to the total number of peaks called in each replicate.</p><h3 id="6-1-3-FRagment-proportion-in-Peaks-regions-FRiPs"><a href="#6-1-3-FRagment-proportion-in-Peaks-regions-FRiPs" class="headerlink" title="6.1.3 FRagment proportion in Peaks regions (FRiPs)."></a>6.1.3 FRagment proportion in Peaks regions (FRiPs).</h3><p>We calculate the fraction of reads in peaks (FRiPs) as a measure of signal-to-noise, and contrast it to FRiPs in the IgG control dataset for illustration. Although sequencing depths for CUT&amp;Tag are typically only 1-5 million reads, the low background of the method results in high FRiP scores.</p><figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs reasonml">##=== R command ===## <br>library(chromVAR)<br><br>bamDir = paste0(projPath, <span class="hljs-string">&quot;/alignment/bam&quot;</span>)<br>inPeakData = c<span class="hljs-literal">()</span><br>## overlap <span class="hljs-keyword">with</span> bam file <span class="hljs-keyword">to</span> get count<br><span class="hljs-keyword">for</span>(hist <span class="hljs-keyword">in</span> histL)&#123;<br>  <span class="hljs-keyword">for</span>(rep <span class="hljs-keyword">in</span> repL)&#123;<br>    peakRes = read.table(paste0(projPath, <span class="hljs-string">&quot;/peakCalling/SEACR/&quot;</span>, hist, <span class="hljs-string">&quot;_&quot;</span>, rep, <span class="hljs-string">&quot;_seacr_control.peaks.stringent.bed&quot;</span>), header = FALSE, fill = TRUE)<br>    peak.gr = <span class="hljs-constructor">GRanges(<span class="hljs-params">seqnames</span> = <span class="hljs-params">peakRes$V1</span>, IRanges(<span class="hljs-params">start</span> = <span class="hljs-params">peakRes$V2</span>, <span class="hljs-params">end</span> = <span class="hljs-params">peakRes$V3</span>)</span>, strand = <span class="hljs-string">&quot;*&quot;</span>)<br>    bamFile = paste0(bamDir, <span class="hljs-string">&quot;/&quot;</span>, hist, <span class="hljs-string">&quot;_&quot;</span>, rep, <span class="hljs-string">&quot;_bowtie2.mapped.bam&quot;</span>)<br>    fragment_counts &lt;- get<span class="hljs-constructor">Counts(<span class="hljs-params">bamFile</span>, <span class="hljs-params">peak</span>.<span class="hljs-params">gr</span>, <span class="hljs-params">paired</span> = TRUE, <span class="hljs-params">by_rg</span> = FALSE, <span class="hljs-params">format</span> = <span class="hljs-string">&quot;bam&quot;</span>)</span><br>    inPeakN = counts(fragment_counts)<span class="hljs-literal">[,<span class="hljs-number">1</span>]</span> %&gt;% sum<br>    inPeakData = rbind(inPeakData, data.frame(inPeakN = inPeakN, Histone = hist, Replicate = rep))<br>  &#125;<br>&#125;<br><br>frip = left<span class="hljs-constructor">_join(<span class="hljs-params">inPeakData</span>, <span class="hljs-params">alignResult</span>, <span class="hljs-params">by</span> = <span class="hljs-params">c</span>(<span class="hljs-string">&quot;Histone&quot;</span>, <span class="hljs-string">&quot;Replicate&quot;</span>)</span>) %&gt;% mutate(frip = inPeakN/MappedFragNum_hg38<span class="hljs-operator"> * </span><span class="hljs-number">100</span>)<br>frip %&gt;% select(Histone, Replicate, SequencingDepth, MappedFragNum_hg38, AlignmentRate_hg38, FragInPeakNum = inPeakN, FRiPs = frip)<br></code></pre></td></tr></table></figure><table><thead><tr><th align="left">Histone<chr></th><th align="left">Replicate<chr></th><th align="right">SequencingDepth<dbl></th><th align="right">MappedFragNum_hg38<dbl></th><th align="right">AlignmentRate_hg38<dbl></th><th align="right">FragInPeakNum<dbl></th><th align="left"><strong>FRiPs</strong></th></tr></thead><tbody><tr><td align="left">K27me3</td><td align="left">rep1</td><td align="right">2984630</td><td align="right">2859520</td><td align="right">95.81</td><td align="right">2223813</td><td align="left">77.76875</td></tr><tr><td align="left">K27me3</td><td align="left">Rep2</td><td align="right"></td><td align="right"></td><td align="right"></td><td align="right"></td><td align="left">40.68507</td></tr><tr><td align="left">K4me3</td><td align="left">rep1</td><td align="right"></td><td align="right"></td><td align="right"></td><td align="right"></td><td align="left">91.60169</td></tr><tr><td align="left">K4me3</td><td align="left">Rep2</td><td align="right"></td><td align="right"></td><td align="right"></td><td align="right"></td><td align="left">71.46116</td></tr></tbody></table><h3 id="6-1-4-Visualization-of-peak-number-peak-width-peak-reproducibility-and-FRiPs"><a href="#6-1-4-Visualization-of-peak-number-peak-width-peak-reproducibility-and-FRiPs" class="headerlink" title="6.1.4 Visualization of peak number, peak width, peak reproducibility and FRiPs."></a>6.1.4 Visualization of peak number, peak width, peak reproducibility and FRiPs.</h3><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><code class="hljs sh">fig7A = peakN %&gt;% ggplot(aes(x = Histone, y = peakN, fill = Histone)) +<br>    geom_boxplot() +<br>    geom_jitter(aes(color = Replicate), position = position_jitter(0.15)) +<br>    facet_grid(~peakType) +<br>    scale_fill_viridis(discrete = TRUE, begin = 0.1, end = 0.55, option = <span class="hljs-string">&quot;magma&quot;</span>, alpha = 0.8) +<br>    scale_color_viridis(discrete = TRUE, begin = 0.1, end = 0.9) +<br>    theme_bw(base_size = 18) +<br>    ylab(<span class="hljs-string">&quot;Number of Peaks&quot;</span>) +<br>    xlab(<span class="hljs-string">&quot;&quot;</span>)<br><br>fig7B = peakWidth %&gt;% ggplot(aes(x = Histone, y = width, fill = Histone)) +<br>    geom_violin() +<br>    facet_grid(Replicate~peakType) +<br>    scale_fill_viridis(discrete = TRUE, begin = 0.1, end = 0.55, option = <span class="hljs-string">&quot;magma&quot;</span>, alpha = 0.8) +<br>    scale_color_viridis(discrete = TRUE, begin = 0.1, end = 0.9) +<br>    scale_y_continuous(trans = <span class="hljs-string">&quot;log&quot;</span>, breaks = c(400, 3000, 22000)) +<br>    theme_bw(base_size = 18) +<br>    ylab(<span class="hljs-string">&quot;Width of Peaks&quot;</span>) +<br>    xlab(<span class="hljs-string">&quot;&quot;</span>)<br><br>fig7C = peakReprod %&gt;% ggplot(aes(x = Histone, y = peakReprodRate, fill = Histone, label = round(peakReprodRate, 2))) +<br>    geom_bar(<span class="hljs-built_in">stat</span> = <span class="hljs-string">&quot;identity&quot;</span>) +<br>    geom_text(vjust = 0.1) +<br>    facet_grid(Replicate~peakType) +<br>    scale_fill_viridis(discrete = TRUE, begin = 0.1, end = 0.55, option = <span class="hljs-string">&quot;magma&quot;</span>, alpha = 0.8) +<br>    scale_color_viridis(discrete = TRUE, begin = 0.1, end = 0.9) +<br>    theme_bw(base_size = 18) +<br>    ylab(<span class="hljs-string">&quot;% of Peaks Reproduced&quot;</span>) +<br>    xlab(<span class="hljs-string">&quot;&quot;</span>)<br><br>fig7D = frip %&gt;% ggplot(aes(x = Histone, y = frip, fill = Histone, label = round(frip, 2))) +<br>    geom_boxplot() +<br>    geom_jitter(aes(color = Replicate), position = position_jitter(0.15)) +<br>    scale_fill_viridis(discrete = TRUE, begin = 0.1, end = 0.55, option = <span class="hljs-string">&quot;magma&quot;</span>, alpha = 0.8) +<br>    scale_color_viridis(discrete = TRUE, begin = 0.1, end = 0.9) +<br>    theme_bw(base_size = 18) +<br>    ylab(<span class="hljs-string">&quot;% of Fragments in Peaks&quot;</span>) +<br>    xlab(<span class="hljs-string">&quot;&quot;</span>)<br><br>ggarrange(fig7A, fig7B, fig7C, fig7D, ncol = 2, nrow=2, common.legend = TRUE, legend=<span class="hljs-string">&quot;bottom&quot;</span>)<br></code></pre></td></tr></table></figure><p><img src="/GeekFocus/./7.png" alt="7"></p><hr><h1 id="VII-Visualization"><a href="#VII-Visualization" class="headerlink" title="VII. Visualization"></a>VII. Visualization</h1><p>Typically we are interested in visualizing a chromatin landscape in regions using a genome browser. The <a href="http://software.broadinstitute.org/software/igv/home">Integrative Genomic Viewer</a> provides a web app version and a local desktop version that are easy to use. The <a href="https://genome.ucsc.edu/">UCSC Genome Browser</a> provides the most comprehensive supplementary genome information.</p><h2 id="7-1-Browser-display-of-normalized-bedgraph-files"><a href="#7-1-Browser-display-of-normalized-bedgraph-files" class="headerlink" title="7.1. Browser display of normalized bedgraph files."></a>7.1. Browser display of normalized bedgraph files.</h2><p><img src="/GeekFocus/./8.png" alt="7"></p><h2 id="7-2-Heatmap-visualization-on-specific-regions"><a href="#7-2-Heatmap-visualization-on-specific-regions" class="headerlink" title="7.2. Heatmap visualization on specific regions"></a>7.2. Heatmap visualization on specific regions</h2><p>We are also interested in looking at chromatin features at a list of annotated sites, for example histone modification signal at gene promoters.We will use the <code>computeMatrix</code> and <code>plotHeatmap</code> functions from <a href="https://deeptools.readthedocs.io/en/develop/">deepTools</a> to generate the heatmap.</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-comment">##== linux command ==##</span><br><span class="hljs-built_in">mkdir</span> -p <span class="hljs-variable">$projPath</span>/alignment/bigwig                                                                                                                                        <br>samtools <span class="hljs-built_in">sort</span> -o <span class="hljs-variable">$projPath</span>/alignment/bam/<span class="hljs-variable">$&#123;histName&#125;</span>.sorted.bam <span class="hljs-variable">$projPath</span>/alignment/bam/<span class="hljs-variable">$&#123;histName&#125;</span>_bowtie2.mapped.bam                                                     <br>samtools index <span class="hljs-variable">$projPath</span>/alignment/bam/<span class="hljs-variable">$&#123;histName&#125;</span>.sorted.bam                                                                                                              <br>bamCoverage -b <span class="hljs-variable">$projPath</span>/alignment/bam/<span class="hljs-variable">$&#123;histName&#125;</span>.sorted.bam -o <span class="hljs-variable">$projPath</span>/alignment/bigwig/<span class="hljs-variable">$&#123;histName&#125;</span>_raw.bw         <br></code></pre></td></tr></table></figure><h3 id="7-2-1-Heatmap-over-transcription-units"><a href="#7-2-1-Heatmap-over-transcription-units" class="headerlink" title="7.2.1 Heatmap over transcription units"></a>7.2.1 Heatmap over transcription units</h3><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-comment">##== linux command ==##</span><br>cores=8<br>computeMatrix scale-regions -S <span class="hljs-variable">$projPath</span>/alignment/bigwig/K27me3_rep1_raw.bw \<br>                               <span class="hljs-variable">$projPath</span>/alignment/bigwig/K27me3_rep2_raw.bw \<br>                               <span class="hljs-variable">$projPath</span>/alignment/bigwig/K4me3_rep1_raw.bw \<br>                               <span class="hljs-variable">$projPath</span>/alignment/bigwig/K4me3_rep2_raw.bw \<br>                              -R <span class="hljs-variable">$projPath</span>/data/hg38_gene/hg38_gene.tsv \<br>                              --beforeRegionStartLength 3000 \<br>                              --regionBodyLength 5000 \<br>                              --afterRegionStartLength 3000 \<br>                              --skipZeros -o <span class="hljs-variable">$projPath</span>/data/hg38_gene/matrix_gene.mat.gz -p <span class="hljs-variable">$cores</span><br><br>plotHeatmap -m <span class="hljs-variable">$projPath</span>/data/hg38_gene/matrix_gene.mat.gz -out <span class="hljs-variable">$projPath</span>/data/hg38_gene/Histone_gene.png --sortUsing <span class="hljs-built_in">sum</span><br></code></pre></td></tr></table></figure><p><img src="/GeekFocus/./9.png" alt="7"></p><h3 id="7-2-2-Heatmap-on-CUT-amp-Tag-peaks"><a href="#7-2-2-Heatmap-on-CUT-amp-Tag-peaks" class="headerlink" title="7.2.2. Heatmap on CUT&amp;Tag peaks"></a>7.2.2. Heatmap on CUT&amp;Tag peaks</h3><p>We use the midpoint of the signal block returned from SEACR to align signals in heatmaps. The sixth column of the SEACR output is an entry in the form chr:start-end that represents the first and ending bases of the region with the maximum signal of the region. We first generate a new bed file containing this midpoint information in column 6 and use deeptools for the heatmap visualization.</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-comment">#== linux command ==##</span><br>awk <span class="hljs-string">&#x27;&#123;split($6, summit, &quot;:&quot;); split(summit[2], region, &quot;-&quot;); print summit[1]&quot;\t&quot;region[1]&quot;\t&quot;region[2]&#125;&#x27;</span> <span class="hljs-variable">$projPath</span>/peakCalling/SEACR/<span class="hljs-variable">$&#123;histName&#125;</span>_<span class="hljs-variable">$&#123;repName&#125;</span>_seacr_control.pe\<br>aks.stringent.bed &gt;<span class="hljs-variable">$projPath</span>/peakCalling/SEACR/<span class="hljs-variable">$&#123;histName&#125;</span>_<span class="hljs-variable">$&#123;repName&#125;</span>_seacr_control.peaks.summitRegion.bed<br><br>computeMatrix reference-point -S <span class="hljs-variable">$projPath</span>/alignment/bigwig/<span class="hljs-variable">$&#123;histName&#125;</span>_<span class="hljs-variable">$&#123;repName&#125;</span>_raw.bw \<br>              -R <span class="hljs-variable">$projPath</span>/peakCalling/SEACR/<span class="hljs-variable">$&#123;histName&#125;</span>_<span class="hljs-variable">$&#123;repName&#125;</span>_seacr_control.peaks.summitRegion.bed \<br>              --skipZeros -o <span class="hljs-variable">$projPath</span>/peakCalling/SEACR/<span class="hljs-variable">$&#123;histName&#125;</span>_<span class="hljs-variable">$&#123;repName&#125;</span>_SEACR.mat.gz -p <span class="hljs-variable">$cores</span> -a 3000 -b 3000 --referencePoint center<br><br>plotHeatmap -m <span class="hljs-variable">$projPath</span>/peakCalling/SEACR/<span class="hljs-variable">$&#123;histName&#125;</span>_SEACR.mat.gz -out <span class="hljs-variable">$projPath</span>/peakCalling/SEACR/<span class="hljs-variable">$&#123;histName&#125;</span>_SEACR_heatmap.png --sortUsing <span class="hljs-built_in">sum</span> --startLabel <span class="hljs-string">&quot;Peak Start&quot;</span> -\<br>-endLabel <span class="hljs-string">&quot;Peak End&quot;</span> --xAxisLabel <span class="hljs-string">&quot;&quot;</span> --regionsLabel <span class="hljs-string">&quot;Peaks&quot;</span> --samplesLabel <span class="hljs-string">&quot;<span class="hljs-variable">$&#123;histName&#125;</span> <span class="hljs-variable">$&#123;repName&#125;</span>&quot;</span><br></code></pre></td></tr></table></figure><p><img src="/GeekFocus/./10.png" alt="7"></p><hr><h1 id="VIII-Differention-analysis"><a href="#VIII-Differention-analysis" class="headerlink" title="VIII. Differention analysis"></a>VIII. Differention analysis</h1><ul><li>DESeq2: <a href="https://genomebiology.biomedcentral.com/articles/10.1186/s13059-014-0550-8">Moderated estimation of fold change and dispersion for RNA-seq data with DESeq2</a></li></ul><p>Estimate variance-mean dependence in count data from high-throughput sequencing assays and test for differential expression based on a model using the negative binomial distribution.</p><h2 id="8-1-Create-the-peak-x-sample-matrix"><a href="#8-1-Create-the-peak-x-sample-matrix" class="headerlink" title="8.1. Create the peak x sample matrix."></a>8.1. Create the peak x sample matrix.</h2><p>Usually, the differential tests compare two or more conditions of the same histone modification. In this tutorial, limited by the demonstration data, we will illustrate the differential detection by comparing two replicates of H3K27me3 and two replicates of H3K4me3. We will use DESeq2 (<a href="http://bioconductor.org/packages/release/bioc/vignettes/DESeq2/inst/doc/DESeq2.html#why-un-normalized-counts">complete tutorial</a>) as illustration.</p><h3 id="8-1-1-Create-a-master-peak-list-merging-all-the-peaks-called-for-each-sample"><a href="#8-1-1-Create-a-master-peak-list-merging-all-the-peaks-called-for-each-sample" class="headerlink" title="8.1.1 Create a master peak list merging all the peaks called for each sample."></a>8.1.1 Create a master peak list merging all the peaks called for each sample.</h3><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-comment">##=== R command ===## </span><br>mPeak = GRanges()<br><span class="hljs-comment">## overlap with bam file to get count</span><br><span class="hljs-keyword">for</span>(hist <span class="hljs-keyword">in</span> histL)&#123;<br>  <span class="hljs-keyword">for</span>(rep <span class="hljs-keyword">in</span> repL)&#123;<br>    peakRes = read.table(paste0(projPath, <span class="hljs-string">&quot;/peakCalling/SEACR/&quot;</span>, hist, <span class="hljs-string">&quot;_&quot;</span>, rep, <span class="hljs-string">&quot;_seacr_control.peaks.stringent.bed&quot;</span>), header = FALSE, fill = TRUE)<br>    mPeak = GRanges(seqnames = peakRes<span class="hljs-variable">$V1</span>, IRanges(start = peakRes<span class="hljs-variable">$V2</span>, end = peakRes<span class="hljs-variable">$V3</span>), strand = <span class="hljs-string">&quot;*&quot;</span>) %&gt;% append(mPeak, .)<br>  &#125;<br>&#125;<br>masterPeak = reduce(mPeak)<br></code></pre></td></tr></table></figure><h3 id="8-1-2-Get-the-fragment-counts-for-each-peak-in-the-master-peak-list"><a href="#8-1-2-Get-the-fragment-counts-for-each-peak-in-the-master-peak-list" class="headerlink" title="8.1.2 Get the fragment counts for each peak in the master peak list."></a>8.1.2 Get the fragment counts for each peak in the master peak list.</h3><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs r"><span class="hljs-comment">##=== R command ===## </span><br>library<span class="hljs-punctuation">(</span>DESeq2<span class="hljs-punctuation">)</span><br>bamDir <span class="hljs-operator">=</span> paste0<span class="hljs-punctuation">(</span>projPath<span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;/alignment/bam&quot;</span><span class="hljs-punctuation">)</span><br>countMat <span class="hljs-operator">=</span> matrix<span class="hljs-punctuation">(</span><span class="hljs-literal">NA</span><span class="hljs-punctuation">,</span> <span class="hljs-built_in">length</span><span class="hljs-punctuation">(</span>masterPeak<span class="hljs-punctuation">)</span><span class="hljs-punctuation">,</span> <span class="hljs-built_in">length</span><span class="hljs-punctuation">(</span>histL<span class="hljs-punctuation">)</span><span class="hljs-operator">*</span><span class="hljs-built_in">length</span><span class="hljs-punctuation">(</span>repL<span class="hljs-punctuation">)</span><span class="hljs-punctuation">)</span><br><span class="hljs-comment">## overlap with bam file to get count</span><br>i <span class="hljs-operator">=</span> <span class="hljs-number">1</span><br><span class="hljs-keyword">for</span><span class="hljs-punctuation">(</span>hist <span class="hljs-keyword">in</span> histL<span class="hljs-punctuation">)</span><span class="hljs-punctuation">&#123;</span><br>  <span class="hljs-keyword">for</span><span class="hljs-punctuation">(</span><span class="hljs-built_in">rep</span> <span class="hljs-keyword">in</span> repL<span class="hljs-punctuation">)</span><span class="hljs-punctuation">&#123;</span><br>    <br>    bamFile <span class="hljs-operator">=</span> paste0<span class="hljs-punctuation">(</span>bamDir<span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;/&quot;</span><span class="hljs-punctuation">,</span> hist<span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;_&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-built_in">rep</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;_bowtie2.mapped.bam&quot;</span><span class="hljs-punctuation">)</span><br>    fragment_counts <span class="hljs-operator">&lt;-</span> getCounts<span class="hljs-punctuation">(</span>bamFile<span class="hljs-punctuation">,</span> masterPeak<span class="hljs-punctuation">,</span> paired <span class="hljs-operator">=</span> <span class="hljs-literal">TRUE</span><span class="hljs-punctuation">,</span> by_rg <span class="hljs-operator">=</span> <span class="hljs-literal">FALSE</span><span class="hljs-punctuation">,</span> format <span class="hljs-operator">=</span> <span class="hljs-string">&quot;bam&quot;</span><span class="hljs-punctuation">)</span><br>    countMat<span class="hljs-punctuation">[</span><span class="hljs-punctuation">,</span> i<span class="hljs-punctuation">]</span> <span class="hljs-operator">=</span> counts<span class="hljs-punctuation">(</span>fragment_counts<span class="hljs-punctuation">)</span><span class="hljs-punctuation">[</span><span class="hljs-punctuation">,</span><span class="hljs-number">1</span><span class="hljs-punctuation">]</span><br>    i <span class="hljs-operator">=</span> i <span class="hljs-operator">+</span> <span class="hljs-number">1</span><br>  <span class="hljs-punctuation">&#125;</span><br><span class="hljs-punctuation">&#125;</span><br>colnames<span class="hljs-punctuation">(</span>countMat<span class="hljs-punctuation">)</span> <span class="hljs-operator">=</span> paste<span class="hljs-punctuation">(</span><span class="hljs-built_in">rep</span><span class="hljs-punctuation">(</span>histL<span class="hljs-punctuation">,</span> <span class="hljs-number">2</span><span class="hljs-punctuation">)</span><span class="hljs-punctuation">,</span> <span class="hljs-built_in">rep</span><span class="hljs-punctuation">(</span>repL<span class="hljs-punctuation">,</span> each <span class="hljs-operator">=</span> <span class="hljs-number">2</span><span class="hljs-punctuation">)</span><span class="hljs-punctuation">,</span> sep <span class="hljs-operator">=</span> <span class="hljs-string">&quot;_&quot;</span><span class="hljs-punctuation">)</span><br></code></pre></td></tr></table></figure><h2 id="8-2-Sequencing-depth-normalization-and-differential-enriched-peaks-detection"><a href="#8-2-Sequencing-depth-normalization-and-differential-enriched-peaks-detection" class="headerlink" title="8.2. Sequencing depth normalization and differential enriched peaks detection"></a>8.2. Sequencing depth normalization and differential enriched peaks detection</h2><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs r"><span class="hljs-comment">##=== R command ===## </span><br>selectR <span class="hljs-operator">=</span> which<span class="hljs-punctuation">(</span>rowSums<span class="hljs-punctuation">(</span>countMat<span class="hljs-punctuation">)</span> <span class="hljs-operator">&gt;</span> <span class="hljs-number">5</span><span class="hljs-punctuation">)</span> <span class="hljs-comment">## remove low count genes</span><br>dataS <span class="hljs-operator">=</span> countMat<span class="hljs-punctuation">[</span>selectR<span class="hljs-punctuation">,</span><span class="hljs-punctuation">]</span><br>condition <span class="hljs-operator">=</span> factor<span class="hljs-punctuation">(</span><span class="hljs-built_in">rep</span><span class="hljs-punctuation">(</span>histL<span class="hljs-punctuation">,</span> each <span class="hljs-operator">=</span> <span class="hljs-built_in">length</span><span class="hljs-punctuation">(</span>repL<span class="hljs-punctuation">)</span><span class="hljs-punctuation">)</span><span class="hljs-punctuation">)</span><br>dds <span class="hljs-operator">=</span> DESeqDataSetFromMatrix<span class="hljs-punctuation">(</span>countData <span class="hljs-operator">=</span> dataS<span class="hljs-punctuation">,</span><br>                              colData <span class="hljs-operator">=</span> DataFrame<span class="hljs-punctuation">(</span>condition<span class="hljs-punctuation">)</span><span class="hljs-punctuation">,</span><br>                              design <span class="hljs-operator">=</span> <span class="hljs-operator">~</span> condition<span class="hljs-punctuation">)</span><br>DDS <span class="hljs-operator">=</span> DESeq<span class="hljs-punctuation">(</span>dds<span class="hljs-punctuation">)</span><br>normDDS <span class="hljs-operator">=</span> counts<span class="hljs-punctuation">(</span>DDS<span class="hljs-punctuation">,</span> normalized <span class="hljs-operator">=</span> <span class="hljs-literal">TRUE</span><span class="hljs-punctuation">)</span> <span class="hljs-comment">## normalization with respect to the sequencing depth</span><br>colnames<span class="hljs-punctuation">(</span>normDDS<span class="hljs-punctuation">)</span> <span class="hljs-operator">=</span> paste0<span class="hljs-punctuation">(</span>colnames<span class="hljs-punctuation">(</span>normDDS<span class="hljs-punctuation">)</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;_norm&quot;</span><span class="hljs-punctuation">)</span><br>res <span class="hljs-operator">=</span> results<span class="hljs-punctuation">(</span>DDS<span class="hljs-punctuation">,</span> independentFiltering <span class="hljs-operator">=</span> <span class="hljs-literal">FALSE</span><span class="hljs-punctuation">,</span> altHypothesis <span class="hljs-operator">=</span> <span class="hljs-string">&quot;greaterAbs&quot;</span><span class="hljs-punctuation">)</span><br><br>countMatDiff <span class="hljs-operator">=</span> cbind<span class="hljs-punctuation">(</span>dataS<span class="hljs-punctuation">,</span> normDDS<span class="hljs-punctuation">,</span> res<span class="hljs-punctuation">)</span><br>head<span class="hljs-punctuation">(</span>countMatDiff<span class="hljs-punctuation">)</span><br></code></pre></td></tr></table></figure><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs r">DataFrame with <span class="hljs-number">6</span> rows and <span class="hljs-number">14</span> columns<br>  K27me3_rep1 K4me3_rep1 K27me3_rep2 K4me3_rep2 K27me3_rep1_norm<br>    <span class="hljs-operator">&lt;</span>numeric<span class="hljs-operator">&gt;</span>  <span class="hljs-operator">&lt;</span>numeric<span class="hljs-operator">&gt;</span>   <span class="hljs-operator">&lt;</span>numeric<span class="hljs-operator">&gt;</span>  <span class="hljs-operator">&lt;</span>numeric<span class="hljs-operator">&gt;</span>        <span class="hljs-operator">&lt;</span>numeric<span class="hljs-operator">&gt;</span><br><span class="hljs-number">1</span>           <span class="hljs-number">6</span>          <span class="hljs-number">2</span>           <span class="hljs-number">1</span>          <span class="hljs-number">6</span>         <span class="hljs-number">1.408657</span><br><span class="hljs-number">2</span>           <span class="hljs-number">1</span>          <span class="hljs-number">0</span>         <span class="hljs-number">242</span>        <span class="hljs-number">182</span>         <span class="hljs-number">0.234776</span><br><span class="hljs-number">3</span>           <span class="hljs-number">0</span>          <span class="hljs-number">0</span>         <span class="hljs-number">176</span>         <span class="hljs-number">88</span>         <span class="hljs-number">0.000000</span><br><span class="hljs-number">4</span>           <span class="hljs-number">0</span>          <span class="hljs-number">0</span>         <span class="hljs-number">274</span>        <span class="hljs-number">194</span>         <span class="hljs-number">0.000000</span><br><span class="hljs-number">5</span>           <span class="hljs-number">3</span>          <span class="hljs-number">4</span>           <span class="hljs-number">0</span>          <span class="hljs-number">1</span>         <span class="hljs-number">0.704328</span><br><span class="hljs-number">6</span>           <span class="hljs-number">0</span>          <span class="hljs-number">1</span>         <span class="hljs-number">109</span>         <span class="hljs-number">59</span>         <span class="hljs-number">0.000000</span><br>  K4me3_rep1_norm K27me3_rep2_norm K4me3_rep2_norm  baseMean log2FoldChange<br>        <span class="hljs-operator">&lt;</span>numeric<span class="hljs-operator">&gt;</span>        <span class="hljs-operator">&lt;</span>numeric<span class="hljs-operator">&gt;</span>       <span class="hljs-operator">&lt;</span>numeric<span class="hljs-operator">&gt;</span> <span class="hljs-operator">&lt;</span>numeric<span class="hljs-operator">&gt;</span>      <span class="hljs-operator">&lt;</span>numeric<span class="hljs-operator">&gt;</span><br><span class="hljs-number">1</span>        <span class="hljs-number">0.620403</span>            <span class="hljs-number">4.170</span>         <span class="hljs-number">18.2724</span>   <span class="hljs-number">6.11787</span>       <span class="hljs-number">3.496854</span><br><span class="hljs-number">2</span>        <span class="hljs-number">0.000000</span>         <span class="hljs-number">1009.141</span>        <span class="hljs-number">554.2634</span> <span class="hljs-number">390.90978</span>      <span class="hljs-number">12.510325</span><br><span class="hljs-number">3</span>        <span class="hljs-number">0.000000</span>          <span class="hljs-number">733.921</span>        <span class="hljs-number">267.9955</span> <span class="hljs-number">250.47905</span>      <span class="hljs-number">13.297304</span><br><span class="hljs-number">4</span>        <span class="hljs-number">0.000000</span>         <span class="hljs-number">1142.581</span>        <span class="hljs-number">590.8082</span> <span class="hljs-number">433.34733</span>      <span class="hljs-number">14.089840</span><br><span class="hljs-number">5</span>        <span class="hljs-number">1.240806</span>            <span class="hljs-number">0.000</span>          <span class="hljs-number">3.0454</span>   <span class="hljs-number">1.24763</span>       <span class="hljs-number">0.846266</span><br><span class="hljs-number">6</span>        <span class="hljs-number">0.310202</span>          <span class="hljs-number">454.530</span>        <span class="hljs-number">179.6788</span> <span class="hljs-number">158.62986</span>      <span class="hljs-number">11.189689</span><br>      lfcSE      stat      pvalue        padj<br>  <span class="hljs-operator">&lt;</span>numeric<span class="hljs-operator">&gt;</span> <span class="hljs-operator">&lt;</span>numeric<span class="hljs-operator">&gt;</span>   <span class="hljs-operator">&lt;</span>numeric<span class="hljs-operator">&gt;</span>   <span class="hljs-operator">&lt;</span>numeric<span class="hljs-operator">&gt;</span><br><span class="hljs-number">1</span>   <span class="hljs-number">1.19893</span>  <span class="hljs-number">2.916635</span> <span class="hljs-number">3.53829e-03</span> <span class="hljs-number">4.22134e-02</span><br><span class="hljs-number">2</span>   <span class="hljs-number">1.50039</span>  <span class="hljs-number">8.338074</span> <span class="hljs-number">7.55102e-17</span> <span class="hljs-number">2.18197e-15</span><br><span class="hljs-number">3</span>   <span class="hljs-number">1.58547</span>  <span class="hljs-number">8.386969</span> <span class="hljs-number">4.98837e-17</span> <span class="hljs-number">1.50548e-15</span><br><span class="hljs-number">4</span>   <span class="hljs-number">1.55196</span>  <span class="hljs-number">9.078730</span> <span class="hljs-number">1.09850e-19</span> <span class="hljs-number">6.73560e-18</span><br><span class="hljs-number">5</span>   <span class="hljs-number">2.18326</span>  <span class="hljs-number">0.387617</span> <span class="hljs-number">6.98300e-01</span> <span class="hljs-number">9.72755e-01</span><br><span class="hljs-number">6</span>   <span class="hljs-number">1.53046</span>  <span class="hljs-number">7.311313</span> <span class="hljs-number">2.64545e-13</span> <span class="hljs-number">4.33546e-12</span><br></code></pre></td></tr></table></figure><ul><li>DESeq2 requires the input matrix should be un-normalized counts or estimated counts of sequencing reads.</li><li>DESeq2 model internally corrects for library size.</li><li><strong>countMatDiff</strong> summarizes the differential analysis results:<ul><li>First 4 columns: raw reads counts after filtering the peak regions with low counts</li><li>Second 4 columns: normalized read counts eliminating library size difference.</li><li>Remaining columns: differential detection results.</li></ul></li></ul><h1 id="References"><a href="#References" class="headerlink" title="References"></a>References</h1><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">Kaya</span>-Okur HS, Wu SJ, Codomo CA, Pledger ES, Bryson TD, Henikoff JG, Ahmad K, Henikoff S: CUT&amp;Tag for efficient epigenomic profiling of small samples and single cells. Nature Communications <span class="hljs-number">2019</span> <span class="hljs-number">10</span>:<span class="hljs-number">1930</span> (PMID:<span class="hljs-number">31036827</span>).<br><br><span class="hljs-attribute">Meers</span>, M.P., Tenenbaum, D. &amp; Henikoff, S. Peak calling by Sparse Enrichment Analysis for CUT&amp;RUN chromatin profiling. Epigenetics &amp; Chromatin <span class="hljs-number">12</span>, <span class="hljs-number">42</span> (<span class="hljs-number">2019</span>). https://doi.org/<span class="hljs-number">10</span>.<span class="hljs-number">1186</span>/s13072-<span class="hljs-number">019</span>-<span class="hljs-number">0287</span>-<span class="hljs-number">4</span><br><br></code></pre></td></tr></table></figure><h1 id="IX-Additional-Alternatives"><a href="#IX-Additional-Alternatives" class="headerlink" title="IX. Additional Alternatives"></a>IX. Additional Alternatives</h1><h2 id="9-1-ChIPseqSpikeInFree-for-normalizing-data-without-spike-in-DNA-Optional"><a href="#9-1-ChIPseqSpikeInFree-for-normalizing-data-without-spike-in-DNA-Optional" class="headerlink" title="9.1 ChIPseqSpikeInFree for normalizing data without spike-in DNA [Optional]"></a>9.1 ChIPseqSpikeInFree for normalizing data without spike-in DNA [Optional]</h2><p><a href="https://academic.oup.com/bioinformatics/article/36/4/1270/5578481">ChIPseqSpikeInFree: a ChIP-seq normalization approach to reveal global changes in histone modifications without spike-in</a> is a novel ChIP-seq normalization method to effectively determine scaling factors for samples across various conditions and treatments, which does not rely on exogenous spike-in chromatin or peak detection to reveal global changes in histone modification occupancy. The installation details can be found on <a href="https://github.com/stjude/ChIPseqSpikeInFree">github</a>.</p><ul><li><a href="https://github.com/stjude/ChIPseqSpikeInFree#interpretation-of-scaling-factor-table">Interpretation of the ChIPseqSpikeInFree output.</a></li><li><a href="https://github.com/stjude/ChIPseqSpikeInFree#how-to-use-chipseqspikein-scaling-factor">How to use ChIPseqSpikeInFree scaling factor.</a></li></ul><h2 id="9-2-Other-peak-calling-methods"><a href="#9-2-Other-peak-calling-methods" class="headerlink" title="9.2. Other peak calling methods."></a>9.2. Other peak calling methods.</h2><ul><li>MACS2: <a href="https://genomebiology.biomedcentral.com/articles/10.1186/gb-2008-9-9-r137">Model-based Analysis of ChIP-Seq (MACS)</a>. Installation details can be found <a href="https://github.com/taoliu/MACS/wiki">here</a>.</li></ul><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-comment">##== linux command ==##</span><br>histName=<span class="hljs-string">&quot;K27me3&quot;</span><br>controlName=<span class="hljs-string">&quot;IgG&quot;</span><br><br><span class="hljs-built_in">mkdir</span> -p <span class="hljs-variable">$projPath</span>/peakCalling<br>macs2 callpeak -t <span class="hljs-variable">$&#123;projPath&#125;</span>/alignment/bam/<span class="hljs-variable">$&#123;histName&#125;</span>_rep1_bowtie2.mapped.bam \<br>      -c <span class="hljs-variable">$&#123;projPath&#125;</span>/alignment/bam/<span class="hljs-variable">$&#123;controlName&#125;</span>_rep1_bowtie2.mapped.bam \<br>      -g hs -f BAMPE -n macs2_peak_q0.1 --outdir <span class="hljs-variable">$projPath</span>/peakCalling/MACS2 -q 0.1 --keep-dup all 2&gt;<span class="hljs-variable">$&#123;projPath&#125;</span>/peakCalling/MACS2/macs2Peak_summary.txt<br></code></pre></td></tr></table></figure><ul><li>dPeak: <a href="https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1003246">dPeak: High Resolution Identification of Transcription Factor Binding Sites from PET and SET ChIP-Seq Data</a></li><li>MOSAiCS: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4608541/">A Statistical Framework for the Analysis of ChIP-Seq Data</a></li></ul><h2 id="9-3-Other-packages-for-differential-analysis-of-binding-sites"><a href="#9-3-Other-packages-for-differential-analysis-of-binding-sites" class="headerlink" title="9.3 Other packages for differential analysis of binding sites"></a>9.3 Other packages for differential analysis of binding sites</h2><ul><li>Limma: <a href="https://academic.oup.com/nar/article/43/7/e47/2414268">limma powers differential expression analyses for RNA-sequencing and microarray studies</a></li></ul><p>Limma is an R package for the analysis of gene expression microarray data, especially the use of linear models for analysing designed experiments and the assessment of differential expression. Limma provides the ability to analyse comparisons between many RNA targets simultaneously in arbitrary complicated designed experiments. Empirical Bayesian methods are used to provide stable results even when the number of arrays is small. Limma can be extended to study differential fragment enrichment analysis within peak regions. Notably, limma can deal with both fixed effect model and random effect model.</p><ul><li>edgeR: <a href="https://academic.oup.com/nar/article/40/10/4288/2411520">Differential Expression Analysis of Multifactor RNA-Seq Experiments With Respect to Biological Variation</a></li></ul><p>Differential expression analysis of RNA-seq expression profiles with biological replication. Implements a range of statistical methodology based on the negative binomial distributions, including empirical Bayes estimation, exact tests, generalized linear models and quasi-likelihood tests. As well as RNA-seq, it be applied to differential signal analysis of other types of genomic data that produce read counts, including ChIP-seq, ATAC-seq, Bisulfite-seq, SAGE and CAGE. edgeR can deal with multifactor problem.</p><h1 id="X-Troubleshooting-Generating-your-data"><a href="#X-Troubleshooting-Generating-your-data" class="headerlink" title="X. Troubleshooting: Generating your data"></a>X. Troubleshooting: Generating your data</h1><p>This workflow can be followed with your own data and will generate a standardized set of quality-control reports. However, many sequencing facilities do not perform 25x25 PE sequencing, and alternate parameters for trimming and mapping are provided here. Control datasets for non-specific antibody (IgG) profiling or ATAC-seq profiling of your material can also be used for optional analysis detailed here.</p><p>Stringent washing with 300 mM NaCl is critical to limit the affinity of Tn5 for exposed DNA. We describe here the need for controlling background Tn5 affinities and describe how our CUT&amp;Tag protocol effectively suppresses this artifact for unambiguous mapping of chromatin epitopes. We present a protocol that can process either native or fixed nuclei and includes alternative methods for DNA isolation. To illustrate the method, we describe a typical experiment, including evaluation of the results using a new metric for peak-calling information. Further, we validate a single-tube format for CUT&amp;Tag that requires no DNA isolation but instead uses tagmented material directly for library amplification. We document critical steps for the CUT&amp;Tag protocol, informed by our experiences, helping users establish this method in their research.</p><hr><p>Cite:<a href="https://yezhengstat.github.io/CUTTag_tutorial/#">https://yezhengstat.github.io/CUTTag_tutorial/#</a> Zheng Y et al (2020). Protocol.io</p>]]></content>
    
    
    <categories>
      
      <category>NGS</category>
      
    </categories>
    
    
    <tags>
      
      <tag>pipeline</tag>
      
      <tag>CUT-tag</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【ATAC-seq-pipeline】</title>
    <link href="/GeekFocus/2022/03/20/2022-03-20-ATAC-seq-6/"/>
    <url>/GeekFocus/2022/03/20/2022-03-20-ATAC-seq-6/</url>
    
    <content type="html"><![CDATA[<p>ATAC-seq信息分析流程主要分为以下几个部分：数据质控、序列比对、峰检测、motif分析、峰注释、富集分析.</p><p>an <strong>a</strong>ssay for <strong>t</strong>ransposase-<strong>a</strong>ccessible <strong>c</strong>hromatin using <strong>seq</strong>uencing </p><span id="more"></span><hr><p><a href="https://www.biostars.org/p/442707/">?</a></p><p><a href="https://www.biostars.org/p/413626/">?</a></p><p><a href="https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSM3455685">Data processing1:Johns Hopkins University School of Medicine</a>2019 mar</p><p>ATAC-seq data were <strong>aligned</strong> using <strong>Bowtie2</strong> (Version 2.3.2 t -X 2000 <strong>–no-mixed –no-discordant</strong>) </p><p> <strong>duplicate</strong> reads were removed (<strong>picard</strong> MarkDuplicates)</p><p>Peaks were called using <strong>MACS2</strong> (Version 2.1.1.20160309 callpeak <strong>–nomodel –keep-dup all –shift −100 –extsize 200</strong> –call-summits) (Zhang et al., 2008). </p><p>Peaks were then <strong>filtered for fold-change &gt;2 and -log(qvalue) &gt;2</strong>. </p><p><strong>deepTools</strong> was used to visualize ATAC-seq peaks on the browser (bamCoverage -bs 1 –normalizeUsing <strong>RPKM</strong>).<br>Genome_build: <strong>mm10</strong><br>Supplementary_files_format_and_content: narrowPeak and .bw</p><p><a href="https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSM5502736">Data processing2:University of California, San Diego</a>  2022 Jan<br>Sequenced reads were trimmed for adaptor sequence, and masked for low-complexity or low-quality sequence, then mapped to hg38 whole genome using <strong>bowtie</strong> v2.3.5.1 with parameters -q -p 4 -e 100 -y -a -m 10 –best –strata<br>For <strong>RNA-seq data</strong>: Transcripts per Million (<strong>TPM</strong>) were calculated using a protocol from <strong>Chepelev et al</strong>., Nucleic Acids Research, 2009. In short, exons from all isoforms of a gene were merged to create one meta-transcript. The number of reads falling in the exons of this meta-transcript were counted and normalized by the size of the meta-transcript and by the size of the library.<br>For <strong>ATAC-seq data</strong>: peaks were called using <strong>Genrich</strong> version 0.6.1 with the following setting: -j -y -r -e chrM -v.</p><p><strong>Bigwig</strong> file generated using bamCoverage version 3.3.2 with the following setting: <strong>—binSize 20 —normalizeUsing BPM —smoothLength 60 —centerReads</strong>. Heatmap, genomic tracker and scatter map generated using EaSeq version 1.111.<br>For <strong>ChIP-seq data</strong>: peaks were called using <strong>MACS3</strong> version 3.0.0a6 with the following setting: -g hs -f BAM. Bigwig file generated using bamCoverage version 3.3.2 with the following setting: <strong>—binSize 20 —normalizeUsing BPM —smoothLength 60 —centerReads</strong>. Heatmap, genomic tracker and scatter map generated using EaSeq version 1.111.<br>For <strong>CUT&amp;Tag-seq data</strong>: peaks were called using <strong>SEACR</strong> version 1.3 with the following setting: <strong>-norm strigent</strong>. </p><p>Bigwig file generated using bamCoverage version 3.3.2 with the following setting: <strong>—binSize 20 —normalizeUsing BPM —smoothLength 60 —centerReads</strong>. Heatmap, genomic tracker and scatter map generated using <strong>EaSeq</strong> version 1.111.<br>Genome_build: <strong>hg38</strong><br>Supplementary_files_format_and_content: For RNA-seq: tab-delimited text files include TPM values for each Sample<br>Supplementary_files_format_and_content: For ATAC-seq, ChIP-seq and CUT&amp;Tag-seq: bigwid files for display in hg38 genome browser track</p><p><a href="https://https.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSM4432199">Data processing3:Hong Kong University of Science and Technology</a>  2020 may</p><p>For ChIP-seq, Base-calling is done by bcl2-fastq<br>For sequencing alignment and duplicate removal, sequencing data were mapped to the mm10 mice genome assembly by using the <strong>BWA</strong>. Duplicates were marked and removed using the <strong>Picard</strong> tools MarkDuplicates function with the parameter, REMOVE_DUPLICATES&#x3D;TRUE.<br>For <strong>peak identification</strong>, the <strong>HOMER</strong> (Heinz et al., 2010) maketagdirectory function was used to combine sequencing data from the biological replicates, and the <strong>findPeaks</strong> function was used to identify binding&#x2F;accessible regions with the following parameters: -style factor (for PU.1 ChIP-seq), <strong>-style histone</strong> (for H3K4me3 ChIP-seq), and <strong>-style histone -minDist 200</strong> (for ATAC-seq). Regions were annotated by the <strong>annotatePeaks.pl</strong> function. deepTools bamCoverage function and visualized in igv browser (Robinson et al., 2011).<br><strong>Read count in the binding&#x2F;accessible regions</strong> was <strong>quantified</strong> by the <strong>bedtools</strong> (Quinlan and Hall, 2010) <strong>multicov</strong> function. Differential binding&#x2F;accessible regions (p &lt; 0.05) were calculated using R.<br>Genome_build: mm10<br>Supplementary_files_format_and_content: bigWig files were generated using <strong>Bamcoverage –normalizeUsing CPM –binSize 10</strong><br>For scRNA-seq,Base-calling is done by bcl2-fastq<br>The sequencing data were aligned, quantified, and clustered using Cell Ranger (version 3.0) as previously described (Zheng et al., 2017).<br>Genome_build: mm10<br>Supplementary_files_format_and_content: Matrix of read count, barcode were generated using cell ranger v3</p><p><a href="https://https.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSM4160552">Data processing 4:Johns Hopkins University School of Medicine</a> 2020 Jan</p><p>ATAC-seq data were <strong>aligned</strong> to the GRCm38 genome using <strong>HISAT2</strong> version 2.1.0 (hisat2 -t -X 2000 –no-mixed –no-discordant) and then duplicate reads were removed (<strong>picard</strong> MarkDuplicates). Peaks were called using <strong>MACS2</strong> version 2.1.2 (<strong>callpeak -f BAM –nomodel –keep-dup all –shift −100 –extsize 200</strong>) (Zhang et al., 2008). Peaks were then filtered for <strong>fold-change &gt;2 and -log(qvalue) &gt;2</strong>. deepTools was used to visualize ATAC-seq peaks on the browser (bamCoverage <strong>-bs 1 –extendReads –ignoreDuplicates –normalizeUsing CPM</strong>).<br>Genome_build: mm10</p><p>GEO ATAC-seq?????</p><p>GEO CUT&amp;Tag??????</p><p><a href="https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE101940">2018Arab</a></p><hr><p><a href="https://www.jianshu.com/p/dc0c49bfcd41;https://seqhealth.biomart.cn/news/2995703.htm;https://zhuanlan.zhihu.com/p/146068902;https://www.jianshu.com/p/09e05bcd6981">Ref1</a></p><blockquote><p><strong>一、数据过滤与质量评估</strong></p></blockquote><p>fastp fastqc</p><blockquote><p><strong>二、比对</strong></p></blockquote><p>Bowtie2,bwa</p><p>后续分析reads需要唯一比对且去重复的，比对结果通过<strong>MAPQ</strong>值提取唯一比对reads，可以用picard、sambamba等去除dup，最终得到唯一比对且去重复的bam</p><p>质体序列去除。samtools提取，将不含质体的染色体写到chrlist文件[Chr1….12]，一条染色体一行</p><p><code>samtools view -b A1.bam $chrlist &gt; A1.del_MT_PT.bam</code></p><blockquote><p><strong>三、reads在染色体上分布的可视化</strong></p></blockquote><p>bam转bigWig（bw），IGV展示(no shift)。deeptools可实现bw格式转化和可视化展示</p><p><code>bamCoverage -b A1.bam -o A1.bw</code></p><p>deeptools展示reads在特定区域的分布，如：</p><figure class="highlight ldif"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs ldif">computeMatrix reference-point   \ <span class="hljs-comment"># reference-pioint表示计算一个参照点附近的reads分布，与之相对的是scale-regions，计算一个区域附近的reads分布</span><br><span class="hljs-literal">-</span>-referencePoint TSS   \<span class="hljs-comment">#以输入的bed文件的起始位置作为参照点</span><br><span class="hljs-literal">-</span>S  A1.bw \ <span class="hljs-comment">#可以是一个或多个bw文件</span><br><span class="hljs-literal">-</span>R  gene.bed \ <span class="hljs-comment">#基因组位置文件</span><br><span class="hljs-literal">-</span>b 3000   \ <span class="hljs-comment">#计算边界为参考点上游3000bp</span><br><span class="hljs-literal">-</span>a 3000   \ <span class="hljs-comment">#计算边界为参考点下游3000bp，与-b合起来就是绘制参考点上下游3000bp以内的reads分布</span><br><span class="hljs-literal">-</span>o  A1.matrix.mat.gz \ <span class="hljs-comment">#输出作图数据名称</span><br></code></pre></td></tr></table></figure><figure class="highlight livescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs livescript"><span class="hljs-string">\#图形绘制</span><br>plotHeatmap <span class="hljs-string">\</span><br>-m  new_A1.matrix.mat.gz <span class="hljs-string">\</span> <span class="hljs-comment">#上一步生成的作图数据</span><br>-out A1.pdf <span class="hljs-string">\</span> <span class="hljs-comment"># 输出图片名称</span><br></code></pre></td></tr></table></figure><blockquote><p><strong>四、Peak calling</strong></p></blockquote><p>MACS2检测DNA片断富集区域，是ATAC-seq call peak的<strong>主流软件</strong>。峰检出原理：首先将所有的reads都向3’方向延伸插入片段长度，然后将基因组进行滑窗，计算该窗口的dynamic λ，λ的计算公式为：λlocal &#x3D; λBG（λBG是指背景区域上的reads数目），然后利用泊松分布模型的公式计算该窗口的显著性P值，最后对每一个窗口的显著性P值进行FDR校正。默认校正后的P值（即qvalue）小于或者等于0.05的区域为peak区域。</p><figure class="highlight ldif"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs ldif">macs2 callpeak \<br><span class="hljs-literal">-</span>t A1.uni.dedup.bam \ <span class="hljs-comment">#bam文件</span><br><span class="hljs-literal">-</span>n A1 \ <span class="hljs-comment"># 输出文件前缀名</span><br><span class="hljs-literal">-</span>-shift -100 \ <span class="hljs-comment">#extsize的一半乘以-1</span><br><span class="hljs-literal">-</span>-extsize 200 \ <span class="hljs-comment">#一般是核小体大小</span><br><span class="hljs-literal">-</span>-call-summits <span class="hljs-comment">#检测峰顶信息</span><br><br><span class="hljs-comment">#注：以上参数参考文献（Jie Wang，et.al.2018.“ATAC-Seq analysis reveals a widespread decrease of chromatin accessibility in age-related macular degeneration.”Nature Communications）</span><br></code></pre></td></tr></table></figure><blockquote><p><strong>五、motif分析</strong></p></blockquote><p>ATAC的peak是染色质开放区域，染色质开放区域预示着转录因子结合，对peak区进行motif分析很有意义。常见的motif分析软件有homer和MEME。以homer软件为例 motif分析：</p><figure class="highlight livescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs livescript">findMotifsGenome.pl <span class="hljs-string">\</span><br>A1_peaks.bed <span class="hljs-string">\</span> <span class="hljs-comment">#用于进行motif分析的bed文件</span><br>genome.fa  <span class="hljs-string">\</span> <span class="hljs-comment">#参考基因组fa文件</span><br>A1  <span class="hljs-string">\</span> <span class="hljs-comment">#输出文件前缀</span><br>-size  given <span class="hljs-string">\</span> <span class="hljs-comment">#使用给定的bed区域位置进行分析，如果填-size -100,50则是用给定bed中间位置的上游100bp到下游50bp的区域进行分析</span><br></code></pre></td></tr></table></figure><p>homer分析motif的原理及结果参见：<a href="http://homer.ucsd.edu/homer/motif/index.html">http://homer.ucsd.edu/homer/motif/index.html</a></p><p>根据motif与已知转录因子的富集情况可以绘制气泡图，从而可以看到样本与已知转录因子的富集显著性。</p><p><img src="/GeekFocus/./1.png" alt="img"></p><blockquote><p><strong>六、差异分析</strong></p></blockquote><p>差异peak是染色质开放性差异位点，ChIP-seq和ATAC-seq都可用<strong>DiffBind</strong>差异分析。DiffBind通过bam文件和peak的bed文件计算<strong>peak区域标准化的readcount</strong>，可选择edgeR、DESeq2等模型进行差异分析。</p><blockquote><p><strong>七、峰注释</strong></p></blockquote><p>peak区域与基因联系，通过对peak注释找到peak相关基因。常见的peak注释软件有ChIPseeker、homer、PeakAnnotator等。以ChIPseeker为例，安装ChIPseeker包和GenomicFeatures包，然后分析</p><figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs reasonml">library(ChIPseeker)<br>library(GenomicFeatures)<br>txdb&lt;- make<span class="hljs-constructor">TxDbFromGFF(‘<span class="hljs-params">gene</span>.<span class="hljs-params">gtf</span>’)</span>#生成txdb对象，如果研究物种没有已知的TxDb,可以用GenomicFeatures中的函数生成<br>peakfile &lt;-read<span class="hljs-constructor">PeakFile(‘A1_peaks.<span class="hljs-params">narrowPeak</span>’)</span>#导入需要注释的peak文件<br>peakAnno &lt;- annotate<span class="hljs-constructor">Peak(<span class="hljs-params">peakfile</span>,<span class="hljs-params">tssRegion</span>=<span class="hljs-params">c</span>(-2000, 2000)</span>, TxDb=txdb)<br>\# 用peak文件和txdb进行peak注释，这里可以通过tssRegion定义TSS区域的区间<br>对peak注释的结果可视化展示：<br>p &lt;- plot<span class="hljs-constructor">AnnoPie(<span class="hljs-params">peakAnno</span>)</span><br></code></pre></td></tr></table></figure><blockquote><p><strong>八、富集分析</strong></p></blockquote><p>peak相关基因使用goseq、topGO等R包GO富集分析，用kobas进行kegg富集分析，也可用DAVID在线工具富集分析。挑选感兴趣的GO term或pathway进一步<strong>筛选候选基因</strong>。</p><hr><p><a href="https://seqhealth.biomart.cn/news/2995703.htm">Ref2</a></p><p>澳大利亚莫纳什大学的Yan F.等人于2020年2月在Genome Biology上发表综述《From reads to insight: a hitchhiker’s guide to ATAC-seq data analysis》</p><p>哺乳动物DNA通过三个主要层次尺度 高度压缩：</p><ul><li>第一层是核小体，DNA缠绕在核小体单体上；</li><li>第二层是染色质，核小体单体互相缠绕形成染色质；</li><li>第三层是染色体，染色质进一步压缩为染色体。</li></ul><p>DNA压缩的三个尺度及其相互作用共同造就了基因表达调控。</p><p>ATAC-seq使用基因工程改造的<strong>超高活性Tn5转座酶</strong>（Hyperactive Transposase Tn5），Tn5酶<strong>预载</strong>测序文库构建的Adaptor（<strong>P5和P7</strong>）。Tn5酶切割开放染色质区域，在酶切位点留下9 bp粘性末端，并将两种Adaptor连接到切口的粘性末端；随后DNA片段扩增形成文库测序。下图中<strong>NFR fragments</strong>是开放染色质中核小体间的<strong>Linker DNA片段</strong>，由Peak Calling的Peak鉴定；<strong>蓝色Footprint是转录因子足迹</strong>，对应<strong>转录因子足迹分析</strong>；核小体单体（Mononucleosome）结合DNA片段则反映核小体位置信息，对应<strong>核小体占位分析</strong>。</p><p><img src="/GeekFocus/./2.png" alt="img"></p><p>由于ATAC-seq和ChIP-seq数据相似性较高，综述针对ATAC-seq分析现有软件全面介绍和评估。</p><p><img src="/GeekFocus/./3.png" alt="img"></p><blockquote><p> 质控</p></blockquote><p>FastQC。ATAC-seq文库采用<strong>Illumina Nextera建库</strong>，<strong>接头和Truseq文库不一样</strong>，cutadapt、AdapterRemoval v2、Skewer或trimmomatic(去Nextera接头)。</p><blockquote><p>序列比对</p></blockquote><p>过滤后FastQC。<strong>BWA-MEM</strong>和<strong>Bowtie2</strong>两个软件的soft-clip策略保留突出和没有比对上的碱基，可<strong>增加</strong>在参考序列唯1比对的序列数目（<strong>Unique比对率</strong>）。哺乳动物，**Unique比对率大于80%**的数据是比较成功的ATAC-seq文库。</p><blockquote><p>比对后处理和质控</p></blockquote><p>Picard和SAMtools软件统计Unique比对率、重复reads比例和片段大小分布。</p><p><strong>Mapping后去除干扰reads</strong>：</p><ol><li>配对错误和比对质量较低的reads剔除</li><li><strong>线粒体基因组没有染色质组装</strong>，处于开放状态，<strong>更容易被Tn5酶切割</strong>，线粒体序列去除</li><li>ENCODE数据库黑名单区域（blacklisted regions）包含一些异常、read覆盖度很高的区域，区域reads去除</li><li>由PCR建库产生、重复率过高的reads需要去除。</li></ol><p>此外，<strong>测序文库插入片段大小分布</strong>也可用来判断ATAC-seq实验质量。插入片段大小理论分布为：NFR fragments（&lt;100 bp）、核小体单体（<del>200 bp）、核小体二聚体（</del>400 bp）和核小体三聚体（~600 bp）</p><blockquote><p>核心分析 peak calling</p></blockquote><p>ENCODE选择MACS2作为ATAC-seq标准Peak Calling。与ChIP-seq不同，<strong>由于Tn5酶切割的随机性和成本</strong>，ATAC-seq没<strong>有Input对照</strong>。ATAC-seq数据包含<strong>NFR reads</strong>和<strong>DNA与核小体结合区域reads</strong>，而<font color="red">ATAC-seq关注<strong>NFR部分reads</strong></font>，不能直接用所有reads Peak Calling。一种方式把NFR reads单独提取分析；<font color="red">另一种方式采用<strong>shift-extend</strong>分析</font>，这种方法尝试对Tn5酶切口的末端平滑化事件进行计数（见下图）。第二种更通用，因为这种方法<strong>几乎适用所有为ChIP-seq数据开发的Peak Calling软件，且不受插入片段大小影响</strong>。</p><p><img src="/GeekFocus/./4.png" alt="img"></p><p>ChIP-seq Peak Calling软件根据原理分两大类：<font color="red"><strong>Count-based</strong>和<strong>Shaped-based</strong></font>。Count-based的软件更易于使用和解释结果。这些软件采用<font color="red">不同统计方法比较<strong>目标区域和随机背景区域</strong>的<strong>reads分布</strong>形状</font>，常用包括：</p><ul><li>假设片段分布为泊松分布：<strong>MACS2、HOMER、SICER&#x2F;epic2</strong></li><li>假设片段分布为零膨胀负二项分布：<strong>ZINBA</strong></li><li>核密度估计来判断片段分布：<strong>F-seq、PeakDEck</strong></li><li>不使用片段分布假设但通过软件打分：<strong>SPP</strong></li><li>混合模型：<strong>JAMM</strong></li></ul><p>其中F-seq, ZINBA 不更新<br><font color="red">Shaped-based</font>直接或者间接<font color="red">利用reads<strong>密度分布信息</strong>Peak Calling</font>，包括和等软件，暂时没用于ATAC-seq。目前专门为ATAC-seq开发的Peak Calling软件只有<strong>HMMRATAC</strong>。该软件通过三状态半监督隐马尔科夫模型算法把基因组分成高信号强度的活性染色质区域、中等信号强度的核小体区域和低信号强度的背景区域。计算量偏大，耗时较长，<font color="red"><strong>结果比MACS2更好</strong></font>，同时提供核小体位置信息。</p><p><img src="/GeekFocus/./5.png" alt="img"></p><p><font color="red"><strong>MACS2 pair-end 和MACS2 shift-extend哪个好?</strong></font></p><p>Count-based软件差异不大，但Shaped-based结果非常不同。<font color="red"><strong>目前仍没有综合性指标评估Peak Calling软件的结果表现。</strong></font><br>以上分析Peak Calling软件结果，但是并没有针对存在生物学重复的Peak Calling结果可信度进行探讨。</p><p><strong>Peak Calling可信度</strong>: <strong>IDR</strong>（Irreproducibility Discovery Rate）是指不可重现的发现率，用于测量生物学重复中的可重现性。ATAC-seq比较一对经过排序的regions&#x2F;peaks，计算反映其重复性的值。IDR分析结果的Peak是可信度更高的Peak。建议每组样品2个及以上生物学重复。</p><blockquote><p> ATAC-seq高级分析</p></blockquote><p>ATAC-seq主要功能是揭示转录调控各个方面，可4种水平对结果分析和解释：1. Peak注释和差异Peak分析；2. Motif分析；3. 核小体占位分析；4. 转录因子足迹分析。</p><p><font color="green"><strong>Peak注释和差异Peak分析</strong></font></p><p>Peak与其最近基因或调控元件的Peak注释，<strong>HOMER、ChIPseeker</strong>和<strong>ChIPpeakAnno</strong>三个软件都可把Peak分配到最近或重叠的基因、外显子、内含子、启动子、5’UTR、3’UTR和其它基因组功能区。随后用Gene Ontology（GO）、KEGG和Reactome等数据库做Peak关联基因功能富集分析。<strong>ChIPseeker</strong>和<strong>ChIPpeakAnno</strong>软件具有可视化功能。<br>目前没有专门为ATAC-seq开发的差异Peak分析软件。差异Peak分析首先通过<strong>寻找候选区域</strong>（共有Peak或根据bin划分的基因组），然后<strong>标准化</strong>，再对落在<strong>区域内的片段计数</strong>，最后在相同坐标内与其它处理条件的样本进行<strong>统计学比较</strong>。在以共有Peak为基础分析的软件中，<strong>HOMER、DBChIP</strong>和<strong>DiffBind</strong>依赖RNA-seq差异表达基因分析中使用的R包计算差异Peak，例如<strong>edgeR、DESeq</strong>和<strong>DESeq2</strong>等，都要求生物学重复。</p><p><strong>HOMER</strong>把所有生物学重复样品数据合并到一起减少差异peak的假阳性结果。<strong>DBChIP</strong>和<strong>DiffBind</strong>通过取交集或并集的方法得到共有Peak，取交集会忽略一些样本或特殊的Peak，而取并集使假阳性增多。</p><p>另外不依赖RNA-seq分析R包的软件包括<strong>PePr、DiffReps</strong>和<strong>ChIPDiff</strong>，还有一种<strong>edgeR</strong>包的扩展软件<strong>csaw</strong>，这些软件使用滑窗（Sliding window）方法进行分析，但是得到的<strong>结果假阳性率很高</strong>，需要设置严格的FDR。<br>文章推荐Peak注释与差异分析软件：<strong>HOMER&#x2F;ChIPseeker&#x2F;ChIPpeakAnno + csaw</strong><br>康科Peak注释与差异分析软件：<strong>Bedtools</strong> + <strong>edgeR</strong></p><p><font color="green"><strong>Motif分析</strong></font></p><p>开放染色质区域一般可结合特定转录因子进而影响转录，转录因子结合识别的DNA序列即为motif，人体大约<strong>1600种转录因子</strong>，其中一半多已有明确报道的motif。对motif的分析包括<strong>motif富集分析</strong>和<strong>转录因子Footprint（足迹）分析</strong>。</p><p>Motif富集分析</p><p>目前很多motif数据库，使用最普遍的是<strong>JASPAR数据库</strong>，该数据库收录多物种的motif数据，可以通过APIs或者Bioconductor的R包下载相关数据。此外，CIS-BP和TRANSFAC数据库收录<strong>真核生物</strong>转录因子的motif信息，HOCOMOCO数据库则专门收录了<strong>人和小鼠</strong>的motif，RegulonDB为大肠杆菌的motif数据库。<br><strong>HOMER、MEME-AME、MEME-CentriMo</strong> <strong>DAStk</strong></p><p><font color="green"><strong>转录因子足迹分析</strong></font></p><p>另一种ATAC-seq<strong>解释转录因子调控方式</strong>的是足迹分析。<font color="red">转录因子足迹指一个转录因子结合在DNA，<strong>阻止Tn5酶切割</strong>，在<strong>染色质开放区域留</strong>下一个<strong>相对缺失的位置</strong></font>。</p><p>做足迹分析三个问题需要解决：</p><p>1）由于建库时Tn5酶切时会产生9 bp的粘性末端切口，经过末端修复补齐后，原始reads在预处理时需要经过移位才可以准确检测到Footprint；</p><p>2）Tn5酶切具有5’端偏好性；</p><p>3）某些瞬时结合的转录因子足迹信号较弱。</p><p>足迹分析软件根据算法分为两大类：de novo和Motif-centric。</p><p>de novo类型的软件通过理论计算鉴别转录因子足迹信息，消除Tn5酶切时的5’偏好性。目前只有<strong>HINT-ATAC</strong>可以处理ATAC-seq数据特有的偏好性。</p><p>Motif-centric方法主要关注已知TF的结合位点，主要软件有<strong>MILLIPEDE、DeFCoM</strong>等。</p><p>联合ChIP-seq数据的Motif-centric方法在足迹分析上优于de nove的方法，但是这些ChIP-seq数据来源于特定的转录因子和特定的细胞类型，通用性不强。而de novo的方法在一些低质量和新发现的一些motif上具有优势。</p><p>文章推荐转录因子足迹分析软件：<strong>HINT-ATAC</strong><br>康测科技转录因子足迹分析软件：<strong>HOMER + Bedtools自编脚本</strong></p><p><font color="green"><strong>核小体占位分析</strong></font></p><p>核小体单体可以结合大约147 bp的DNA，在标准ATAC-seq文库中，较长的插入片段对应DNA与核小体结合的区域。ATAC-seq数据核小体结合区域比染色质开放区域reads<strong>覆盖度更低</strong>，所以相比MNase-seq，ATAC-seq的核小体占位分析<strong>难度更高</strong>。一般情况，为MNase-seq开发的软件（比如<strong>DNAPOS2、PuFFIN、iNPS</strong>和<strong>NucTools</strong>）可用于ATAC-seq。专门为ATAC-seq开发的软件包括<strong>NuleoATAC</strong>和<strong>HMMRATAC</strong>。<strong>NuleoATAC</strong>比<strong>DANPOS2</strong>结果表现更好，而<strong>HMMRATAC</strong>可以同时完成Peak Calling和核小体占位分析。<br>文章推荐核小体占位分析软件：<strong>NuleoATAC</strong> <strong>&#x2F;HMMRATAC</strong><br>康测科技核小体占位分析软件：<strong>Samtools自编脚本</strong></p><blockquote><p> ATAC-seq与多组学数据联合分析</p></blockquote><ol><li><strong>转录因子ChIP-seq</strong>：大部分转录因子结合染色质开放区域，所以ATAC-seq的Peak可能和转录因子ChIP-seq的Peak存在部分重叠，而且ATAC-seq得到的Peak长度往往更长，因此ATAC-seq数据和转录因子ChIP-seq数据可以<font color="red"><strong>相互验证</strong></font>。转录因子在<strong>ChIP-seq中独有</strong>的Peak暗示这个转录因子<strong>可能结合在异染色质区域</strong>的<strong>驱动型转录因子</strong>（Pioneer TFs），<font color="red"><strong>驱动型转录因子</strong>随后招募<strong>染色质重塑复合体</strong>以及其它转录因子开始转录</font>。联合分析报道ChIP-seq数据可更准确地分析转录因子的足迹。</li><li><strong>组蛋白修饰ChIP-seq</strong>：ATAC-seq同样可以和<font color="red"><strong>组蛋白修饰ChIP-seq</strong></font>联合分析，其中<font color="red">转录<strong>激活</strong>性修饰（H3K4me3，H3K4me1和H3K27ac等）</font>与染<strong>色质开放程度呈正相关</strong>，<font color="red">转录<strong>抑制</strong>性修饰（H3K27me3）</font>与染色质开放程度呈<strong>负相关</strong>。联合已知的<strong>增强子和启动子之间的相互作用</strong>数据也可以帮助<strong>构建调控网络</strong>。</li><li><strong>RNA-seq</strong>：ATAC-seq通过联合RNA-seq发现哪些<font color="red">差异表达的基因</font>是<font color="red">受染色质可及性调控的</font>，进一步推测这些差异表达基因<font color="red">哪些是受开放染色质中<strong>具有motif和footprint</strong>的转录因子调控</font>，因此ATAC-seq与RNA-seq的联合分析有助于破译<strong>基因调控网络</strong>和细胞异质性。</li></ol><p>通过鉴定染色质开放区域并<strong>结合motif信息和基因表达信息</strong>，建立<strong>转录因子-靶基因</strong>的互作网络。</p><blockquote><p>总结</p></blockquote><p>该review系统描述ATAC-seq生信分析主要流程，并推荐相关软件：<strong>FastQC</strong>质控；<strong>trimmomatic</strong>去除低质量碱基和接头序列；<strong>BWA-MEM</strong>比对；<strong>MACS2</strong> Peak Calling；<strong>csaw</strong>差异Peak分析；<strong>MEME-CentriMo</strong>寻找motif以及富集分析；<strong>ChIPseeker</strong> Peak注释和可视化；<strong>HMMRATAC</strong>分析核小体占位；<strong>HINT-ATAC</strong>转录因子Footprint分析。</p><p>康测科技稍有不同：引入<strong>IDR</strong>判断Peak可信度；差异Peak分析使用<strong>bedtools</strong>和单独的<strong>edgeR</strong>包结合自编脚本提高差异Peak分析中参数设置自由度，得到准确度和可信度更高的分析结果。</p><p><img src="/GeekFocus/./6.png" alt="img"></p><hr><p><a href="https://www.jianshu.com/p/09e05bcd6981">Ref3</a></p><blockquote><p>比对</p></blockquote><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs sh">bowtie2  -p 5  --very-sensitive -X 2000 -x  <span class="hljs-variable">$bowtie2_index</span> -1 <span class="hljs-variable">$fq1</span> -2 <span class="hljs-variable">$fq2</span> |samtools <span class="hljs-built_in">sort</span>  -O bam  -@ 5 -o - &gt; <span class="hljs-variable">$&#123;sample&#125;</span>.raw.bam<br><br>samtools index <span class="hljs-variable">$&#123;sample&#125;</span>.raw.bam<br>bedtools bamtobed -i <span class="hljs-variable">$&#123;sample&#125;</span>.raw.bam  &gt; <span class="hljs-variable">$&#123;sample&#125;</span>.raw.bed<br>samtools flagstat <span class="hljs-variable">$&#123;sample&#125;</span>.raw.bam  &gt; <span class="hljs-variable">$&#123;sample&#125;</span>.raw.stat<br><span class="hljs-comment"># https://github.com/biod/sambamba/issues/177</span><br><span class="hljs-comment"># 三种不同的去重复软件</span><br><span class="hljs-comment"># 这里选用sambamba来去重复</span><br>sambamba markdup --overflow-list-size 600000  --tmpdir=<span class="hljs-string">&#x27;./&#x27;</span>  -r <span class="hljs-variable">$&#123;sample&#125;</span>.raw.bam  <span class="hljs-variable">$&#123;sample&#125;</span>.rmdup.bam<br>samtools index   <span class="hljs-variable">$&#123;sample&#125;</span>.rmdup.bam<br>samtools flagstat  <span class="hljs-variable">$&#123;sample&#125;</span>.rmdup.bam &gt; <span class="hljs-variable">$&#123;sample&#125;</span>.rmdup.stat<br><br><span class="hljs-comment">## ref:https://www.biostars.org/p/170294/ </span><br><span class="hljs-comment">## Calculate %mtDNA:</span><br>mtReads=$(samtools idxstats  <span class="hljs-variable">$&#123;sample&#125;</span>.rmdup.bam | grep <span class="hljs-string">&#x27;chrM&#x27;</span> | <span class="hljs-built_in">cut</span> -f 3)<br>totalReads=$(samtools idxstats  <span class="hljs-variable">$&#123;sample&#125;</span>.rmdup.bam | awk <span class="hljs-string">&#x27;&#123;SUM += $3&#125; END &#123;print SUM&#125;&#x27;</span>)<br><span class="hljs-built_in">echo</span> <span class="hljs-string">&#x27;==&gt; mtDNA Content:&#x27;</span> $(bc &lt;&lt;&lt; <span class="hljs-string">&quot;scale=2;100*<span class="hljs-variable">$mtReads</span>/<span class="hljs-variable">$totalReads</span>&quot;</span>)<span class="hljs-string">&#x27;%&#x27;</span><br><br><span class="hljs-comment">## 保留两条reads比对到同一条染色体(Proper paired) ，还有高质量的比对结果(Mapping quality&gt;=30)</span><br><span class="hljs-comment">## 顺便过滤 线粒体reads</span><br>samtools view  -h  -f 2 -q 30    <span class="hljs-variable">$&#123;sample&#125;</span>.rmdup.bam   |grep -v chrM |samtools <span class="hljs-built_in">sort</span>  -O bam  -@ 5 -o - &gt; <span class="hljs-variable">$&#123;sample&#125;</span>.last.bam<br><br>samtools index   <span class="hljs-variable">$&#123;sample&#125;</span>.last.bam<br>samtools flagstat  <span class="hljs-variable">$&#123;sample&#125;</span>.last.bam &gt; <span class="hljs-variable">$&#123;sample&#125;</span>.last.stat<br><br><span class="hljs-comment"># 转bed 文件 用MACS2 shift extend model</span><br>bedtools bamtobed -i <span class="hljs-variable">$&#123;sample&#125;</span>.last.bam  &gt; <span class="hljs-variable">$&#123;sample&#125;</span>.bed<br></code></pre></td></tr></table></figure><blockquote><p>Deeptools 可视化</p></blockquote><p><strong>bam转bw</strong></p><p><a href="https://deeptools.readthedocs.io/en/develop/content/tools/bamCoverage.html">bamCoverage</a></p><p><font color="red"><strong>–normalizeUsing</strong></font></p><p>Possible choices: RPKM, CPM, BPM, RPGC, None</p><p>Use one of the entered methods to normalize the number of reads per bin. By <strong>default, no normalization</strong> is performed. <strong>RPKM</strong> &#x3D; Reads Per Kilobase per Million mapped reads; <strong>CPM</strong> &#x3D; Counts Per Million mapped reads, same as CPM in RNA-seq; <strong>BPM</strong> &#x3D; Bins Per Million mapped reads, same as <strong>TPM</strong> in RNA-seq; <strong>RPGC</strong> &#x3D; reads per genomic content (1x normalization); Mapped reads <strong>are considered after blacklist filtering?</strong> (if applied). </p><p>RPKM (per bin) &#x3D; number of reads per bin &#x2F; (number of mapped reads (in millions) * bin length (kb)). </p><p>CPM (per bin) &#x3D; number of reads per bin &#x2F; number of mapped reads (in millions). BPM (per bin) &#x3D; number of reads per bin &#x2F; sum of all reads per bin (in millions). </p><p>RPGC (per bin) &#x3D; number of reads per bin &#x2F; scaling factor for 1x average coverage. None &#x3D; the default and equivalent to not setting this option at all. This scaling factor, in turn, is determined from the sequencing depth: (total number of mapped reads * fragment length) &#x2F; effective genome size. The scaling factor used is the inverse of the sequencing depth computed for the sample to match the 1x coverage. This option requires –effectiveGenomeSize. Each read is considered independently, if you want to only count one mate from a pair in paired-end data, then use the –samFlagInclude&#x2F;–samFlagExclude options. (Default: None)</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">cd</span>  ~/project/atac/deeptools_result<br><br><span class="hljs-comment">###构建索引</span><br><span class="hljs-built_in">ls</span>  *.bam  |xargs -i samtools index &#123;&#125;<br><span class="hljs-comment">###将最终的bam转换成bigwig文件</span><br><span class="hljs-built_in">ls</span> *last.bam |<span class="hljs-keyword">while</span> <span class="hljs-built_in">read</span> <span class="hljs-built_in">id</span>;<span class="hljs-keyword">do</span><br><span class="hljs-built_in">nohup</span> bamCoverage -b <span class="hljs-variable">$&#123;id&#125;</span> -p 5 --normalizeUsing RPKM  -o <span class="hljs-variable">$&#123;id%%.*&#125;</span>.last.bw &amp;<br><span class="hljs-keyword">done</span><br><span class="hljs-comment">###将去重的bam转换成bigwig文件</span><br><span class="hljs-comment"># cd dup </span><br><span class="hljs-built_in">ls</span>  *.bam  |xargs -i samtools index &#123;&#125; <br><span class="hljs-built_in">ls</span> *rmdup.bam |<span class="hljs-keyword">while</span> <span class="hljs-built_in">read</span> <span class="hljs-built_in">id</span>;<span class="hljs-keyword">do</span><br><span class="hljs-built_in">nohup</span> bamCoverage --normalizeUsing CPM -b <span class="hljs-variable">$id</span> -o <span class="hljs-variable">$&#123;id%%.*&#125;</span>.rm.bw &amp; <br><span class="hljs-keyword">done</span><br></code></pre></td></tr></table></figure><p><strong>查看TSS附件信号强度（激活marker，27ac）</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment">## both -R and -S can accept multiple files </span><br><span class="hljs-built_in">mkdir</span> -p  ~/project/atac/tss<br><span class="hljs-built_in">cd</span>   ~/project/atac/tss <br><span class="hljs-comment"># source activate atac # 由于我这里自己系统有就没调用了</span><br>computeMatrix reference-point  --referencePoint TSS  -p 15  \<br>-b 10000 -a 10000    \<br>-R ~/project/atac/mm10_Refgene/Refseq.bed  \<br>-S ~/project/atac/deeptools_result/*.bw  \<br>--skipZeros  -o matrix1_test_TSS.gz  \<br>--outFileSortedRegions regions1_test_genes.bed<br><br><span class="hljs-comment">##     both plotHeatmap and plotProfile will use the output from   computeMatrix</span><br>plotHeatmap -m matrix1_test_TSS.gz  -out test_Heatmap.png<br>plotHeatmap -m matrix1_test_TSS.gz  -out test_Heatmap.pdf --plotFileFormat pdf  --dpi 720  <br>plotProfile -m matrix1_test_TSS.gz  -out test_Profile.png<br>plotProfile -m matrix1_test_TSS.gz  -out test_Profile.pdf --plotFileFormat pdf --perGroup --dpi 720 <br></code></pre></td></tr></table></figure><p><strong>查看基因body的信号强度（抑制marker，27me3）</strong></p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-comment">#source activate atac</span><br><span class="hljs-built_in">mkdir</span> Body<br><span class="hljs-built_in">cd</span> ~/project/atac/Body<br>computeMatrix scale-regions  -p 15  \<br>-R ~/project/atac/mm10_Refgene/Refseq.bed  \<br>-S ~/project/atac/deeptools_result/*.bw  \<br>-b 10000 -a 10000  \<br>--skipZeros -o matrix1_test_body.gz<br><span class="hljs-comment"># plotHeatmap -m matrix1_test_body.gz  -out ExampleHeatmap1.png</span><br>plotHeatmap -m matrix1_test_body.gz  -out test_body_Heatmap.png<br>plotProfile -m matrix1_test_body.gz  -out test_body_Profile.png<br>plotProfile -m matrix1_test_body.gz -out test_Body_Profile.pdf --plotFileFormat pdf --perGroup --dpi 720<br></code></pre></td></tr></table></figure><ul><li>–regionBodyLength #调整genebody区域</li><li>–binSize</li></ul><blockquote><p>call peak</p></blockquote><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-comment">#macs2 callpeak -t 2-cell-1.bed  -g mm --nomodel --shift -100 --extsize 200  -n 2-cell-1 --outdir ../peaks/</span><br><span class="hljs-built_in">cd</span> ~/project/atac/peaks/<br><span class="hljs-built_in">ls</span> *.bed | <span class="hljs-keyword">while</span> <span class="hljs-built_in">read</span> <span class="hljs-built_in">id</span> ;<span class="hljs-keyword">do</span> (macs2 callpeak -t <span class="hljs-variable">$id</span>  -g mm --nomodel --<span class="hljs-built_in">shift</span>  -100 --extsize 200  -n <span class="hljs-variable">$&#123;id%%.*&#125;</span> --outdir ./) ;<span class="hljs-keyword">done</span><br></code></pre></td></tr></table></figure><blockquote><p> 计算插入片段长度，FRiP值，IDR计算重复情况</p></blockquote><ul><li>非冗余非线粒体能够比对的fragment、比对率、NRF、PBC1、PBC2、peak数、无核小体区NFR、TSS富集、FRiP 、IDR重复的一致性！</li></ul><p><strong>统计indel插入长度的分布</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment">#创建提取bam文件的第九列indel插入长度信息的sh文件 indel_length.sh，内容如下：</span><br><span class="hljs-built_in">cat</span> config.last_bam |<span class="hljs-keyword">while</span> <span class="hljs-built_in">read</span> <span class="hljs-built_in">id</span>;<br><span class="hljs-keyword">do</span><br>arr=(<span class="hljs-variable">$id</span>)<br>sample=<span class="hljs-variable">$&#123;arr[0]&#125;</span><br>sample_name=<span class="hljs-variable">$&#123;arr[1]&#125;</span><br>samtools view <span class="hljs-variable">$sample</span> |awk <span class="hljs-string">&#x27;&#123;print $9&#125;&#x27;</span>  &gt; <span class="hljs-variable">$&#123;sample_name&#125;</span>_length.txt<br><span class="hljs-keyword">done</span><br></code></pre></td></tr></table></figure><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs R"><span class="hljs-comment">#indel_length_distribution.sh</span><br>md<span class="hljs-operator">=</span>commandArgs<span class="hljs-punctuation">(</span>trailingOnly<span class="hljs-operator">=</span><span class="hljs-literal">TRUE</span><span class="hljs-punctuation">)</span>; <br>input<span class="hljs-operator">=</span>cmd<span class="hljs-punctuation">[</span><span class="hljs-number">1</span><span class="hljs-punctuation">]</span>; output<span class="hljs-operator">=</span>cmd<span class="hljs-punctuation">[</span><span class="hljs-number">2</span><span class="hljs-punctuation">]</span>; <br>a<span class="hljs-operator">=</span><span class="hljs-built_in">abs</span><span class="hljs-punctuation">(</span><span class="hljs-built_in">as.numeric</span><span class="hljs-punctuation">(</span>read.table<span class="hljs-punctuation">(</span>input<span class="hljs-punctuation">)</span><span class="hljs-punctuation">[</span><span class="hljs-punctuation">,</span><span class="hljs-number">1</span><span class="hljs-punctuation">]</span><span class="hljs-punctuation">)</span><span class="hljs-punctuation">)</span>; <br>png<span class="hljs-punctuation">(</span>file<span class="hljs-operator">=</span>output<span class="hljs-punctuation">)</span>;<br>hist<span class="hljs-punctuation">(</span>a<span class="hljs-punctuation">,</span><br>main<span class="hljs-operator">=</span><span class="hljs-string">&quot;Insertion Size distribution&quot;</span><span class="hljs-punctuation">,</span><br>ylab<span class="hljs-operator">=</span><span class="hljs-string">&quot;Read Count&quot;</span><span class="hljs-punctuation">,</span>xlab<span class="hljs-operator">=</span><span class="hljs-string">&quot;Insert Size&quot;</span><span class="hljs-punctuation">,</span><br>xaxt<span class="hljs-operator">=</span><span class="hljs-string">&quot;n&quot;</span><span class="hljs-punctuation">,</span><br>breaks<span class="hljs-operator">=</span>seq<span class="hljs-punctuation">(</span><span class="hljs-number">0</span><span class="hljs-punctuation">,</span><span class="hljs-built_in">max</span><span class="hljs-punctuation">(</span>a<span class="hljs-punctuation">)</span><span class="hljs-punctuation">,</span>by<span class="hljs-operator">=</span><span class="hljs-number">10</span><span class="hljs-punctuation">)</span><br><span class="hljs-punctuation">)</span>; <br><br>axis<span class="hljs-punctuation">(</span>side<span class="hljs-operator">=</span><span class="hljs-number">1</span><span class="hljs-punctuation">,</span><br>at<span class="hljs-operator">=</span>seq<span class="hljs-punctuation">(</span><span class="hljs-number">0</span><span class="hljs-punctuation">,</span><span class="hljs-built_in">max</span><span class="hljs-punctuation">(</span>a<span class="hljs-punctuation">)</span><span class="hljs-punctuation">,</span>by<span class="hljs-operator">=</span><span class="hljs-number">100</span><span class="hljs-punctuation">)</span><span class="hljs-punctuation">,</span><br>labels<span class="hljs-operator">=</span>seq<span class="hljs-punctuation">(</span><span class="hljs-number">0</span><span class="hljs-punctuation">,</span><span class="hljs-built_in">max</span><span class="hljs-punctuation">(</span>a<span class="hljs-punctuation">)</span><span class="hljs-punctuation">,</span>by<span class="hljs-operator">=</span><span class="hljs-number">100</span><span class="hljs-punctuation">)</span><br><span class="hljs-punctuation">)</span>;<br><br>dev.off<span class="hljs-punctuation">(</span><span class="hljs-punctuation">)</span> <br></code></pre></td></tr></table></figure><p><strong>FRiP值的计算：fraction of reads in called peak regions</strong></p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs sh">bedtools intersect -a 2-cell-1.bed -b 2-cell-1_peaks.narrowPeak |<span class="hljs-built_in">wc</span> -l<br>148210<br><span class="hljs-built_in">wc</span>  -l 2-cell-1.bed<br>5105850 <br><span class="hljs-comment"># 故2-cell-1的FRiP为</span><br>148210/5105850 = 0.0292<br></code></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">cd</span> ~/project/atac/peaks<br><span class="hljs-built_in">ls</span> *narrowPeak|<span class="hljs-keyword">while</span>  <span class="hljs-built_in">read</span> <span class="hljs-built_in">id</span>;<br><span class="hljs-keyword">do</span><br><span class="hljs-built_in">echo</span> <span class="hljs-variable">$id</span><br>bed=$(<span class="hljs-built_in">basename</span> <span class="hljs-variable">$id</span> <span class="hljs-string">&quot;_peaks.narrowPeak&quot;</span>).bed<br><span class="hljs-comment">#ls  -lh $bed </span><br>Reads=$(bedtools intersect -a <span class="hljs-variable">$bed</span> -b <span class="hljs-variable">$id</span> |<span class="hljs-built_in">wc</span> -l|awk <span class="hljs-string">&#x27;&#123;print $1&#125;&#x27;</span>)<br>totalReads=$(<span class="hljs-built_in">wc</span> -l <span class="hljs-variable">$bed</span>|awk <span class="hljs-string">&#x27;&#123;print $1&#125;&#x27;</span>)<br><span class="hljs-built_in">echo</span> <span class="hljs-variable">$Reads</span>  <span class="hljs-variable">$totalReads</span> <br><span class="hljs-built_in">echo</span> <span class="hljs-string">&#x27;==&gt; FRiP value:&#x27;</span> $(bc &lt;&lt;&lt; <span class="hljs-string">&quot;scale=2;100*<span class="hljs-variable">$Reads</span>/<span class="hljs-variable">$totalReads</span>&quot;</span>)<span class="hljs-string">&#x27;%&#x27;</span><br><span class="hljs-keyword">done</span><br></code></pre></td></tr></table></figure><p>Fraction of reads in peaks (FRiP) - Fraction of all mapped reads that fall into the called peak regions, i.e. usable reads in significantly enriched peaks divided by all usable reads. In general, FRiP scores correlate positively with the number of regions. (Landt et al, Genome Research Sept. 2012, 22(9): 1813–1831)<br><strong>使用R包看不同peaks文件的overlap情况</strong></p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs r">options<span class="hljs-punctuation">(</span>BioC_mirror<span class="hljs-operator">=</span><span class="hljs-string">&quot;https://mirrors.ustc.edu.cn/bioc/&quot;</span><span class="hljs-punctuation">)</span> <br>options<span class="hljs-punctuation">(</span><span class="hljs-string">&quot;repos&quot;</span> <span class="hljs-operator">=</span> <span class="hljs-built_in">c</span><span class="hljs-punctuation">(</span>CRAN<span class="hljs-operator">=</span><span class="hljs-string">&quot;https://mirrors.tuna.tsinghua.edu.cn/CRAN/&quot;</span><span class="hljs-punctuation">)</span><span class="hljs-punctuation">)</span><br>source<span class="hljs-punctuation">(</span><span class="hljs-string">&quot;http://bioconductor.org/biocLite.R&quot;</span><span class="hljs-punctuation">)</span> <br>library<span class="hljs-punctuation">(</span><span class="hljs-string">&#x27;BiocInstaller&#x27;</span><span class="hljs-punctuation">)</span><br><span class="hljs-comment"># biocLite(&quot;ChIPpeakAnno&quot;)</span><br><span class="hljs-comment"># biocLite(&quot;ChIPseeker&quot;)</span><br>library<span class="hljs-punctuation">(</span>ChIPseeker<span class="hljs-punctuation">)</span><br>library<span class="hljs-punctuation">(</span>ChIPpeakAnno<span class="hljs-punctuation">)</span><br>setwd<span class="hljs-punctuation">(</span><span class="hljs-string">&quot;E://desktop/sept/ATAC-seq_practice/find_peaks_overlaping/&quot;</span><span class="hljs-punctuation">)</span><br>list.files<span class="hljs-punctuation">(</span><span class="hljs-string">&#x27;./&#x27;</span><span class="hljs-punctuation">,</span><span class="hljs-string">&quot;*.narrowPeak&quot;</span><span class="hljs-punctuation">)</span><br>tmp <span class="hljs-operator">=</span> lapply<span class="hljs-punctuation">(</span>list.files<span class="hljs-punctuation">(</span><span class="hljs-string">&#x27;./&#x27;</span><span class="hljs-punctuation">,</span><span class="hljs-string">&quot;*.narrowPeak&quot;</span><span class="hljs-punctuation">)</span><span class="hljs-punctuation">,</span><span class="hljs-keyword">function</span><span class="hljs-punctuation">(</span>x<span class="hljs-punctuation">)</span><span class="hljs-punctuation">&#123;</span><br>  <span class="hljs-built_in">return</span><span class="hljs-punctuation">(</span>readPeakFile<span class="hljs-punctuation">(</span>file.path<span class="hljs-punctuation">(</span><span class="hljs-string">&#x27;./&#x27;</span><span class="hljs-punctuation">,</span> x<span class="hljs-punctuation">)</span><span class="hljs-punctuation">)</span><span class="hljs-punctuation">)</span><br>  <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">)</span><br>tmp<br>ol <span class="hljs-operator">&lt;-</span> findOverlapsOfPeaks<span class="hljs-punctuation">(</span>tmp<span class="hljs-punctuation">[[</span><span class="hljs-number">1</span><span class="hljs-punctuation">]</span><span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span>tmp<span class="hljs-punctuation">[[</span><span class="hljs-number">2</span><span class="hljs-punctuation">]</span><span class="hljs-punctuation">]</span><span class="hljs-punctuation">)</span> <span class="hljs-comment"># 这里选取的是第一个文件和第二个文件，即cell.1_peak_1和cell.2_peak</span><br>png<span class="hljs-punctuation">(</span><span class="hljs-string">&#x27;overlapVenn.png&#x27;</span><span class="hljs-punctuation">)</span><br>makeVennDiagram<span class="hljs-punctuation">(</span>ol<span class="hljs-punctuation">)</span><br>dev.off<span class="hljs-punctuation">(</span><span class="hljs-punctuation">)</span><br></code></pre></td></tr></table></figure><p><strong>IDR 计算，同时考虑peaks间的overlap，和富集倍数的一致性</strong></p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><code class="hljs sh">conda  create -n py3 -y   python=3 idr<br>conda activate py3<br>idr -h <br>idr --samples  2-cell-1_peaks.narrowPeak 2-cell-2_peaks.narrowPeak  --plot<br><br><span class="hljs-comment">###############---</span><br>idr --samples SRR2927018_peaks.narrowPeak SRR3545580_peaks.narrowPeak \<br>--input-file-type narrowPeak \<br>--rank p.value \<br>--output-file group2-idr \<br>--plot \<br>--log-output-file group2.idr.log<br><br><span class="hljs-built_in">ls</span> -lh group*|<span class="hljs-built_in">cut</span> -d <span class="hljs-string">&quot; &quot;</span> -f 5-<br><span class="hljs-comment"># 740K Apr 19 22:00 group1-idr</span><br><span class="hljs-comment">#  205 Apr 19 22:00 group1.idr.log</span><br><span class="hljs-comment"># 341K Apr 19 22:00 group1-idr.png</span><br><span class="hljs-comment"># 315K Apr 19 22:00 group2-idr</span><br><span class="hljs-comment">#  202 Apr 19 22:00 group2.idr.log</span><br><span class="hljs-comment"># 218K Apr 19 22:00 group2-idr.png</span><br><span class="hljs-built_in">cat</span> group1.idr.log<br><span class="hljs-comment"># Initial parameter values: [0.10 1.00 0.20 0.50]</span><br><span class="hljs-comment"># Final parameter values: [0.59 1.05 0.62 0.79]</span><br><span class="hljs-comment"># Number of reported peaks - 5869/5869 (100.0%)</span><br><span class="hljs-comment"># Number of peaks passing IDR cutoff of 0.05 - 1571/5869 (26.8%)</span><br><br><span class="hljs-built_in">cat</span> group2.idr.log<br><span class="hljs-comment"># Initial parameter values: [0.10 1.00 0.20 0.50]</span><br><span class="hljs-comment"># Final parameter values: [0.35 1.06 0.47 0.50]</span><br><span class="hljs-comment"># Number of reported peaks - 2505/2505 (100.0%)</span><br><span class="hljs-comment"># Number of peaks passing IDR cutoff of 0.05 - 38/2505 (1.5%)</span><br><br><span class="hljs-comment">#输出标则表示：</span><br>左上： Rep1 peak ranks vs Rep2 peak ranks，没有通过特定IDR阈值的peaks显示为红色。 右上：Rep1 log10 peak scores vs Rep2 log10 peak scores，没有通过特定IDR阈值的peaks显示为红色。 下面两个图： Peak rank vs IDR scores，箱线图展示了IDR值的分布，默认情况下，IDR值的阈值为-1E-6。<br></code></pre></td></tr></table></figure><blockquote><p>注释</p></blockquote><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs bash">options(BioC_mirror=<span class="hljs-string">&quot;https://mirrors.ustc.edu.cn/bioc/&quot;</span>) <br>options(<span class="hljs-string">&quot;repos&quot;</span> = c(CRAN=<span class="hljs-string">&quot;https://mirrors.tuna.tsinghua.edu.cn/CRAN/&quot;</span>))<br><span class="hljs-built_in">source</span>(<span class="hljs-string">&quot;http://bioconductor.org/biocLite.R&quot;</span>) <br>library(<span class="hljs-string">&#x27;BiocInstaller&#x27;</span>)<br>biocLite(<span class="hljs-string">&quot;ChIPpeakAnno&quot;</span>)<br>library(ChIPpeakAnno)<br>setwd(<span class="hljs-string">&quot;E://desktop/sept/ATAC-seq_practice/peaks_annotaion/&quot;</span>)<br>biocLite(<span class="hljs-string">&quot;TxDb.Mmusculus.UCSC.mm10.knownGene&quot;</span>)<br>biocLite(<span class="hljs-string">&quot;org.Mm.eg.db&quot;</span>)<br>txdb &lt;- TxDb.Mmusculus.UCSC.mm10.knownGene<br>promoter &lt;- getPromoters(TxDb=txdb, <br>                         upstream=3000, downstream=3000)<br>files = list(cell_1_summits = <span class="hljs-string">&quot;2-cell-1_summits.bed&quot;</span>, cell_2_summits = <span class="hljs-string">&quot;2-cell-2_summits.bed&quot;</span>,<br>                   cell_4_summits = <span class="hljs-string">&quot;2-cell-4_summits.bed&quot;</span>, cell_5_summits = <span class="hljs-string">&quot;2-cell-5_summits.bed&quot;</span>)<br>peakAnno &lt;- annotatePeak(files[[1]], <span class="hljs-comment"># 分别改成2或者3或者4即可，分别对应四个文件</span><br>                         tssRegion=c(-3000, 3000),<br>                         TxDb=txdb, annoDb=<span class="hljs-string">&quot;org.Hs.eg.db&quot;</span>)<br>plotAnnoPie(peakAnno)<br></code></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs undefined">plotAnnoBar(peakAnno)<br></code></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs undefined">vennpie(peakAnno)<br></code></pre></td></tr></table></figure><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs sh">upsetplot(peakAnno)<br>upsetplot(peakAnno, vennpie=TRUE)<br></code></pre></td></tr></table></figure><p><img src="/GeekFocus/./8.png" alt="img"></p><p>ChIPseeker注释最近基因，peak离最近基因的距离分布</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">plotDistToTSS(peakAnno,<br>              title=<span class="hljs-string">&quot;Distribution of transcription factor-binding loci\nrelative to TSS&quot;</span>)<br></code></pre></td></tr></table></figure><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs sh">peakAnnoList &lt;- lapply(files, annotatePeak, <br>                       TxDb=txdb,tssRegion=c(-3000, 3000))<br>plotAnnoBar(peakAnnoList)<br></code></pre></td></tr></table></figure><p>ChIPseeker提供了vennplot函数，看注释的最近基因在不同样本的overlap</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs sh">genes &lt;- lapply(peakAnnoList, <span class="hljs-keyword">function</span>(i) <br>    as.data.frame(i)<span class="hljs-variable">$geneId</span>)<br>vennplot(genes[2:4], by=<span class="hljs-string">&#x27;Vennerable&#x27;</span>)<br></code></pre></td></tr></table></figure><blockquote><p>Motif 寻找 注释</p></blockquote><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># mkdir -p  ~/project/atac/motif</span><br><span class="hljs-built_in">cd</span>   ~/project/atac/motif<br><span class="hljs-comment"># source activate atac</span><br><span class="hljs-built_in">ls</span> ../peaks/*.narrowPeak |<span class="hljs-keyword">while</span> <span class="hljs-built_in">read</span> <span class="hljs-built_in">id</span>;<br><span class="hljs-keyword">do</span><br>file=$(<span class="hljs-built_in">basename</span> <span class="hljs-variable">$id</span> )<br>sample=<span class="hljs-variable">$&#123;file%%.*&#125;</span><br><span class="hljs-built_in">echo</span> <span class="hljs-variable">$sample</span> <br>awk <span class="hljs-string">&#x27;&#123;print $4&quot;\t&quot;$1&quot;\t&quot;$2&quot;\t&quot;$3&quot;\t+&quot;&#125;&#x27;</span> <span class="hljs-variable">$id</span> &gt; <span class="hljs-variable">$&#123;sample&#125;</span>.homer_peaks.tmp<br><span class="hljs-built_in">nohup</span> findMotifsGenome.pl <span class="hljs-variable">$&#123;sample&#125;</span>.homer_peaks.tmp  mm10 <span class="hljs-variable">$&#123;sample&#125;</span>_motifDir -len 8,10,12  &amp;<br><span class="hljs-keyword">done</span><br></code></pre></td></tr></table></figure><blockquote><p> 差异peaks分析</p></blockquote><p>diffbind, DESeq2</p>]]></content>
    
    
    <categories>
      
      <category>NGS</category>
      
    </categories>
    
    
    <tags>
      
      <tag>atac-seq</tag>
      
      <tag>pipeline</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【bowtie2】</title>
    <link href="/GeekFocus/2022/03/20/2022-03-20-bowtie2/"/>
    <url>/GeekFocus/2022/03/20/2022-03-20-bowtie2/</url>
    
    <content type="html"><![CDATA[<p><strong>Bowtie 2</strong> is an ultrafast and memory-efficient tool for aligning sequencing reads to long reference sequences. It is particularly good at aligning reads of about <strong>50 up to 100s or 1,000s</strong> of characters, and particularly <strong>good at aligning to relatively long</strong> (e.g. mammalian) genomes. Bowtie 2 indexes the genome with an <strong>FM Index</strong> to keep its <strong>memory footprint small</strong>: for the human genome, its memory footprint is typically around 3.2 GB. Bowtie 2 supports <strong>gapped</strong>, <strong>local</strong>, and <strong>paired-end</strong> alignment modes.</p><span id="more"></span><p><a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml">http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml</a></p><h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p><a href="http://bowtie-bio.sf.net/bowtie2">Bowtie 2</a> is an ultrafast and memory-efficient tool for aligning sequencing reads to long reference sequences. It is particularly good at aligning reads of about 50 up to 100s of characters to relatively long (e.g. mammalian) genomes. Bowtie 2 indexes the genome with an <a href="http://en.wikipedia.org/wiki/FM-index">FM Index</a> (based on the <a href="http://en.wikipedia.org/wiki/Burrows-Wheeler_transform">Burrows-Wheeler Transform</a> or <a href="http://en.wikipedia.org/wiki/Burrows-Wheeler_transform">BWT</a>) to keep its memory footprint small: for the human genome, its memory footprint is typically around 3.2 gigabytes of RAM. Bowtie 2 supports gapped, local, and paired-end alignment modes. Multiple processors can be used simultaneously to achieve greater alignment speed.</p><p>Bowtie 2 outputs alignments in <a href="http://samtools.sourceforge.net/SAM1.pdf">SAM</a> format, enabling interoperation with a large number of other tools (e.g. <a href="http://samtools.sourceforge.net/">SAMtools</a>, <a href="http://www.broadinstitute.org/gsa/wiki/index.php/The_Genome_Analysis_Toolkit">GATK</a>) that use SAM. Bowtie 2 is distributed under the <a href="http://www.gnu.org/licenses/gpl-3.0.html">GPLv3 license</a>, and it runs on the command line under Windows, Mac OS X and Linux and BSD.</p><p><a href="http://bowtie-bio.sf.net/bowtie2">Bowtie 2</a> is often the first step in pipelines for <font color="blue"><strong>comparative genomics</strong></font>, including for <font color="blue"><strong>variation calling, ChIP-seq, RNA-seq, BS-seq</strong></font>. <a href="http://bowtie-bio.sf.net/bowtie2">Bowtie 2</a> and <a href="http://bowtie-bio.sf.net/">Bowtie</a>(also called “<a href="http://bowtie-bio.sf.net/">Bowtie 1</a>“ here) are also tightly integrated into many other tools, some of which <a href="http://bowtie-bio.sourceforge.net/bowtie2/other_tools.shtml">are listed here</a>.</p><p>If you use <a href="http://bowtie-bio.sf.net/bowtie2">Bowtie 2</a> for your published research, please cite our work. Papers describing Bowtie 2 are:</p><ul><li>Langmead B, Wilks C, Antonescu V, Charles R. <a href="https://doi.org/10.1093/bioinformatics/bty648">Scaling read aligners to hundreds of threads on general-purpose processors</a>. <em>Bioinformatics</em>. 2018 Jul 18. doi: 10.1093&#x2F;bioinformatics&#x2F;bty648.</li><li>Langmead B, Salzberg SL. <a href="https://www.nature.com/articles/nmeth.1923">Fast gapped-read alignment with Bowtie 2</a>. <em>Nature Methods</em>. 2012 Mar 4;9(4):357-9. doi: 10.1038&#x2F;nmeth.1923.</li></ul><h2 id="How-is-Bowtie-2-different-from-Bowtie-1"><a href="#How-is-Bowtie-2-different-from-Bowtie-1" class="headerlink" title="How is Bowtie 2 different from Bowtie 1?"></a>How is Bowtie 2 different from Bowtie 1?</h2><p><font color="blue"><strong>Bowtie 1</strong></font> was released in 2009 and was geared toward <strong>aligning the relatively short sequencing reads</strong> (up to <strong>25-50 nucl</strong>eotides) prevalent at the time. Since then, technology has improved both sequencing throughput (more nucleotides produced per sequencer per day) and read length (more nucleotides per read).</p><p>The chief differences between Bowtie 1 and Bowtie 2 are:</p><ol><li>For reads <strong>longer than about 50 bp</strong> Bowtie 2 is generally <strong>faster</strong>, more <strong>sensitive</strong>, and uses <strong>less memory</strong> than Bowtie 1. For relatively short reads (e.g. <strong>less than 50 bp) Bowtie 1</strong> is sometimes <strong>faster</strong> and&#x2F;or more <strong>sensitive</strong>.</li><li>Bowtie 2 <strong>supports gapped alignment</strong> with affine gap penalties. Number of gaps and gap lengths are not restricted, except by way of the configurable scoring scheme. <strong>Bowtie 1</strong> finds just <strong>ungapped alignments</strong>.</li><li>Bowtie 2 <strong>supports</strong> <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#end-to-end-alignment-versus-local-alignment"><strong>local alignment</strong></a>, which doesn’t require reads to align end-to-end. Local alignments might be “trimmed” (“soft clipped”) at one or both extremes in a way that optimizes alignment score. Bowtie 2 <strong>also supports</strong> <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#end-to-end-alignment-versus-local-alignment">end-to-end alignment</a> which, like <strong>Bowtie 1, requires that the read align entirely.</strong></li><li>There is <strong>no upper limit on read length</strong> in <strong>Bowtie 2</strong>. Bowtie 1 had an upper limit of around 1000 bp.</li><li>Bowtie 2 <strong>allows</strong> alignments to <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#ambiguous-characters">overlap ambiguous characters</a> (e.g. <code>N</code>s) in the reference. Bowtie 1 does not.</li><li>Bowtie 2 does away with Bowtie 1’s notion of alignment “stratum”, and its distinction between “Maq-like” and “end-to-end” modes. In Bowtie 2 all alignments <strong>lie along a continuous spectrum of alignment scores</strong> where the <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#scores-higher-more-similar">scoring scheme</a>, <strong>similar to</strong> <a href="http://en.wikipedia.org/wiki/Needleman-Wunsch_algorithm">Needleman-Wunsch</a> and <a href="http://en.wikipedia.org/wiki/Smith_waterman">Smith-Waterman</a>.</li><li>Bowtie 2’s <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#aligning-pairs">paired-end alignment</a> is <strong>more flexible</strong>. E.g. for pairs that do not align in a paired fashion, Bowtie 2 attempts to <strong>find unpaired alignments for each mate</strong>.</li><li>Bowtie 2 <strong>reports</strong> a spectrum of <strong>mapping qualities</strong>, in contrast for Bowtie 1 which reports either 0 or high.</li><li>Bowtie 2 does not align <strong>colorspace reads?</strong>.</li></ol><p>Bowtie 2 is not a “drop-in” replacement for Bowtie 1. Bowtie 2’s command-line <strong>arguments and genome index format are both different</strong> from Bowtie 1’s.</p><h2 id="What-isn’t-Bowtie-2"><a href="#What-isn’t-Bowtie-2" class="headerlink" title="What isn’t Bowtie 2?"></a>What isn’t Bowtie 2?</h2><p>Bowtie 2 is geared toward aligning relatively short sequencing reads to long genomes. That said, it handles arbitrarily small reference sequences (e.g. amplicons) and very long reads (i.e. upwards of 10s or 100s of kilobases), though it is slower in those settings. It is optimized for the read lengths and error modes yielded by typical Illumina sequencers.</p><p>Bowtie 2 <strong>does not support</strong> alignment of colorspace reads. (Bowtie 1 does.)</p><h1 id="Obtaining-Bowtie-2"><a href="#Obtaining-Bowtie-2" class="headerlink" title="Obtaining Bowtie 2"></a>Obtaining Bowtie 2</h1><p>Bowtie 2 is available from various package managers, notably <a href="https://anaconda.org/bioconda/bowtie2">Bioconda</a>. With Bioconda installed, you should be able to install Bowtie 2 with <code>conda install bowtie2</code>.</p><p>Containerized versions of Bowtie 2 are also available via the <a href="https://biocontainers.pro/">Biocontainers</a> project (e.g. <a href="https://hub.docker.com/r/biocontainers/bowtie2/">via Docker Hub</a>).</p><p>You can also download Bowtie 2 sources and binaries from the <a href="https://sourceforge.net/projects/bowtie-bio/files/bowtie2/">Download</a> section of the Sourceforge site. <strong>Binaries</strong> are available for the <code>x86_64</code>architecture running Linux, Mac OS X, and Windows.  If you plan to <strong>compile Bowtie 2 yourself</strong>, make sure to get the <strong>source package</strong>, i.e., the filename that ends in “-source.zip”.</p><h2 id="Building-from-source"><a href="#Building-from-source" class="headerlink" title="Building from source"></a>Building from source</h2><p>Building from source</p><p>Unzip the <strong>-source.zip</strong>, change to the unzipped directory, and build the Bowtie 2 tools by running GNU <code>make</code> (usually with the command <code>make</code>, but sometimes with <code>gmake</code>) with no arguments. </p><p>The Bowtie 2 Makefile also includes recipes for basic automatic dependency management. Running <code>make static-libs &amp;&amp; make STATIC_BUILD=1</code>will issue a series of commands that will: 1. download <strong>zstd</strong> and <strong>zlib 2</strong>. compile them as static libraries 3. <strong>link the resulting libraries to the compiled Bowtie 2 binaries</strong></p><p>As of version 2.3.5 bowtie2 now <strong>supports aligning SRA reads</strong>. Prepackaged builds will include a package that supports SRA. If you’re building bowtie2 from source please make sure that the Java runtime is available on your system. You can then proceed with the build by running <code>make sra-deps &amp;&amp; make USE_SRA=1</code>.</p><h1 id="The-bowtie2-aligner"><a href="#The-bowtie2-aligner" class="headerlink" title="The bowtie2 aligner"></a>The <code>bowtie2</code> aligner</h1><p><code>bowtie2</code> takes a Bowtie 2 <strong>index</strong> and a set of sequencing <strong>read</strong> files and outputs a set of alignments in <strong>SAM</strong> format.</p><p>“Alignment” is the process by which we discover <strong>how and where the read sequences are similar to the reference</strong> sequence. An “alignment” is a result from this process, specifically: an alignment is a way of “lining up” some or all of the characters in the read with some characters from the reference in a way that reveals how they’re similar. For example:</p><figure class="highlight gherkin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs gherkin">Read:      GACTGGGCGATCTCGACTTCG<br>           |||||<span class="hljs-string">  </span>||||||||||<span class="hljs-string"> </span>|||<br>Reference: GACTG--CGATCTCGACATCG<br></code></pre></td></tr></table></figure><p>Where dash symbols represent <strong>gaps</strong> and <strong>vertical bars</strong> show where aligned characters <strong>match</strong>.</p><p>We use alignment to <strong>make an educated guess</strong> as to where a read originated with respect to the reference genome. <strong>It’s not always possible to determine this with certainty</strong>. For instance, if the reference genome contains several long stretches of As (<code>AAAAAAAAA</code> etc.) and the read sequence is a short stretch of As (<code>AAAAAAA</code>), we cannot know for certain exactly where in the sea of <code>A</code>s the read originated.</p><h2 id="End-to-end-alignment-versus-local-alignment"><a href="#End-to-end-alignment-versus-local-alignment" class="headerlink" title="End-to-end alignment versus local alignment"></a>End-to-end alignment versus local alignment</h2><p><font color="blue">By default, Bowtie 2 performs <strong>end-to-end</strong> read alignment</font>. That is, it searches for alignments involving all of the read characters. This is also called an “untrimmed” or “unclipped” alignment.</p><p>When the <font color="blue"><strong>–local option</strong></font> is specified, Bowtie 2 performs local read alignment. In this mode, Bowtie 2 <font color="blue">might “trim” or “clip” some read characters from one or both ends of the alignment</font> if doing so maximizes the alignment score.</p><h3 id="End-to-end-alignment-example"><a href="#End-to-end-alignment-example" class="headerlink" title="End-to-end alignment example"></a>End-to-end alignment example</h3><p>The following is an “end-to-end” alignment because it involves all the characters in the read. Such an alignment can be produced by Bowtie 2 in either end-to-end mode or in local mode.</p><figure class="highlight dts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs dts"><span class="hljs-symbol">Read:</span>      GACTGGGCGATCTCGACTTCG<br><span class="hljs-symbol">Reference:</span> GACTGCGATCTCGACATCG<br><span class="hljs-symbol"></span><br><span class="hljs-symbol">Alignment:</span><br><span class="hljs-symbol">  Read:</span>      GACTGGGCGATCTCGACTTCG<br>             |||||  |||||||||| |||<br><span class="hljs-symbol">  Reference:</span> GACTG--CGATCTCGACATCG<br></code></pre></td></tr></table></figure><h3 id="Local-alignment-example"><a href="#Local-alignment-example" class="headerlink" title="Local alignment example"></a>Local alignment example</h3><p>The following is a “local” alignment because <font color="blue">some of the characters <strong>at the ends of the read do not participate</strong></font>. In this case, 4 characters are <font color="red"><strong>omitted</strong> (or “<strong>soft trimmed</strong>“ or “<strong>soft clipped</strong>“)</font> from the beginning and 3 characters are omitted from the end. This sort of alignment can be produced by Bowtie 2 <strong>only in local mode</strong>.</p><figure class="highlight dts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs dts"><span class="hljs-symbol">Read:</span>      ACGGTTGCGTTAATCCGCCACG<br><span class="hljs-symbol">Reference:</span> TAACTTGCGTTAAATCCGCCTGG<br><span class="hljs-symbol"></span><br><span class="hljs-symbol">Alignment:</span><br><span class="hljs-symbol">  Read:</span>      ACGGTTGCGTTAA-TCCGCCACG<br>                 ||||||||| ||||||<br><span class="hljs-symbol">  Reference:</span> TAACTTGCGTTAAATCCGCCTGG<br></code></pre></td></tr></table></figure><h2 id="Scores-higher-x3D-more-similar"><a href="#Scores-higher-x3D-more-similar" class="headerlink" title="Scores: higher &#x3D; more similar"></a>Scores: higher &#x3D; more similar</h2><p>An alignment score quantifies how similar the read sequence is to the reference sequence aligned to. The higher the score, the more similar they are. A score is <font color="blue"><strong>calculated</strong> by <strong>subtracting penalties</strong> for each difference (<strong>mismatch</strong>, <strong>gap</strong>, etc.)</font> and, in local alignment mode, adding bonuses for each match.</p><p>The scores can be configured with the <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-ma"><code>--ma</code></a> (match bonus), <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-mp"><code>--mp</code></a> (mismatch penalty), <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-np"><code>--np</code></a> (penalty for having an N in either the read or the reference), <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-rdg"><code>--rdg</code></a> (affine read gap penalty) and <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-rfg"><code>--rfg</code></a> (affine reference gap penalty) options.</p><h3 id="End-to-end-alignment-score-example-Default"><a href="#End-to-end-alignment-score-example-Default" class="headerlink" title="End-to-end alignment score example[Default]"></a>End-to-end alignment score example[Default]</h3><p>A <strong>mismatched</strong> base at a high-quality position in the read receives a penalty of <strong>-6</strong> by default. A length-2 read <strong>gap</strong> receives a penalty of -11 by default (<strong>-5 for the gap open</strong>, <strong>-3 for the first extension</strong>, -3 for the second extension). Thus, if 50 bp, one mismatch, one length-2 read gap, the overall score is -(6 + 11) &#x3D; -<strong>17</strong>.</p><p>The <strong>best</strong> possible alignment <strong>score</strong> in end-to-end mode is <strong>0</strong>, which happens when there are <strong>no differences</strong> between the read and the reference. <font color="red"><strong>No match bonus</strong>. </font> </p><h3 id="Local-alignment-score-example"><a href="#Local-alignment-score-example" class="headerlink" title="Local alignment score example"></a>Local alignment score example</h3><p>A mismatched base at a high-quality position in the read receives a penalty of -6 by default. A length-2 read gap receives a penalty of -11 by default (-5 for the gap open, -3 for the first extension, -3 for the second extension). A base that <font color="red"><strong>matches receives a bonus of +2 be default</strong></font>. Thus, if 50 bp, one mismatch, one length-2 read gap, <strong>bonus, 2 * 49</strong>, minus the total penalty, 6 + 11, &#x3D; <strong>81</strong>.</p><p>The best possible score in local mode equals the match bonus times the length of the read. This happens when there are no differences between the read and the reference.</p><h3 id="Valid-alignments-meet-or-exceed-the-minimum-score-threshold"><a href="#Valid-alignments-meet-or-exceed-the-minimum-score-threshold" class="headerlink" title="Valid alignments meet or exceed the minimum score threshold"></a><font color="red">Valid alignments meet or exceed the minimum score threshold</font></h3><p>For an alignment to be considered “valid” (i.e. “good enough”) by Bowtie 2, it must have an alignment score no less than the minimum score threshold. The threshold is configurable and is expressed as a function of the read length. In <font color="red"><strong>end-to-end</strong> alignment mode, the <strong>default minimum score threshold</strong></font> is <code>-0.6 + -0.6 * L</code>, where <code>L</code> is the read length. In <font color="red"><strong>local</strong> alignment mode, the <strong>default minimum score threshold</strong></font> is <code>20 + 8.0 * ln(L)</code>, where L is the read length. This can be configured with the <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-score-min"><code>--score-min</code></a> option. For details on how to set options like <code>--score-min</code> that correspond to functions, see the section on <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#setting-function-options">setting function options</a>.</p><h2 id="MAPQ-Mapping-quality-higher-x3D-more-unique"><a href="#MAPQ-Mapping-quality-higher-x3D-more-unique" class="headerlink" title="MAPQ,Mapping quality: higher &#x3D; more unique"></a><font color="red">MAPQ</font>,Mapping quality: higher &#x3D; more unique</h2><p>The aligner cannot always assign a read to its point of origin with high confidence. For instance, a read that originated inside a repeat element might align equally well to many occurrences of the element throughout the genome, leaving the aligner with no basis for preferring one over the others.</p><p>Aligners characterize their degree of confidence in the point of origin by reporting a mapping quality: a non-negative integer <font color="red"><strong>Q &#x3D; -10 log10 p</strong></font>, where <font color="blue">p is an estimate of the probability that the alignment does not correspond to the read’s true point of origin</font>. Mapping quality is sometimes abbreviated <font color="red"><strong>MAPQ</strong></font>, and is recorded in the <a href="http://samtools.sourceforge.net/SAM1.pdf">SAM</a> <code>MAPQ</code> field.</p><p>Mapping quality is related to “uniqueness.” We say an alignment is unique if it has a much higher alignment score than all the other possible alignments. The bigger the gap between the best alignment’s score and the second-best alignment’s score, the more unique the best alignment, and the higher its mapping quality should be.</p><p><strong>Accurate mapping qualities</strong> are <strong>useful</strong> for <strong>downstream tools</strong> like <strong>variant callers</strong>. For instance, a variant caller might choose to ignore evidence from alignments with mapping quality less than, say, 10. A mapping quality of 10 or less indicates that there is at least a 1 in 10 chance that the read truly originated elsewhere.</p><h2 id="Aligning-pairs"><a href="#Aligning-pairs" class="headerlink" title="Aligning pairs"></a>Aligning pairs</h2><p>A “paired-end” or “mate-pair” read consists of pair of mates, called mate 1 and mate 2. Pairs come with a prior expectation about (a) the relative orientation of the mates, and (b) the distance separating them on the original DNA molecule. Exactly what expectations hold for a given dataset depends on the lab procedures used to generate the data. For example, a common lab procedure for producing pairs is Illumina’s Paired-end Sequencing Assay, which yields pairs with a <font color="blue"><strong>relative orientation of FR (“forward, reverse”)</strong></font> meaning that if <font color="blue">mate 1 came from the <strong>Watson strand</strong></font>, <font color="blue">mate 2 very likely came from the <strong>Crick strand</strong></font> and vice versa. Also, this protocol yields pairs where the expected genomic distance from end to end is about <strong>200-500 base pairs</strong>.</p><p>For simplicity, this manual uses the term “paired-end” to refer to any pair of reads with some expected relative orientation and distance. Depending on the protocol, these might actually be referred to as “paired-end” or “mate-paired.” Also, we always refer to the individual sequences making up the pair as “mates.”</p><h3 id="Paired-inputs"><a href="#Paired-inputs" class="headerlink" title="Paired inputs"></a>Paired inputs</h3><p>Bowtie 2, mate 1s mates using the <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-1"><code>-1</code></a> ,  mate 2s using the <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-2"><code>-2</code></a> argument. </p><h3 id="Paired-SAM-output"><a href="#Paired-SAM-output" class="headerlink" title="Paired SAM output"></a>Paired SAM output</h3><p>When Bowtie 2 prints a SAM alignment for a pair, it <font color="blue"><strong>prints two records</strong> (i.e. two lines of output), one for each mate(1&amp;2)</font>. In both records, some of the fields of the SAM record describe various properties of the alignment; for instance, the <font color="blue">7th and 8th</font> fields (<code>RNEXT</code> and <code>PNEXT</code> respectively) indicate the <font color="blue">reference <strong>name</strong> and <strong>position</strong> where the other mate aligned</font>, and the <font color="blue"><strong>9th</strong> field indicates the inferred length of the <strong>DNA fragment</strong></font> from which the two mates were sequenced. See the <a href="http://samtools.sourceforge.net/SAM1.pdf">SAM specification</a> for more details regarding these fields.</p><h3 id="Concordant-pairs-match-pair-expectations-discordant-pairs-don’t"><a href="#Concordant-pairs-match-pair-expectations-discordant-pairs-don’t" class="headerlink" title="Concordant pairs match pair expectations, discordant pairs don’t"></a><font color="red">Concordant pairs</font> match pair expectations, discordant pairs don’t</h3><p>A pair that aligns <font color="blue">with the <strong>expected relative mate orientation</strong> and with the <strong>expected range</strong> of distances between mates</font> is said to align “<font color="red"><strong>concordantly</strong></font>“. If both mates have unique alignments, but the alignments do not match paired-end expectations (i.e. the mates aren’t in the expected relative orientation, or aren’t within the expected distance range, or both), the pair is said to align “<font color="red"><strong>discordantly</strong></font>“. Discordant alignments may be of particular interest, for instance, when seeking <a href="http://www.ncbi.nlm.nih.gov/dbvar/content/overview/"><font color="red"><strong>structural variants</strong></font></a>.</p><p>The expected relative orientation of the mates is set using the <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-fr"><code>--ff</code></a>, <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-fr"><code>--fr</code></a>, or <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-fr"><code>--rf</code></a> options. The <strong>expected range of inter-mates distances</strong> (as measured from the furthest extremes of the mates; also called “outer distance”) is set with the <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-I"><code>-I</code></a> and <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-X"><code>-X</code></a> options. Note that setting <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-I"><code>-I</code></a> and <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-X"><code>-X</code></a> far apart <font color="blue">makes Bowtie 2 slower</font>. See documentation for <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-I"><code>-I</code></a> and <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-X"><code>-X</code></a>.</p><p>To declare that a pair aligns discordantly, Bowtie 2 requires that both mates align uniquely. This is a conservative threshold, but this is often desirable when seeking structural variants.</p><p><font color="red">By default, Bowtie 2 searches for both concordant and discordant alignments</font>, though searching for discordant alignments can be <strong>disabled</strong> with the <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-no-discordant"><code>--no-discordant</code></a> option.</p><h3 id="Mixed-mode-paired-where-possible-unpaired-otherwise"><a href="#Mixed-mode-paired-where-possible-unpaired-otherwise" class="headerlink" title="Mixed mode: paired where possible, unpaired otherwise"></a>Mixed mode: paired where possible, unpaired otherwise</h3><p>If Bowtie 2 <font color="blue"><strong>cannot find</strong> a <strong>paired-end</strong> alignment for a <strong>pair</strong></font>, <font color="blue">by default it will go on to <strong>look for unpaired alignments</strong> for the constituent mates</font>. This is called “mixed mode.” To disable mixed mode, set the <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-no-mixed"><code>--no-mixed</code></a> option.</p><p>Bowtie 2 <strong>runs a little faster</strong> in <code>--no-mixed</code> mode, but will only consider alignment status of pairs per se, not individual mates.</p><h3 id="Some-SAM-FLAGS-describe-paired-end-properties"><a href="#Some-SAM-FLAGS-describe-paired-end-properties" class="headerlink" title="Some SAM FLAGS describe paired-end properties"></a>Some <font color="red">SAM FLAGS</font> describe <font color="red">paired-end properties</font></h3><p>The SAM <code>FLAGS</code> field, the <font color="red"><strong>second field</strong></font> in a SAM record, has multiple bits that describe the paired-end nature of the read and alignment. </p><p>The first (least significant) bit (1 in decimal, 0x1 in hexadecimal) is set if the read is part of a pair. </p><p>The second bit (2 in decimal, 0x2 in hexadecimal) is set if <font color="blue">the read is part of a pair that aligned in a paired-end fashion</font>. </p><p>The fourth bit (8 in decimal, 0x8 in hexadecimal) is set if the read is part of a pair and the other mate in the pair had at least one valid alignment. </p><p>The sixth bit (32 in decimal, 0x20 in hexadecimal) is set if the read is part of a pair and the other mate in the pair aligned to the Crick strand (or, equivalently, if the reverse complement of the other mate aligned to the Watson strand). </p><p>The seventh bit (64 in decimal, 0x40 in hexadecimal) is set if the read is mate 1 in a pair. </p><p>The eighth bit (128 in decimal, 0x80 in hexadecimal) is set if the read is mate 2 in a pair. </p><p>See the <a href="http://samtools.sourceforge.net/SAM1.pdf">SAM specification</a> for a more detailed description of the <code>FLAGS</code> field.</p><h3 id="Some-SAM-optional-fields-describe-more-paired-end-properties"><a href="#Some-SAM-optional-fields-describe-more-paired-end-properties" class="headerlink" title="Some SAM optional fields describe more paired-end properties"></a>Some SAM optional fields describe more paired-end properties</h3><p>The last several fields of each SAM record usually contain SAM optional fields, which are simply tab-separated strings conveying additional information about the reads and alignments. A SAM optional field is formatted like this: “XP:i:1” where “XP” is the <code>TAG</code>, “i” is the <code>TYPE</code> (“integer” in this case), and “1” is the <code>VALUE</code>. See the <a href="http://samtools.sourceforge.net/SAM1.pdf">SAM specification</a> for details regarding SAM optional fields.</p><h3 id="Mates-can-overlap-contain-or-dovetail-each-other"><a href="#Mates-can-overlap-contain-or-dovetail-each-other" class="headerlink" title="Mates can overlap, contain, or dovetail each other"></a>Mates can <font color="red">overlap, contain, or dovetail</font> each other</h3><p>The fragment and read lengths might be such that alignments for the two mates from a pair overlap each other. Consider this example:</p><p>(For these examples, assume we expect mate 1 to align to the left of mate 2.)</p><figure class="highlight nestedtext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs nestedtext"><span class="hljs-attribute">Mate 1</span><span class="hljs-punctuation">:</span> <span class="hljs-string">   GCAGATTATATGAGTCAGCTACGATATTGTT</span><br><span class="hljs-attribute">Mate 2</span><span class="hljs-punctuation">:</span> <span class="hljs-string">                              TGTTTGGGGTGACACATTACGCGTCTTTGAC</span><br><span class="hljs-attribute">Reference</span><span class="hljs-punctuation">:</span> <span class="hljs-string">GCAGATTATATGAGTCAGCTACGATATTGTTTGGGGTGACACATTACGCGTCTTTGAC</span><br></code></pre></td></tr></table></figure><p>It’s also possible, though unusual, for one mate alignment to contain the other, as in these examples:</p><figure class="highlight nestedtext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs nestedtext"><span class="hljs-attribute">Mate 1</span><span class="hljs-punctuation">:</span> <span class="hljs-string">   GCAGATTATATGAGTCAGCTACGATATTGTTTGGGGTGACACATTACGC</span><br><span class="hljs-attribute">Mate 2</span><span class="hljs-punctuation">:</span> <span class="hljs-string">                              TGTTTGGGGTGACACATTACGC</span><br><span class="hljs-attribute">Reference</span><span class="hljs-punctuation">:</span> <span class="hljs-string">GCAGATTATATGAGTCAGCTACGATATTGTTTGGGGTGACACATTACGCGTCTTTGAC</span><br><br><span class="hljs-attribute">Mate 1</span><span class="hljs-punctuation">:</span> <span class="hljs-string">                  CAGCTACGATATTGTTTGGGGTGACACATTACGC</span><br><span class="hljs-attribute">Mate 2</span><span class="hljs-punctuation">:</span> <span class="hljs-string">                     CTACGATATTGTTTGGGGTGAC</span><br><span class="hljs-attribute">Reference</span><span class="hljs-punctuation">:</span> <span class="hljs-string">GCAGATTATATGAGTCAGCTACGATATTGTTTGGGGTGACACATTACGCGTCTTTGAC</span><br></code></pre></td></tr></table></figure><p>And it’s also possible, though unusual, for the mates to “dovetail”, with the mates seemingly extending “past” each other as in this example:</p><figure class="highlight nestedtext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs nestedtext"><span class="hljs-attribute">Mate 1</span><span class="hljs-punctuation">:</span> <span class="hljs-string">                GTCAGCTACGATATTGTTTGGGGTGACACATTACGC</span><br><span class="hljs-attribute">Mate 2</span><span class="hljs-punctuation">:</span> <span class="hljs-string">           TATGAGTCAGCTACGATATTGTTTGGGGTGACACAT                   </span><br><span class="hljs-attribute">Reference</span><span class="hljs-punctuation">:</span> <span class="hljs-string">GCAGATTATATGAGTCAGCTACGATATTGTTTGGGGTGACACATTACGCGTCTTTGAC</span><br></code></pre></td></tr></table></figure><p>In some situations, it’s desirable for the aligner to consider all these cases as “concordant” as long as other paired-end constraints are not violated. <font color="red"><strong>Bowtie 2’s default</strong></font> behavior is to consider <font color="blue">overlapping and containing</font> as being consistent with <font color="blue">concordant</font> alignment. By default, <font color="blue">dovetailing is considered inconsistent with concordant alignment</font>.</p><p>These <font color="red"><strong>defaults can be overridden</strong></font>. Setting <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-no-overlap"><code>--no-overlap</code></a> causes Bowtie 2 to consider overlapping mates as non-concordant. Setting <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-no-contain"><code>--no-contain</code></a>causes Bowtie 2 to consider cases where one mate alignment contains the other as non-concordant. Setting <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-dovetail"><code>--dovetail</code></a> causes Bowtie 2 to consider cases where the mate alignments dovetail as concordant.</p><h2 id="Reporting"><a href="#Reporting" class="headerlink" title="Reporting"></a>Reporting</h2><p>The reporting mode governs how many alignments Bowtie 2 looks for, and how to report them. Bowtie 2 has three distinct reporting modes. The default reporting mode is similar to the default reporting mode of many other read alignment tools, including <a href="http://bio-bwa.sourceforge.net/">BWA</a>. It is also similar to Bowtie 1’s <code>-M</code>alignment mode.</p><p>In general, when we say that a read has an alignment, we mean that it has a <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#valid-alignments-meet-or-exceed-the-minimum-score-threshold">valid alignment</a>. When we say that a read has multiple alignments, we mean that it has multiple alignments that are valid and distinct from one another.</p><h3 id="Distinct-alignments-map-a-read-to-different-places"><a href="#Distinct-alignments-map-a-read-to-different-places" class="headerlink" title="Distinct alignments map a read to different places"></a>Distinct alignments map a read to different places</h3><p>Two alignments for the same individual read are “distinct” if they map the same read to different places. Specifically, we say that two alignments are distinct if there are no alignment positions where a particular read offset is aligned opposite a particular reference offset in both alignments with the same orientation. E.g. if the first alignment is in the forward orientation and aligns the read character at read offset 10 to the reference character at chromosome 3, offset 3,445,245, and the second alignment is also in the forward orientation and also aligns the read character at read offset 10 to the reference character at chromosome 3, offset 3,445,245, they are not distinct alignments.</p><p>Two alignments for the same pair are distinct if either the mate 1s in the two paired-end alignments are distinct or the mate 2s in the two alignments are distinct or both.</p><h3 id="Default-mode-search-for-multiple-alignments-report-the-best-one"><a href="#Default-mode-search-for-multiple-alignments-report-the-best-one" class="headerlink" title="Default mode: search for multiple alignments, report the best one"></a><font color="red">Default mode</font>: search for multiple alignments, <font color="red">report the best one</font></h3><p>By default, Bowtie 2 searches for distinct, valid alignments for each read. When it finds a valid alignment, it generally will continue to look for alignments that are nearly as good or better. It will eventually stop looking, either because it <font color="red">exceeded a limit placed on search effort</font> (see <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-D"><code>-D</code></a> and <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-R"><code>-R</code></a>) or because it already knows all it needs to know to report an alignment. <font color="blue">Information from the best alignments are used to estimate mapping quality</font> (the <code>MAPQ</code> <a href="http://samtools.sourceforge.net/SAM1.pdf">SAM</a> field) and to set SAM optional fields, such as <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-build-opt-fields-as"><code>AS:i</code></a> and <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-build-opt-fields-xs"><code>XS:i</code></a>. Bowtie 2 does not guarantee that the alignment reported is the best possible in terms of alignment score.</p><p>See also: <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-D"><code>-D</code></a>, which puts an <strong>upper limit</strong> on the number of dynamic programming problems (i.e. seed extensions) that can “fail” in a row before Bowtie 2 stops searching. Increasing <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-D"><code>-D</code></a> makes Bowtie 2 <strong>slower</strong>, but increases the likelihood that it will report the correct alignment for a read that aligns many places.</p><p>See also: <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-R"><code>-R</code></a>, which sets the maximum number of times Bowtie 2 will “re-seed” when attempting to align a read with repetitive seeds. Increasing <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-R"><code>-R</code></a>makes Bowtie 2 <strong>slower</strong>, but increases the likelihood that it will report the correct alignment for a read that aligns many places.</p><h3 id="k-mode-search-for-one-or-more-alignments-report-each"><a href="#k-mode-search-for-one-or-more-alignments-report-each" class="headerlink" title="-k mode: search for one or more alignments, report each"></a><font color="red">-k mode</font>: search for one or more alignments, report each</h3><p>In <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-k"><code>-k</code></a> mode, Bowtie 2 <font color="red">searches for up to N distinct</font>, valid alignments for each read, where N equals the integer specified with the <code>-k</code> parameter. That is, if <code>-k 2</code> is specified, Bowtie 2 will search for at most 2 distinct alignments. It reports all alignments found, in descending order by alignment score. The alignment score for a paired-end alignment equals the sum of the alignment scores of the individual mates. Each reported read or pair alignment beyond the first has the SAM ‘secondary’ bit (which equals 256) set in its FLAGS field. Supplementary alignments will also be assigned a MAPQ of 255. See the <a href="http://samtools.sourceforge.net/SAM1.pdf">SAM specification</a> for details.</p><p>Bowtie 2 does not “find” alignments in any specific order, so for reads that have more than N distinct, valid alignments, Bowtie 2 does not guarantee that the N alignments reported are the best possible in terms of alignment score. Still, this mode can be effective and fast in situations where the user <font color="red">cares more about whether a read aligns (or aligns a certain number of times) than where exactly it originated</font>.</p><h3 id="a-mode-search-for-and-report-all-alignments"><a href="#a-mode-search-for-and-report-all-alignments" class="headerlink" title="-a mode: search for and report all alignments"></a>-a mode: search for and report all alignments</h3><p><a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-a"><code>-a</code></a> mode is similar to <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-k"><code>-k</code></a> mode except that there is <font color="red">no upper limit on the number of alignments Bowtie 2 should report</font>. Alignments are reported in descending order by alignment score. The alignment score for a paired-end alignment equals the sum of the alignment scores of the individual mates. Each reported read or pair alignment beyond the first has the SAM ‘secondary’ bit (which equals 256) set in its FLAGS field. Supplementary alignments will be assigned a MAPQ of 255. See the <a href="http://samtools.sourceforge.net/SAM1.pdf">SAM specification</a> for details.</p><p>Some tools are designed with this reporting mode in mind. Bowtie 2 is not! For very large genomes, this mode is <strong>very slow</strong>.</p><h3 id="Randomness-in-Bowtie-2"><a href="#Randomness-in-Bowtie-2" class="headerlink" title="Randomness in Bowtie 2"></a>Randomness in Bowtie 2</h3><p>Bowtie 2’s search for alignments for a given read is “randomized.” That is, when Bowtie 2 encounters <font color="blue">a set of equally-good choices, it uses a <strong>pseudo-random number</strong> to choose?</font>. For example, if Bowtie 2 discovers a set of 3 equally-good alignments and wants to decide which to report, it picks a pseudo-random integer 0, 1 or 2 and reports the corresponding alignment. Arbitrary choices can crop up at various points during alignment.</p><p>The pseudo-random number generator is re-initialized for every read, and the seed used to initialize it is a function of the read name, nucleotide string, quality string, and the value specified with <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-seed"><code>--seed</code></a>. If you run the same version of Bowtie 2 on two reads with identical names, nucleotide strings, and quality strings, and if <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-seed"><code>--seed</code></a> is <font color="blue">set the same for both runs, Bowtie 2 will produce the same output</font>; i.e., it will align the read to the same place, even if there are multiple equally good alignments. This is intuitive and desirable in most cases. <font color="red">Most users expect Bowtie to produce the <strong>same output</strong> when run twice on the <strong>same input</strong></font>.</p><p>However, when the user specifies the <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-non-deterministic"><code>--non-deterministic</code></a> option, Bowtie 2 will use the current time to re-initialize the pseudo-random number generator. When this is specified, Bowtie 2 might report different alignments for identical reads. This is counter-intuitive for some users, but might be more appropriate in situations where the input consists of many identical reads.</p><h2 id="Multiseed-heuristic"><a href="#Multiseed-heuristic" class="headerlink" title="Multiseed heuristic"></a>Multiseed heuristic</h2><p>To rapidly narrow the number of possible alignments that must be considered, Bowtie 2 begins by extracting substrings (“seeds”) from the read and its reverse complement and aligning them in an ungapped fashion with the help of the <a href="http://portal.acm.org/citation.cfm?id=796543">FM Index</a>. This is “multiseed alignment” and it is similar to what <a href="http://genomebiology.com/2009/10/3/R25">Bowtie 1 does</a>, except Bowtie 1 attempts to align the entire read this way.</p><p>This initial step makes Bowtie 2 much faster than it would be without such a filter, but at the expense of missing some valid alignments. For instance, it is possible for a read to have a valid overall alignment but to have no valid seed alignments because each potential seed alignment is interrupted by too many mismatches or gaps.</p><p>The <font color="red">trade-off between <strong>speed</strong> and <strong>sensitivity&#x2F;accuracy</strong> can be adjusted by setting the seed length</font> (<a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-L"><code>-L</code></a>), the interval between extracted seeds (<a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-i"><code>-i</code></a>), and the number of mismatches permitted per seed (<a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-N"><code>-N</code></a>). For more sensitive alignment, set these parameters to (a) make the seeds closer together, (b) make the seeds shorter, and&#x2F;or (c) allow more mismatches. You can adjust these options one-by-one, though Bowtie 2 comes with some useful combinations of options prepackaged as “<a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#presets-setting-many-settings-at-once">preset options</a>.”</p><p><a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-D"><code>-D</code></a> and <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-R"><code>-R</code></a> are also options that adjust the trade-off between speed and sensitivity&#x2F;accuracy.</p><h3 id="FM-Index-memory-footprint"><a href="#FM-Index-memory-footprint" class="headerlink" title="FM Index memory footprint"></a>FM Index memory footprint</h3><p>Bowtie 2 uses the <a href="http://portal.acm.org/citation.cfm?id=796543">FM Index</a> to find ungapped alignments for seeds. This step accounts for the bulk of Bowtie 2’s memory footprint, as the <a href="http://portal.acm.org/citation.cfm?id=796543">FM Index</a>itself is typically the largest data structure used. For instance, the memory footprint of the <a href="http://portal.acm.org/citation.cfm?id=796543">FM Index</a> for the human genome is about 3.2 gigabytes of RAM.</p><h2 id="Ambiguous-characters"><a href="#Ambiguous-characters" class="headerlink" title="Ambiguous characters"></a>Ambiguous characters</h2><p>Non-whitespace characters besides A, C, G or T are considered “ambiguous.” N is a common ambiguous character that appears in reference sequences. Bowtie 2 considers all ambiguous characters in the reference (including <a href="http://www.bioinformatics.org/sms/iupac.html">IUPAC nucleotide codes</a>) to be Ns.</p><p>Bowtie 2 <font color="red"><strong>allows</strong> alignments to overlap ambiguous characters in the reference</font>. An alignment position that contains an ambiguous character in the read, reference, or both, is penalized according to <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-np"><code>--np</code></a>. <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-n-ceil"><code>--n-ceil</code></a> sets an upper limit on the number of positions that may contain ambiguous reference characters in a valid alignment. The optional field <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-build-opt-fields-xn"><code>XN:i</code></a> reports the number of ambiguous reference characters overlapped by an alignment.</p><p>Note that the <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#multiseed-heuristic">multiseed heuristic</a> cannot find <em>seed</em> alignments that overlap ambiguous reference characters. For an alignment overlapping an ambiguous reference character to be found, it must have one or more seed alignments that do not overlap ambiguous reference characters.</p><h2 id="Presets-setting-many-settings-at-once"><a href="#Presets-setting-many-settings-at-once" class="headerlink" title="Presets: setting many settings at once"></a>Presets: setting many settings at once</h2><p>Bowtie 2 comes with some useful combinations of parameters packaged into shorter “preset” parameters. For example, running Bowtie 2 with the <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-very-sensitive"><code>--very-sensitive</code></a> option is the same as running with options: <code>-D 20 -R 3 -N 0 -L 20 -i S,1,0.50</code>. The preset options that come with Bowtie 2 are <font color="red">designed to cover a wide area of the speed&#x2F;sensitivity&#x2F;accuracy trade-off space</font>, with the presets ending in <code>fast</code> generally being faster but less sensitive and less accurate, and the presets ending in <code>sensitive</code> generally being slower but <strong>more sensitive and more accurate</strong>. See the <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#preset-options-in---end-to-end-mode">documentation for the preset options</a> for details.</p><p>As of Bowtie2 v2.4.0, individual preset values can be overridden by providing the specific options e.g. the configured seed length of 20 in the [<code>--very-senitive</code>] preset above can be changed to 25 by <strong>also specifying</strong> the <code>-L 25</code> parameter anywhere on the command line[masked -L 20].</p><h2 id="Filtering"><a href="#Filtering" class="headerlink" title="Filtering"></a>Filtering</h2><p>Some <font color="red"><strong>reads</strong></font> are skipped or “<font color="red"><strong>filtered out</strong></font>“ by Bowtie 2. For example, reads may be filtered out because they are extremely short or have a high proportion of ambiguous nucleotides. Bowtie 2 will still print a SAM record for such a read, but no alignment will be reported and the <code>YF:i</code> SAM optional field will be set to indicate the reason the read was filtered.</p><ul><li><code>YF:Z:LN</code>: the read was filtered because it had <font color="blue">length less than or equal</font> to the number of seed mismatches set with the <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-N"><code>-N</code></a> option.</li><li><code>YF:Z:NS</code>: the read was filtered because it <font color="blue">contains a number of ambiguous characters</font> (usually <code>N</code> or <code>.</code>) greater than the ceiling specified with <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-n-ceil"><code>--n-ceil</code></a>.</li><li><code>YF:Z:SC</code>: the read was filtered because the read length and the match bonus (set with <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-ma"><code>--ma</code></a>) are such that the read <font color="blue">can’t possibly earn an alignment score</font> greater than or equal to the threshold set with <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-score-min"><code>--score-min</code></a></li><li><code>YF:Z:QC</code>: the read was filtered because it was <font color="blue">marked as failing quality control</font> and the user specified the <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-qc-filter"><code>--qc-filter</code></a> option. This only happens when the input is in Illumina’s QSEQ format (i.e. when <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-qseq"><code>--qseq</code></a> is specified) and the last (11th) field of the read’s QSEQ record contains <code>1</code>.</li></ul><p>If a read could be filtered for more than one reason, the value <code>YF:Z</code> flag will reflect only one of those reasons.</p><h2 id="Alignment-summary"><a href="#Alignment-summary" class="headerlink" title="Alignment summary"></a>Alignment summary</h2><p>When Bowtie 2 finishes running, it prints messages summarizing what happened. These messages are printed to the “standard error” (“stderr”) filehandle. For datasets <font color="blue">consisting of unpaired reads</font>, the summary might look like this:</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">20000</span> reads; of these:<br>  <span class="hljs-attribute">20000</span> (<span class="hljs-number">100</span>.<span class="hljs-number">00</span>%) were unpaired; of these:<br>    <span class="hljs-attribute">1247</span> (<span class="hljs-number">6</span>.<span class="hljs-number">24</span>%) aligned <span class="hljs-number">0</span> times<br>    <span class="hljs-attribute">18739</span> (<span class="hljs-number">93</span>.<span class="hljs-number">69</span>%) aligned exactly <span class="hljs-number">1</span> time<br>    <span class="hljs-attribute">14</span> (<span class="hljs-number">0</span>.<span class="hljs-number">07</span>%) aligned &gt;<span class="hljs-number">1</span> times<br><span class="hljs-attribute">93</span>.<span class="hljs-number">77</span>% overall alignment rate<br></code></pre></td></tr></table></figure><p>For datasets <font color="blue">consisting of pairs</font>, the summary might look like this:</p><figure class="highlight applescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs applescript"><span class="hljs-number">10000</span> reads; <span class="hljs-keyword">of</span> these:<br>  <span class="hljs-number">10000</span> (<span class="hljs-number">100.00</span>%) were paired; <span class="hljs-keyword">of</span> these:<br>    <span class="hljs-number">650</span> (<span class="hljs-number">6.50</span>%) aligned concordantly <span class="hljs-number">0</span> <span class="hljs-keyword">times</span><br>    <span class="hljs-number">8823</span> (<span class="hljs-number">88.23</span>%) aligned concordantly exactly <span class="hljs-number">1</span> <span class="hljs-built_in">time</span><br>    <span class="hljs-number">527</span> (<span class="hljs-number">5.27</span>%) aligned concordantly &gt;<span class="hljs-number">1</span> <span class="hljs-keyword">times</span><br>    <span class="hljs-comment">----</span><br>    <span class="hljs-number">650</span> pairs aligned concordantly <span class="hljs-number">0</span> <span class="hljs-keyword">times</span>; <span class="hljs-keyword">of</span> these:<br>      <span class="hljs-number">34</span> (<span class="hljs-number">5.23</span>%) aligned discordantly <span class="hljs-number">1</span> <span class="hljs-built_in">time</span><br>    <span class="hljs-comment">----</span><br>    <span class="hljs-number">616</span> pairs aligned <span class="hljs-number">0</span> <span class="hljs-keyword">times</span> concordantly <span class="hljs-keyword">or</span> discordantly; <span class="hljs-keyword">of</span> these:<br>      <span class="hljs-number">1232</span> mates make up <span class="hljs-keyword">the</span> pairs; <span class="hljs-keyword">of</span> these:<br>        <span class="hljs-number">660</span> (<span class="hljs-number">53.57</span>%) aligned <span class="hljs-number">0</span> <span class="hljs-keyword">times</span><br>        <span class="hljs-number">571</span> (<span class="hljs-number">46.35</span>%) aligned exactly <span class="hljs-number">1</span> <span class="hljs-built_in">time</span><br>        <span class="hljs-number">1</span> (<span class="hljs-number">0.08</span>%) aligned &gt;<span class="hljs-number">1</span> <span class="hljs-keyword">times</span><br><span class="hljs-number">96.70</span>% overall alignment rate<br></code></pre></td></tr></table></figure><p>The indentation indicates how subtotals relate to totals.</p><h2 id="Wrapper-scripts"><a href="#Wrapper-scripts" class="headerlink" title="Wrapper scripts"></a>Wrapper scripts</h2><p>The <code>bowtie2</code>, <code>bowtie2-build</code> and <code>bowtie2-inspect</code> executables are actually wrapper scripts that call binary programs as appropriate. The wrappers shield users from having to distinguish between “small” and “large” index formats, discussed briefly in the following section. Also, the <code>bowtie2</code>wrapper provides some key functionality, like the ability to handle compressed inputs, and the functionality for <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-un"><code>--un</code></a>, <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-al"><code>--al</code></a> and related options.</p><p>It is recommended that you always run the bowtie2 wrappers and <strong>not run the binaries directly.</strong></p><h2 id="Small-and-large-indexes"><a href="#Small-and-large-indexes" class="headerlink" title="Small and large indexes"></a>Small and large indexes</h2><p><code>bowtie2-build</code> can index reference genomes of any size. For genomes less than about 4 billion nucleotides in length, <code>bowtie2-build</code> builds a “small” index using 32-bit numbers in various parts of the index. When the genome is longer, <code>bowtie2-build</code> builds a “large” index using 64-bit numbers. <font color="blue">Small indexes are stored in files with the <code>.bt2</code> extension, and large indexes are stored in files with the <code>.bt2l</code> extension. </font>The user need not worry about whether a particular index is small or large; the wrapper scripts will automatically build and use the appropriate index.</p><h2 id="Performance-tuning"><a href="#Performance-tuning" class="headerlink" title="Performance tuning"></a>Performance tuning</h2><ol><li><p>If your computer has multiple processors&#x2F;cores, use <code>-p</code></p><p>The <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-p"><code>-p</code></a> option causes Bowtie 2 to launch a specified number of parallel search threads. Each thread runs on a different processor&#x2F;core and all threads find alignments in parallel, increasing alignment throughput by approximately a multiple of the number of threads (though in practice, speedup is somewhat worse than linear).</p></li><li><p>If reporting many alignments per read, try reducing <code>bowtie2-build --offrate</code></p><p><font color="blue">If you are using <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-k"><code>-k</code></a> or <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-a"><code>-a</code></a> options and Bowtie 2 is reporting many alignments per read, using an index with a denser SA sample can speed things up considerably</font>. To do this, specify a smaller-than-default <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-o"><code>-o</code>&#x2F;<code>--offrate</code></a> value when running <code>bowtie2-build</code>. A denser SA sample yields a larger index, but is also particularly effective at speeding up alignment when many alignments are reported per read.</p></li><li><p>If <code>bowtie2</code> “thrashes”, try increasing <code>bowtie2-build --offrate</code></p><p>If <code>bowtie2</code> runs very slowly on a relatively low-memory computer, try setting <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-o"><code>-o</code>&#x2F;<code>--offrate</code></a> to a <em>larger</em> value when building the index. This decreases the memory footprint of the index.</p></li></ol><h2 id="Command-Line"><a href="#Command-Line" class="headerlink" title="Command Line"></a>Command Line</h2><h3 id="Alignment"><a href="#Alignment" class="headerlink" title="Alignment"></a><font color="red">Alignment</font></h3><p>Here are a few that may benefit the alignment of an <a href="https://informatics.fas.harvard.edu/atac-seq-guidelines.html">ATAC-seq dataset on Cannon</a>:</p><table><thead><tr><th align="left">Argument</th><th align="left">Description</th></tr></thead><tbody><tr><td align="left"><code>-X &lt;int&gt;</code></td><td align="left"><strong>Maximum DNA fragment length</strong> (default 500bp). If you anticipate that you may have DNA fragments longer than the default value, you should increase this parameter accordingly; otherwise, alignments from such fragments are considered not properly paired (see Fig. 3B below).</td></tr><tr><td align="left"><code>--very-sensitive</code></td><td align="left">Bowtie2 has a number of alignment and effort parameters that interact in complex (and sometimes unexpected) ways. Preset collections of these parameters are provided for convenience; the default is <code>--sensitive</code>, but <strong>better alignment results</strong> are frequently achieved with <code>--very-sensitive</code>.</td></tr><tr><td align="left"><code>-k &lt;int&gt;</code></td><td align="left">Maximum number of <strong>alignments to report per read</strong>. By default, Bowtie2 reports at most one alignment per read, and if multiple equivalent alignments exist, it chooses one randomly. Generate huge output</td></tr><tr><td align="left"><code>-p &lt;int&gt;</code></td><td align="left">Number of cores on which to run</td></tr></tbody></table><p>The output is a <a href="https://samtools.github.io/hts-specs/SAMv1.pdf">SAM file</a>, which contains alignment information for each input read. The SAM <strong>should be compressed to a binary format (BAM)</strong> and sorted by queryname with <a href="http://www.htslib.org/doc/samtools.html">SAMtools</a>. This is best accomplished by piping the output from Bowtie2 directly to <code>samtools view</code> and <code>samtools sort</code>, </p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs sh">module load bowtie2   <span class="hljs-comment"># if not already loaded</span><br>module load samtools<br>bowtie2  --very-sensitive  -k 10  -x &lt;genomeIndexName&gt;  -1 &lt;name&gt;_1.fastq.gz  -2 &lt;name&gt;_2.fastq.gz  \<br>  |  samtools view  -u  -  \<br>  |  samtools <span class="hljs-built_in">sort</span>  -n  -o &lt;BAM&gt;  -<br></code></pre></td></tr></table></figure><p>For input files of <strong>20 million paired reads</strong>, this command takes around <strong>five hours</strong> on Cannon. This can be decreased by increasing the number of cores in the Bowtie2 command. For example, one could specify eight cores for Bowtie2 with <code>-p 8</code> and adjust the request in the SLURM script to <code>#SBATCH -n 10</code>(that is, <strong>eight cores for Bowtie2 and one each for SAMtools view and sort, simultaneously processing</strong>). The memory usage of Bowtie2 depends primarily on the genome length; enough must be requested to load the genome indexes.</p><p>Bowtie2 also provides (via <code>stderr</code>) a summary of the mapping results, separated according to uniqueness and alignment type (concordant, discordant, and non-concordant&#x2F;non-discordant). In terms of alignment interpretation, it is conceptually easier to divide alignments into two <strong>basic categories: properly paired and unpaired</strong> (Fig. 3).</p><p><img src="/GeekFocus/./1.png" alt="Alignment types"></p><p><strong>Figure 3. Alignment types for paired-end reads. A:</strong> Properly paired alignments (“concordant”) have the reads aligned in opposite orientations on the same reference sequence (chromosome). The reads may overlap to some extent (bottom).  <strong>B:</strong> A read alignment (for R1) can be unpaired for several reasons: if the read’s mate (R2) is unaligned (upper left), aligns to a different chromosome (upper right), aligns in the incorrect orientation (middle cases), or aligns in the correct orientation but at an invalid distance (bottom). In all cases except the upper left, the R2 read alignment is also unpaired, and the read pair align discordantly (though Bowtie2 also requires uniqueness for such alignments to be counted as discordant).</p><h3 id="Usage"><a href="#Usage" class="headerlink" title="Usage"></a>Usage</h3><figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs vim">bowtie2 [<span class="hljs-keyword">options</span>]* -<span class="hljs-keyword">x</span> <span class="hljs-symbol">&lt;bt2-idx&gt;</span> &#123;-<span class="hljs-number">1</span> <span class="hljs-symbol">&lt;m1&gt;</span> -<span class="hljs-number">2</span> <span class="hljs-symbol">&lt;m2&gt;</span> | -U <span class="hljs-symbol">&lt;r&gt;</span> | --interleaved <span class="hljs-symbol">&lt;i&gt;</span> | --sra-acc <span class="hljs-symbol">&lt;acc&gt;</span> | <span class="hljs-keyword">b</span> <span class="hljs-symbol">&lt;bam&gt;</span>&#125; -S [<span class="hljs-symbol">&lt;sam&gt;</span>]<br></code></pre></td></tr></table></figure><h3 id="Main-arguments"><a href="#Main-arguments" class="headerlink" title="Main arguments"></a>Main arguments</h3><table><thead><tr><th><code>-x &lt;bt2-idx&gt;</code></th><th>The basename of the index for the reference genome.</th></tr></thead><tbody><tr><td><code>-1 &lt;m1&gt;</code></td><td>Comma-separated list of files containing mate 1s (filename usually includes <code>_1</code>), e.g. <code>-1 flyA_1.fq,flyB_1.fq</code>.</td></tr><tr><td><code>-2 &lt;m2&gt;</code></td><td>Comma-separated list of files containing mate 2s (filename usually includes <code>_2</code>), e.g. <code>-2 flyA_2.fq,flyB_2.fq</code>.</td></tr><tr><td><code>-U &lt;r&gt;</code></td><td>Comma-separated list of files containing unpaired reads to be aligned, e.g. <code>lane1.fq,lane2.fq,lane3.fq,lane4.fq</code>. Reads may be a mix of different lengths. If <code>-</code> is specified, <code>bowtie2</code> gets the reads from the “standard in” or “stdin” filehandle.</td></tr><tr><td><code>--interleaved</code></td><td>Reads interleaved FASTQ files where the first two records (8 lines) represent a mate pair.</td></tr><tr><td><code>--sra-acc</code></td><td>Reads are SRA accessions.</td></tr><tr><td><code>-b &lt;bam&gt;</code></td><td>Reads are unaligned BAM records sorted by read name. The <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-align-paired-reads"><code>--align-paired-reads</code></a> and <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-preserve-tags"><code>--preserve-tags</code></a> options affect the way Bowtie 2 processes records.</td></tr><tr><td><code>-S &lt;sam&gt;</code></td><td>File to write SAM alignments to. By default, alignments are written to the “standard out” or “stdout” filehandle (i.e. the console).</td></tr></tbody></table><h3 id="Options"><a href="#Options" class="headerlink" title="Options"></a>Options</h3><h4 id="Input-options"><a href="#Input-options" class="headerlink" title="Input options"></a>Input options</h4><table><thead><tr><th><code>-q</code></th><th>Reads (specified with <code>&lt;m1&gt;</code>, <code>&lt;m2&gt;</code>, <code>&lt;s&gt;</code>) are FASTQ files. FASTQ files usually have extension <code>.fq</code> or <code>.fastq</code>. FASTQ is the default format. See also: <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-solexa-quals"><code>--solexa-quals</code></a> and <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-int-quals"><code>--int-quals</code></a>.</th></tr></thead><tbody><tr><td><code>--tab5</code></td><td>Each read or pair is on a single line. An unpaired read line is <code>[name]\t[seq]\t[qual]\n</code>. A paired-end read line is <code>[name]\t[seq1]\t[qual1]\t[seq2]\t[qual2]\n</code>. An input file can be a mix of unpaired and paired-end reads and Bowtie 2 recognizes each according to the number of fields, handling each as it should.</td></tr><tr><td><code>--tab6</code></td><td>Similar to <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-tab5"><code>--tab5</code></a> except, for paired-end reads, the second end can have a different name from the first: <code>[name1]\t[seq1]\t[qual1]\t[name2]\t[seq2]\t[qual2]\n</code></td></tr><tr><td><code>--qseq</code></td><td>Reads (specified with <code>&lt;m1&gt;</code>, <code>&lt;m2&gt;</code>, <code>&lt;s&gt;</code>) are QSEQ files. QSEQ files usually end in <code>_qseq.txt</code>. See also: <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-solexa-quals"><code>--solexa-quals</code></a> and <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-int-quals"><code>--int-quals</code></a>.</td></tr><tr><td><code>-f</code></td><td>Reads (specified with <code>&lt;m1&gt;</code>, <code>&lt;m2&gt;</code>, <code>&lt;s&gt;</code>) are <a href="https://en.wikipedia.org/wiki/FASTA"><code>FASTA</code></a> files. <a href="https://en.wikipedia.org/wiki/FASTA"><code>FASTA</code></a> files usually have extension <code>.fa</code>, <code>.fasta</code>, <code>.mfa</code>, <code>.fna</code>or similar. <a href="https://en.wikipedia.org/wiki/FASTA"><code>FASTA</code></a> files do not have a way of specifying quality values, so when <code>-f</code> is set, the result is as if <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-ignore-quals"><code>--ignore-quals</code></a> is also set.</td></tr><tr><td><code>-r</code></td><td>Reads (specified with <code>&lt;m1&gt;</code>, <code>&lt;m2&gt;</code>, <code>&lt;s&gt;</code>) are files with one input sequence per line, without any other information (no read names, no qualities). When <code>-r</code> is set, the result is as if <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-ignore-quals"><code>--ignore-quals</code></a> is also set.</td></tr><tr><td><code>-F k:&lt;int&gt;,i:&lt;int&gt;</code></td><td>Reads are substrings (k-mers) extracted from a FASTA file <code>&lt;s&gt;</code>. Specifically, for every reference sequence in FASTA file <code>&lt;s&gt;</code>, Bowtie 2 aligns the k-mers at offsets 1, 1+i, 1+2i, … until reaching the end of the reference. Each k-mer is aligned as a separate read. Quality values are set to all Is (40 on Phred scale). Each k-mer (read) is given a name like <code>&lt;sequence&gt;_&lt;offset&gt;</code>, where <code>&lt;sequence&gt;</code> is the name of the FASTA sequence it was drawn from and <code>&lt;offset&gt;</code> is its 0-based offset of origin with respect to the sequence. Only single k-mers, i.e. unpaired reads, can be aligned in this way.</td></tr><tr><td><code>-c</code></td><td>The read sequences are given on command line. I.e. <code>&lt;m1&gt;</code>, <code>&lt;m2&gt;</code> and <code>&lt;singles&gt;</code> are comma-separated lists of reads rather than lists of read files. There is no way to specify read names or qualities, so <code>-c</code> also implies <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-ignore-quals"><code>--ignore-quals</code></a>.</td></tr><tr><td><code>-s/--skip &lt;int&gt;</code></td><td><strong>Skip (i.e. do not align) the first <code>&lt;int&gt;</code> reads or pairs in the input.</strong></td></tr><tr><td><code>-u/--qupto &lt;int&gt;</code></td><td><strong>Align the first <code>&lt;int&gt;</code> reads or read pairs from the input</strong> (after the <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-s"><code>-s</code>&#x2F;<code>--skip</code></a> reads or pairs have been skipped), then stop. Default: no limit.</td></tr><tr><td><code>-5/--trim5 &lt;int&gt;</code></td><td><strong>Trim <code>&lt;int&gt;</code> bases from 5’ (left) end</strong> of each read before alignment (default: <strong>0</strong>).</td></tr><tr><td><code>-3/--trim3 &lt;int&gt;</code></td><td><strong>Trim <code>&lt;int&gt;</code> bases from 3’ (right) end</strong> of each read before alignment (default: <strong>0</strong>).</td></tr><tr><td>&#96;–trim-to [3:</td><td>5:]<int>&#96;</td></tr><tr><td><code>--phred33</code></td><td>Input qualities are ASCII chars equal to the <a href="http://en.wikipedia.org/wiki/Phred_quality_score">Phred quality</a> plus 33. This is also called the “Phred+33” encoding, which is <strong>used by the very latest Illumina pipelines.</strong></td></tr><tr><td><code>--phred64</code></td><td>Input qualities are ASCII chars equal to the <a href="http://en.wikipedia.org/wiki/Phred_quality_score">Phred quality</a> plus 64. This is also called the “Phred+64” encoding.</td></tr><tr><td><code>--solexa-quals</code></td><td>Convert input qualities from <a href="http://en.wikipedia.org/wiki/Phred_quality_score">Solexa</a> (which can be negative) to <a href="http://en.wikipedia.org/wiki/Phred_quality_score">Phred</a> (which can’t). This scheme was used in older Illumina GA Pipeline versions (prior to 1.3). <strong>Default: off.</strong></td></tr><tr><td><code>--int-quals</code></td><td>Quality values are represented in the read input file as space-separated ASCII integers, e.g., <code>40 40 30 40</code>…, rather than ASCII characters, e.g., <code>II?I</code>…. Integers are treated as being on the <a href="http://en.wikipedia.org/wiki/Phred_quality_score">Phred quality</a> scale unless <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-solexa-quals"><code>--solexa-quals</code></a> is also specified. <strong>Default: off.</strong></td></tr></tbody></table><h4 id="Preset-options-in-end-to-end-mode"><a href="#Preset-options-in-end-to-end-mode" class="headerlink" title="Preset options in --end-to-end mode"></a>Preset options in <code>--end-to-end</code> mode</h4><table><thead><tr><th><code>--very-fast</code></th><th>Same as: <code>-D 5 -R 1 -N 0 -L 22 -i S,0,2.50</code></th></tr></thead><tbody><tr><td><code>--fast</code></td><td>Same as: <code>-D 10 -R 2 -N 0 -L 22 -i S,0,2.50</code></td></tr><tr><td><code>--sensitive</code></td><td>Same as: <code>-D 15 -R 2 -N 0 -L 22 -i S,1,1.15</code> (default in <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-end-to-end"><code>--end-to-end</code></a> mode)</td></tr><tr><td><code>--very-sensitive</code></td><td>Same as: <code>-D 20 -R 3 -N 0 -L 20 -i S,1,0.50</code></td></tr></tbody></table><h4 id="Preset-options-in-local-mode"><a href="#Preset-options-in-local-mode" class="headerlink" title="Preset options in --local mode"></a>Preset options in <code>--local</code> mode</h4><table><thead><tr><th><code>--very-fast-local</code></th><th>Same as: <code>-D 5 -R 1 -N 0 -L 25 -i S,1,2.00</code></th></tr></thead><tbody><tr><td><code>--fast-local</code></td><td>Same as: <code>-D 10 -R 2 -N 0 -L 22 -i S,1,1.75</code></td></tr><tr><td><code>--sensitive-local</code></td><td>Same as: <code>-D 15 -R 2 -N 0 -L 20 -i S,1,0.75</code> (default in <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-local"><code>--local</code></a> mode)</td></tr><tr><td><code>--very-sensitive-local</code></td><td>Same as: <code>-D 20 -R 3 -N 0 -L 20 -i S,1,0.50</code></td></tr></tbody></table><h4 id="Alignment-options"><a href="#Alignment-options" class="headerlink" title="Alignment options"></a>Alignment options</h4><table><thead><tr><th><code>-N &lt;int&gt;</code></th><th>Sets the number of mismatches to allowed in a seed alignment during <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#multiseed-heuristic">multiseed alignment</a>. Can be set to 0 or 1. Setting this higher makes alignment slower (often much slower) but increases sensitivity. Default: 0.</th></tr></thead><tbody><tr><td><code>-L &lt;int&gt;</code></td><td><strong>Sets the length of the seed substrings to align</strong> during <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#multiseed-heuristic">multiseed alignment</a>. <font color="red"><strong>Smaller values make alignment slower but more sensitive</strong></font>. Default: the <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-sensitive"><code>--sensitive</code></a> preset is used by default, which sets <code>-L</code> to 22 and 20 in <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-end-to-end"><code>--end-to-end</code></a> mode and in <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-local"><code>--local</code></a> mode.</td></tr><tr><td><code>-i &lt;func&gt;</code></td><td>Sets a function governing the interval between seed substrings to use during <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#multiseed-heuristic">multiseed alignment</a>. For instance, if the read has 30 characters, and seed length is 10, and the seed interval is 6, the seeds extracted will be:<code>Read:      TAGCTACGCTCTACGCTATCATGCATAAAC Seed 1 fw: TAGCTACGCT Seed 1 rc: AGCGTAGCTA Seed 2 fw:       CGCTCTACGC Seed 2 rc:       GCGTAGAGCG Seed 3 fw:             ACGCTATCAT Seed 3 rc:             ATGATAGCGT Seed 4 fw:                   TCATGCATAA Seed 4 rc:                   TTATGCATGA</code>Since it’s best to use longer intervals for longer reads, this parameter sets the interval as a function of the read length, rather than a single one-size-fits-all number. For instance, specifying <code>-i S,1,2.5</code> sets the interval function <code>f</code> to <code>f(x) = 1 + 2.5 * sqrt(x)</code>, where x is the read length. See also: <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#setting-function-options">setting function options</a>. If the function returns a result less than 1, it is rounded up to 1. Default: the <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-sensitive"><code>--sensitive</code></a> preset is used by default, which sets <code>-i</code> to <code>S,1,1.15</code> in <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-end-to-end"><code>--end-to-end</code></a>mode to <code>-i S,1,0.75</code> in <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-local"><code>--local</code></a> mode.</td></tr><tr><td><code>--n-ceil &lt;func&gt;</code></td><td>Sets a function governing the maximum number of ambiguous characters (usually <code>N</code>s and&#x2F;or <code>.</code>s) allowed in a read as a function of read length. For instance, specifying <code>-L,0,0.15</code> sets the N-ceiling function <code>f</code> to <code>f(x) = 0 + 0.15 * x</code>, where x is the read length. See also: <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#setting-function-options">setting function options</a>. Reads exceeding this ceiling are <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#filtering">filtered out</a>. Default: <code>L,0,0.15</code>.</td></tr><tr><td><code>--dpad &lt;int&gt;</code></td><td>“Pads” dynamic programming problems by <code>&lt;int&gt;</code> columns on either side to allow gaps. Default: 15.</td></tr><tr><td><code>--gbar &lt;int&gt;</code></td><td>Disallow gaps within <code>&lt;int&gt;</code> positions of the beginning or end of the read. Default: 4.</td></tr><tr><td><code>--ignore-quals</code></td><td>When calculating a mismatch penalty, always consider the quality value at the mismatched position to be the highest possible, regardless of the actual value. I.e. input is treated as though all quality values are high. This is also the default behavior when the input doesn’t specify quality values (e.g. in <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-f"><code>-f</code></a>, <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-r"><code>-r</code></a>, or <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-c"><code>-c</code></a> modes).</td></tr><tr><td><code>--nofw/--norc</code></td><td>If <code>--nofw</code> is specified, <code>bowtie2</code> will not attempt to align unpaired reads to the forward (Watson) reference strand. If <code>--norc</code> is specified, <code>bowtie2</code> will not attempt to align unpaired reads against the reverse-complement (Crick) reference strand. In paired-end mode, <code>--nofw</code> and <code>--norc</code> pertain to the fragments; i.e. specifying <code>--nofw</code> causes <code>bowtie2</code> to explore only those paired-end configurations corresponding to fragments from the reverse-complement (Crick) strand. Default: both strands enabled.</td></tr><tr><td><code>--no-1mm-upfront</code></td><td>By default, Bowtie 2 will attempt to find either an exact or a 1-mismatch end-to-end alignment for the read <em>before</em> trying the <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#multiseed-heuristic">multiseed heuristic</a>. Such alignments can be found very quickly, and many short read alignments have exact or near-exact end-to-end alignments. However, this can lead to unexpected alignments when the user also sets options governing the <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#multiseed-heuristic">multiseed heuristic</a>, like <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-L"><code>-L</code></a> and <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-N"><code>-N</code></a>. For instance, if the user specifies <code>-N 0</code> and <code>-L</code> equal to the length of the read, the user will be surprised to find 1-mismatch alignments reported. This option prevents Bowtie 2 from searching for 1-mismatch end-to-end alignments before using the <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#multiseed-heuristic">multiseed heuristic</a>, which leads to the expected behavior when combined with options such as <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-L"><code>-L</code></a> and <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-N"><code>-N</code></a>. This comes at the expense of speed.</td></tr><tr><td><code>--end-to-end</code></td><td>In this mode, Bowtie 2 requires that the entire read align from one end to the other, without any trimming (or “soft clipping”) of characters from either end. The match bonus <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-ma"><code>--ma</code></a> always equals 0 in this mode, so all alignment scores are less than or equal to 0, and the greatest possible alignment score is 0. This is mutually exclusive with <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-local"><code>--local</code></a>. <code>--end-to-end</code> is the default mode.</td></tr><tr><td><code>--local</code></td><td>In this mode, Bowtie 2 does not require that the entire read align from one end to the other. Rather, some characters may be omitted (“soft clipped”) from the ends in order to achieve the greatest possible alignment score. The match bonus <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-ma"><code>--ma</code></a>is used in this mode, and the best possible alignment score is equal to the match bonus (<a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-ma"><code>--ma</code></a>) times the length of the read. Specifying <code>--local</code> and one of the presets (e.g. <code>--local --very-fast</code>) is equivalent to specifying the local version of the preset (<code>--very-fast-local</code>). This is mutually exclusive with <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-end-to-end"><code>--end-to-end</code></a>. <code>--end-to-end</code> is the default mode.</td></tr></tbody></table><h4 id="Scoring-options"><a href="#Scoring-options" class="headerlink" title="Scoring options"></a>Scoring options</h4><table><thead><tr><th><code>--ma &lt;int&gt;</code></th><th>Sets the match bonus. In <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-local"><code>--local</code></a> mode <code>&lt;int&gt;</code> is added to the alignment score for each position where a read character aligns to a reference character and the characters match. Not used in <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-end-to-end"><code>--end-to-end</code></a> mode. Default: 2.</th></tr></thead><tbody><tr><td><code>--mp MX,MN</code></td><td>Sets the maximum (<code>MX</code>) and minimum (<code>MN</code>) mismatch penalties, both integers. A number less than or equal to <code>MX</code> and greater than or equal to <code>MN</code> is subtracted from the alignment score for each position where a read character aligns to a reference character, the characters do not match, and neither is an <code>N</code>. If <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-ignore-quals"><code>--ignore-quals</code></a> is specified, the number subtracted quals <code>MX</code>. Otherwise, the number subtracted is <code>MN + floor( (MX-MN)(MIN(Q, 40.0)/40.0) )</code> where Q is the Phred quality value. Default: <code>MX</code> &#x3D; 6, <code>MN</code> &#x3D; 2.</td></tr><tr><td><code>--np &lt;int&gt;</code></td><td>Sets penalty for positions where the read, reference, or both, contain an ambiguous character such as <code>N</code>. Default: 1.</td></tr><tr><td><code>--rdg &lt;int1&gt;,&lt;int2&gt;</code></td><td>Sets the read gap open (<code>&lt;int1&gt;</code>) and extend (<code>&lt;int2&gt;</code>) penalties. A read gap of length N gets a penalty of <code>&lt;int1&gt;</code> + N * <code>&lt;int2&gt;</code>. Default: 5, 3.</td></tr><tr><td><code>--rfg &lt;int1&gt;,&lt;int2&gt;</code></td><td>Sets the reference gap open (<code>&lt;int1&gt;</code>) and extend (<code>&lt;int2&gt;</code>) penalties. A reference gap of length N gets a penalty of <code>&lt;int1&gt;</code> + N * <code>&lt;int2&gt;</code>. Default: 5, 3.</td></tr><tr><td><code>--score-min &lt;func&gt;</code></td><td>Sets a function governing the minimum alignment score needed for an alignment to be considered “valid” (i.e. good enough to report). This is a function of read length. For instance, specifying <code>L,0,-0.6</code> sets the minimum-score function <code>f</code> to <code>f(x) = 0 + -0.6 * x</code>, where <code>x</code> is the read length. See also: <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#setting-function-options">setting function options</a>. The default in <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-end-to-end"><code>--end-to-end</code></a>mode is <code>L,-0.6,-0.6</code> and the default in <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-local"><code>--local</code></a> mode is <code>G,20,8</code>.</td></tr></tbody></table><h4 id="Reporting-options"><a href="#Reporting-options" class="headerlink" title="Reporting options"></a>Reporting options</h4><table><thead><tr><th><code>-k &lt;int&gt;</code></th><th>By default, <code>bowtie2</code> searches for distinct, valid alignments for each read. When it finds a valid alignment, it continues looking for alignments that are nearly as good or better. The best alignment found is reported (randomly selected from among best if tied). Information about the best alignments is used to estimate mapping quality and to set SAM optional fields, such as <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-build-opt-fields-as"><code>AS:i</code></a> and <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-build-opt-fields-xs"><code>XS:i</code></a>.When <code>-k</code> is specified, however, <code>bowtie2</code> behaves differently. Instead, it searches for at most <code>&lt;int&gt;</code> distinct, valid alignments for each read. The search terminates when it can’t find more distinct valid alignments, or when it finds <code>&lt;int&gt;</code>, whichever happens first. All alignments found are reported in descending order by alignment score. The alignment score for a paired-end alignment equals the sum of the alignment scores of the individual mates. Each reported read or pair alignment beyond the first has the SAM ‘secondary’ bit (which equals 256) set in its FLAGS field. For reads that have more than <code>&lt;int&gt;</code> distinct, valid alignments, <code>bowtie2</code>does not guarantee that the <code>&lt;int&gt;</code> alignments reported are the best possible in terms of alignment score. <code>-k</code> is mutually exclusive with <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-a"><code>-a</code></a>.Note: Bowtie 2 is not designed with large values for <code>-k</code> in mind, and when aligning reads to long, repetitive genomes large <code>-k</code> can be very, very slow.</th></tr></thead><tbody><tr><td><code>-a</code></td><td>Like <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-k"><code>-k</code></a> but with no upper limit on number of alignments to search for. <code>-a</code> is mutually exclusive with <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-k"><code>-k</code></a>.Note: Bowtie 2 is not designed with <code>-a</code> mode in mind, and when aligning reads to long, repetitive genomes this mode can be very, very slow.</td></tr></tbody></table><h4 id="Effort-options"><a href="#Effort-options" class="headerlink" title="Effort options"></a>Effort options</h4><table><thead><tr><th><code>-D &lt;int&gt;</code></th><th>Up to <code>&lt;int&gt;</code> consecutive seed extension attempts can “fail” before Bowtie 2 moves on, using the alignments found so far. A seed extension “fails” if it does not yield a new best or a new second-best alignment. This limit is automatically adjusted up when -k or -a are specified. Default: 15.</th></tr></thead><tbody><tr><td><code>-R &lt;int&gt;</code></td><td><code>&lt;int&gt;</code> is the maximum number of times Bowtie 2 will “re-seed” reads with repetitive seeds. When “re-seeding,” Bowtie 2 simply chooses a new set of reads (same length, same number of mismatches allowed) at different offsets and searches for more alignments. A read is considered to have repetitive seeds if the total number of seed hits divided by the number of seeds that aligned at least once is greater than 300. Default: 2.</td></tr></tbody></table><h4 id="Paired-end-options"><a href="#Paired-end-options" class="headerlink" title="Paired-end options"></a>Paired-end options</h4><table><thead><tr><th><code>-I/--minins &lt;int&gt;</code></th><th>The minimum fragment length for valid paired-end alignments. E.g. if <code>-I 60</code> is specified and a paired-end alignment consists of two 20-bp alignments in the appropriate orientation with a 20-bp gap between them, that alignment is considered valid (as long as <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-X"><code>-X</code></a> is also satisfied). A 19-bp gap would not be valid in that case. If trimming options <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-3"><code>-3</code></a> or <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-5"><code>-5</code></a>are also used, the <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-I"><code>-I</code></a> constraint is applied with respect to the untrimmed mates.The larger the difference between <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-I"><code>-I</code></a> and <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-X"><code>-X</code></a>, the slower Bowtie 2 will run. This is because larger differences between <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-I"><code>-I</code></a>and <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-X"><code>-X</code></a> require that Bowtie 2 scan a larger window to determine if a concordant alignment exists. For typical fragment length ranges (200 to 400 nucleotides), Bowtie 2 is very efficient.Default: 0 (essentially imposing no minimum)</th></tr></thead><tbody><tr><td><code>-X/--maxins &lt;int&gt;</code></td><td>The maximum fragment length for valid paired-end alignments. E.g. if <code>-X 100</code> is specified and a paired-end alignment consists of two 20-bp alignments in the proper orientation with a 60-bp gap between them, that alignment is considered valid (as long as <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-I"><code>-I</code></a> is also satisfied). A 61-bp gap would not be valid in that case. If trimming options <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-3"><code>-3</code></a> or <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-5"><code>-5</code></a> are also used, the <code>-X</code> constraint is applied with respect to the untrimmed mates, not the trimmed mates.The larger the difference between <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-I"><code>-I</code></a> and <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-X"><code>-X</code></a>, the slower Bowtie 2 will run. This is because larger differences between <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-I"><code>-I</code></a>and <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-X"><code>-X</code></a> require that Bowtie 2 scan a larger window to determine if a concordant alignment exists. For typical fragment length ranges (200 to 400 nucleotides), Bowtie 2 is very efficient.Default: 500.</td></tr><tr><td><code>--fr/--rf/--ff</code></td><td>The upstream&#x2F;downstream mate orientations for a valid paired-end alignment against the forward reference strand. E.g., if <code>--fr</code> is specified and there is a candidate paired-end alignment where mate 1 appears upstream of the reverse complement of mate 2 and the fragment length constraints (<a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-I"><code>-I</code></a> and <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-X"><code>-X</code></a>) are met, that alignment is valid. Also, if mate 2 appears upstream of the reverse complement of mate 1 and all other constraints are met, that too is valid. <code>--rf</code> likewise requires that an upstream mate1 be reverse-complemented and a downstream mate2 be forward-oriented. <code>--ff</code> requires both an upstream mate 1 and a downstream mate 2 to be forward-oriented. Default: <code>--fr</code> (appropriate for Illumina’s Paired-end Sequencing Assay).</td></tr><tr><td><code>--no-mixed</code></td><td>By default, when <code>bowtie2</code> cannot find a concordant or discordant alignment for a pair, it then tries to find alignments for the individual mates. This option disables that behavior.</td></tr><tr><td><code>--no-discordant</code></td><td>By default, <code>bowtie2</code> looks for discordant alignments if it cannot find any concordant alignments. A discordant alignment is an alignment where both mates align uniquely, but that does not satisfy the paired-end constraints (<a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-fr"><code>--fr</code>&#x2F;<code>--rf</code>&#x2F;<code>--ff</code></a>, <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-I"><code>-I</code></a>, <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-X"><code>-X</code></a>). This option disables that behavior.</td></tr><tr><td><code>--dovetail</code></td><td>If the mates “dovetail”, that is if one mate alignment extends past the beginning of the other such that the wrong mate begins upstream, consider that to be concordant. See also: <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#mates-can-overlap-contain-or-dovetail-each-other">Mates can overlap, contain or dovetail each other</a>. Default: mates cannot dovetail in a concordant alignment.</td></tr><tr><td><code>--no-contain</code></td><td>If one mate alignment contains the other, consider that to be non-concordant. See also: <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#mates-can-overlap-contain-or-dovetail-each-other">Mates can overlap, contain or dovetail each other</a>. Default: a mate can contain the other in a concordant alignment.</td></tr><tr><td><code>--no-overlap</code></td><td>If one mate alignment overlaps the other at all, consider that to be non-concordant. See also: <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#mates-can-overlap-contain-or-dovetail-each-other">Mates can overlap, contain or dovetail each other</a>. Default: mates can overlap in a concordant alignment.</td></tr></tbody></table><h4 id="BAM-options"><a href="#BAM-options" class="headerlink" title="BAM options"></a>BAM options</h4><table><thead><tr><th><code>--align-paired-reads</code></th><th>Bowtie 2 will, by default, attempt to align unpaired BAM reads. Use this option to align paired-end reads instead.</th></tr></thead><tbody><tr><td><code>--preserve-tags</code></td><td>Preserve tags from the original BAM record by appending them to the end of the corresponding Bowtie 2 SAM output.</td></tr></tbody></table><h4 id="Output-options"><a href="#Output-options" class="headerlink" title="Output options"></a>Output options</h4><table><thead><tr><th><code>-t/--time</code></th><th>Print the wall-clock time required to load the index files and align the reads. This is printed to the “standard error” (“stderr”) filehandle. Default: off.</th></tr></thead><tbody><tr><td><code>--un &lt;path&gt; --un-gz &lt;path&gt; --un-bz2 &lt;path&gt; --un-lz4 &lt;path&gt;</code></td><td>Write unpaired reads that fail to align to file at <code>&lt;path&gt;</code>. These reads correspond to the SAM records with the FLAGS <code>0x4</code> bit set and neither the <code>0x40</code> nor <code>0x80</code> bits set. If <code>--un-gz</code> is specified, output will be gzip compressed. If <code>--un-bz2</code>or <code>--un-lz4</code> is specified, output will be bzip2 or lz4 compressed. Reads written in this way will appear exactly as they did in the input file, without any modification (same sequence, same name, same quality string, same quality encoding). Reads will not necessarily appear in the same order as they did in the input.</td></tr><tr><td><code>--al &lt;path&gt; --al-gz &lt;path&gt; --al-bz2 &lt;path&gt; --al-lz4 &lt;path&gt;</code></td><td>Write unpaired reads that align at least once to file at <code>&lt;path&gt;</code>. These reads correspond to the SAM records with the FLAGS <code>0x4</code>, <code>0x40</code>, and <code>0x80</code> bits unset. If <code>--al-gz</code> is specified, output will be gzip compressed. If <code>--al-bz2</code> is specified, output will be bzip2 compressed. Similarly if <code>--al-lz4</code> is specified, output will be lz4 compressed. Reads written in this way will appear exactly as they did in the input file, without any modification (same sequence, same name, same quality string, same quality encoding). Reads will not necessarily appear in the same order as they did in the input.</td></tr><tr><td><code>--un-conc &lt;path&gt; --un-conc-gz &lt;path&gt; --un-conc-bz2 &lt;path&gt; --un-conc-lz4 &lt;path&gt;</code></td><td>Write paired-end reads that fail to align concordantly to file(s) at <code>&lt;path&gt;</code>. These reads correspond to the SAM records with the FLAGS <code>0x4</code> bit set and either the <code>0x40</code> or <code>0x80</code> bit set (depending on whether it’s mate #1 or #2). <code>.1</code> and <code>.2</code>strings are added to the filename to distinguish which file contains mate #1 and mate #2. If a percent symbol, <code>%</code>, is used in <code>&lt;path&gt;</code>, the percent symbol is replaced with <code>1</code> or <code>2</code> to make the per-mate filenames. Otherwise, <code>.1</code> or <code>.2</code> are added before the final dot in <code>&lt;path&gt;</code> to make the per-mate filenames. Reads written in this way will appear exactly as they did in the input files, without any modification (same sequence, same name, same quality string, same quality encoding). Reads will not necessarily appear in the same order as they did in the inputs.</td></tr><tr><td><code>--al-conc &lt;path&gt; --al-conc-gz &lt;path&gt; --al-conc-bz2 &lt;path&gt; --al-conc-lz4 &lt;path&gt;</code></td><td>Write paired-end reads that align concordantly at least once to file(s) at <code>&lt;path&gt;</code>. These reads correspond to the SAM records with the FLAGS <code>0x4</code> bit unset and either the <code>0x40</code> or <code>0x80</code> bit set (depending on whether it’s mate #1 or #2). <code>.1</code> and <code>.2</code> strings are added to the filename to distinguish which file contains mate #1 and mate #2. If a percent symbol, <code>%</code>, is used in <code>&lt;path&gt;</code>, the percent symbol is replaced with <code>1</code> or <code>2</code> to make the per-mate filenames. Otherwise, <code>.1</code> or <code>.2</code> are added before the final dot in <code>&lt;path&gt;</code> to make the per-mate filenames. Reads written in this way will appear exactly as they did in the input files, without any modification (same sequence, same name, same quality string, same quality encoding). Reads will not necessarily appear in the same order as they did in the inputs.</td></tr><tr><td><code>--quiet</code></td><td>Print nothing besides alignments and serious errors.</td></tr><tr><td><code>--met-file &lt;path&gt;</code></td><td>Write <code>bowtie2</code> metrics to file <code>&lt;path&gt;</code>. Having alignment metric can be useful for debugging certain problems, especially performance issues. See also: <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-met"><code>--met</code></a>. Default: metrics disabled.</td></tr><tr><td><code>--met-stderr &lt;path&gt;</code></td><td>Write <code>bowtie2</code> metrics to the “standard error” (“stderr”) filehandle. This is not mutually exclusive with <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-met-file"><code>--met-file</code></a>. Having alignment metric can be useful for debugging certain problems, especially performance issues. See also: <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-met"><code>--met</code></a>. Default: metrics disabled.</td></tr><tr><td><code>--met &lt;int&gt;</code></td><td>Write a new <code>bowtie2</code> metrics record every <code>&lt;int&gt;</code> seconds. Only matters if either <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-met-stderr"><code>--met-stderr</code></a> or <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-met-file"><code>--met-file</code></a> are specified. Default: 1.</td></tr></tbody></table><h4 id="SAM-options"><a href="#SAM-options" class="headerlink" title="SAM options"></a>SAM options</h4><table><thead><tr><th><code>--no-unal</code></th><th>Suppress SAM records for reads that failed to align.</th></tr></thead><tbody><tr><td><code>--no-hd</code></td><td>Suppress SAM header lines (starting with <code>@</code>).</td></tr><tr><td><code>--no-sq</code></td><td>Suppress <code>@SQ</code> SAM header lines.</td></tr><tr><td><code>--rg-id &lt;text&gt;</code></td><td>Set the read group ID to <code>&lt;text&gt;</code>. This causes the SAM <code>@RG</code> header line to be printed, with <code>&lt;text&gt;</code> as the value associated with the <code>ID:</code> tag. It also causes the <code>RG:Z:</code> extra field to be attached to each SAM output record, with value set to <code>&lt;text&gt;</code>.</td></tr><tr><td><code>--rg &lt;text&gt;</code></td><td>Add <code>&lt;text&gt;</code> (usually of the form <code>TAG:VAL</code>, e.g. <code>SM:Pool1</code>) as a field on the <code>@RG</code> header line. Note: in order for the <code>@RG</code> line to appear, <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-rg-id"><code>--rg-id</code></a> must also be specified. This is because the <code>ID</code> tag is required by the <a href="http://samtools.sourceforge.net/SAM1.pdf">SAM Spec</a>. Specify <code>--rg</code> multiple times to set multiple fields. See the <a href="http://samtools.sourceforge.net/SAM1.pdf">SAM Spec</a> for details about what fields are legal.</td></tr><tr><td><code>--omit-sec-seq</code></td><td>When printing secondary alignments, Bowtie 2 by default will write out the <code>SEQ</code> and <code>QUAL</code> strings. Specifying this option causes Bowtie 2 to print an asterisk in those fields instead.</td></tr><tr><td><code>--soft-clipped-unmapped-tlen</code></td><td>Consider soft-clipped bases unmapped when calculating <code>TLEN</code>. Only available in <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-local"><code>--local</code></a> mode.</td></tr><tr><td><code>--sam-no-qname-trunc</code></td><td>Suppress standard behavior of truncating readname at first whitespace at the expense of generating non-standard SAM</td></tr><tr><td><code>--xeq</code></td><td>Use <code>&#39;=&#39;/&#39;X&#39;</code>, instead of <code>&#39;M&#39;</code>, to specify matches&#x2F;mismatches in SAM record</td></tr><tr><td><code>--sam-append-comment</code></td><td>Append FASTA&#x2F;FASTQ comment to SAM record, where a comment is everything after the first space in the read name.</td></tr></tbody></table><h4 id="Performance-options"><a href="#Performance-options" class="headerlink" title="Performance options"></a>Performance options</h4><table><thead><tr><th><code>-o/--offrate &lt;int&gt;</code></th><th>Override the offrate of the index with <code>&lt;int&gt;</code>. If <code>&lt;int&gt;</code> is greater than the offrate used to build the index, then some row markings are discarded when the index is read into memory. This reduces the memory footprint of the aligner but requires more time to calculate text offsets. <code>&lt;int&gt;</code> must be greater than the value used to build the index.</th></tr></thead><tbody><tr><td><code>-p/--threads NTHREADS</code></td><td>Launch <code>NTHREADS</code> parallel search threads (default: 1). Threads will run on separate processors&#x2F;cores and synchronize when parsing reads and outputting alignments. Searching for alignments is highly parallel, and speedup is close to linear. Increasing <code>-p</code> increases Bowtie 2’s memory footprint. E.g. when aligning to a human genome index, increasing <code>-p</code> from 1 to 8 increases the memory footprint by a few hundred megabytes. This option is only available if <code>bowtie</code> is linked with the <code>pthreads</code> library (i.e. if <code>BOWTIE_PTHREADS=0</code> is not specified at build time).</td></tr><tr><td><code>--reorder</code></td><td>Guarantees that output SAM records are printed in an order corresponding to the order of the reads in the original input file, even when <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-p"><code>-p</code></a> is set greater than 1. Specifying <code>--reorder</code> and setting <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-p"><code>-p</code></a> greater than 1 causes Bowtie 2 to run somewhat slower and use somewhat more memory than if <code>--reorder</code> were not specified. Has no effect if <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-p"><code>-p</code></a> is set to 1, since output order will naturally correspond to input order in that case.</td></tr><tr><td><code>--mm</code></td><td>Use memory-mapped I&#x2F;O to load the index, rather than typical file I&#x2F;O. Memory-mapping allows many concurrent <code>bowtie</code> processes on the same computer to share the same memory image of the index (i.e. you pay the memory overhead just once). This facilitates memory-efficient parallelization of <code>bowtie</code> in situations where using <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-p"><code>-p</code></a> is not possible or not preferable.</td></tr></tbody></table><h4 id="Other-options"><a href="#Other-options" class="headerlink" title="Other options"></a>Other options</h4><table><thead><tr><th><code>--qc-filter</code></th><th>Filter out reads for which the QSEQ filter field is non-zero. Only has an effect when read format is <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-qseq"><code>--qseq</code></a>. Default: off.</th></tr></thead><tbody><tr><td><code>--seed &lt;int&gt;</code></td><td>Use <code>&lt;int&gt;</code> as the seed for pseudo-random number generator. Default: 0.</td></tr><tr><td><code>--non-deterministic</code></td><td>Normally, Bowtie 2 re-initializes its pseudo-random generator for each read. It seeds the generator with a number derived from (a) the read name, (b) the nucleotide sequence, (c) the quality sequence, (d) the value of the <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-seed"><code>--seed</code></a>option. This means that if two reads are identical (same name, same nucleotides, same qualities) Bowtie 2 will find and report the same alignment(s) for both, even if there was ambiguity. When <code>--non-deterministic</code> is specified, Bowtie 2 re-initializes its pseudo-random generator for each read using the current time. This means that Bowtie 2 will not necessarily report the same alignment for two identical reads. This is counter-intuitive for some users, but might be more appropriate in situations where the input consists of many identical reads.</td></tr><tr><td><code>--version</code></td><td>Print version information and quit.</td></tr><tr><td><code>-h/--help</code></td><td>Print usage information and quit.</td></tr></tbody></table><h2 id="SAM-output"><a href="#SAM-output" class="headerlink" title="SAM output"></a>SAM output</h2><p>Following is a brief description of the <a href="http://samtools.sourceforge.net/SAM1.pdf">SAM</a> format as output by <code>bowtie2</code>. For more details, see the <a href="http://samtools.sourceforge.net/SAM1.pdf">SAM format specification</a>.</p><p>By default, <code>bowtie2</code> prints a SAM header with <code>@HD</code>, <code>@SQ</code> and <code>@PG</code> lines. When one or more <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-rg"><code>--rg</code></a> arguments are specified, <code>bowtie2</code> will also print an <code>@RG</code> line that includes all user-specified <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-rg"><code>--rg</code></a> tokens separated by tabs.</p><p>Each subsequent line describes an alignment or, if the read failed to align, a read. Each line is a collection of at least 12 fields separated by tabs; from left to right, the fields are:</p><ol><li><p>Name of read that aligned.</p><p>Note that the <a href="http://samtools.sourceforge.net/SAM1.pdf">SAM specification</a> disallows whitespace in the read name. If the read name contains any whitespace characters, Bowtie 2 will truncate the name at the first whitespace character. This is similar to the behavior of other tools. The standard behavior of truncating at the first whitespace can be suppressed with <code>--sam-no-qname-trunc</code> at the expense of generating non-standard SAM.</p></li><li><p><font color="red">Sum of all applicable flags. Flags relevant to Bowtie are:</font></p><table><thead><tr><th><code>1</code></th><th>The read is one of a pair</th></tr></thead><tbody><tr><td><code>2</code></td><td>The alignment is one end of a proper paired-end alignment</td></tr><tr><td><code>4</code></td><td>The read has no reported alignments</td></tr><tr><td><code>8</code></td><td>The read is one of a pair and has no reported alignments</td></tr><tr><td><code>16</code></td><td>The alignment is to the reverse reference strand</td></tr><tr><td><code>32</code></td><td>The other mate in the paired-end alignment is aligned to the reverse reference strand</td></tr><tr><td><code>64</code></td><td>The read is mate 1 in a pair</td></tr><tr><td><code>128</code></td><td>The read is mate 2 in a pair</td></tr></tbody></table><p>Thus, an unpaired read that aligns to the reverse reference strand will have flag 16. A paired-end read that aligns and is the first mate in the pair will have flag 83 (&#x3D; 64 + 16 + 2 + 1).</p></li><li><p>Name of reference sequence where alignment occurs</p></li><li><p>1-based offset into the forward reference strand where leftmost character of the alignment occurs</p></li><li><p>Mapping quality</p></li><li><p>CIGAR string representation of alignment</p></li><li><p>Name of reference sequence where mate’s alignment occurs. Set to <code>=</code> if the mate’s reference sequence is the same as this alignment’s, or <code>*</code>if there is no mate.</p></li><li><p>1-based offset into the forward reference strand where leftmost character of the mate’s alignment occurs. Offset is 0 if there is no mate.</p></li><li><p>Inferred fragment length. Size is negative if the mate’s alignment occurs upstream of this alignment. Size is 0 if the mates did not align concordantly. However, size is non-0 if the mates aligned discordantly to the same chromosome.</p></li><li><p>Read sequence (reverse-complemented if aligned to the reverse strand)</p></li><li><p>ASCII-encoded read qualities (reverse-complemented if the read aligned to the reverse strand). The encoded quality values are on the <a href="http://en.wikipedia.org/wiki/Phred_quality_score">Phred quality</a> scale and the encoding is ASCII-offset by 33 (ASCII char <code>!</code>), similarly to a <a href="http://en.wikipedia.org/wiki/FASTQ_format">FASTQ</a> file.</p></li><li><p>Optional fields. Fields are tab-separated. <code>bowtie2</code> outputs zero or more of these optional fields for each alignment, depending on the type of the alignment:</p></li></ol><table><thead><tr><th><code>AS:i:&lt;N&gt;</code></th><th>Alignment score. Can be negative. Can be greater than 0 in <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-local"><code>--local</code></a> mode (but not in <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-end-to-end"><code>--end-to-end</code></a> mode). Only present if SAM record is for an aligned read.</th></tr></thead><tbody><tr><td><code>XS:i:&lt;N&gt;</code></td><td>Alignment score for the best-scoring alignment found other than the alignment reported. Can be negative. Can be greater than 0 in <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-local"><code>--local</code></a> mode (but not in <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-end-to-end"><code>--end-to-end</code></a> mode). Only present if the SAM record is for an aligned read and more than one alignment was found for the read. Note that, when the read is part of a concordantly-aligned pair, this score could be greater than <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-build-opt-fields-as"><code>AS:i</code></a>.</td></tr><tr><td><code>YS:i:&lt;N&gt;</code></td><td>Alignment score for opposite mate in the paired-end alignment. Only present if the SAM record is for a read that aligned as part of a paired-end alignment.</td></tr><tr><td><code>XN:i:&lt;N&gt;</code></td><td>The number of ambiguous bases in the reference covering this alignment. Only present if SAM record is for an aligned read.</td></tr><tr><td><code>XM:i:&lt;N&gt;</code></td><td>The number of mismatches in the alignment. Only present if SAM record is for an aligned read.</td></tr><tr><td><code>XO:i:&lt;N&gt;</code></td><td>The number of gap opens, for both read and reference gaps, in the alignment. Only present if SAM record is for an aligned read.</td></tr><tr><td><code>XG:i:&lt;N&gt;</code></td><td>The number of gap extensions, for both read and reference gaps, in the alignment. Only present if SAM record is for an aligned read.</td></tr><tr><td><code>NM:i:&lt;N&gt;</code></td><td>The edit distance; that is, the minimal number of one-nucleotide edits (substitutions, insertions and deletions) needed to transform the read string into the reference string. Only present if SAM record is for an aligned read.</td></tr><tr><td><code>YF:Z:&lt;S&gt;</code></td><td>String indicating reason why the read was filtered out. See also: <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#filtering">Filtering</a>. Only appears for reads that were filtered out.</td></tr><tr><td><code>YT:Z:&lt;S&gt;</code></td><td>Value of <code>UU</code> indicates the read was not part of a pair. Value of <code>CP</code> indicates the read was part of a pair and the pair aligned concordantly. Value of <code>DP</code> indicates the read was part of a pair and the pair aligned discordantly. Value of <code>UP</code> indicates the read was part of a pair but the pair failed to aligned either concordantly or discordantly.</td></tr><tr><td><code>MD:Z:&lt;S&gt;</code></td><td>A string representation of the mismatched reference bases in the alignment. See <a href="https://samtools.github.io/hts-specs/SAMtags.pdf">SAM Tags format specification</a> for details. Only present if SAM record is for an aligned read.</td></tr></tbody></table><h1 id="The-bowtie2-build-indexer"><a href="#The-bowtie2-build-indexer" class="headerlink" title="The bowtie2-build indexer"></a>The <code>bowtie2-build</code> indexer</h1><p><code>bowtie2-build</code> builds a Bowtie index from a set of DNA sequences. <code>bowtie2-build</code> outputs a set of 6 files with suffixes <code>.1.bt2</code>, <code>.2.bt2</code>, <code>.3.bt2</code>, <code>.4.bt2</code>, <code>.rev.1.bt2</code>, and <code>.rev.2.bt2</code>. In the case of a large index these suffixes will have a <code>bt2l</code> termination. These files together constitute the index: they are all that is needed to align reads to that reference. The original sequence <a href="https://en.wikipedia.org/wiki/FASTA"><code>FASTA</code></a> files are no longer used by Bowtie 2 once the index is built.</p><p>Bowtie 2’s <code>.bt2</code> index format is different from Bowtie 1’s <code>.ebwt</code> format, and they are not compatible with each other.</p><p>Use of Karkkainen’s <a href="http://portal.acm.org/citation.cfm?id=1314852">blockwise algorithm</a> allows <code>bowtie2-build</code> to trade off between running time and memory usage. <code>bowtie2-build</code> has three options governing how it makes this trade: <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-build-options-p"><code>-p</code>&#x2F;<code>--packed</code></a>, <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-build-options-bmax"><code>--bmax</code></a>&#x2F;<a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-build-options-bmaxdivn"><code>--bmaxdivn</code></a>, and <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-build-options-dcv"><code>--dcv</code></a>. By default, <code>bowtie2-build</code> will automatically search for the settings that yield the best running time without exhausting memory. This behavior can be disabled using the <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-build-options-a"><code>-a</code>&#x2F;<code>--noauto</code></a> option.</p><p>The indexer provides options pertaining to the “shape” of the index, e.g. <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-build-options-o"><code>--offrate</code></a> governs the fraction of <a href="http://en.wikipedia.org/wiki/Burrows-Wheeler_transform">Burrows-Wheeler</a> rows that are “marked” (i.e., the density of the suffix-array sample; see the original <a href="http://portal.acm.org/citation.cfm?id=796543">FM Index</a> paper for details). All of these options are potentially profitable trade-offs depending on the application. They have been set to defaults that are reasonable for most cases according to our experiments. See <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#performance-tuning">Performance tuning</a> for details.</p><p><code>bowtie2-build</code> can generate either <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#small-and-large-indexes">small or large indexes</a>. The wrapper will decide which based on the length of the input genome. If the reference does not exceed 4 billion characters but a large index is preferred, the user can specify <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-build-options-large-index"><code>--large-index</code></a> to force <code>bowtie2-build</code> to build a large index instead.</p><p>The Bowtie 2 index is based on the <a href="http://portal.acm.org/citation.cfm?id=796543">FM Index</a> of Ferragina and Manzini, which in turn is based on the <a href="http://en.wikipedia.org/wiki/Burrows-Wheeler_transform">Burrows-Wheeler</a> transform. The algorithm used to build the index is based on the <a href="http://portal.acm.org/citation.cfm?id=1314852">blockwise algorithm</a> of Karkkainen.</p><h2 id="Command-Line-1"><a href="#Command-Line-1" class="headerlink" title="Command Line"></a>Command Line</h2><p>Usage:</p><figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs vim">bowtie2-build [<span class="hljs-keyword">options</span>]* <span class="hljs-symbol">&lt;reference_in&gt;</span> <span class="hljs-symbol">&lt;bt2_base&gt;</span><br></code></pre></td></tr></table></figure><h3 id="Main-arguments-1"><a href="#Main-arguments-1" class="headerlink" title="Main arguments"></a>Main arguments</h3><table><thead><tr><th><code>&lt;reference_in&gt;</code></th><th>A comma-separated list of <a href="https://en.wikipedia.org/wiki/FASTA"><code>FASTA</code></a> files containing the reference sequences to be aligned to, or, if <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-build-options-c"><code>-c</code></a> is specified, the sequences themselves. E.g., <code>&lt;reference_in&gt;</code> might be <code>chr1.fa,chr2.fa,chrX.fa,chrY.fa</code>, or, if <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-build-options-c"><code>-c</code></a> is specified, this might be <code>GGTCATCCT,ACGGGTCGT,CCGTTCTATGCGGCTTA</code>.</th></tr></thead><tbody><tr><td><code>&lt;bt2_base&gt;</code></td><td>The basename of the index files to write. By default, <code>bowtie2-build</code> writes files named <code>NAME.1.bt2</code>, <code>NAME.2.bt2</code>, <code>NAME.3.bt2</code>, <code>NAME.4.bt2</code>, <code>NAME.rev.1.bt2</code>, and <code>NAME.rev.2.bt2</code>, where <code>NAME</code> is <code>&lt;bt2_base&gt;</code>.</td></tr></tbody></table><h3 id="Options-1"><a href="#Options-1" class="headerlink" title="Options"></a>Options</h3><table><thead><tr><th><code>-f</code></th><th>The reference input files (specified as <code>&lt;reference_in&gt;</code>) are <a href="https://en.wikipedia.org/wiki/FASTA"><code>FASTA</code></a> files (usually having extension <code>.fa</code>, <code>.mfa</code>, <code>.fna</code> or similar).</th></tr></thead><tbody><tr><td><code>-c</code></td><td>The reference sequences are given on the command line. I.e. <code>&lt;reference_in&gt;</code> is a comma-separated list of sequences rather than a list of <a href="https://en.wikipedia.org/wiki/FASTA"><code>FASTA</code></a> files.</td></tr><tr><td><code>--large-index</code></td><td>Force <code>bowtie2-build</code> to build a <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#small-and-large-indexes">large index</a>, even if the reference is less than ~ 4 billion nucleotides inlong.</td></tr><tr><td><code>-a/--noauto</code></td><td>Disable the default behavior whereby <code>bowtie2-build</code> automatically selects values for the <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-build-options-bmax"><code>--bmax</code></a>, <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-build-options-dcv"><code>--dcv</code></a> and <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-build-options-p"><code>--packed</code></a> parameters according to available memory. Instead, user may specify values for those parameters. If memory is exhausted during indexing, an error message will be printed; it is up to the user to try new parameters.</td></tr><tr><td><code>-p/--packed</code></td><td>Use a packed (2-bits-per-nucleotide) representation for DNA strings. This saves memory but makes indexing 2-3 times slower. Default: off. This is configured automatically by default; use <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-build-options-a"><code>-a</code>&#x2F;<code>--noauto</code></a> to configure manually.</td></tr><tr><td><code>--bmax &lt;int&gt;</code></td><td>The maximum number of suffixes allowed in a block. Allowing more suffixes per block makes indexing faster, but increases peak memory usage. Setting this option overrides any previous setting for <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-build-options-bmax"><code>--bmax</code></a>, or <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-build-options-bmaxdivn"><code>--bmaxdivn</code></a>. Default (in terms of the <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-build-options-bmaxdivn"><code>--bmaxdivn</code></a> parameter) is <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-build-options-bmaxdivn"><code>--bmaxdivn</code></a> 4 * number of threads. This is configured automatically by default; use <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-build-options-a"><code>-a</code>&#x2F;<code>--noauto</code></a> to configure manually.</td></tr><tr><td><code>--bmaxdivn &lt;int&gt;</code></td><td>The maximum number of suffixes allowed in a block, expressed as a fraction of the length of the reference. Setting this option overrides any previous setting for <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-build-options-bmax"><code>--bmax</code></a>, or <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-build-options-bmaxdivn"><code>--bmaxdivn</code></a>. Default: <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-build-options-bmaxdivn"><code>--bmaxdivn</code></a> 4 * number of threads. This is configured automatically by default; use <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-build-options-a"><code>-a</code>&#x2F;<code>--noauto</code></a> to configure manually.</td></tr><tr><td><code>--dcv &lt;int&gt;</code></td><td>Use <code>&lt;int&gt;</code> as the period for the difference-cover sample. A larger period yields less memory overhead, but may make suffix sorting slower, especially if repeats are present. Must be a power of 2 no greater than 4096. Default: 1024. This is configured automatically by default; use <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-build-options-a"><code>-a</code>&#x2F;<code>--noauto</code></a> to configure manually.</td></tr><tr><td><code>--nodc</code></td><td>Disable use of the difference-cover sample. Suffix sorting becomes quadratic-time in the worst case (where the worst case is an extremely repetitive reference). Default: off.</td></tr><tr><td><code>-r/--noref</code></td><td>Do not build the <code>NAME.3.bt2</code> and <code>NAME.4.bt2</code> portions of the index, which contain a bitpacked version of the reference sequences and are used for paired-end alignment.</td></tr><tr><td><code>-3/--justref</code></td><td>Build only the <code>NAME.3.bt2</code> and <code>NAME.4.bt2</code> portions of the index, which contain a bitpacked version of the reference sequences and are used for paired-end alignment.</td></tr><tr><td><code>-o/--offrate &lt;int&gt;</code></td><td>To map alignments back to positions on the reference sequences, it’s necessary to annotate (“mark”) some or all of the <a href="http://en.wikipedia.org/wiki/Burrows-Wheeler_transform">Burrows-Wheeler</a> rows with their corresponding location on the genome. <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-build-options-o"><code>-o</code>&#x2F;<code>--offrate</code></a> governs how many rows get marked: the indexer will mark every 2^<code>&lt;int&gt;</code> rows. Marking more rows makes reference-position lookups faster, but requires more memory to hold the annotations at runtime. The default is 5 (every 32nd row is marked; for human genome, annotations occupy about 340 megabytes).</td></tr><tr><td><code>-t/--ftabchars &lt;int&gt;</code></td><td>The ftab is the lookup table used to calculate an initial <a href="http://en.wikipedia.org/wiki/Burrows-Wheeler_transform">Burrows-Wheeler</a> range with respect to the first <code>&lt;int&gt;</code>characters of the query. A larger <code>&lt;int&gt;</code> yields a larger lookup table but faster query times. The ftab has size 4^(<code>&lt;int&gt;</code>+1) bytes. The default setting is 10 (ftab is 4MB).</td></tr><tr><td><code>--seed &lt;int&gt;</code></td><td>Use <code>&lt;int&gt;</code> as the seed for pseudo-random number generator.</td></tr><tr><td><code>--cutoff &lt;int&gt;</code></td><td>Index only the first <code>&lt;int&gt;</code> bases of the reference sequences (cumulative across sequences) and ignore the rest.</td></tr><tr><td><code>-q/--quiet</code></td><td><code>bowtie2-build</code> is verbose by default. With this option <code>bowtie2-build</code> will print only error messages.</td></tr><tr><td><code>--threads &lt;int&gt;</code></td><td>By default <code>bowtie2-build</code> is using only one thread. Increasing the number of threads will speed up the index building considerably in most cases.</td></tr><tr><td><code>-h/--help</code></td><td>Print usage information and quit.</td></tr><tr><td><code>--version</code></td><td>Print version information and quit.</td></tr></tbody></table><h1 id="The-bowtie2-inspect-index-inspector"><a href="#The-bowtie2-inspect-index-inspector" class="headerlink" title="The bowtie2-inspect index inspector"></a>The <code>bowtie2-inspect</code> index inspector</h1><p><code>bowtie2-inspect</code> extracts information from a Bowtie index about what kind of index it is and what reference sequences were used to build it. When run without any options, the tool will output a <a href="https://en.wikipedia.org/wiki/FASTA"><code>FASTA</code></a> file containing the sequences of the original references (with all non-<code>A</code>&#x2F;<code>C</code>&#x2F;<code>G</code>&#x2F;<code>T</code> characters converted to <code>N</code>s). It can also be used to extract just the reference sequence names using the <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-inspect-options-n"><code>-n</code>&#x2F;<code>--names</code></a> option or a more verbose summary using the <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-inspect-options-s"><code>-s</code>&#x2F;<code>--summary</code></a> option.</p><h2 id="Command-Line-2"><a href="#Command-Line-2" class="headerlink" title="Command Line"></a>Command Line</h2><p>Usage:</p><figure class="highlight gradle"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs gradle">bowtie2-<span class="hljs-keyword">inspect</span> [<span class="hljs-keyword">options</span>]* &lt;bt2_base&gt;<br></code></pre></td></tr></table></figure><h3 id="Main-arguments-2"><a href="#Main-arguments-2" class="headerlink" title="Main arguments"></a>Main arguments</h3><table><thead><tr><th><code>&lt;bt2_base&gt;</code></th><th>The basename of the index to be inspected. The basename is name of any of the index files but with the <code>.X.bt2</code> or <code>.rev.X.bt2</code>suffix omitted. <code>bowtie2-inspect</code> first looks in the current directory for the index files, then in the directory specified in the <code>BOWTIE2_INDEXES</code> environment variable.</th></tr></thead><tbody><tr><td></td><td></td></tr></tbody></table><h3 id="Options-2"><a href="#Options-2" class="headerlink" title="Options"></a>Options</h3><table><thead><tr><th><code>-a/--across &lt;int&gt;</code></th><th>When printing <a href="https://en.wikipedia.org/wiki/FASTA"><code>FASTA</code></a> output, output a newline character every <code>&lt;int&gt;</code> bases (default: 60).</th></tr></thead><tbody><tr><td><code>-n/--names</code></td><td>Print reference sequence names, one per line, and quit.</td></tr><tr><td><code>-s/--summary</code></td><td>Print a summary that includes information about index settings, as well as the names and lengths of the input sequences. The summary has this format:<code>Colorspace  &lt;0 or 1&gt; SA-Sample   1 in &lt;sample&gt; FTab-Chars  &lt;chars&gt; Sequence-1  &lt;name&gt;  &lt;len&gt; Sequence-2  &lt;name&gt;  &lt;len&gt; ... Sequence-N  &lt;name&gt;  &lt;len&gt;</code>Fields are separated by tabs. Colorspace is always set to 0 for Bowtie 2.</td></tr><tr><td><code>-o/--output &lt;filename&gt;</code></td><td>Save output to user-specified filename (default: stdout)</td></tr><tr><td><code>-v/--verbose</code></td><td>Print verbose output (for debugging).</td></tr><tr><td><code>--version</code></td><td>Print version information and quit.</td></tr><tr><td><code>-h/--help</code></td><td>Print usage information and quit.</td></tr></tbody></table><h1 id="Getting-started-with-Bowtie-2-Lambda-phage-example"><a href="#Getting-started-with-Bowtie-2-Lambda-phage-example" class="headerlink" title="Getting started with Bowtie 2: Lambda phage example"></a>Getting started with Bowtie 2: Lambda phage example</h1><p>Bowtie 2 comes with some example files to get you started. The example files are not scientifically significant; we use the <a href="http://en.wikipedia.org/wiki/Lambda_phage">Lambda phage</a> reference genome simply because it’s short, and the reads were generated by a computer program, not a sequencer. However, these files will let you start running Bowtie 2 and downstream tools right away.</p><p>First follow the manual instructions to <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#obtaining-bowtie-2">obtain Bowtie 2</a>. Set the <code>BT2_HOME</code> environment variable to point to the new Bowtie 2 directory containing the <code>bowtie2</code>, <code>bowtie2-build</code> and <code>bowtie2-inspect</code> binaries. This is important, as the <code>BT2_HOME</code> variable is used in the commands below to refer to that directory.</p><h2 id="Indexing-a-reference-genome"><a href="#Indexing-a-reference-genome" class="headerlink" title="Indexing a reference genome"></a>Indexing a reference genome</h2><p>To create an index for the <a href="http://en.wikipedia.org/wiki/Lambda_phage">Lambda phage</a> reference genome included with Bowtie 2, create a new temporary directory (it doesn’t matter where), change into that directory, and run:</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs awk"><span class="hljs-variable">$BT2_HOME</span><span class="hljs-regexp">/bowtie2-build $BT2_HOME/</span>example<span class="hljs-regexp">/reference/</span>lambda_virus.fa lambda_virus<br></code></pre></td></tr></table></figure><p>The command should print many lines of output then quit. When the command completes, the current directory will contain four new files that all start with <code>lambda_virus</code> and end with <code>.1.bt2</code>, <code>.2.bt2</code>, <code>.3.bt2</code>, <code>.4.bt2</code>, <code>.rev.1.bt2</code>, and <code>.rev.2.bt2</code>. These files constitute the index - you’re done!</p><p>You can use <code>bowtie2-build</code> to create an index for a set of <a href="https://en.wikipedia.org/wiki/FASTA"><code>FASTA</code></a> files obtained from any source, including sites such as <a href="http://genome.ucsc.edu/cgi-bin/hgGateway">UCSC</a>, <a href="http://www.ncbi.nlm.nih.gov/sites/genome">NCBI</a>, and <a href="http://www.ensembl.org/">Ensembl</a>. When indexing multiple <a href="https://en.wikipedia.org/wiki/FASTA"><code>FASTA</code></a> files, specify all the files using commas to separate file names. For more details on how to create an index with <code>bowtie2-build</code>, see the <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#the-bowtie2-build-indexer">manual section on index building</a>. You may also want to bypass this process by obtaining a pre-built index. See <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#using-a-pre-built-index">using a pre-built index</a> below for an example.</p><h2 id="Aligning-example-reads"><a href="#Aligning-example-reads" class="headerlink" title="Aligning example reads"></a>Aligning example reads</h2><p>Stay in the directory created in the previous step, which now contains the <code>lambda_virus</code> index files. Next, run:</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs awk"><span class="hljs-variable">$BT2_HOME</span><span class="hljs-regexp">/bowtie2 -x lambda_virus -U $BT2_HOME/</span>example<span class="hljs-regexp">/reads/</span>reads_1.fq -S eg1.sam<br></code></pre></td></tr></table></figure><p>This runs the Bowtie 2 aligner, which aligns a set of unpaired reads to the <a href="http://en.wikipedia.org/wiki/Lambda_phage">Lambda phage</a> reference genome using the index generated in the previous step. The alignment results in SAM format are written to the file <code>eg1.sam</code>, and a short alignment summary is written to the console. (Actually, the summary is written to the “standard error” or “stderr” filehandle, which is typically printed to the console.)</p><p>To see the first few lines of the SAM output, run:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">head</span> eg1.sam<br></code></pre></td></tr></table></figure><p>You will see something like this:</p><figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs pgsql">@HD VN:<span class="hljs-number">1.0</span>  SO:unsorted<br>@SQ SN:gi|<span class="hljs-number">9626243</span>|<span class="hljs-keyword">ref</span>|NC_001416<span class="hljs-number">.1</span>|  LN:<span class="hljs-number">48502</span><br>@PG ID:bowtie2  PN:bowtie2  VN:<span class="hljs-number">2.0</span><span class="hljs-number">.1</span><br>r1  <span class="hljs-number">0</span>   gi|<span class="hljs-number">9626243</span>|<span class="hljs-keyword">ref</span>|NC_001416<span class="hljs-number">.1</span>| <span class="hljs-number">18401</span>   <span class="hljs-number">42</span>  <span class="hljs-number">122</span>M    *   <span class="hljs-number">0</span>   <span class="hljs-number">0</span>   TGAATGCGAACTCCGGGACGCTCAGTAATGTGACGATAGCTGAAAACTGTACGATAAACNGTACGCTGAGGGCAGAAAAAATCGTCGGGGACATTNTAAAGGCGGCGAGCGCGGCTTTTCCG  +&quot;@6&lt;:27(F&amp;5)9&quot;B):%B+A-%<span class="hljs-number">5</span>A?<span class="hljs-number">2</span>$HCB0B+<span class="hljs-number">0</span>=D&lt;<span class="hljs-number">7</span>E/&lt;<span class="hljs-number">.03</span>#!.F77@<span class="hljs-number">6</span>B==?C&quot;7&gt;;))%;,3-$.A06+&lt;-1/@@?,26&quot;&gt;=?*@<span class="hljs-string">&#x27;0;$:;??G+:#+(A?9+10!8!?()?7C&gt;  AS:i:-5 XN:i:0  XM:i:3  XO:i:0  XG:i:0  NM:i:3  MD:Z:59G13G21G26    YT:Z:UU</span><br><span class="hljs-string">r2  0   gi|9626243|ref|NC_001416.1| 8886    42  275M    *   0   0   NTTNTGATGCGGGCTTGTGGAGTTCAGCCGATCTGACTTATGTCATTACCTATGAAATGTGAGGACGCTATGCCTGTACCAAATCCTACAATGCCGGTGAAAGGTGCCGGGATCACCCTGTGGGTTTATAAGGGGATCGGTGACCCCTACGCGAATCCGCTTTCAGACGTTGACTGGTCGCGTCTGGCAAAAGTTAAAGACCTGACGCCCGGCGAACTGACCGCTGAGNCCTATGACGACAGCTATCTCGATGATGAAGATGCAGACTGGACTGC (#!!&#x27;</span>+!$&quot;&quot;%+(+)<span class="hljs-string">&#x27;%)%!+!(&amp;++)&#x27;&#x27;&quot;#&quot;#&amp;#&quot;!&#x27;</span>!(&quot;%&#x27;&quot;&quot;(&quot;+&amp;%$%*%%#$%#%#!)*<span class="hljs-string">&#x27;(#&quot;)(($&amp;$&#x27;</span>&amp;%+&amp;#%*)*#*%*<span class="hljs-string">&#x27;)(%+!%%*&quot;$%&quot;#+)$&amp;&amp;+)&amp;)*+!&quot;*)!*!(&quot;&amp;&amp;&quot;*#+&quot;&amp;&quot;&#x27;</span>(%)*(&quot;&#x27;!$*!!%$&amp;&amp;&amp;$!!&amp;&amp;&quot;(*&quot;$&amp;&quot;#&amp;!$%<span class="hljs-string">&#x27;%&quot;#)$#+%*+)!&amp;*)+(&quot;&quot;#!)!%*#&quot;*)*&#x27;</span>)&amp;&quot;)($+*%%)!*)!(&#x27;(%&quot;&quot;+%&quot;$##&quot;#+((&#x27;!*(($*&#x27;!&quot;*(<span class="hljs-string">&#x27;&quot;+)&amp;%#&amp;$+(&#x27;</span>**$$<span class="language-ruby">&amp;+*&amp;!<span class="hljs-comment">#%)&#x27;)&#x27;(+(!%+ AS:i:-14    XN:i:0  XM:i:8  XO:i:0  XG:i:0  NM:i:8  MD:Z:0A0C0G0A108C23G9T81T46 YT:Z:UU</span></span><br><span class="language-ruby">r3  <span class="hljs-number">16</span>  gi|<span class="hljs-params">9626243</span>|ref|<span class="hljs-params">NC_001416.1</span>| <span class="hljs-number">11599</span>   <span class="hljs-number">42</span>  338M    *   <span class="hljs-number">0</span>   <span class="hljs-number">0</span>   <span class="hljs-variable constant_">GGGCGCGTTACTGGGATGATCGTGAAAAGGCCCGTCTTGCGCTTGAAGCCGCCCGAAAGAAGGCTGAGCAGCAGACTCAAGAGGAGAAAAATGCGCAGCAGCGGAGCGATACCGAAGCGTCACGGCTGAAATATACCGAAGAGGCGCAGAAGGCTNACGAACGGCTGCAGACGCCGCTGCAGAAATATACCGCCCGTCAGGAAGAACTGANCAAGGCACNGAAAGACGGGAAAATCCTGCAGGCGGATTACAACACGCTGATGGCGGCGGCGAAAAAGGATTATGAAGCGACGCTGTAAAAGCCGAAACAGTCCAGCGTGAAGGTGTCTGCGGGCGAT</span>  7F<span class="hljs-variable">$%</span><span class="hljs-number">6</span>=<span class="hljs-variable">$:</span>9B@/F<span class="hljs-string">&#x27;&gt;=?!D?@0(:A*)7/&gt;9C&gt;6#1&lt;6:C(.CC;#.;&gt;;2&#x27;</span><span class="hljs-variable">$4D</span><span class="hljs-symbol">:<span class="hljs-string">?&amp;</span>B!&gt;</span><span class="hljs-number">689</span>?(<span class="hljs-number">0</span>(<span class="hljs-variable constant_">G7</span>+<span class="hljs-number">0</span>=<span class="hljs-variable">@37F</span>)<span class="hljs-variable constant_">GG</span>=&gt;<span class="hljs-string">?9</span>58.<span class="hljs-variable constant_">D2E04C</span>&lt;E,*<span class="hljs-variable constant_">AD</span>%<span class="hljs-variable constant_">G0</span>.%<span class="hljs-variable">$+</span><span class="hljs-symbol">A:</span><span class="hljs-string">&#x27;H;?8&lt;72:88?E6((CF)6DF#.)=&gt;B&gt;D-=&quot;C&#x27;</span><span class="hljs-variable constant_">B080E</span><span class="hljs-string">&#x27;5BH&quot;77&#x27;</span><span class="hljs-symbol">:<span class="hljs-string">&quot;@70#4%A5=6.2/1&gt;;9&quot;</span>&amp;-H6</span>)=<span class="hljs-variable">$/</span><span class="hljs-number">0</span>;5<span class="hljs-symbol">E:</span>&lt;8G!@<span class="hljs-symbol">:</span><span class="hljs-symbol">:</span><span class="hljs-number">1</span>?2DC7C*;@*<span class="hljs-comment">#.1C0.D&gt;H/20,!&quot;C-#,6@%&lt;+&lt;D(AG-).?&amp;#0.00&#x27;@)/F8?B!&amp;&quot;170,)&gt;:?&lt;A7#1(A@0E#&amp;A.*DC.E&quot;)AH&quot;+.,5,2&gt;5&quot;2?:G,F&quot;D0B8D-6$65D&lt;D!A/38860.*4;4B&lt;*31?6  AS:i:-22    XN:i:0  XM:i:8  XO:i:0  XG:i:0  NM:i:8  MD:Z:80C4C16A52T23G30A8T76A41   YT:Z:UU</span></span><br><span class="language-ruby">r4  <span class="hljs-number">0</span>   gi|<span class="hljs-params">9626243</span>|ref|<span class="hljs-params">NC_001416.1</span>| <span class="hljs-number">40075</span>   <span class="hljs-number">42</span>  184M    *   <span class="hljs-number">0</span>   <span class="hljs-number">0</span>   <span class="hljs-variable constant_">GGGCCAATGCGCTTACTGATGCGGAATTACGCCGTAAGGCCGCAGATGAGCTTGTCCATATGACTGCGAGAATTAACNGTGGTGAGGCGATCCCTGAACCAGTAAAACAACTTCCTGTCATGGGCGGTAGACCTCTAAATCGTGCACAGGCTCTGGCGAAGATCGCAGAAATCAAAGCTAAGT</span>(=8B)<span class="hljs-variable constant_">GD04</span>*G%&amp;4F,<span class="hljs-number">1</span><span class="hljs-string">&#x27;A&gt;.C&amp;7=F$,+#6!))43C,5/5+)?-/0&gt;/D3=-,2/+.1?@-&gt;;)00!&#x27;</span><span class="hljs-number">3</span>!7BH<span class="hljs-variable">$G</span>)<span class="hljs-variable constant_">HG</span>+<span class="hljs-variable constant_">ADC</span><span class="hljs-string">&#x27;#-9F)7&lt;7&quot;$?&amp;.&gt;0)@5;4,!0-#C!15CF8&amp;HB+B==H&gt;7,/)C5)5*+(F5A%D,EA&lt;(&gt;G9E0&gt;7&amp;/E?4%;#&#x27;</span><span class="hljs-number">92</span>)&lt;<span class="hljs-number">5</span>+<span class="hljs-variable">@7</span><span class="hljs-symbol">:A</span>.(<span class="hljs-variable constant_">BG</span><span class="hljs-variable">@BG8</span>6@.G <span class="hljs-variable constant_">AS</span><span class="hljs-symbol">:i</span><span class="hljs-symbol">:-</span><span class="hljs-number">1</span> <span class="hljs-variable constant_">XN</span><span class="hljs-symbol">:i</span><span class="hljs-symbol">:</span><span class="hljs-number">0</span>  <span class="hljs-variable constant_">XM</span><span class="hljs-symbol">:i</span><span class="hljs-symbol">:</span><span class="hljs-number">1</span>  <span class="hljs-variable constant_">XO</span><span class="hljs-symbol">:i</span><span class="hljs-symbol">:</span><span class="hljs-number">0</span>  <span class="hljs-variable constant_">XG</span><span class="hljs-symbol">:i</span><span class="hljs-symbol">:</span><span class="hljs-number">0</span>  <span class="hljs-variable constant_">NM</span><span class="hljs-symbol">:i</span><span class="hljs-symbol">:</span><span class="hljs-number">1</span>  <span class="hljs-variable constant_">MD</span><span class="hljs-symbol">:Z</span><span class="hljs-symbol">:</span>77C106 <span class="hljs-variable constant_">YT</span><span class="hljs-symbol">:Z</span><span class="hljs-symbol">:UU</span></span><br><span class="language-ruby">r5  <span class="hljs-number">0</span>   gi|<span class="hljs-params">9626243</span>|ref|<span class="hljs-params">NC_001416.1</span>| <span class="hljs-number">48010</span>   <span class="hljs-number">42</span>  138M    *   <span class="hljs-number">0</span>   <span class="hljs-number">0</span>   <span class="hljs-variable constant_">GTCAGGAAAGTGGTAAAACTGCAACTCAATTACTGCAATGCCCTCGTAATTAAGTGAATTTACAATATCGTCCTGTTCGGAGGGAAGAACGCGGGATGTTCATTCTTCATCACTTTTAATTGATGTATATGCTCTCTT</span>  <span class="hljs-number">9</span><span class="hljs-string">&#x27;&#x27;</span><span class="hljs-string">%&lt;D)A03E1-*7=),:F/0!6,D9:H,&lt;9D%:0B(%&#x27;E,(8EFG$E89B$27G8F*2+4,-!,0D5()&amp;=(FGG:5;3*@/.0F-G#5#3-&gt;</span>(<span class="hljs-string">&#x27;FDFEG?)5.!)&quot;AGADB3?6(@H(:B&lt;&gt;6!&gt;;&gt;6&gt;G,.&quot;?%  AS:i:0  XN:i:0  XM:i:0  XO:i:0  XG:i:0  NM:i:0  MD:Z:138    YT:Z:UU</span></span><br><span class="hljs-string"><span class="language-ruby">r6  16  gi|9626243|ref|NC_001416.1| 41607   42  72M2D119M   *   0   0   TCGATTTGCAAATACCGGAACATCTCGGTAACTGCATATTCTGCATTAAAAAATCAACGCAAAAAATCGGACGCCTGCAAAGATGAGGAGGGATTGCAGCGTGTTTTTAATGAGGTCATCACGGGATNCCATGTGCGTGACGGNCATCGGGAAACGCCAAAGGAGATTATGTACCGAGGAAGAATGTCGCT 1H#G;H&quot;$E*E#&amp;&quot;*)2%66?=9/9&#x27;</span>=;<span class="hljs-number">4</span>)<span class="hljs-number">4</span>/&gt;@%+<span class="hljs-number">5</span><span class="hljs-comment">#@#$4A*!&lt;D==&quot;8#1*A9BA=:(1+#C&amp;.#(3#H=9E)AC*5,AC#E&#x27;536*2?)H14?&gt;9&#x27;B=7(3H/B:+A:8%1-+#(E%&amp;$$</span></span>&amp;<span class="hljs-number">14</span>&quot;76D?&gt;7(&amp;20H5%*&amp;CF8!G5B+A4F$7(:&quot;<span class="hljs-string">&#x27;?0$?G+$)B-?2&lt;0&lt;F=D!38BH,%=8&amp;5@+ AS:i:-13    XN:i:0  XM:i:2  XO:i:1  XG:i:2  NM:i:4  MD:Z:72^TT55C15A47  YT:Z:UU</span><br><span class="hljs-string">r7  16  gi|9626243|ref|NC_001416.1| 4692    42  143M    *   0   0   TCAGCCGGACGCGGGCGCTGCAGCCGTACTCGGGGATGACCGGTTACAACGGCATTATCGCCCGTCTGCAACAGGCTGCCAGCGATCCGATGGTGGACAGCATTCTGCTCGATATGGACANGCCCGGCGGGATGGTGGCGGGG -&quot;/@*7A0)&gt;2,AAH@&amp;&quot;%B)*5*23B/,)90.B@%=FE,E063C9?,:26$-0:,.,1849&#x27;</span><span class="hljs-number">4.</span>;F&gt;FA;<span class="hljs-number">76</span>+<span class="hljs-number">5</span>&amp;$&lt;C&quot;:$!A*,&lt;B,&lt;)@&lt;&#x27;85D%C*:)30@85;?.B$05=@95DCDH&lt;53!8G:F:B7/A.E&#x27;:434&gt; AS:i:-6 XN:i:0  XM:i:2  XO:i:0  XG:i:0  NM:i:2  MD:Z:98G21C22   YT:Z:UU<br></code></pre></td></tr></table></figure><p>The first few lines (beginning with <code>@</code>) are SAM header lines, and the rest of the lines are SAM alignments, one line per read or mate. See the <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#sam-output">Bowtie 2 manual section on SAM output</a> and the <a href="http://samtools.sourceforge.net/SAM1.pdf">SAM specification</a> for details about how to interpret the SAM file format.</p><h2 id="Paired-end-example"><a href="#Paired-end-example" class="headerlink" title="Paired-end example"></a>Paired-end example</h2><p>To align paired-end reads included with Bowtie 2, stay in the same directory and run:</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs awk"><span class="hljs-variable">$BT2_HOME</span><span class="hljs-regexp">/bowtie2 -x lambda_virus -1 $BT2_HOME/</span>example<span class="hljs-regexp">/reads/</span>reads_1.fq -<span class="hljs-number">2</span> <span class="hljs-variable">$BT2_HOME</span><span class="hljs-regexp">/example/</span>reads/reads_2.fq -S eg2.sam<br></code></pre></td></tr></table></figure><p>This aligns a set of paired-end reads to the reference genome, with results written to the file <code>eg2.sam</code>.</p><h2 id="Local-alignment-example-1"><a href="#Local-alignment-example-1" class="headerlink" title="Local alignment example"></a>Local alignment example</h2><p>To use <a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#end-to-end-alignment-versus-local-alignment">local alignment</a> to align some longer reads included with Bowtie 2, stay in the same directory and run:</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs awk"><span class="hljs-variable">$BT2_HOME</span><span class="hljs-regexp">/bowtie2 --local -x lambda_virus -U $BT2_HOME/</span>example<span class="hljs-regexp">/reads/</span>longreads.fq -S eg3.sam<br></code></pre></td></tr></table></figure><p>This aligns the long reads to the reference genome using local alignment, with results written to the file <code>eg3.sam</code>.</p><h2 id="Using-SAMtools-x2F-BCFtools-downstream"><a href="#Using-SAMtools-x2F-BCFtools-downstream" class="headerlink" title="Using SAMtools&#x2F;BCFtools downstream"></a>Using SAMtools&#x2F;BCFtools downstream</h2><p><a href="http://samtools.sourceforge.net/">SAMtools</a> is a collection of tools for manipulating and analyzing SAM and BAM alignment files. <a href="http://samtools.sourceforge.net/mpileup.shtml">BCFtools</a> is a collection of tools for calling variants and manipulating VCF and BCF files, and it is typically distributed with <a href="http://samtools.sourceforge.net/">SAMtools</a>. Using these tools together allows you to get from alignments in SAM format to variant calls in VCF format. This example assumes that <code>samtools</code> and <code>bcftools</code> are installed and that the directories containing these binaries are in your <a href="http://en.wikipedia.org/wiki/PATH_(variable)">PATH environment variable</a>.</p><p>Run the paired-end example:</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs awk"><span class="hljs-variable">$BT2_HOME</span><span class="hljs-regexp">/bowtie2 -x $BT2_HOME/</span>example<span class="hljs-regexp">/index/</span>lambda_virus -<span class="hljs-number">1</span> <span class="hljs-variable">$BT2_HOME</span><span class="hljs-regexp">/example/</span>reads<span class="hljs-regexp">/reads_1.fq -2 $BT2_HOME/</span>example<span class="hljs-regexp">/reads/</span>reads_2.fq -S eg2.sam<br></code></pre></td></tr></table></figure><p>Use <code>samtools view</code> to convert the SAM file into a BAM file. BAM is the binary format corresponding to the SAM text format. Run:</p><figure class="highlight gcode"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs gcode">samtools view -bS e<span class="hljs-name">g2.</span>sam &gt; e<span class="hljs-name">g2.</span>bam<br></code></pre></td></tr></table></figure><p>Use <code>samtools sort</code> to convert the BAM file to a sorted BAM file.</p><figure class="highlight gcode"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs gcode">samtools sort e<span class="hljs-name">g2.</span>bam -o e<span class="hljs-name">g2.</span>sorted.bam<br></code></pre></td></tr></table></figure><p>We now have a sorted BAM file called <code>eg2.sorted.bam</code>. Sorted BAM is a useful format because the alignments are (a) compressed, which is convenient for long-term storage, and (b) sorted, which is conveneint for variant discovery. To generate variant calls in VCF format, run:</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs awk">bcftools mpileup -f <span class="hljs-variable">$BT2_HOME</span><span class="hljs-regexp">/example/</span>reference/lambda_virus.fa eg2.sorted.bam | bcftools view -Ov - &gt; eg2.raw.bcf<br></code></pre></td></tr></table></figure><p>Then to view the variants, run:</p><figure class="highlight cos"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs cos">bcftools <span class="hljs-keyword">view</span> eg2.raw.bcf<br></code></pre></td></tr></table></figure><p>See the official SAMtools guide to <a href="http://samtools.sourceforge.net/mpileup.shtml">Calling SNPs&#x2F;INDELs with SAMtools&#x2F;BCFtools</a> for more details and variations on this process.</p>]]></content>
    
    
    <categories>
      
      <category>Software</category>
      
    </categories>
    
    
    <tags>
      
      <tag>mapping</tag>
      
      <tag>bowtie2</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【blast+】</title>
    <link href="/GeekFocus/2022/03/20/2022-03-18-blast/"/>
    <url>/GeekFocus/2022/03/20/2022-03-18-blast/</url>
    
    <content type="html"><![CDATA[<p>Short introduction to using NCBI blast tools from the command line</p><span id="more"></span><p><a href="https://www.ncbi.nlm.nih.gov/books/NBK279690/">BLAST® Command Line Applications User Manual</a></p><h2 id="Exercise-2-performing-a-basic-BLASTp-search"><a href="#Exercise-2-performing-a-basic-BLASTp-search" class="headerlink" title="Exercise 2: performing a basic BLASTp search"></a>Exercise 2: performing a basic BLASTp search</h2><p>BLAST+ search strategies are run by typing the type you want on the command line followed by the input options. This includes <strong>blastn, blastp, blastx, tblastn and tblastx</strong>. Ensure you know which search strategy is appropriate for your data and database type. You can find an extensive overview of these <a href="https://www.ncbi.nlm.nih.gov/books/NBK1734/">here</a>.</p><p>We will now search a few <strong>protein sequences against the database</strong> and <strong>retrieve the results</strong>. You can get download sample protein sequences for this tutorial <a href="https://raw.githubusercontent.com/conmeehan/conmeehan.github.io/master/proteins.fasta">here</a>. Save this page as proteins.fasta and put in the same directory as the pdbaa folder we downloaded earlier. We will perform a default BLASTp search on these to find out what proteins they are. The advantage of BLAST+ is that we can run BLASTp once using this file as an input and it will <strong>perform a search on all sequences within</strong>, meaning we <strong>do not have to do each sequence individually</strong>.</p><p>Navigate to the folder containing proteins.fasta. The <strong>pdbaa folder</strong> should be <strong>in this folder too.</strong> Type the following on the command line:</p><figure class="highlight stata"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs stata">blastp -<span class="hljs-keyword">query</span> proteins.fasta -<span class="hljs-keyword">db</span> pdbaa/pdbaa -<span class="hljs-keyword">out</span> proteins_blastp.txt<br></code></pre></td></tr></table></figure><p>This will perform a blastp search, using all the sequences in proteins.fasta as queries, using the pdbaa database and output the results to proteins_blastp.txt. You will see the output looks quite like the website output with the overview first and the individual alignments next.</p><p>Q. Look at the file proteins_blastp.txt. What sequences do we appear to have?</p><p>There are many ways to modify how this is run. Type</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">blastp -<span class="hljs-built_in">help</span><br></code></pre></td></tr></table></figure><p>This will print to the screen a large amount of text, <strong>detailing all the flags (options) we can change during the BLAST search</strong>. We will modify some of these now.</p><h2 id="Exercise-3-modifying-the-defaults-and-output-types"><a href="#Exercise-3-modifying-the-defaults-and-output-types" class="headerlink" title="Exercise 3: modifying the defaults and output types"></a>Exercise 3: modifying the defaults and output types</h2><p>Often if we are working with <strong>many sequences</strong> we want to make it easier to <strong>get the best results</strong> in an easy to read format. We can do this by <strong>limiting the number of results returned</strong>. Often this is performed by changing the number of alignments displayed and&#x2F;or the <strong>e-value cut-off</strong>.</p><p>Lets run BLASTp, keeping all the overviews but only displaying the top hit alignment. We change the number of alignments displayed with the <strong>-num_alignments</strong> flag. To <strong>keep only the top hit alignment</strong> we can use</p><figure class="highlight stata"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs stata">blastp -<span class="hljs-keyword">query</span> proteins.fasta -<span class="hljs-keyword">db</span> <span class="hljs-keyword">db</span>/pdbaa -<span class="hljs-keyword">out</span> proteins_blastp_1align.txt -num_alignments 1<br></code></pre></td></tr></table></figure><p>If you look in this file we can see that all the descriptions are retained but <strong>now we only have 1 alignment per query sequence</strong>. Another way to limit the results is to set an <strong>e-value cut-off</strong>. In the help output of each program you can see the default e-value (listed under ‘general search options’). You can see it is quite high (10). We will retain only those hits with an e-value of <strong>1e-30 or higher.</strong> We use the <strong>-evalue</strong> flag for this. Lets combines the above alignment display restriction with an <strong>evalue restriction</strong>. This done by typing:</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">blastp</span> -query proteins.fasta -db db/pdbaa -out proteins_blastp_1align_1e-<span class="hljs-number">30</span>.txt -num_alignments <span class="hljs-number">1</span> -evalue <span class="hljs-number">1</span>e-<span class="hljs-number">30</span><br></code></pre></td></tr></table></figure><p>You can see now that we have a smaller number of hits, hopefully including only those we are certain are likely to be correct.</p><p>Often we <strong>dont need</strong> the output <strong>alignments</strong> but <strong>want all the details of each hit</strong> (e-value, bit score, percent identity etc) on 1 line. This is achieved by changing the <strong>output type</strong>. So far we have used the default output type but we can change this with the <strong>-outfmt</strong> flag. There are 11 output types (listed in the help output) but we <font color="blue"><strong>shall use type 6</strong></font>: tabular output. This gives you <strong>a line per hit with 12 columns</strong>:</p><ul><li>Query id</li><li><strong>Subject id</strong></li><li><strong>% identity</strong></li><li><strong>alignment length</strong></li><li><strong>mismatches</strong></li><li><strong>gap</strong> openings</li><li><strong>query start</strong></li><li><strong>query end</strong></li><li><strong>subject start</strong></li><li><strong>subject end</strong></li><li>e-value</li><li>bit score</li></ul><p>This saves a lot of space in the output but does not separate queries into separate sections. We no longer need to limit the number of alignments with this output format (as none are displayed) but we may still want to limit the e-value. We can do this by typing:</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">blastp</span> -query proteins.fasta -db db/pdbaa -out proteins_blastp_1e-<span class="hljs-number">30</span>_table.txt -evalue <span class="hljs-number">1</span>e-<span class="hljs-number">30</span> -outfmt <span class="hljs-number">6</span><br></code></pre></td></tr></table></figure><p>We can see the output is much more compressed with queries all together, only separated by the name in the first column. You may notice however that the subject name (column 2) is truncated, with the information we want having been cut off. This is a known problem in the tabular output that supposedly NCBI are working on. You can see we do happen to have the GI included in the description which we can search the NCBI website for. When we create our own database we may wish to try have short names so that this is less of a problem. There is a way to switch between some output types even after you have run the analysis which I will outline briefly later.</p><p>A small note ( we will not do an exercise on this): There are different types of BLAST searches within the basic types. For example in blastn you can perform standard blastn, megablast or discontiguous megablast. These options are changed with the <strong>-task</strong> flag. Note that megablast is the default for blastn, not standard blastn.</p><h2 id="Excerise-4-Extracting-the-sequences-from-a-BLAST-database"><a href="#Excerise-4-Extracting-the-sequences-from-a-BLAST-database" class="headerlink" title="Excerise 4: Extracting the sequences from a BLAST database"></a>Excerise 4: Extracting the sequences from a BLAST database</h2><p>If you want to extract the sequences that are contained in a BLAST database, you can use the <strong>blastdbcmd</strong> command to do this. Lets extract all the sequences from the pdb database we have downloaded. Navigate to the folder that contains the database file (pdbaa in the above examples) and run:</p><figure class="highlight ada"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs ada">blastdbcmd -<span class="hljs-keyword">entry</span> <span class="hljs-keyword">all</span> -db pdbaa -<span class="hljs-keyword">out</span> pdbaa.fasta<br></code></pre></td></tr></table></figure><p>This will extract all the sequences from the database named pdbaa and place them into a Fasta file named pdbaa.fasta.</p><h2 id="Exercise-5-creating-a-custom-database"><a href="#Exercise-5-creating-a-custom-database" class="headerlink" title="Exercise 5: creating a custom database"></a>Exercise 5: <font color="blue">creating a custom database</font></h2><p>Often we <strong>do not want to use all of NR</strong> or any of the pre-made databases supplied by NCBI. We may want to use <strong>a custom database of only species or genes we are interested in</strong>. If we have a fasta format file (unaligned) of these sequences we can create a database from this with the <strong>makeblastdb</strong> command. Lets create the pdb amino acid database from a fasta file, resulting in the database we already used.</p><p>Create a new folder called db2. Copy the file pdbaa.fasta you just created from the pdbaa folder to the db2 folder. Navigate into the db2 folder and create a protein database by typing:</p><figure class="highlight elm"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs elm"><span class="hljs-title">makeblastdb</span> -<span class="hljs-keyword">in</span> pdbaa.fasta -title pdbaa -db<span class="hljs-keyword">type</span> prot -out pdbaa -parse_seqids<br></code></pre></td></tr></table></figure><p>The <strong>-in</strong> flag states the fasta file to create the database from, the <strong>-title</strong> flag gives the database a title, <strong>-dbtype</strong> says whether it is protein (prot) or nucleotide (nucl), <strong>-out</strong> is the name of the database and <strong>-parse_seqids</strong> states we want to <strong>retain the full names of each sequence</strong>. You will now see in db2 we have exactly the same files as in the db folder. We can use this as our database in exactly the same way we did for the original pdbaa database, just remember to use db2&#x2F;pdbaa for the database instead of pdbaa&#x2F;pdbaa.</p><h2 id="Exercise-6-BLASTing-against-a-remote-database"><a href="#Exercise-6-BLASTing-against-a-remote-database" class="headerlink" title="Exercise 6: BLASTing against a remote database"></a>Exercise 6: BLASTing against a remote database</h2><p>Instead of having to download the entirety of NR or other NCBI databases, we can BLAST against the version held on the website. This ensures we have the most up to date version but is also significantly slower. We use the <strong>-remote</strong>command to do this. Lets BLAST our sequences against NR held on the NCBI website by typing:</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">blastp</span> -query proteins.fasta -remote -db nr -out proteins_nr.txt -outfmt <span class="hljs-number">6</span> -evalue <span class="hljs-number">1</span>e-<span class="hljs-number">30</span><br></code></pre></td></tr></table></figure><p>Q. Did weget the same sequences back from the nr database as we did from the pdb database?</p><h2 id="Exercise-7-Extracting-hits-from-the-BLAST-database"><a href="#Exercise-7-Extracting-hits-from-the-BLAST-database" class="headerlink" title="Exercise 7: Extracting hits from the BLAST database"></a>Exercise 7: Extracting hits from the BLAST database</h2><p>Once we have our BLAST results we may wish to go back and get the sequences for the hits from the database. For this we require a file of the sequence names of the hits (or parts of it, such as the section output from type 6 output) and the database used for the original BLAST (which must have been created with the -parse_seqids flag). Lets take 2 sequences from our hits against the pdbaa database. Copy the following into a file called hits.txt</p><table><thead><tr><th>gi</th><th>1942986</th><th>pdb</th><th>1OCC</th><th>A</th></tr></thead><tbody><tr><td>gi</td><td>40889823</td><td>pdb</td><td>1V54</td><td>A</td></tr></tbody></table><p>This is portions of 2 names of sequences we found to be good hits to our first query sequence. We will use the <strong>blastdbcmd</strong> program to get these sequences from the pdbaa database. Type:</p><figure class="highlight stata"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs stata">blastdbcmd -<span class="hljs-keyword">db</span> <span class="hljs-keyword">db</span>/pdbaa -dbtype prot -entry_batch hits.txt -outfmt %f -<span class="hljs-keyword">out</span> hits.fasta <br></code></pre></td></tr></table></figure><p>This command is similar to in excerise 4 but instead of getting all the sequences in the database, we are <strong>getting a subselection</strong>. The <strong>-db</strong>, <strong>-dbtype</strong> and <strong>-out</strong> we have seen before, <strong>-entry_batch</strong> is the file containing the sequence names and <strong>-outfmt</strong> here says we want <strong>fasta formatted sequences (%f)</strong>. If you now open hits.fasta you should see the 2 sequences we requested.</p><h2 id="Exercise-8-Converting-output-format-types"><a href="#Exercise-8-Converting-output-format-types" class="headerlink" title="Exercise 8: Converting output format types"></a>Exercise 8: Converting output format types</h2><p>If you wish to change output formats after you have run a BLAST search we can use <strong>blast_formatter</strong>. This requires that the original run used <strong>-outfmt 11</strong> (archive type) and the database was made with the <strong>-parse_seqids</strong> flag. If we ran a BLAST such as</p><figure class="highlight stata"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs stata">blastp -<span class="hljs-keyword">query</span> proteins.fasta -<span class="hljs-keyword">db</span> <span class="hljs-keyword">db</span>/pdbaa -<span class="hljs-keyword">out</span> protein_archive.txt -outfmt 11<br></code></pre></td></tr></table></figure><p>We could retrieve the results in out format 6 by typing</p><figure class="highlight nsis"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs nsis">blast_formatter -<span class="hljs-params">archive</span> protein_<span class="hljs-params">archive</span>.txt -outfmt <span class="hljs-number">6</span> -out proteins_tabular.txt<br></code></pre></td></tr></table></figure><p><strong>Thus a good way to run BLAST+ is to use -outfmt 11 and then after that use blast_formatter to change the output to different formats as needed.</strong></p><hr><p><a href="https://github.com/enormandeau/ncbi_blast_tutorial">https://github.com/enormandeau/ncbi_blast_tutorial</a></p><h2 id="install"><a href="#install" class="headerlink" title="install"></a>install</h2><p>Get the compiled executables from this URL:</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs awk">ftp:<span class="hljs-regexp">//</span>ftp.ncbi.nlm.nih.gov<span class="hljs-regexp">/blast/</span>executables<span class="hljs-regexp">/blast+/</span>LATEST/<br></code></pre></td></tr></table></figure><p>Decompress the archive. </p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">tar</span> xvfz ncbi-blast-<span class="hljs-number">2</span>.<span class="hljs-number">9</span>.<span class="hljs-number">0</span>+-x64-linux.tar.gz<br></code></pre></td></tr></table></figure><p>Add the <code>bin</code> folder from the extracted archive to your path.</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs routeros"><span class="hljs-built_in">export</span> <span class="hljs-attribute">PATH</span>=<span class="hljs-string">&quot;/PATH/TO/ncbi-blast-2.9.0+/bin&quot;</span>:$PATH<br></code></pre></td></tr></table></figure><h2 id="Example-sequences-to-use-with-the-tutorial"><a href="#Example-sequences-to-use-with-the-tutorial" class="headerlink" title="Example sequences to use with the tutorial"></a>Example sequences to use with the tutorial</h2><p>In order to test blast, you need a test fasta file. Use the following files that come with the tutorial:</p><ul><li><code>sequences.fasta</code></li><li><code>reference.fasta</code></li></ul><h2 id="Create-blast-database"><a href="#Create-blast-database" class="headerlink" title="Create blast database"></a>Create blast database</h2><p>The different blast tools require a formatted database to search against. In order to create the database, we use the <code>makeblastdb</code> tool:</p><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs angelscript">makeblastdb -<span class="hljs-keyword">in</span> <span class="hljs-built_in">ref</span>erence.fasta -title <span class="hljs-built_in">ref</span>erence -dbtype nucl -<span class="hljs-keyword">out</span> databases/<span class="hljs-built_in">ref</span>erence<br></code></pre></td></tr></table></figure><p>This will create a list of files in the <code>databases</code> folder. These are all part of the blast database.</p><h2 id="Blast"><a href="#Blast" class="headerlink" title="Blast"></a>Blast</h2><p>We can now <font color="blue"><strong>blast our sequences against the database</strong></font>. In this case, both our query sequences and database sequences are DNA sequences, so we use the <code>blastn</code> tool:</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">blastn</span> -db databases/reference -query sequences.fasta -evalue <span class="hljs-number">1</span>e-<span class="hljs-number">3</span> -word_size <span class="hljs-number">11</span> -outfmt <span class="hljs-number">0</span> &gt; sequences.reference<br></code></pre></td></tr></table></figure><p>You can use different output formats with the <code>outmft</code> option:</p><figure class="highlight tap"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs tap">-outfmt &lt;String&gt;<br>  alignment view options:<br>   <span class="hljs-number"> 0 </span>= pairwise,<br>   <span class="hljs-number"> 1 </span>= query-anchored showing identities,<br>   <span class="hljs-number"> 2 </span>= query-anchored no identities,<br>   <span class="hljs-number"> 3 </span>= flat query-anchored, show identities,<br>   <span class="hljs-number"> 4 </span>= flat query-anchored, no identities,<br>   <span class="hljs-number"> 5 </span>= XML Blast output,<br>   <span class="hljs-number"> 6 </span>= tabular,<br>   <span class="hljs-number"> 7 </span>= tabular with comment lines,<br>   <span class="hljs-number"> 8 </span>= Text ASN.1,<br>   <span class="hljs-number"> 9 </span>= Binary ASN.1,<br>  <span class="hljs-number"> 10 </span>= Comma-separated values,<br>  <span class="hljs-number"> 11 </span>= BLAST archive format (ASN.1)<br></code></pre></td></tr></table></figure><h2 id="Blast-with-parallel"><a href="#Blast-with-parallel" class="headerlink" title="Blast with parallel"></a>Blast with parallel</h2><p>If you need to run your blasts faster (and who doesn’t?), you can maximise CPU usage with <code>gnu parallel</code>. You will find it <a href="http://ftp.gnu.org/gnu/parallel/parallel-latest.tar.bz2">at this link</a>.</p><p>Download the archive, extract it (with <code>tar xvfB parallel-latest.tar.bz2</code>) and install it with the following commands:</p><figure class="highlight gauss"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs gauss">./configure<br><span class="hljs-built_in">make</span><br>sudo <span class="hljs-built_in">make</span> install<br></code></pre></td></tr></table></figure><p>We can now use <code>parallel</code> to speed up blast:</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">time</span> cat sequences.fasta | parallel -k --block <span class="hljs-number">1</span>k --recstart &#x27;&gt;&#x27; --pipe &#x27;blastn -db databases/reference -query - -evalue <span class="hljs-number">1</span>e-<span class="hljs-number">3</span> -word_size <span class="hljs-number">11</span> -outfmt <span class="hljs-number">0</span>&#x27; &gt; sequences.reference<br></code></pre></td></tr></table></figure><h2 id="blast-distribution"><a href="#blast-distribution" class="headerlink" title="blast+ distribution"></a>blast+ distribution</h2><p>An exhaustive list of the programs that come with the blast+ distribution</p><figure class="highlight mipsasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs mipsasm"><span class="hljs-keyword">blastdb_aliastool</span><br><span class="hljs-keyword"></span><span class="hljs-keyword">blastdbcheck</span><br><span class="hljs-keyword"></span><span class="hljs-keyword">blastdbcmd</span><br><span class="hljs-keyword"></span><span class="hljs-keyword">blast_formatter</span><br><span class="hljs-keyword"></span><span class="hljs-keyword">blastn</span><br><span class="hljs-keyword"></span><span class="hljs-keyword">blastp</span><br><span class="hljs-keyword"></span><span class="hljs-keyword">blastx</span><br><span class="hljs-keyword"></span>convert<span class="hljs-symbol">2b</span>lastmask<br>deltablast<br>dustmasker<br>legacy_blast.pl<br>makeblastdb<br>makembindex<br>makeprofiledb<br>psiblast<br>rpsblast<br>rpstblastn<br>segmasker<br>tblastn<br>tblastx<br>update_blastdb.pl<br>windowmasker<br></code></pre></td></tr></table></figure><hr><p><a href="https://ncbi.github.io/magicblast/cook/blastdb.html">https://ncbi.github.io/magicblast/cook/blastdb.html</a></p>]]></content>
    
    
    <categories>
      
      <category>Software</category>
      
    </categories>
    
    
    <tags>
      
      <tag>blast</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【CUT-Tag】【ATAC-seq】</title>
    <link href="/GeekFocus/2022/03/18/2022-03-19-CUT-Tag/"/>
    <url>/GeekFocus/2022/03/18/2022-03-19-CUT-Tag/</url>
    
    <content type="html"><![CDATA[<p>CUT&amp;RUN CUT&amp;Tag ChIP-seq ATAC-seq</p><span id="more"></span><p><a href="https://www.bilibili.com/video/BV11K4y147fN?from=search&seid=6789892139579942949&spm_id_from=333.337.0.0">嘉因生物</a></p><p><img src="/GeekFocus/./1.png" alt="1"></p><p><strong>测序数据量</strong></p><p>参考ChIP-seq 20M&#x2F;40M（2000万reads）（对PE50约为 6&#x2F;12G）</p><p><strong>CUT&amp;Tag-去除测序接头</strong></p><p><img src="/GeekFocus/./2.png" alt="1"></p><p><strong>去接头软件</strong></p><p>Trimmomatic；Cutadapt；fastp</p><p><strong>参考序列比对</strong></p><p><img src="/GeekFocus/./3.png" alt="1"></p><p><strong>数据过滤</strong></p><p><img src="/GeekFocus/./4.png" alt="1"></p><p><strong>CUT&amp;Tag片段长度分布</strong></p><p><img src="/GeekFocus/./5.png" alt="1"></p><p><img src="/GeekFocus/./6.png" alt="1"></p><p><strong>CUT&amp;Tag-结合位点检测（PeakCalling）</strong></p><p>MACS2 主流</p><p><img src="/GeekFocus/./7.png" alt="1"></p><p><img src="/GeekFocus/./8.png" alt="1"></p><p><img src="/GeekFocus/./9.png" alt="9"></p><p><img src="/GeekFocus/./10.png" alt="1"></p><p>SEACR 结果没那么好</p><p><img src="/GeekFocus/./11.png" alt="1"></p><p><img src="/GeekFocus/./12.png" alt="1"></p><p><strong>CUT&amp;Tag-结合位点信号分布</strong></p><p><img src="/GeekFocus/./13.png" alt="1"></p><p><img src="/GeekFocus/./14.png" alt="1"></p><p><strong>CUT&amp;Tag-Peaks 功能性区域注释</strong></p><p><img src="/GeekFocus/./15.png" alt="1"></p><p><strong>CUT&amp;Tag-Motif Analysis</strong></p><p><img src="/GeekFocus/./16.png" alt="1"></p><p><img src="/GeekFocus/./17.png" alt="1"></p><p><strong>CUT&amp;Tag-其他分析</strong></p><p><img src="/GeekFocus/./18.png" alt="1"></p><p><strong>CUT&amp;Tag-联合RNA-seq分析</strong></p><p><img src="/GeekFocus/./19.png" alt="1"></p><p>BETA 功能1，2。3用hommer更多</p><p><img src="/GeekFocus/./20.png" alt="1"></p><p><img src="/GeekFocus/./21.png" alt="1"></p><p><img src="/GeekFocus/./22.png" alt="1"></p><p>Activating&#x2F;repressive function prediction</p><p><img src="/GeekFocus/./23.png" alt="1"></p><p>Target gene</p><p><img src="/GeekFocus/./24.png" alt="1"></p><p><strong>如何评估CUT&amp;Tag中IgG的作用</strong></p><p><img src="/GeekFocus/./25.png" alt="1"></p><p><img src="/GeekFocus/./26.png" alt="1"></p><p><img src="/GeekFocus/./27.png" alt="1"></p><p><img src="/GeekFocus/./28.png" alt="1"></p><p><img src="/GeekFocus/./29.png" alt="1"></p><p>为何IgG信号和组蛋白信号同步出现？</p><p><img src="/GeekFocus/./30.png" alt="1"></p><p><img src="/GeekFocus/./31.png" alt="1"></p><p><strong>CUT&amp;Tag-Quality Control</strong></p><p><img src="/GeekFocus/./32.png" alt="1"></p><p><img src="/GeekFocus/./33.png" alt="1"></p><p><img src="/GeekFocus/./34.png" alt="1"></p><p><img src="/GeekFocus/./35.png" alt="1"></p><p><img src="/GeekFocus/./36.png" alt="1"></p><p><img src="/GeekFocus/./37.png" alt="1"></p><p><img src="/GeekFocus/./38.png" alt="1"></p><p>组蛋白，转录起始激活marker，在起始TSS高；<strong>抑制</strong>的<strong>marker</strong>H3K36me3在<strong>genebody区域比较高</strong></p><p><strong>UCSC tools工具</strong></p><p><img src="/GeekFocus/./39.png" alt="1"></p><p><strong>Cistrome：ChIP-seq在线分析工具</strong></p><p>提前查数据 </p><p> <img src="/GeekFocus/./40.png" alt="1"></p><p><strong>Motif数据库JASPAR</strong></p><p><strong>Motif工具MEME</strong></p><p> <img src="/GeekFocus/./41.png" alt="1"></p><p><a href="https://www.bilibili.com/video/BV1py4y1a7L5/?spm_id_from=333.788.recommend_more_video.2">FraserGen</a></p><p>ATAC测序，Illumina PE150，测序数据量最终可用推荐：50M（开放区域），200M（TFfootprint）</p><p><strong>ATAC-seq项目展示 动物植物</strong></p><p> <img src="/GeekFocus/./42.png" alt="1"></p><p> <img src="/GeekFocus/./43.png" alt="1"></p><p>注意trimmomatic 的NexteraPE-PE.fa;注意bowtie2 -X 最大插入片段长度设置1000&#x2F;2000.</p><p><strong>插入片段长度统计</strong></p><p> <img src="/GeekFocus/./44.png" alt="1"></p><p><strong>-f 0x40 只统计reads1</strong>(统计一次indertsize)</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs R"><span class="hljs-comment">#Rscript plotInsertSize.R insertSize.txt insertSize.png</span><br><span class="hljs-comment">#plotInsertSize.R</span><br>cmd<span class="hljs-operator">=</span>commandArgs<span class="hljs-punctuation">(</span>trailingOnly<span class="hljs-operator">=</span><span class="hljs-literal">TRUE</span><span class="hljs-punctuation">)</span>;<br>input<span class="hljs-operator">=</span>cmd<span class="hljs-punctuation">[</span><span class="hljs-number">1</span><span class="hljs-punctuation">]</span>;<br>output<span class="hljs-operator">=</span>cmd<span class="hljs-punctuation">[</span><span class="hljs-number">2</span><span class="hljs-punctuation">]</span>;<br>d<span class="hljs-operator">=</span>read.table<span class="hljs-punctuation">(</span>input<span class="hljs-punctuation">)</span>;<br>png<span class="hljs-punctuation">(</span>file<span class="hljs-operator">=</span>output<span class="hljs-punctuation">)</span>;<br>hist<span class="hljs-punctuation">(</span>d<span class="hljs-operator">$</span>V1<span class="hljs-punctuation">,</span>mian<span class="hljs-operator">=</span><span class="hljs-string">&quot;&quot;</span><span class="hljs-punctuation">,</span>ylab<span class="hljs-operator">=</span><span class="hljs-string">&quot;readCount&quot;</span><span class="hljs-punctuation">,</span>xlab<span class="hljs-operator">=</span><span class="hljs-string">&quot;insertsize&quot;</span><span class="hljs-punctuation">,</span>xaxt<span class="hljs-operator">=</span><span class="hljs-string">&quot;n&quot;</span><span class="hljs-punctuation">,</span>breaks<span class="hljs-operator">=</span>seq<span class="hljs-punctuation">(</span><span class="hljs-number">0</span><span class="hljs-punctuation">,</span><span class="hljs-built_in">max</span><span class="hljs-punctuation">(</span>d<span class="hljs-operator">$</span>V1<span class="hljs-punctuation">,</span>by<span class="hljs-operator">=</span><span class="hljs-number">1</span><span class="hljs-punctuation">)</span><span class="hljs-punctuation">)</span><span class="hljs-punctuation">)</span>;<br>axis<span class="hljs-punctuation">(</span><span class="hljs-punctuation">)</span>;<br>dev.off;<br></code></pre></td></tr></table></figure><p><strong>Peak calling principle for atac</strong></p><p> <img src="/GeekFocus/./45.png" alt="1"></p><p> <img src="/GeekFocus/./46.png" alt="1"></p><p>Shift -75 往5‘端移动；<strong>nomodel 不建立双峰模型</strong>；**-SMPR对数据量标准化**</p><blockquote><p>单端测序时需要建立双峰模型推测DNA片段的长度。双端不需要</p><p>平移让Tn5切割断点处于reads正中心</p><p>-SMPR save signal per million reads</p></blockquote><p>BDG to BigWig【使用BDG转换的bigwig文件和bam转化bw，直接使用narrowpeak的区别是】</p><p>建议用bdg转换的bigwig文件，因为该文件做了平移shift和延伸extend</p><p> <img src="/GeekFocus/./47.png" alt="1"></p><p><strong>Data Quality Assesment</strong></p><p> <img src="/GeekFocus/./48.png" alt="1"></p><p><strong>Data Visualization</strong></p><p> <img src="/GeekFocus/./49.png" alt="1"></p><p><strong>Multiple Replicates</strong></p><p> <img src="/GeekFocus/./50.png" alt="1"></p><p>IDR所有点代表有overlap，红点表示富集倍数有差异，黑点表示富集倍数一致。IDR在动物里算出的结果较好，植物由于实验问题效果没那么好（不推荐？），植物直接overlap-peak。</p><p><strong>Peak annotation</strong></p><p> <img src="/GeekFocus/./51.png" alt="1"></p><p><strong>Motif analysis</strong></p><p> <img src="/GeekFocus/./52.png" alt="1"></p><p><strong>个性化分析</strong></p><p> <img src="/GeekFocus/./53.png" alt="1"></p><p>TF网络需要多组数据不同处理条件下</p><p><strong>联合分析</strong></p><p> <img src="/GeekFocus/./54.png" alt="1"></p><p>表达程度越高信号越高。</p><p><strong>案例</strong></p><p> <img src="/GeekFocus/./55.png" alt="1"></p><p> <img src="/GeekFocus/./56.png" alt="1"></p><p>H3K27me3 genebody</p><p> <img src="/GeekFocus/./57.png" alt="1"></p><p>peak-to-gene link prediction【大样本量的ATAC和RNAseq关联分析】</p><p> <img src="/GeekFocus/./58.png" alt="1"></p><hr><p><strong>CUT&amp;Tag</strong></p><p> <img src="/GeekFocus/./59.png" alt="1"></p><p>ChIP实验新方法：CUT&amp;RUN 和 CUT&amp;Tag 周期快；材料需求少；数据信噪比高</p><p><strong>C</strong>leavage <strong>U</strong>nder <strong>T</strong>argets and <strong>R</strong>elease <strong>U</strong>sing <strong>N</strong>uclease</p><p><strong>C</strong>leavage <strong>U</strong>nder <strong>T</strong>argets and <strong>Tag</strong>mentation</p><p><strong>原理介绍</strong></p><p> <img src="/GeekFocus/./60.png" alt="1"></p><p>蛋白磁珠吸附核膜，细胞绑定在磁珠上。细胞膜穿孔，pAG-MNase进入，primary Ab抗体加入。多余抗体多余pAG-MNase洗掉，<strong>pAG-MNase and primary Ab binding</strong>。加入钙离子激活，靶向位点切割，整个基因组少部分位置切割【背景噪音高低取决于抗体质量好坏】。只有切割的小片段从小孔出来(大部分背景遗留在核内)。CUT&amp;RUN用的pAG-MNase依然要补平加接头，替换为Protein-A-Tn5则变为CUT&amp;Tag，一天以内完成的”ChIP”实验。</p><p><strong>实验流程</strong></p><p> <img src="/GeekFocus/./61.png" alt="1"></p><p>文库片段分布和ATAC类似（Tn5，核小体）</p><p>IgG阴性对照帮助判断到底是ChIP峰还是ATAC峰(实验是否成功)。植物难度大，植物用原生质体。植物推荐做chip就行？动物冻存组织可尝试，植物冻存不推荐。CUT技术是针对少量细胞的。少量细胞可能数据量少。CUT&amp;Tag缺点是由于Tn5只做开放区域，若是异染色质H3K9，H3K39三甲基化这种marker做不了</p><p><strong>CUT&amp;Tag数据分析</strong></p><p> <img src="/GeekFocus/./62.png" alt="1"></p><p><strong>提升CUT&amp;Tag数据关键</strong></p><p>抗体质量：ChIP-grade；Western验证；抗体批次效应</p><p>细胞质量：活细胞比例&gt;95%(native chromatin )；细胞均一性</p><p><strong>MACS软件</strong></p><p>数据噪音评估</p><p> <img src="/GeekFocus/./63.png" alt="1"></p><p><strong>！！！Peak calling for ATAC</strong></p><p> <img src="/GeekFocus/./64.png" alt="1"></p><p><font color="red"><strong>对于ATAC，一条DNA fragment代表两个酶切位点信息，转bed格式。如果用bam文件会默认丢掉reads2</strong></font></p><p><strong>Code</strong></p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-comment">#step1 去接头</span><br><br><span class="hljs-comment">#step2 建立index</span><br>ref.fa<br>genes.gtf<br>bowtie2 build<br>samtools faidx ref.fa<br><br><span class="hljs-comment">#step3 比对</span><br>bowtie2 -x index/ref -X 1000 -1 R1.fq -2 R2.fq -S .sam<br><br><span class="hljs-comment">#step4 挑选可靠比对结果</span><br>samtools view -b -f 2 -q 30 -0 pairs.bam .sam<br><br><span class="hljs-comment">#step5 去除PCR重复</span><br>samtools <span class="hljs-built_in">sort</span> -o pairs.sorted.bam pairs.bam<br>picard.jar MarkDuplicates<br><br><span class="hljs-comment">#step6 查看mito pt 污染</span><br>samtools index pairs.sorted.dedup.bam<br>samtools idxstats pairs.sorted.dedup.bam<br><br><span class="hljs-comment">#step7 去除线粒体数据</span><br>samtools view -h pairs.sorted.dedup.bam | grep -v <span class="hljs-string">&quot;chrM&quot;</span> | grep -v <span class="hljs-string">&quot;Pt&quot;</span> | samtools view -bS -o final.bam<br><br><span class="hljs-comment">#step8 统计插入片段长度分布</span><br>Rscript plotInsertSize final.bam final.insertsize<br><br><span class="hljs-comment">#step9 peak calling</span><br>bedtools bamtobed -1 final.bam &gt; final.bam.bed<br><br>macs2 callpeak -t final.bam.bed -n rep1 --<span class="hljs-built_in">shift</span> -100 --extsize 200 --nomodel -B --SPMR -g 2e<br><br><span class="hljs-comment">#step10 TSS富集</span><br><span class="hljs-comment">#BDG to BigWig</span><br><span class="hljs-comment">#UCSC utitlities</span><br><span class="hljs-comment">#对bdg文件排序</span><br>bedSort treat.bdg treat.sort.bdg<br><span class="hljs-comment">#生成基因组各条序列长度信息，直接从bam文件得到</span><br>samtools view -H final.bam | perl -ne <span class="hljs-string">&#x27;if(/SN:(\S+)\s+LN:(\d+)/)&#123;print &quot;$1\t$2\n&quot;&#125;&#x27;</span> &gt; chrome.sizes<br><span class="hljs-comment">#生成bigwig文件</span><br>bedClip -<span class="hljs-built_in">truncate</span> treat.sort.bdg chrome.sizes stdout | perl -ane <span class="hljs-string">&#x27;print if($F[1]&lt;$F[2])&#x27;</span> &gt; treat.bdegraph<br>bedGraphToBigWig treat.bdegraph chrome.sizes treat.bw<br><br>computeMatrix reference-point -S Rep1.bw Rep2.bw -R .gtf -a 3000 -b 3000 -p 1 -o matrix.gz<br>plotHeatmap -m matrix.gz -o heatmap.png --colorMap Reds<br><br><span class="hljs-comment">#step11 peak重复性</span><br>bedtools intersect -a .peak -b .peak | <span class="hljs-built_in">wc</span> -l<br>bedtools intersect -a .peak -b .peak -f 0.5 -F 0.5 | <span class="hljs-built_in">wc</span> -l<br>idr -s rep1.peak rep2.peak -o idr --plot<br><br><span class="hljs-comment">#step12 peak在基因上的分布</span><br>Rscript PeakAnnotation.R .gtf rep1.peak Rep1<br><br></code></pre></td></tr></table></figure><hr><p>IgG？</p>]]></content>
    
    
    <categories>
      
      <category>NGS</category>
      
    </categories>
    
    
    <tags>
      
      <tag>atac-seq</tag>
      
      <tag>CUT-tag</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Assembly Gene Annotation</title>
    <link href="/GeekFocus/2022/03/18/2022-03-18-annotation/"/>
    <url>/GeekFocus/2022/03/18/2022-03-18-annotation/</url>
    
    <content type="html"><![CDATA[<p>Structural annotation and functional annotation</p><span id="more"></span><p><a href="https://phytozome-next.jgi.doe.gov/">https://phytozome-next.jgi.doe.gov</a></p><hr><h1 id="基因组注释简介"><a href="#基因组注释简介" class="headerlink" title="基因组注释简介"></a>基因组注释简介</h1><p>基因组注释主要包括四个研究方向：<strong>重复序列识别</strong>；<strong>非编码RNA预测</strong>；基因<strong>结构预测</strong>和基因<strong>功能注释</strong>。分别对四个领域阐述。</p><h2 id="1：重复序列的识别"><a href="#1：重复序列的识别" class="headerlink" title="1：重复序列的识别"></a>1：重复序列的识别</h2><p><strong>重复序列的研究背景和意义：</strong>重复序列可分为<font color="blue">串联重复序列（Tendam repeat）</font>和<font color="blue">散在重复序列(Interpersed repeat)</font>两大类。其中<strong>串联重复序列</strong>包括<font color="blue">卫星DNA，微卫星序列，小卫星序列</font>；<strong>散在重复序列</strong>又称<font color="blue">转座子元件</font>，包括以DNA-DNA方式转座的<font color="blue">DNA转座子和反转录转座子(retrotransposon)</font>。常见的反转录转座子类别有<font color="blue">LTR,LINE和SINE</font>。</p><p><strong>重复序列识别的发展现状：</strong>目前，识别<font color="blue">重复序列</font>和<font color="blue">转座子</font>的方法为<font color="red"><strong>序列比对</strong></font>和<font color="red"><strong>从头预测</strong></font>两类。<font color="blue"><strong>序列比对</strong></font>方法一般采用<font color="red"><strong>Repeatmasker</strong></font>软件，<font color="blue">识别</font>与已知重复序列<font color="blue">相似</font>的序列，并对其<font color="blue">分类</font>。常用<font color="red"><strong>Repbase</strong>重复序列数据库</font>。<font color="blue"><strong>从头预测</strong></font>方法利用重复序列或转座子<font color="blue">自身的序列或结构特征</font>构建<font color="blue"><strong>从头预测算法或软件</strong></font>对序列进行<font color="blue">识别</font>。从头预测方法的<font color="blue"><strong>优点</strong></font>在于能够根据转座子元件自身的结构特征进行预测，<font color="blue">不依赖</font>于已有转座子数据库，能够<font color="blue">发现未知</font>的转座子元件。常见的从头预测方法有<font color="red">Recon，Piler，Repeatscout,LTR-finder，ReAS</font>等。</p><p><strong>重复序列识别的研究内容：</strong>获得组装好的基因组序列后，<font color="blue"><strong>首先预测</strong></font>基因组中的<font color="blue">重复序列和转座子元件</font>。一方面，采用RepeatScout、LTR-finder、Tendem Repeat Finder、Repeatmoderler、Piler等从头预测软件<font color="red"><strong>预测重复序列</strong></font>。为了获得从头预测方法得到的重复序列的类别信息，<font color="blue">把这些序列<strong>与Repbase数据库比对</strong></font>，将能够归类的重复序列<font color="red">分类</font>。另一方面，利用<font color="red">Repeatmasker<strong>识别</strong></font>与已知重复序列<font color="blue"><strong>相似</strong>的重复序列或蛋白质序列</font>。通过构建Repbase数据库在<font color="blue"><strong>DNA水平</strong>和<strong>蛋白质水平</strong></font>的重复序列，Repeatmasker分别识别在DNA水平和蛋白质水平重复的序列，提高识别率。</p><p><strong>重复序列识别的关键技术难点：</strong></p><p>1）：<font color="blue"><strong>二代</strong></font>测序测基因组，成本低、速度快。但读长（reads）较短。由于基因组序列采用kmer算法进行组装，<strong>高度相似</strong>的<strong>重复序列</strong>可能会<strong>被压缩到一起</strong>，影响后续重复序列识别。</p><p>2）：某些<strong>高度重复序列</strong>用现有的组装方法<strong>难以组装</strong>，成为未组装reads（<strong>unassembled reads</strong>）。有必要**同时分析未组装reads?**以得到更为完整的重复序列分布图。华大开发ReAS软件，专门用于识别未组装reads中的重复序列。但该软件目前只能处理传统测序技术(如sanger测序)生成的较长片段的reads，需进一步改进方可用于分析二代reads。同时，未组装的短片段reads重复度更高，识别其重复区域具有较大难度。</p><p><strong>重复序列识别的研究方向：</strong></p><p>1）：整合现有的重复序列预测方法，对<font color="blue">组装好的基因组序列</font>进行分析。</p><p>2）：综合考虑并结合短序列组装策略，<font color="blue">校正重复序列识别</font>的结果。</p><p>3）：<font color="blue">开发识别<strong>未组装reads</strong>重复序列的算法和流程</font>并构建一致性序列。</p><h2 id="2：非编码RNA序列的预测"><a href="#2：非编码RNA序列的预测" class="headerlink" title="2：非编码RNA序列的预测"></a>2：非编码RNA序列的预测</h2><p><strong>非编码RNA预测的研究背景和意义：</strong>非编码RNA，指不被翻译成蛋白质的RNA，如tRNA, rRNA等，这些RNA不被翻译成蛋白质，但具有重要生物学功能。<font color="red"><strong>miRNA</strong></font>结合其靶向基因的mRNA序列结合，将mRNA降解或抑制其翻译成蛋白质，具有<font color="blue"><strong>沉默基因</strong></font>的功能。<font color="red"><strong>tRNA</strong></font> (转运RNA)携带氨基酸进入核糖体，使之在mRNA指导下<font color="blue"><strong>合成蛋白质</strong></font>。<font color="red"><strong>rRNA</strong></font>(核糖体RNA)与蛋白质结合<font color="blue"><strong>形成核糖体</strong></font>，其功能是作为mRNA的支架，提供mRNA翻译成蛋白质的场所。<font color="red"><strong>snRNA（小核RNA）</strong></font>主要参与<font color="blue"><strong>RNA前体加工</strong></font>，是<font color="blue"><strong>RNA剪切体</strong>主要成分</font>。</p><p><strong>非编码RNA预测的发展现状：</strong>由于ncRNA种类繁多，特征各异，缺少编码蛋白质的基因所具有的典型特征，现有的ncRNA<strong>预测软件</strong>一般<strong>专注于搜索单一种类</strong>的ncRNA，如<font color="blue">tRNAScan-SE 搜索tRNA、snoScan 搜索带C&#x2F;D盒的snoRNAs、SnoGps 搜索带H&#x2F;ACA 盒的snoRNAs、mirScan 搜索microRNA</font>等。Sanger实验室开发了<font color="blue">Infernal软件</font>，<font color="blue">建立1600多个RNA家族</font>，并对每个家族建立<font color="blue">一致性二级结构和协方差模型</font>，形成了<font color="red"><strong>Rfam数据库</strong></font>。采用Rfam数据库中的每个RNA的协方差模型，结合<font color="blue">Infernal</font>软件可以<font color="blue"><strong>预测</strong>已有<strong>RNA家族的新成员</strong></font>。Rfam&#x2F;Infernal方法应用广泛，可以预测各种RNA家族成员，但<strong>特异性较差</strong>。建议：如果有更好的专门预测某一类非编码RNA的软件，则采用该软件预测；否则，使用Rfam&#x2F;Infernal流程。</p><p><strong>非编码RNA预测的研究内容：</strong>利用Rfam家族的协方差模型，采用Rfam自带的<font color="red"><strong>Infernal软件预测miRNA</strong>和<strong>snRNA</strong>序列</font>。由于rRNA的保守性很强，用<font color="red"><strong>序列比对</strong>已知rRNA序列识别基因组中的<strong>rRNA</strong></font>序列。<font color="red"><strong>tRNAscan-SE</strong></font>工具综合多个识别和分析程序，通过分析启动子元件的保守序列模式、tRNA二级结构的分析、转录控制元件分析和除去绝大多数假阳性的筛选过程，据称能识别99%的真tRNA基因。</p><p><strong>非编码RNA预测中拟解决的关键技术难点：</strong></p><p><strong>识别非编码RNA的假基因：</strong>基因组中<font color="blue">很多序列由<strong>非编码RNA基因复制</strong>而来，与非编码RNA基因序列<strong>相似</strong>，但<strong>不具有非编码RNA的功能</strong></font>。目前采用的非编码RNA序列的预测方法都是基于序列比对和结构预测，不能够很好的去除这类非编码RNA的假基因。针对这个问题，考虑结合RNA表达信息如<strong>RNA-seq</strong>数据<strong>筛选</strong>。</p><p><strong>非编码RNA预测的研究方向：</strong></p><p>1）：专门检测小片段RNA序列的方法现在已经得到广泛应用，利用<strong>小片段RNA序列</strong>数据进行<strong>非编码RNA的预测</strong>是重要研究方向。</p><p>2）：开发<strong>miRNA靶向基因预测</strong>流程：miRNA通过调控其靶向基因的mRNA稳定性或翻译来控制生命活动的进程。预测miRNA靶向基因能够给研究miRNA功能带来提示。由于miRNA在动物和植物中对靶向基因的调控机制差别较大，建议<strong>对动物和植物分别建立靶向基因预测流程</strong>，提高预测准确度。</p><h2 id="3：基因结构预测"><a href="#3：基因结构预测" class="headerlink" title="3：基因结构预测"></a>3：基因结构预测</h2><p><strong>基因结构预测的研究背景和意义：</strong>通过基因结构预测，能够获得基因组详细的<font color="blue">基因分布和结构信息</font>，也将为<font color="blue">功能注释和进化分析</font>工作提供重要的原料。基因结构预测包括预测基因组中的<font color="red"><strong>基因位点</strong>、<strong>开放性阅读框架</strong>（ORF）、<strong>翻译起始位点和终止位点</strong>、<strong>内含子</strong>和<strong>外显子</strong>、<strong>启动子</strong>、<strong>可变剪切位点</strong>以及蛋白质<strong>编码序列</strong></font>等等。</p><p><strong>基因结构预测的发展现状：</strong> <font color="blue">原核生物</font>基因的各种信号位点（如<font color="blue">启动子和终止子</font>信号位点）<font color="blue">特异性较强</font>且容易识别，因此相应的基因预测方法已基本<font color="blue">成熟</font>。<font color="blue">Glimmer</font>是应用最广泛的<font color="blue">原核</font>生物基因结构预测软件，准确度高。而真核生物的基因预测难度大大增加。首先，真核生物中的<font color="blue">启动子和终止子等信号位点更为复杂</font>，难以识别。其次，真核生物<font color="blue">广泛存在可变剪切</font>，使<font color="blue">外显子和内含子定位更困难</font>。因此，预测真核生物的基因结构需要运用更为复杂的算法，常用的有<font color="red">隐马尔科夫模型</font>等。常用的软件有<font color="red"><strong>Genscan、SNAP、GeneMark、Twinscan</strong></font>等。</p><p><strong>基因结构预测的研究内容：</strong>基因结构预测主要通过<font color="red"><strong>序列比对结合从头预测</strong></font>。序列比对方法采用blat和pasa等比对方法，将基因组序列与外部数据进行比对，以找到可能的基因位置信息。常用的数据包括<font color="blue"><strong>物种自身</strong>或其<strong>近缘物种</strong>的<strong>蛋白质序列</strong>、<strong>EST序列</strong>、<strong>全长cDNA序列</strong>、<strong>unigene序列</strong></font>等。此方法数据<strong>依赖性很高</strong>，并且在选择数据的同时要充分<strong>考虑到</strong>物种之间的<strong>亲缘关系和进化距离</strong>。基因<font color="blue">从头预测</font>方法则是通过搜索基因组中的重要信号位点进行的。常用的软件有<font color="red"><strong>Genscan、SNAP、Augustus、Glimmer、GlimmerHMM</strong></font>等等。同时采用<font color="blue"><strong>多种方法</strong></font>进行基因预测将产生众多结果，因此最后需要对结果进行<font color="blue"><strong>整合</strong></font>以得到基因的一致性序列。常用软件有<font color="blue"><strong>Glean，EVM</strong></font>等。</p><p><strong>基因结构预测中拟解决的关键技术难点：</strong></p><p>真核生物的基因结构预测方法仍有较大改进空间，主要面临以下的技术难点。</p><p>1）：如何利用现有的数据和算法，<font color="blue">更好地识别基因的<strong>可变性剪切位点</strong></font>。</p><p>2）：随着测序工作的进展，许多目前研究较少的物种也将提上测序日程。大多基因结构的从头预测算法需要<font color="blue">预先训练预测参数</font>。<font color="blue">现有资源和数据稀缺的物种</font>将很<font color="blue">难</font>获得预测参数。</p><p>3）：克服<font color="blue">组装错误</font>对基因结果预测的影响</p><p>4）：建立基因结构预测的<font color="blue">评价系统</font>。</p><p>可变性剪切位点的预测较为困难。如何<strong>结合RNA-seq数据</strong>进行<strong>可变剪切预测</strong>将是重要的工作方向和难点。</p><p><strong>基因结构预测的研究方向：</strong></p><p>1）：利用<font color="red">RNA-seq、EST等数据<strong>校正</strong>基因结构预测</font>，识别可变剪切位点。</p><p>2）：对于<font color="red">研究较少物种</font>，建议利用<font color="red">近缘物种的同源基因数据</font>以训练基因结构预测软件。</p><p>3）：利用<font color="red">同源基因组之间的共线性信息，辅助基因结构预测</font>。</p><h2 id="4：基因功能注释"><a href="#4：基因功能注释" class="headerlink" title="4：基因功能注释"></a>4：基因功能注释</h2><p><strong>基因功能注释的研究背景和意义：</strong>获得基因结构信息后，希望进一步获得基因功能信息。基因功能注释方向包括<font color="red">预测基因中的<strong>模序</strong>和<strong>结构域</strong>、<strong>蛋白质的功能</strong>和所在<strong>生物学通路</strong>等</font>。</p><p><strong>基因功能注释的发展现状：</strong>全基因组测序将产生大量数据，而实验方法由于成本较高，不适用于全基因组测序的后续功能分析。目前普遍采用<font color="red"><strong>比对方法</strong></font>对全基因组测序的基因功能进行注释。<strong>KEGG和Gene Ontology</strong>是目前使用最为广泛的蛋白质<strong>功能数据库</strong>，分别对蛋白质的生物学通路和功能进行注释。<font color="blue"><strong>Interpro</strong></font>通过<font color="blue">整合多个记录蛋白质特征的数据库</font>，根据蛋白质<font color="blue">序列或结构中的特征</font>对<font color="blue">蛋白质分类</font>。</p><p><strong>基因功能注释的研究内容：</strong>目前利用四个常用的数据库进行基因功能注释。使用的数据库有<font color="red"><strong>Uniprot蛋白质序列数据库</strong>、<strong>KEGG生物学通路数据库</strong>、<strong>Interpro蛋白质家族数据库</strong>和<strong>Gene Ontology基因功能注释数据库</strong></font>。</p><p>1）：与Uniprot蛋白质序列数据库比对，获得<font color="blue">序列初步信息</font>。</p><p>2）：与KEGG数据库比对，预测蛋白质可能具有的<font color="blue">生物学<strong>通路</strong>信息</font>。</p><p>3）：与Interpro数据库比对将获得蛋白质的<font color="blue"><strong>保守性序列，模序和结构域</strong></font>等。</p><p>4）：预测蛋白质的功能。Interpro进一步建立了与Gene Ontology的交互系统：<font color="blue">Interpro2GO</font>。该系统记录了每个蛋白质家族与Gene Ontology中的功能节点的对应关系，通过此系统便能预测蛋白质执行的生物学功能。</p><p><strong>基因功能注释中拟解决的关键技术难点</strong>：</p><p>目前功能注释工作是建立在比对基础上，这将会带来两个比较大的问题。首先此方法<strong>严重依赖于外部数据</strong>，对某些<strong>研究较少的物种限制很大</strong>。其次，<strong>序列相似并不表示实际生物学功能相似</strong>，考虑引入序列<strong>比对之外的方法</strong>，进一步完善基因功能注释工作。</p><p>基因功能注释的研究方向：考虑引入序列比对之外的数据（如蛋白质互作网络、基因表达谱等），利用概率模型算法进行整合? 完善基因功能注释工作。</p><hr><h1 id="example"><a href="#example" class="headerlink" title="example"></a>example</h1><p><a href="https://blog.csdn.net/u012110870/article/details/82500684">https://blog.csdn.net/u012110870/article/details/82500684</a></p><p>基因组组装完成后，或者是完成了草图，就不可避免遇到一个问题，需要对基因组序列进行注释。<strong>注释之前</strong>首先得<strong>构建基因模型</strong>，有三种策略：</p><ul><li><font color="red">从头注释(de novo prediction)</font>：通过已有的概率模型来预测基因结构，在<font color="blue">预测<strong>剪切位点和UTR区准确性较低</strong></font></li><li><font color="red">同源预测(homology-based prediction)</font>：有一些基因蛋白在<font color="blue">相近物种间保守性高</font>，可使用已有的<font color="blue">高质量近缘物种注释信息</font>通过<font color="blue"><strong>序列联配</strong></font>的方式确定<font color="blue"><strong>外显子边界</strong>和<strong>剪切位点</strong></font></li><li><font color="red">基于转录组预测(transcriptome-based prediction)</font>：通过物种的RNA-seq数据辅助注释，能够较为准确的<font color="blue">确定<strong>剪切位点</strong>和<strong>外显子区域</strong></font>。<br>每种方法都有自己的优缺点，所以最后需要用<font color="blue"><strong>EvidenceModeler(EVM)<strong>和</strong>GLEAN</strong>工具<strong>整合</strong></font>，合并成完整的基因结构。<font color="red">基于<strong>可靠的基因结构</strong>，后续可才是<strong>功能注释</strong>，<strong>蛋白功能域注释</strong>，<strong>GO注释</strong>，<strong>通路注释</strong></font>等。</li></ul><p>那么基因注释重要吗？非常重要！尤其是高通量测序价格下降。花不到一万的价格对600M的物种进行100X的普通文库测序，然后拼接出草图。但是这个草图的价值还需要注释后才能显现。<br>从案例中学习套路</p><p>陆地棉基因组注释</p><p>文章标题为“Sequencing of allotetraploid cotton (Gossypium hirsutum L. acc. TM-1) provides a resource for fiber improvement”.</p><p><font color="blue">同源注释</font>：从Phytozome上下载了7个植物的<font color="blue">基因组蛋白序列</font>(Arabidopsis thaliana, Carica papaya, Glycine max, G. raimondii, Populus trichocarpa, Theobroma cacao and Vitis vinifera), 使用<font color="blue"> <strong>TblastN</strong></font> 将<font color="blue">蛋白序列比对到组装序列</font>，E-value的阈值为<font color="blue"><strong>1e-5</strong></font>. 将不同蛋白的BLAST的<font color="blue">hits</font>用 <font color="blue"><strong>Solar</strong> 软件合并</font>。<font color="blue"><strong>GeneWise</strong></font> 根据每个BLAST hit的对应基因区域预测完整的基因结构。</p><p><font color="blue">从头预测</font>：<strong>先</strong>得构建<strong>repeat-mask</strong> genome， 在这个基础上就用 <strong>August</strong>, Genescan, GlimmerHMM, Geneid 和 <strong>SNAP</strong> 预测编码区</p><p><font color="blue">转录组预测</font>：用<strong>Tophat将RNA-seq数据</strong>比对到组装序列上，然后用<strong>cufflinks</strong>组装转录本形成基因模型。</p><p>综上，使用 EvidenceModeler(EVM) 将上面的结果组装成非冗余的基因结构。进一步根据Cscore &gt; 0.5，peptide coverage &gt; 0.5 和CDS overlaping with TE进行筛选。还有过滤掉超过30%编码区被Pfam或Interprot TE domain的注释的基因模型。</p><p>这些基因模型使用<strong>BLASTP进行功能注释</strong>，所用数据库为SWiss-Prot和TrEMBL.<font color="blue">蛋白功能</font>使用InterProScan和HMMER注释，数据库为InterPro和Pfam。<font color="blue">GO注释</font>则是直接雇佣InterPro和Pfam注释得到的对应entry。<font color="blue">通路注释</font>使用KEGG数据库。</p><p>Cardamine hirsuta基因组注释</p><p>文章标题为“The Cardamine hirsuta genome offers insight into the evolution of morphological diversity”。</p><p>同源注释：使用 GenomeThreader 以拟南芥为剪切模型，以及PlantsGDB resourc上 Brassica rapa (v1.1), A. thaliana(TAIR10), A. lyrata (v6), tomato (v3.6), poplar (v2) 和 A. thaliana (version PUT-169), B. napus (version PUT-172) EST assemblies 的完整的代表性蛋白集。</p><p>转录本预测： 将 C. hirsuta RNA-seq数据比对到基因序列，然后用cufflinks拼接</p><p>从头预测：转录本预测得到的潜在蛋白编码转录本使用网页工具 ORFpredictor 进行预测， 同时用 blastx 和 A. thalina 进行比较，选择90%序列相似度和最高5%长度差异的部分从而保证保留完整的编码框(有启动子和终止子)。 这些基因模型根据相互之间的相似度和重叠度进行聚类，高度相似(&gt;95)从聚类中剔除，保证非冗余训练集。为了训练gene finder, 它们选随机选取了2000个位点，20%是单个外显子基因。从头预测工具为 August , GlimmerHMM, Geneid 和 SNAP . 此外还用了Fgenesh+, 以双子叶特异矩阵为参数进行预测。</p><p>最后使用JIGSAW算法根据以上结果进行训练，随后再次用JIGSAW对每个基因模型计算统计学权重。</p><p>可变剪切模型则是基于苗、叶、花和果实的RNA-seq比对组装结果。</p><p>GO注释使用AHRD流程</p><p>小结</p><p>举的2个例子都是植物，主要是植物基因组不仅是组装，注释都是一大难题。因为植物基因组有大量的重复区，假基因，还有很多新的蛋白编码基因和非编码基因，比如说玉米基因组80%以上都是重复区域。然后当我检索这两篇文章所用工具的时候，我不经意或者说不可避免就遇到了这个网站 <a href="http://www.plantgdb.org/">http://www.plantgdb.org/</a> , 一个整合植物基因组学工具和资源的网站，但是这个网站似乎2年没有更新了。当然这个网站也挺不错,<a href="http://bioservices.usd.edu/gsap.html">http://bioservices.usd.edu/gsap.html</a>, 他给出了一套完整的注释流程以及每一步的输入和输出情况。</p><p>此外，2017年在《Briefings in Bioinformatics》发表的”Plant genome and transcriptome annotations: from misconceptions to simple solution” 则是从五个角度对植物基因组注释做了很完整的总结</p><p>植物科学的常见本体<br>功能注释的常用数据库和资源<br>已注释的植物基因组意味着什么<br>一个自动化注释流程<br>一个参考流程图，用来说明使用公用数据库注释植物基因组&#x2F;转录组的常规步骤<br><img src="/GeekFocus/2022-03-18-annotation/1.png" alt="注释流程图"></p><p><img src="/GeekFocus/./1.png" alt="注释流程图"></p><p>基因组注释</p><p>当我们谈到基因注释的时候，我们通常认为注释是指“对基因功能的描述”，比如说A基因在细胞的那个部分，通过招募B来调控C，从而引起病变。但是基因结构也是注释的一种形式，而且是先决条件，也就是在看似随机的ATCG的碱基排列中找到特殊的部分，而这些特殊的区域有着不一样的功能。<br><img src="/GeekFocus/2022-03-18-annotation/2.png" alt="gene structure"></p><p><img src="/GeekFocus/./2.png" alt="gene structure"></p><p>在<font color="blue">正式启动基因组注释</font>项目之前，需要先检查组装是否合格，比如contig N50的长度是否大于基因的平均长度，使用BUSCO&#x2F;CEGMA检查基因的完整性，如果不满足要求，可能输出结果中大部分的contig中都不存在一个完整的基因结构。当组装得到的contig符合要求时，就可以开始基因组注释环节，这一步分为三步：<font color="blue"><strong>基因结构预测</strong>，基因<strong>功能注释</strong>，<strong>可视化</strong>和<strong>质控</strong></font>。<br>基因组结构注释</p><p>基因结构注释应是功能注释的先决条件，完整的真核生物基因组注释流程需要如下步骤：</p><ul><li><p>必要的基因组<font color="blue">重复序列屏蔽</font></p></li><li><p><font color="blue">从头寻找基因</font>, 可用工具为: GeneMarkHMM, FGENESH, Augustus, SNAP, GlimmerHMM, Genscan</p></li><li><p><font color="blue">同源蛋白预测, 内含子分析</font>: GeneWIse, Exonerate, GenomeThreader</p></li><li><p>将EST序列，全长cDNA序列和Trinity&#x2F;Cufflinks&#x2F;Stringtie组装的转录组和基因组<font color="blue">联配</font></p></li><li><p>如果第4步用到了多个数据来源，使用<font color="blue">PASA基于重叠情况进行联配</font></p></li><li><p>使用<font color="blue">EvidenceModler</font>根据上述结果进行整合</p></li><li><p>使用PASA更新EVM的一致性预测，增加UTR注释和可变剪切注释</p></li><li><p>必要的人工检查</p><p>基本上是套路化的分析流程，也就有一些工具通过整合几步开发了流程管理工具，比如说<font color="blue">BRAKER结合GeneMark和Augustus</font>，<font color="blue">MAKER2整合了SNAP,Exonerate</font>，虽然BRAKER说自己的效果比MAKER2好，但是用的人似乎不多，根据web of knowledge统计，两者的引用率分别是44,283, 当然BRAKER是2016，MAKER2是2011，后者在时间上有优势。</p></li></ul><p>这里准备先按部就班的按照流程进行注释，所用的数据是 Cardamine hirsuta , 数据下载方式如下</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-comment"># Cardamine hirsutat【基因组数据】</span><br><span class="hljs-built_in">mkdir</span> chi_annotation &amp;&amp; <span class="hljs-built_in">cd</span> chi_annotation<br>wget http://chi.mpipz.mpg.de/download/sequences/chi_v1.fa<br><span class="hljs-built_in">cat</span> chi_v1.fa | <span class="hljs-built_in">tr</span> <span class="hljs-string">&#x27;atcg&#x27;</span> <span class="hljs-string">&#x27;ATCG&#x27;</span> &gt; chi_unmasked.fa<br><span class="hljs-comment"># 【注释结果】</span><br>wget http://chi.mpipz.mpg.de/download/annotations/carhr38.gff<br><span class="hljs-comment"># Cardamine hirsutat【转录组数据】</span><br><span class="hljs-built_in">mkdir</span> rna-seq &amp;&amp; <span class="hljs-built_in">cd</span> rna-seq<br>wget -4 -q -A <span class="hljs-string">&#x27;*.fastq.gz&#x27;</span> -np -nd -r 2 http://chi.mpipz.mpg.de/download/fruit_rnaseq/cardamine_hirsuta/ &amp;<br>wget -4 -q -A <span class="hljs-string">&#x27;*.fastq.gz&#x27;</span> -np -nd -r 2 http://chi.mpipz.mpg.de/download/leaf_rnaseq/cardamine_hirsuta/ &amp;<br><br><br></code></pre></td></tr></table></figure><p>软件安装不在正文中出现，会放在附录中，除了某些特别复杂的软件。</p><h2 id="01-重复序列屏蔽RepeatMasker"><a href="#01-重复序列屏蔽RepeatMasker" class="headerlink" title="01-重复序列屏蔽RepeatMasker"></a><strong>01-重复序列屏蔽RepeatMasker</strong></h2><p>重复屏蔽：真核生物的基因组存在大量的重复序列，植物基因组的重复序列甚至可以高达80%。尽管重复序列对维持染色体的空间结构、基因的表达调控、遗传重组等都具有重要作用，但是却会导致BLAST的结果出现大量假阳性，增加基因结构的预测的计算压力甚至影响注释正确性。基因组中的重复按照序列特征可以分为两类：<font color="blue">串联重复(tandem repeats)和散在重复(interspersed repeats)</font>.<br><img src="/GeekFocus/2022-03-18-annotation/3.png" alt="人类中的重复序列划分"></p><p><img src="/GeekFocus/./3.png" alt="人类中的重复序列划分"></p><p>鉴定基因组重复区域的方法有两种：一种基于<font color="blue">文库(library)的同源(homology)</font>方法，该文库收集了<font color="blue">其他物种的某一种重复的一致性序列</font>，通过<font color="blue">相似性鉴定重复</font>；另一种是<font color="blue">从头预测(de novo)</font>，将序列和自己比较或者是<font color="blue">高频K-mer</font>来鉴定重复。</p><p>目前重复序列注释主要软件就是<font color="red"><strong>RepeatMasker</strong>和<strong>RepeatModel</strong></font>。这里要注意分析的<strong>fasta的ID不能过长</strong>，不然会报错。如果序列ID过长可以使用bioawk进行转换，后续用到RepatModel不支持多行存放序列的fasta格式。</p><p>直接使用<font color="blue">同源注释工具RepeatMasker</font>寻找重复序列：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-built_in">mkdir</span> 00-RepeatMask<br>~/opt/biosoft/RepeatMasker/RepeatMasker -e ncbi -species arabidopsis -pa 40 -gff -<span class="hljs-built_in">dir</span> 00-RepeatMask/ chi_unmasked.fa<br><span class="hljs-comment"># -e ncbi</span><br><span class="hljs-comment"># -species 选择物种 用~/opt/biosoft/RepeatMasker/util/queryRepeatDatabase.pl -tree 了解</span><br><span class="hljs-comment"># -lib 增加额外数据库,</span><br><span class="hljs-comment"># -pa 并行计算</span><br><span class="hljs-comment"># -gff 输出gff注释</span><br><span class="hljs-comment"># -dir 输出路径</span><br><span class="hljs-comment"># annotation with the library produced by RepeatModel</span><br><span class="hljs-comment">#-dir 指定的输出结果路径，必须提前建立好，否则无结果</span><br><span class="hljs-comment">#一定要通过 -species 指定物种，否则默认比对的是人类重复序列数据库</span><br><span class="hljs-comment">#如果使用本地的参考库，通过 -lib 指定，替代 -species</span><br><span class="hljs-comment">#-s、-q、-qq 等参数可控制序列比对的灵敏度，如果你的目标物种和参考物种不是很近，可能需要提升灵敏度</span><br></code></pre></td></tr></table></figure><p>输出结果中主要关注如下三个(其中xxx表示一类文件名)</p><ul><li>xxx.fa.masked, 将重复序列用N代替</li><li>xxx.fa.out.gff, 以gff2形式存放重复序列出现的位置</li><li>xxx.fa.tbl, 该文件记录着分类信息</li></ul><figure class="highlight asciidoc"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs asciidoc"><span class="hljs-section">cat 00-RepeatMask/chi_unmasked.fa.tbl</span><br><span class="hljs-section">==================================================</span><br>file name: chi_unmasked.fa<br>sequences:           624<br>total length:  198654690 bp  (191241357 bp excl N/X-runs)<br>GC level:         35.24 %<br><span class="hljs-section">bases masked:   35410625 bp ( 17.83 %)</span><br><span class="hljs-section">==================================================</span><br><br></code></pre></td></tr></table></figure><p>也就是说该物种198M中有将<font color="blue">近18%的重复序列</font>，作为参考，拟南芥125Mb 14%重复序列, 水稻389M，36%重复，人类基因组是3G，50%左右的重复序列。</p><p>使用最后的<font color="blue">chi_unmasked.fa.masked</font>用于<font color="blue">下一步的基因结构预测</font>。</p><h3 id="RepeatMasker使用注意"><a href="#RepeatMasker使用注意" class="headerlink" title="RepeatMasker使用注意"></a>RepeatMasker<a href="https://www.jianshu.com/p/ffdbedae80fa">使用注意</a></h3><p>首先确定数据库中是否收录了目标物种<br>（一）Repbase配置好后，直接通过安装目录中的“RepeatMasker&#x2F;util&#x2F;queryRepeatDatabase.pl”，即可查看当前库中已存在的物种。</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-comment">#查看物种列表</span><br><span class="hljs-built_in">cd</span> RepeatMasker<br>./util/queryRepeatDatabase.pl -tree &gt; species.txt<br>less -S species.txt<br><span class="hljs-comment">#目标物种，这里为 Fusarium tricinctum，我们可直接查看 Fusarium 属所有的</span><br>grep <span class="hljs-string">&#x27;Fusarium&#x27;</span> species.txt<br></code></pre></td></tr></table></figure><p>（二）或者参看“RepeatMasker&#x2F;Libraries&#x2F;taxonomy.dat”中的物种信息，所有已收录物种的名称都存储在该文件中。</p><p>（三）若无法在现有的Repbase库中找到合适参考集，除了<strong>使用近缘物种代替</strong>外，还可考虑基于当前的全基因组序列，执行<strong>重复序列的denovo预测</strong>，如<a href="https://links.jianshu.com/go?to=http://blog.sciencenet.cn/blog-3406804-1202562.html">RepeatModeler</a>等工具，训练重复序列集构建<strong>本地repeat library</strong>，运行RepeatMasker时通过“**-lib<strong>”参数</strong>指定本地repeat library**。</p><p>此外，也并不是说找到参考物种就完全可行。<font color="blue">参考库中的信息可能并不全，没有将目标物种基因组覆盖完全，由此会导致基因组重复序列<strong>识别较少</strong></font>。<font color="blue"><strong>同时多找几个近缘物种</strong></font>的参考库作比对，更改RepeatMasker参数把灵敏度调高（或者将RMBlast替换为更灵敏的工具）等，<font color="blue"><strong>尽可能找到更多的重复序列</strong></font>。如果最大原因仍是<font color="blue">数据库本身不全</font>所致，其实更改参数之类的提升效果也甚微。此时可能<strong>需要考虑执行重复序列的denovo预测</strong>，如RepeatScout、<strong>RepeatModeler</strong></p><h2 id="RepeatModel"><a href="#RepeatModel" class="headerlink" title="RepeatModel"></a>RepeatModel</h2><p>注：当然也可以用<font color="blue">RepeatModel进行<strong>从头预测</strong></font>，得到的预测结果后续可以整合到RepeatMasker</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-comment"># de novo predict</span><br>/programs/RepeatModeler/BuildDatabase -name pyu -engine ncbi pyu_contig.fasta /programs/RepeatModeler/RepeatModeler -pa 2 -engine ncbi -database pyu &gt;&amp; repeatmodeler.log<br></code></pre></td></tr></table></figure><p>这一步速度<font color="blue">极其慢??</font>，由于目的只是<strong>获取屏蔽后序列降低后续从头预测的压力</strong>，所以可先<strong>不做</strong>这一步。在后续分析重复序列在基因组进化上的作用时可以做这一步。</p><p>如果从头预测的结果与同源预测的结果有30%以上的overlap，并且分类不一致，会把从头预测的结果过滤掉。从头预测与同源预测结果有overlap，但是分类一致的，都会保留。但是统计的时候不会重复统计。</p><h2 id="02-从头-ab-initio-预测基因"><a href="#02-从头-ab-initio-预测基因" class="headerlink" title="02-从头(ab initio)预测基因"></a><strong>02-从头(ab initio)预测基因</strong></h2><p>基于已有模型或无监督训练</p><p>目前的<font color="blue">从头预测软件大多是基于HMM(隐马尔科夫链)和贝叶斯理论</font>，通过<font color="blue">已有物种注释信息对软件进行训练</font>，从训练结果中去推断一段基因序列中可能的结构，在这方面做的最好的工具是<font color="red"><strong>AUGUSTUS</strong></font> 它可以仅使用序列信息进行预测，也可以整合EST, cDNA, RNA-seq数据作为先验模型进行预测。</p><h3 id="AUGUSTUS"><a href="#AUGUSTUS" class="headerlink" title="AUGUSTUS"></a>AUGUSTUS</h3><p>AUGUSTUS的无root安装比较麻烦，我折腾了好几天最后卒，不过辛亏有bioconda，<font color="blue">conda create -n annotation augustus&#x3D;3.3</font>.</p><p>它的使用看起来很简单，可以尝试使用一段拟南芥已知的基因序列让其预测，比如前8k序列</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs stylus">seqkit faidx TAIR10<span class="hljs-selector-class">.fa</span> Chr1:<span class="hljs-number">1</span>-<span class="hljs-number">8000</span> &gt; test<span class="hljs-selector-class">.fa</span><br>augustus <span class="hljs-attr">--speices</span>=arabidopsis test<span class="hljs-selector-class">.fa</span> &gt; test.gff<br></code></pre></td></tr></table></figure><p>如果仅仅看两者的CDS区，结果完全一致，相当于看过一遍参考答案去做题目，题目都做对了。<font color="blue">augustus –species&#x3D;help</font></p><blockquote><p>注:已经被训练的物种信息可以用<code>augustus --species=help</code>查看。</p></blockquote><p><img src="/GeekFocus/2022-03-18-annotation/4.png" alt="结果比较"></p><p><img src="/GeekFocus/./4.png" alt="结果比较"></p><p>在<strong>不使用RNA-seq数据</strong>的情况下，可以基于拟南芥的训练模型进行预测，采用下面的方式<font color="blue">多条染色体并行augustus</font></p><figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs vim"><span class="hljs-built_in">mkdir</span> <span class="hljs-number">01</span>-augustsus &amp;&amp; <span class="hljs-keyword">cd</span> <span class="hljs-number">01</span>-augustsus<br><span class="hljs-keyword">ln</span> ../<span class="hljs-number">00</span>-RepeatMask/chi_unmasked.fa.masked genome.fa<br>seqkit <span class="hljs-keyword">split</span> genome.fa #结果文件在genome.fa.<span class="hljs-keyword">split</span><br><span class="hljs-keyword">find</span> genome.fa.<span class="hljs-keyword">split</span>/ -<span class="hljs-built_in">type</span> <span class="hljs-keyword">f</span> -name <span class="hljs-string">&quot;*.fa&quot;</span> | parallel -<span class="hljs-keyword">j</span> <span class="hljs-number">30</span> augustus --species=arabidopsis --gff3=<span class="hljs-keyword">on</span> &gt;&gt; temp.gff #并行处理<br>join_aug_pred.pl &lt; temp.gff  | <span class="hljs-keyword">grep</span> -v <span class="hljs-string">&#x27;^#&#x27;</span> &gt; temp.joined.gff<br>bedtools <span class="hljs-keyword">sort</span> -i temp.joined.gff &gt; augustsus.gff<br><br></code></pre></td></tr></table></figure><h3 id="GeneMark-ES-x2F-ET"><a href="#GeneMark-ES-x2F-ET" class="headerlink" title="GeneMark-ES&#x2F;ET"></a>GeneMark-ES&#x2F;ET</h3><p>AUGUSTUS依赖于已有的模型，而<strong>GeneMark-ES&#x2F;ET</strong>则是唯一一款支持<font color="blue">无监督训练模型</font>，之后再识别真核基因组蛋白编码区的工具。</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs stylus">gmes_petap<span class="hljs-selector-class">.pl</span> <span class="hljs-attr">--ES</span> <span class="hljs-attr">--sequence</span> genome<span class="hljs-selector-class">.fa</span> <span class="hljs-attr">--cores</span> <span class="hljs-number">50</span><br></code></pre></td></tr></table></figure><p>最后得到的是genemark.gtf，是标准的GTF格式，可以使用Sequence Ontology Project提供的<font color="blue">gtf2gff3.pl</font>进行转换</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs awk">wget http:<span class="hljs-regexp">//g</span>enes.mit.edu<span class="hljs-regexp">/burgelab/mi</span>so<span class="hljs-regexp">/scripts/g</span>tf2gff3.pl<br>chmod <span class="hljs-number">755</span> gtf2gff3.pl<br>gtf2gff3.pl genemark.gtf | bedtools sort -i - &gt; genemark.gff<br><br></code></pre></td></tr></table></figure><p>不同从头预测软件的实际效果可以通过在<font color="red">IGV中加载文章<strong>提供的gff文件</strong>和<strong>预测后的gff文件</strong>进行比较</font>，一般会存在如下几个问题：</p><ul><li><p>基因多了，或者少了，也就是假阳性和假阴性现象</p></li><li><p><font color="red">UTR区域难以预测，比较正常</font></p></li><li><p>未正确识别可变剪切位点，导致前后几个基因识别成一个基因</p><p>考虑到转录组测序已经非常便宜，可以通过该物种的RNA-seq提供覆盖度信息进行预测。</p></li></ul><h3 id="Maker"><a href="#Maker" class="headerlink" title="Maker"></a>Maker</h3><p>Genome annotation with Maker</p><p><a href="https://training.galaxyproject.org/training-material/topics/genome-annotation/tutorials/annotation-with-maker/tutorial.html">https://training.galaxyproject.org/training-material/topics/genome-annotation/tutorials/annotation-with-maker/tutorial.html</a></p><h2 id="基于转录组数据预测"><a href="#基于转录组数据预测" class="headerlink" title="基于转录组数据预测"></a>基于转录组数据预测</h2><p>根据已有的模型或者自训练可以正确预测很大一部分的基因，但如果需要提高预测的正确性，还需要额外的信息。在过去就需要提供物种本身的cDNA, EST，而现在更多的是基于转录组序列进行训练。尽管<font color="blue">RNA-seq数据在基因组上的<strong>比对</strong>情况能够<strong>推测内含子</strong>位置，根据<strong>覆盖度</strong>可以推测出<strong>外显子和非编码区</strong>的边界</font>，但是仅<font color="blue">仅依赖于RNA-seq的覆盖<strong>不能可信地推测出蛋白编码区</strong></font>(Hoff K.J. Stanke M. 2015).</p><p><font color="red">AUGUSTUS</font>可以利用转录组比对数据中的<strong>位置信息</strong>来训练模型，<font color="red">GeneMark-ET</font>可以利用RNA-seq得到的<strong>内含子位点</strong>信息自我训练HMM参数，进行基因预测。<font color="red"><strong>BRAKER2</strong></font>将两者进行整合，使用GeneMark-ET根据RNA-seq无监督训练模型寻找基因，然后用AUGUSTUS进行模型训练，最后完成基因预测<br><img src="/GeekFocus/2022-03-18-annotation/5.png" alt="BRAKER流程"></p><p><img src="/GeekFocus/./5.png" alt="BRAKER流程"></p><p>首先使用hisat2根据<font color="blue"><strong>屏蔽</strong>后的参考序列建立索引</font>，进行<strong>比对</strong>。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 项目根目录</span><br><span class="hljs-built_in">mkdir</span> index<br>hisat2-build 01-augustus/genome.fa index/chi_masked<br><br>hisat2 -p 20 -x index/chi_masked -1 rna-seq/leaf_ox_r1_1.fastq.gz -2 rna-seq/leaf_ox_r1_2.fastq.gz | samtools <span class="hljs-built_in">sort</span> -@ 10 &gt; 02-barker/leaf_ox_r1.bam &amp;<br><br>hisat2 -p 20 -x index/chi_masked -1 rna-seq/ox_flower9_rep1_1.fastq.gz -2 rna-seq/ox_flower9_rep1_2.fastq.gz | samtools <span class="hljs-built_in">sort</span> -@ 10 &gt; 02-barker/ox_flower9.bam &amp;<br><br>hisat2 -p 20 -x index/chi_masked -1 rna-seq/ox_flower16_rep1_1.fastq.gz -2 rna-seq/ox_flower16_rep1_2.fastq.gz | samtools <span class="hljs-built_in">sort</span> -@ 10 &gt; 02-barker/ox_flower16.bam &amp;<br><br></code></pre></td></tr></table></figure><p>然后，以<font color="blue"><strong>未屏蔽重复序列的参考序列</strong>和<strong>BAM</strong>文件作为输入</font>，让BRAKER2（安装会稍显麻烦，因为依赖许多软件）进行<strong>预测</strong>。</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs routeros">braker.pl --gff3 --cores 50 <span class="hljs-attribute">--species</span>=carhr <span class="hljs-attribute">--genome</span>=chi_unmasked.fa <span class="hljs-attribute">--bam</span>=02-barker/leaf_ox_r1.bam,02-barker/ox_flower16.bam,02-barker/ox_flower9.bam<br><span class="hljs-comment"># --gff3: 输出GFF3格式</span><br><span class="hljs-comment"># --genome: 基因组序列</span><br><span class="hljs-comment"># --bam: 比对后的BAM文件，【允许多个】</span><br><span class="hljs-comment"># --cores: 处理核心数</span><br><br></code></pre></td></tr></table></figure><p>最后会得到如下输出文件</p><ul><li><p>hintsfile.gff: 从RNA-seq比对结果的<strong>BAM文件中提取</strong>，其中内含子用于训练GeneMark-EX, 使用所有特征训练AUGUSTUS</p></li><li><p>GeneMark-ET&#x2F;genemark.gtf: <strong>GeneMark-EX</strong>根据<strong>RNA-seq</strong>数据<strong>训练后预测</strong>的基因</p></li><li><p>augustus.hints.gff: <strong>AUGUSTUS输出</strong>文件</p><p>将augustus.hints.gff3和文章的注释文件(carhr38.gtf)比较，见下图：<br><img src="/GeekFocus/2022-03-18-annotation/6.png" alt="结果比较"></p><p><img src="/GeekFocus/./6.png" alt="结果比较"></p></li></ul><p>其实不难发现，在不考虑UTR区域情况下，两者的差别其实更多表现是基因数目上，其实也就是利用转录组数据推测结构的问题所在，没有覆盖的区域到底是真的没有基因，还是有基因结构只不过所用组织没有表达，或者说那个区域其实是假基因？此外，如果基因间隔区域很短，有时候还会错误地把两个不同的基因预测为一个基因。因此，应该注重RNA-seq数据在剪切位点识别和外显子边界确定的优势。</p><h2 id="03-同源预测基因结构"><a href="#03-同源预测基因结构" class="headerlink" title="03-同源预测基因结构"></a><strong>03-同源预测基因结构</strong></h2><p>同源预测(homology prediction)利用近缘物种<strong>已知基因进</strong>行<strong>序列比对</strong>，找到同源序列。然后在同源序列的基础上，根据基因信号如<strong>剪切信号</strong>、<strong>基因起始和终止密码子</strong>对基因结构进行预测</p><p>相对于从头预测的“大海捞针”，同源预测相当于先用一块磁铁在基因组大海中缩小可能区域，然后从可能区域中鉴定基因结构。<strong>10年前</strong>，当时RNA-seq还没有普及, 只有<strong>少部分物种</strong>才有<strong>EST序列和cDNA序列</strong>的情况下，这的确是一个比较好的策略，那么问题来了，现在还需要进行这一步吗，如果需要是出于那种角度考虑呢?</p><p>在同源预测上，目前大部分基因组文章都是基于<strong>TBLASTN + GeneWise</strong>，因为大部分基因组文章都是国内做的，这些注释是公司的流程，国内公司大多数又和某一家公司有关系? 不过最近的3010水稻泛基因组用的是<strong>MAKER</strong>, 感谢部分提到这部分工作是由M. Roa(Philippine Genome Center Core Facilities for Bioinformatics, Department of Science)做的。<strong>Cardamine hirsuta文章</strong>，同源注释部分用的是<strong>GenomeThreader</strong>。</p><p>GeneWise网站目前由Ewan Birney维护，不继续开发，因为Guy Slater开发<strong>Exonerate</strong>解决GeneWise存在的很多问题，并且速度快1000倍。考虑到目前只有GeneWise能利用HMM根据蛋白找DNA，而且ENSEMBL的注释流程也有一些核心模块用到了它，所以作者依旧在缓慢的开发这个工具(自2.4.1已经10多年没有更新了)，当然这个工具也是非常的慢。尽管这一步不会用到GeneWise作为我们的同源注释选项，但是可以尝试用<strong>GeneWise手工注释一个基因</strong>，主要步骤如下</p><ul><li>第一步：使用BLASTX，根据DNA序列搜索蛋白质序列，只需第一个最佳比对结果</li><li>第二步：先择最佳比对的氨基酸序列</li><li>第三步：将DNA序列前后延长2kb，与氨基酸序列一并传入genewise进行同源预测</li></ul><p><strong>(1)</strong> 提取前5K序列，然后选择在TAIR上用<strong>BLASTX</strong>进行比对</p><blockquote><p>seqkit faidx chi_unmasked.fa Chr1:1-5000 &gt; chr1_5k.fa</p></blockquote><p><font color="green"><strong>提取序列 30，0000～40，0000 ：seqkit faidx chi_unmasked.fa Chr1:300000-400000</strong></font></p><p><img src="/GeekFocus/2022-03-18-annotation/7.png" alt="BLASTX"></p><p><img src="/GeekFocus/./7.png" alt="BLASTX"></p><p><strong>(2)</strong> 选择第一个比对结果中的氨基酸序列，和前5k的DNA序列一并作为GeneWise的输入</p><p><img src="/GeekFocus/2022-03-18-annotation/8.png" alt="GeneWise2"></p><p><img src="/GeekFocus/./8.png" alt="GeneWise2"></p><p>最后的结果出乎了我的意料</p><p><img src="/GeekFocus/2022-03-18-annotation/9.png" alt="预测结果"></p><p><img src="/GeekFocus/./9.png" alt="预测结果"></p><p>让我们跳过这个尴尬的环节，毕竟很可能是我不太熟练使用工作所致。这里说点我的看法，除非你真的没有转录组数据，必须要用到同源物种的蛋白进行预测，或者你手动处理几个基因，否则不建议使用这个工具，因为你可能连安装都搞不定。</p><p>用<strong>GenomeThreader</strong>基于上面的<strong>DNA序列</strong>和氨基酸序列<strong>进行同源基因结构预测</strong></p><figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs nginx"><span class="hljs-attribute">gth</span> -genomic chr1_5k.fa -protein cer.fa -intermediate -gff3out<br><span class="hljs-comment"># 其中cer.fa就是AT1G02205.2的氨基酸序列</span><br></code></pre></td></tr></table></figure><p>结果一致，并且从RNA-seq的覆盖情况也符合预期</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">Chr1</span>gthexon<span class="hljs-number">1027</span><span class="hljs-number">1197</span>Parent=gene1Chr1    MIPS_CARH_v3.<span class="hljs-number">8</span>  exon    <span class="hljs-number">1027</span>    <span class="hljs-number">1197</span><br><span class="hljs-attribute">Chr1</span>gthexon<span class="hljs-number">1275</span><span class="hljs-number">1448</span>Parent=gene1Chr1    MIPS_CARH_v3.<span class="hljs-number">8</span>  exon    <span class="hljs-number">1275</span>    <span class="hljs-number">1448</span><br><span class="hljs-attribute">Chr1</span>gthexon<span class="hljs-number">1541</span><span class="hljs-number">1662</span>Parent=gene1Chr1    MIPS_CARH_v3.<span class="hljs-number">8</span>  exon    <span class="hljs-number">1555</span>    <span class="hljs-number">1662</span><br><span class="hljs-attribute">Chr1</span>gthexon<span class="hljs-number">1807</span><span class="hljs-number">2007</span>Parent=gene1Chr1    MIPS_CARH_v3.<span class="hljs-number">8</span>  exon    <span class="hljs-number">1807</span>    <span class="hljs-number">2007</span><br><span class="hljs-attribute">Chr1</span>gthexon<span class="hljs-number">2085</span><span class="hljs-number">2192</span>Parent=gene1Chr1    MIPS_CARH_v3.<span class="hljs-number">8</span>  exon    <span class="hljs-number">2085</span>    <span class="hljs-number">2192</span><br><span class="hljs-attribute">Chr1</span>gthexon<span class="hljs-number">2294</span><span class="hljs-number">2669</span>Parent=gene1Chr1    MIPS_CARH_v3.<span class="hljs-number">8</span>  exon    <span class="hljs-number">2294</span>    <span class="hljs-number">2669</span><br><span class="hljs-attribute">Chr1</span>gthexon<span class="hljs-number">3636</span><span class="hljs-number">3855</span>Parent=gene1Chr1    MIPS_CARH_v3.<span class="hljs-number">8</span>  exon    <span class="hljs-number">3636</span>    <span class="hljs-number">3855</span><br><span class="hljs-attribute">Chr1</span>gthexon<span class="hljs-number">3971</span><span class="hljs-number">4203</span>Parent=gene1Chr1    MIPS_CARH_v3.<span class="hljs-number">8</span>  exon    <span class="hljs-number">3971</span>    <span class="hljs-number">4203</span><br><span class="hljs-attribute">Chr1</span>gthexon<span class="hljs-number">4325</span><span class="hljs-number">4548</span>Parent=gene1Chr1    MIPS_CARH_v3.<span class="hljs-number">8</span>  exon    <span class="hljs-number">4325</span>    <span class="hljs-number">4548</span><br><span class="hljs-attribute">Chr1</span>gthexon<span class="hljs-number">4676</span><span class="hljs-number">4735</span>Parent=gene1Chr1    MIPS_CARH_v3.<span class="hljs-number">8</span>  exon    <span class="hljs-number">4676</span>    <span class="hljs-number">4735</span><br><br><br></code></pre></td></tr></table></figure><p>全基因组范围预测流程如下：</p><p><strong>准备cDNA和或protein序列</strong>：在<a href="https://phytozome.jgi.doe.gov/p%E4%B8%8B%E8%BD%BD**%E9%9D%A0%E8%B0%B1%E7%9A%84%E7%89%A9%E7%A7%8D%E7%9A%84%E8%9B%8B%E7%99%BD%E8%B4%A8%E5%BA%8F%E5%88%97**%EF%BC%8C%E5%A6%82">https://phytozome.jgi.doe.gov/p下载**靠谱的物种的蛋白质序列**，如</a> Arabidopsis thaliana, Oryza sativa, Brassica rapa, 查找文献寻找目前该物种的<strong>已有EST&#x2F;cDNA序列</strong>，或者RNA-seq从头组装转录组。这里仅考虑用同源物种的蛋白序列进行比对分析，转录组从头组装数据用于PASA整体比对到参考基因组和更新已有的基因结构。</p><p>分别测试下不同物种的同源注释结果</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs stylus"><span class="hljs-selector-id">#run</span> seperately<br>gth -species arabidopsis -translationtable <span class="hljs-number">1</span> -gff3 -intermediate -protein ~/db/protein_db/Athaliana_167_TAIR10<span class="hljs-selector-class">.protein</span><span class="hljs-selector-class">.fa</span><span class="hljs-selector-class">.gz</span> -genomic chi_unmasked<span class="hljs-selector-class">.fa</span> -o <span class="hljs-number">03</span>-genomethreader/Athaliana<span class="hljs-selector-class">.gff3</span> &amp;<br>gth -species arabidopsis -translationtable <span class="hljs-number">1</span> -gff3 -intermediate -protein ~/db/protein_db/BrapaFPsc_277_v1.<span class="hljs-number">3</span><span class="hljs-selector-class">.protein</span><span class="hljs-selector-class">.fa</span><span class="hljs-selector-class">.gz</span> -genomic chi_unmasked<span class="hljs-selector-class">.fa</span> -o <span class="hljs-number">03</span>-genomethreader/Brapa<span class="hljs-selector-class">.gff3</span> &amp;<br>gth -species arabidopsis -translationtable <span class="hljs-number">1</span> -gff3 -intermediate -protein ~/db/protein_db/Osativa_323_v7.<span class="hljs-number">0</span><span class="hljs-selector-class">.protein</span><span class="hljs-selector-class">.fa</span><span class="hljs-selector-class">.gz</span> -genomic chi_unmasked<span class="hljs-selector-class">.fa</span> -o <span class="hljs-number">03</span>-genomethreader/Osativa<span class="hljs-selector-class">.gff3</span> &amp;<br><br></code></pre></td></tr></table></figure><p>在定性角度上来看，同源注释的结果和从头预测的没啥差别, 其中B. rapa和A. thaliana和C. hirsuta都属于十字花科，而O. sativa是禾本科, 所以前两者预测的效果好。</p><p><img src="/GeekFocus/2022-03-18-annotation/10.png" alt="IGV展示"></p><p><img src="/GeekFocus/./10.png" alt="IGV展示"></p><p>当然实际的同源注释流程中不能是单个物种分别预测，应该是将<strong>所有蛋白序列进行合并</strong>，然后用BLASTX找到最优的联配，之后用<strong>GenomeThreader</strong>进行预测。PASA流程提到的UniRef90作为同源注释的搜索数据库可能是更好的选择，由于UniRef优先选择哪些人工审查、注释质量高、来源于模式动植物的蛋白，所以可靠性相对于直接使用同源物中可能更高。</p><blockquote><p>BLASTX + GenomeThreader的代码探索中</p></blockquote><h2 id="04-RNA-seq的两种使用策略"><a href="#04-RNA-seq的两种使用策略" class="headerlink" title="04-RNA-seq的两种使用策略"></a><strong>04-RNA-seq的两种使用策略</strong></h2><p>对于RNA-seq数据，有两种使用策略，一种是使用HISAT2 + StringTie先比对再组装, 一种是从头组装，然后使用PASA将转录本比对到基因组上。</p><h3 id="基于HISAT2-StringTie"><a href="#基于HISAT2-StringTie" class="headerlink" title="基于HISAT2 + StringTie"></a>基于HISAT2 + StringTie</h3><p>首先，使用HISAT2将RNA-seq数据比对到参考基因组, 这一步和之前相似，但是要增加一个参数–dta，使得StingTie能更好的利用双端信息</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs bash">hisat2-build 01-augustus/genome.fa index/chi_masked<br>hisat2 --dta -p 20 -x index/chi_masked -1 rna-seq/leaf_ox_r1_1.fastq.gz -2 rna-seq/leaf_ox_r1_2.fastq.gz | samtools <span class="hljs-built_in">sort</span> -@ 10 &gt; rna-seq/leaf_ox_r1.bam &amp;<br>hisat2 --dta -p 20 -x index/chi_masked -1 rna-seq/ox_flower9_rep1_1.fastq.gz -2 rna-seq/ox_flower9_rep1_2.fastq.gz | samtools <span class="hljs-built_in">sort</span> -@ 10 &gt; rna-seq/ox_flower9.bam &amp;<br>hisat2 --dta -p 20 -x index/chi_masked -1 rna-seq/ox_flower16_rep1_1.fastq.gz -2 rna-seq/ox_flower16_rep1_2.fastq.gz | samtools <span class="hljs-built_in">sort</span> -@ 10 &gt; rna-seq/ox_flower16.bam &amp;<br>samtools merge -@ 10 rna-seq/merged.bam rna-seq/leaf_ox_r1.bam rna-seq/ox_flower9.bam rna-seq/ox_flower16.bam<br><br></code></pre></td></tr></table></figure><p>然后用StringTie进行转录本预测</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs awk">stringtie -p <span class="hljs-number">10</span> -o rna-seq<span class="hljs-regexp">/merged.gtf rna-seq/m</span>erged.bam<br></code></pre></td></tr></table></figure><p>对于后续的<strong>EvidenceModeler</strong>而言，它<strong>不需要UTR</strong>信息，<strong>只需要编码区CDS</strong>，需要用<strong>TransDecoder</strong>进行编码区预测</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs stylus">util/cufflinks_gtf_genome_to_cdna_fasta<span class="hljs-selector-class">.pl</span> merged<span class="hljs-selector-class">.gtf</span> input/chi_masked<span class="hljs-selector-class">.fa</span> &gt; transcripts<span class="hljs-selector-class">.fasta</span><br>util/cufflinks_gtf_to_alignment_gff3<span class="hljs-selector-class">.pl</span> merged<span class="hljs-selector-class">.gtf</span> &gt; transcripts<span class="hljs-selector-class">.gff3</span><br>TransDecoder<span class="hljs-selector-class">.LongOrfs</span> -t transcripts<span class="hljs-selector-class">.fasta</span><br>TransDecoder<span class="hljs-selector-class">.Predict</span> -t transcripts<span class="hljs-selector-class">.fasta</span><br>util/cdna_alignment_orf_to_genome_orf<span class="hljs-selector-class">.pl</span> \<br>     transcripts<span class="hljs-selector-class">.fasta</span><span class="hljs-selector-class">.transdecoder</span><span class="hljs-selector-class">.gff3</span> \<br>     transcripts<span class="hljs-selector-class">.gff3</span> \<br>     transcripts<span class="hljs-selector-class">.fasta</span> &gt; transcripts<span class="hljs-selector-class">.fasta</span><span class="hljs-selector-class">.transdecoder</span><span class="hljs-selector-class">.genome</span><span class="hljs-selector-class">.gff3</span><br><br></code></pre></td></tr></table></figure><p>最后结果<code>transcripts.fasta.transdecoder.gff3</code>用于提供给EvidenceModeler</p><h3 id="基于PASA"><a href="#基于PASA" class="headerlink" title="基于PASA"></a><strong>基于PASA</strong></h3><p>在多年以前，那个基因组组装还没有白菜价，只有几个模式物种基因组的时代，对于一个未测序的基因组，研究者如果要研究某一个基因的功能，大多会通过同源物种相似基因设计PCR引物，然后去扩增cDNA. 如果是一个已知基因组的物种，如果要大规模识别基因, 研究者通常会使用EST(expressed sequence tags)序列。</p><p>相对于基于算法的从头预测，cDNA和EST序列更能够真实的反应出一个基因的真实结构，如可变剪切、UTR和Poly-A位点。PASA(Progam to Assemble Spliced Alignments)流程最早用于拟南芥基因组注释，最初的设计是通过将全长(full-length)cDNA和EST比对到参考基因组上，去发现和更新基因组注释。其中FL-cDNA和EST序列对最后结果的权重不同。</p><p>这是以前的故事，现在的故事是二代转录组以及一些三代转录组数据，那么如何处理这些数据呢？我认为三代转录组相对于过去的FL-cDNA，而二代转录组数据经过拼接后可以看作是更长的EST序列。由于目前最普及的还是普通的mRNA-seq, 也就只介绍这部分流程。</p><blockquote><p>考虑到我还没有研究过三代的全长转录组，分析过数据，这里的思考极有可能出错，后续可能会修改这一部分思考。</p></blockquote><p>转录组组装使用Trinity(conda安装)</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs stylus">cd rna-seq<br>Trinity <span class="hljs-attr">--seqType</span> fq <span class="hljs-attr">--CPU</span> <span class="hljs-number">50</span> <span class="hljs-attr">--max_memory</span> <span class="hljs-number">64</span>G <span class="hljs-attr">--left</span> leaf_ox_r1_1<span class="hljs-selector-class">.fastq</span><span class="hljs-selector-class">.gz</span>,ox_flower16_rep1_1<span class="hljs-selector-class">.fastq</span><span class="hljs-selector-class">.gz</span>,ox_flower9_rep1_1<span class="hljs-selector-class">.fastq</span><span class="hljs-selector-class">.gz</span> <span class="hljs-attr">--right</span> leaf_ox_r1_2<span class="hljs-selector-class">.fastq</span><span class="hljs-selector-class">.gz</span>,ox_flower16_rep1_2<span class="hljs-selector-class">.fastq</span><span class="hljs-selector-class">.gz</span>,ox_flower9_rep1_2<span class="hljs-selector-class">.fastq</span><span class="hljs-selector-class">.gz</span> &amp;<br><br></code></pre></td></tr></table></figure><p>PASA是由30多个命令组成的流程，相关命令位于<code>PASApipeline/scripts</code>，为了适应不同的分析，有些参数需要通过修改配置文件更改,</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs routeros">cp ~/opt/biosoft/PASApipeline/pasa_conf/pasa.alignAssembly.Template.txt alignAssembly.config<br><span class="hljs-comment"># 修改如下内容</span><br><span class="hljs-attribute">DATABASE</span>=database.sqlite<br>validate_alignments_in_db.dbi:<span class="hljs-attribute">--MIN_PERCENT_ALIGNED</span>=80<br>validate_alignments_in_db.dbi:<span class="hljs-attribute">--MIN_AVG_PER_ID</span>=80<br><br></code></pre></td></tr></table></figure><p>上述几行配置文件表明SQLite3数据库的名字，设置了<code>scripts/validate_alignments_in_db.dbi</code>的几个参数, 表示联配程度和相似程度。后续以Trinity组装结果和参考基因组作为输入，运行程序：</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs awk">~<span class="hljs-regexp">/opt/</span>biosoft<span class="hljs-regexp">/PASApipeline/</span>scripts<span class="hljs-regexp">/Launch_PASA_pipeline.pl -c alignAssembly.config -C -R -g ../</span>chi_unmasked.fa -t ..<span class="hljs-regexp">/rna-seq/</span>trinity_out_dir/Trinity.fasta --ALIGNERS blat,gmap<br><br></code></pre></td></tr></table></figure><p>最后结果如下：</p><ul><li>database.sqlite.pasa_assemblies_described.txt</li><li>database.sqlite.pasa_assemblies.gff3</li><li>database.sqlite.pasa_assemblies.gtf</li><li>database.sqlite.pasa_assemblies.bed<br>其中gff3格式用于后续的分析</li></ul><blockquote><p>目前的一些想法， 将从头组装的转录本比对到参考基因组上很大依赖组装结果，所以和EST序列和cDNA相比，质量上还有一点差距。</p></blockquote><h2 id="05-整合预测结果"><a href="#05-整合预测结果" class="headerlink" title="05-整合预测结果"></a><strong>05-整合预测结果</strong></h2><p>从头预测，同源注释和转录组整合都会得到一个预测结果，相当于收集了大量证据，下一步就是通过这些证据定义出更加可靠的基因结构，这一步可以通过人工排查，也可以使用EVidenceModeler(EVM). EVM只接受三类输入文件：</p><ul><li><p>gene_prediction.gff3: 标准的GFF3格式，必须要有gene, mRNA, exon, CDS这些特征，用EVidenceModeler-1.1.1&#x2F;EvmUtils&#x2F;gff3_gene_prediction_file_validator.pl验证</p></li><li><p>protein_alignments.gff3: 标准的GFF3格式，第9列要有ID信和和target信息, 标明是比对结果</p></li><li><p>transcript_alignments.gff3:标准的GFF3格式，第9列要有ID信和和target信息，标明是比对结果</p><p>EVM对gene_prediction.gff3有特殊的要求，就是GFF文件需要反映出一个基因的结构，gene-&gt;(mRNA -&gt; (exon-&gt;cds(?))(+))(+), 表示一个基因可以有多个mRNA，即基因的可变剪接, 一个mRNA都可以由一个或者多个exon(外显子), 外显子可以是非翻译区(UTR),也可以是编码区(CDS). 而GlimmerHMM, SNAP等</p></li></ul><p>这三类根据人为经验来确定其可信度，从直觉上就是用PASA根据mRNA得到的结果高于从头预测。<br>第一步：创建权重文件,第一列是来源类型(ABINITIO_PREDICTION, PROTEIN, TRANSCRIPT), 第二列对应着GFF3文件的第二列，第三列则是权重.我这里用了<strong>三</strong>个来源的数据。</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">mkdir</span> <span class="hljs-number">05</span>-EVM &amp;&amp; cd <span class="hljs-number">05</span>-EVM<br><span class="hljs-comment">#vim weights.txt</span><br><span class="hljs-attribute">ABINITIO_PREDICTION</span>      augustus       <span class="hljs-number">4</span><br><span class="hljs-attribute">TRANSCRIPT</span>      assembler-database.sqlite      <span class="hljs-number">7</span><br><span class="hljs-attribute">OTHER_PREDICTION</span>  transdecoder  <span class="hljs-number">8</span><br><br></code></pre></td></tr></table></figure><blockquote><p>我觉得根据基因组引导组装的ORF的可信度高于组装后比对，所以得分和PASA差不多一样高。从头预测权重一般都是1，但是BRAKER可信度稍微高一点，可以在2~5之间。</p></blockquote><p>第二步：分割原始数据, 用于后续并行. 为了降低内存消耗，–segmentsSize设置的大小需要少于1Mb(这里是100k)， –overlapSize的不能太小，如果数学好，可用设置成基因平均长度加上2个标准差，数学不好，就设置成10K吧</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs stylus">cat transcripts<span class="hljs-selector-class">.fasta</span><span class="hljs-selector-class">.transdecoder</span><span class="hljs-selector-class">.genome</span><span class="hljs-selector-class">.gff3</span> ../braker/carhr/augustus<span class="hljs-selector-class">.hints</span><span class="hljs-selector-class">.gff3</span> &gt; gene_predictions<span class="hljs-selector-class">.gff3</span><br>ln ../<span class="hljs-number">04</span>-align-transcript/database<span class="hljs-selector-class">.sqlite</span><span class="hljs-selector-class">.pasa_assemblies</span><span class="hljs-selector-class">.gff3</span> transcript_alignments<span class="hljs-selector-class">.gff3</span><br>~/opt/biosoft/EVidenceModeler-<span class="hljs-number">1.1</span>.<span class="hljs-number">1</span>/EvmUtils/partition_EVM_inputs<span class="hljs-selector-class">.pl</span> <span class="hljs-attr">--genome</span> ../chi_unmasked<span class="hljs-selector-class">.fa</span> <span class="hljs-attr">--gene_predictions</span> gene_predictions<span class="hljs-selector-class">.gff3</span> <span class="hljs-attr">--transcript_alignments</span> transcript_alignments<span class="hljs-selector-class">.gff3</span> <span class="hljs-attr">--segmentSize</span> <span class="hljs-number">100000</span> <span class="hljs-attr">--overlapSize</span> <span class="hljs-number">10000</span> <span class="hljs-attr">--partition_listing</span> partitions_list<span class="hljs-selector-class">.out</span><br><br></code></pre></td></tr></table></figure><p>第三步：创建并行运算命令并且执行</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs stylus">~/opt/biosoft/EVidenceModeler-<span class="hljs-number">1.1</span>.<span class="hljs-number">1</span>/EvmUtils/write_EVM_commands<span class="hljs-selector-class">.pl</span> <span class="hljs-attr">--genome</span> ../chi_unmasked<span class="hljs-selector-class">.fa</span> <span class="hljs-attr">--weights</span> `pwd`/weights<span class="hljs-selector-class">.txt</span> \<br>      <span class="hljs-attr">--gene_predictions</span> gene_predictions<span class="hljs-selector-class">.gff3</span> \<br>      <span class="hljs-attr">--transcript_alignments</span> transcript_alignments<span class="hljs-selector-class">.gff3</span> \<br>      <span class="hljs-attr">--output_file_name</span> evm<span class="hljs-selector-class">.out</span>  <span class="hljs-attr">--partitions</span> partitions_list<span class="hljs-selector-class">.out</span> &gt;  commands<span class="hljs-selector-class">.list</span><br>parallel <span class="hljs-attr">--jobs</span> <span class="hljs-number">10</span> &lt; commands<span class="hljs-selector-class">.list</span><br><br></code></pre></td></tr></table></figure><p>第四步：合并并行结果</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs awk">~<span class="hljs-regexp">/opt/</span>biosoft<span class="hljs-regexp">/EVidenceModeler-1.1.1/</span>EvmUtils/recombine_EVM_partial_outputs.pl --partitions partitions_list.out --output_file_name evm.out<br></code></pre></td></tr></table></figure><p>第五步：结果转换成GFF3</p><figure class="highlight gradle"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs gradle">~<span class="hljs-regexp">/opt/</span>biosoft<span class="hljs-regexp">/EVidenceModeler-1.1.1/</span>EvmUtils<span class="hljs-regexp">/convert_EVM_outputs_to_GFF3.pl  --partitions partitions_list.out --output evm.out  --genome ../</span>chi_unmasked.fa<br><span class="hljs-keyword">find</span> . -regex <span class="hljs-string">&quot;.*evm.out.gff3&quot;</span> -exec cat &#123;&#125; \; | bedtools <span class="hljs-keyword">sort</span> -i - &gt; EVM.all.gff<br><br></code></pre></td></tr></table></figure><p>当前权重设置下，EVM的结果更加严格，需要按照实际情况调整，增加其他证据。</p><h2 id="06-可选步骤"><a href="#06-可选步骤" class="headerlink" title="06-可选步骤"></a><strong>06-可选步骤</strong></h2><p>注释过滤：对于初步预测得到的基因，还可以稍微优化一下，例如剔除编码少于50个AA的预测结果，将转座子单独放到一个文件中(软件有TransposonPSI)。</p><p>这里基于gffread先根据注释信息提取所有的CDS序列，过滤出长度不足50AA的序列，基于这些序列过滤原来的的注释</p><figure class="highlight nsis"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs nsis">gffread EVM.<span class="hljs-literal">all</span>.gff -g input/genome.fa -y tr_cds.fa<br>bioawk -c fastx <span class="hljs-string">&#x27;length(<span class="hljs-variable">$seq</span>) &lt; 50 &#123;print <span class="hljs-variable">$comment</span>&#125;&#x27;</span> tr_cds.fa | cut -d <span class="hljs-string">&#x27;=&#x27;</span> -f <span class="hljs-number">2</span> &gt; short_aa_gene_list.txt<br>grep -v -w -f short_aa_gene_list.txt EvM.<span class="hljs-literal">all</span>.gff &gt; filter.gff<br><span class="hljs-comment"># 长度计算错误，原文写的是$seq&lt;50 订正为 length($seq)&lt;50</span><br></code></pre></td></tr></table></figure><p><strong>使用PASA更新EVM结果</strong>：EVM结果不包括UTR区域和可变剪切的注释信息，可以使用PASA进行更新。然而这部分已经无法逃避MySQL, 服务器上并没有MySQL的权限，我需要学习Perl脚本进行修改。因此基因结构注释到此先放一放。</p><p><strong>07-基因编号</strong></p><p>对每个基因实现编号，形如ABCD000010的效果，方便后续分析。如下代码是基于EVM.all.gff，使用方法为<code>python gffrename.py EVM_output.gff prefix &gt; renamed.gff</code>.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#!/usr/bin/env python3</span><br><span class="hljs-keyword">import</span> re<br><span class="hljs-keyword">import</span> sys<br><br><span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(sys.argv) &lt; <span class="hljs-number">3</span>:<br>    sys.exit()<br><br>gff = <span class="hljs-built_in">open</span>(sys.argv[<span class="hljs-number">1</span>])<br>prf = sys.argv[<span class="hljs-number">2</span>]<br><br>count = <span class="hljs-number">0</span><br>mRNA  = <span class="hljs-number">0</span><br>cds   = <span class="hljs-number">0</span><br>exon  = <span class="hljs-number">0</span><br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;##gff-version 3.2.1&quot;</span>)<br><span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> gff:<br>    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> line.startswith(<span class="hljs-string">&quot;\n&quot;</span>):<br>        records = line.split(<span class="hljs-string">&quot;\t&quot;</span>)<br>        records[<span class="hljs-number">1</span>] = <span class="hljs-string">&quot;.&quot;</span><br>    <span class="hljs-keyword">if</span> re.search(<span class="hljs-string">r&quot;\tgene\t&quot;</span>, line):<br>        count = count + <span class="hljs-number">10</span><br>        mRNA  = <span class="hljs-number">0</span><br>        gene_id = prf + <span class="hljs-built_in">str</span>(count).zfill(<span class="hljs-number">6</span>)<br>        records[<span class="hljs-number">8</span>] = <span class="hljs-string">&quot;ID=&#123;&#125;&quot;</span>.<span class="hljs-built_in">format</span>(gene_id)<br>    <span class="hljs-keyword">elif</span> re.search(<span class="hljs-string">r&quot;\tmRNA\t&quot;</span>, line):<br>        cds   = <span class="hljs-number">0</span><br>        exon  = <span class="hljs-number">0</span><br>        mRNA  = mRNA + <span class="hljs-number">1</span><br>        mRNA_id    = gene_id + <span class="hljs-string">&quot;.&quot;</span> + <span class="hljs-built_in">str</span>(mRNA)<br>        records[<span class="hljs-number">8</span>] = <span class="hljs-string">&quot;ID=&#123;&#125;;Parent=&#123;&#125;&quot;</span>.<span class="hljs-built_in">format</span>(mRNA_id, gene_id)<br>    <span class="hljs-keyword">elif</span> re.search(<span class="hljs-string">r&quot;\texon\t&quot;</span>, line):<br>        exon     = exon + <span class="hljs-number">1</span><br>        exon_id  = mRNA_id + <span class="hljs-string">&quot;_exon_&quot;</span> + <span class="hljs-built_in">str</span>(exon)<br>        records[<span class="hljs-number">8</span>] = <span class="hljs-string">&quot;ID=&#123;&#125;;Parent=&#123;&#125;&quot;</span>.<span class="hljs-built_in">format</span>(exon_id, mRNA_id)<br>    <span class="hljs-keyword">elif</span> re.search(<span class="hljs-string">r&quot;\tCDS\t&quot;</span>, line):<br>        cds     = cds + <span class="hljs-number">1</span><br>        cds_id  = mRNA_id + <span class="hljs-string">&quot;_cds_&quot;</span> + <span class="hljs-built_in">str</span>(cds)<br>        records[<span class="hljs-number">8</span>] = <span class="hljs-string">&quot;ID=&#123;&#125;;Parent=&#123;&#125;&quot;</span>.<span class="hljs-built_in">format</span>(cds_id, mRNA_id)<br>    <span class="hljs-keyword">else</span>:<br>        <span class="hljs-keyword">continue</span><br><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;\t&quot;</span>.join(records))<br><br>gff.close()<br><br></code></pre></td></tr></table></figure><p><strong>一些经验</strong></p><p>如果有转录组数据，没必须要使用太多的从头预测工具，braker2 加 GlimmerHMM可能就够用了, 更多是使用PASA和StringTie利用好转录组数据进行注释。</p><p>基因功能注释</p><p>基因功能的注释依赖于上一步的基因结构预测，根据预测结果从基因组上提取翻译后的 蛋白序列 和主流的数据库进行比对，完成功能注释。常用数据库一共有以几种：</p><ul><li>Nr：NCBI官方非冗余蛋白数据库，包括PDB, Swiss-Prot, PIR, PRF; 如果要用DNA序列，就是nt库</li><li>Pfam: 蛋白结构域注释的分类系统</li><li>Swiss-Prot: 高质量的蛋白数据库，蛋白序列得到实验的验证</li><li>KEGG: 代谢通路注释数据库.</li><li>GO: 基因本体论注释数据库</li></ul><p>除了以上几个比较通用的数据库外，其实还有很多小众数据库，应该根据课题研究和背景进行选择。注意，数据库本身并不能进行注释，你只是通过序列相似性进行搜索，而返回的结果你称之为注释。因此数据库和搜索工具要进行区分，所以你需要单独下载数据库和搜索工具，或者是同时下载包含数据库和搜索工具的安装包。</p><blockquote><p>注意，后续分析中一定要保证你的蛋白序列中不能有代表氨基酸字符以外的字符，比如说有些软件会把最后一个终止密码子翻译成”.“或者”*”</p></blockquote><p><strong>BLASTP</strong></p><p>这一部分用到的数据库都是用BLASTP进行检索，基本都是四步发：下载数据库，构建BLASTP索引，数据库检索，结果整理。其中结果整理需要根据BLASTP的输出格式调整。</p><p>Nr的NCBI收集的最全的蛋白序列数据库，但是无论是用NCBI的BLAST还是用速度比较快DIAMOND对nr进行搜索，其实都没有利用好物种本身的信息。因此在RefSeq上下载对应物种的蛋白序列, 用BLASTP进行注释即可。</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs awk"><span class="hljs-comment"># download</span><br>wget -<span class="hljs-number">4</span>  -nd -np -r <span class="hljs-number">1</span> -A *.faa.gz ftp:<span class="hljs-regexp">//</span>ftp.ncbi.nlm.nih.gov<span class="hljs-regexp">/refseq/</span>release<span class="hljs-regexp">/plant/</span><br>mkdir -p ~<span class="hljs-regexp">/db/</span>RefSeq<br>zcat *.gz &gt; ~<span class="hljs-regexp">/db/</span>RefSeq/plant.protein.faa<br><span class="hljs-comment"># build index</span><br>~<span class="hljs-regexp">/opt/</span>biosoft<span class="hljs-regexp">/ncbi-blast-2.7.1+/</span>bin/makeblastdb -<span class="hljs-keyword">in</span> plant.protein.faa -dbtype prot -parse_seqids -title RefSeq_plant -out plant<br><span class="hljs-comment"># search</span><br>~<span class="hljs-regexp">/opt/</span>biosoft<span class="hljs-regexp">/ncbi-blast-2.7.1+/</span>bin<span class="hljs-regexp">/blastp -query protein.fa -out RefSeq_plant_blastp.xml -db ~/</span>db<span class="hljs-regexp">/RefSeq/u</span>niprot_sprot.fasta -evalue <span class="hljs-number">1</span>e-<span class="hljs-number">5</span> -outfmt <span class="hljs-number">5</span> -num_threads <span class="hljs-number">50</span> &amp;<br><br></code></pre></td></tr></table></figure><p><a href="http://www.uniprot.org/downloads">Swiss-Prot</a>里收集了目前可信度最高的蛋白序列，一共有55w条记录，数据量比较小，</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs awk"><span class="hljs-comment"># download</span><br>wget -<span class="hljs-number">4</span> -q ftp:<span class="hljs-regexp">//</span>ftp.uniprot.org<span class="hljs-regexp">/pub/</span>databases<span class="hljs-regexp">/uniprot/</span>current_release<span class="hljs-regexp">/knowledgebase/</span>complete/uniprot_sprot.fasta.gz<br>gzip -d uniprot_sprot.fasta.gz<br><span class="hljs-comment"># builid index</span><br>~<span class="hljs-regexp">/opt/</span>biosoft<span class="hljs-regexp">/ncbi-blast-2.7.1+/</span>bin/makeblastdb -<span class="hljs-keyword">in</span> uniprot_sprot.fasta -dbtype prot -title swiss_prot -parse_seqids<br><span class="hljs-comment"># search</span><br>~<span class="hljs-regexp">/opt/</span>biosoft<span class="hljs-regexp">/ncbi-blast-2.7.1+/</span>bin<span class="hljs-regexp">/blastp -query protein.fa -out swiss_prot.xml -db ~/</span>db<span class="hljs-regexp">/swiss_prot/u</span>niprot_sprot.fasta -evalue <span class="hljs-number">1</span>e-<span class="hljs-number">5</span> -outfmt <span class="hljs-number">5</span> -num_threads <span class="hljs-number">50</span> &amp;<br><br></code></pre></td></tr></table></figure><p>关于结果整理，已经有很多人写了脚本，比如说我搜索BLAST XML CSV，就找到了<a href="https://github.com/Sunhh/NGS_data_processing/blob/master/annot_tools/blast_xml_parse.py">https://github.com/Sunhh/NGS_data_processing/blob/master/annot_tools/blast_xml_parse.py</a>, 所以就不过多介绍。</p><p><strong>InterProScan</strong></p><p>下面介绍的工具是InterProScan, 从它的9G的体量就可以感受它的强大之处，一次运行同时实现多个信息注释。</p><ul><li>InterPro注释</li><li>Pfam数据库注释(可以通过hmmscan搜索pfam数据库完成)</li><li>GO注释(可以基于NR和Pfam等数据库，然后BLAST2GO完成,)</li><li>Reactome通路注释，不同于KEGG</li></ul><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs stylus">./interproscan-<span class="hljs-number">5.29</span>-<span class="hljs-number">68.0</span>/interproscan<span class="hljs-selector-class">.sh</span> -appl Pfam  -f TSV -<span class="hljs-selector-tag">i</span> sample<span class="hljs-selector-class">.fa</span> -cpu <span class="hljs-number">50</span> -<span class="hljs-selector-tag">b</span> sample -goterms -iprlookup -pa<br></code></pre></td></tr></table></figure><p><code>-appl</code>告诉软件要执行哪些数据分析，勾选的越多，分析速度越慢，Pfam就行。</p><p>KEGG</p><p>KEGG数据库目前本地版收费，在线版收费，所以只能将蛋白序列在KEGG服务器上运行。因此你需要在<a href="http://www.genome.jp/tools/kaas/%E9%80%89%E6%8B%A9%E5%90%88%E9%80%82%E7%9A%84%E5%B7%A5%E5%85%B7%E8%BF%9B%E8%A1%8C%E5%90%8E%E7%BB%AD%E7%9A%84%E5%88%86%E6%9E%90%E3%80%82%E6%88%91%E4%B8%8A%E4%BC%A0%E7%9A%8450M%E5%A4%A7%E5%B0%8F%E8%9B%8B%E7%99%BD%E5%BA%8F%E5%88%97%EF%BC%8C%E5%9C%A8KEGG%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%B8%8A%E5%8F%AA%E9%9C%80%E8%A6%81%E8%BF%90%E8%A1%8C8%E4%B8%AA%E5%B0%8F%E6%97%B6%EF%BC%8C%E4%B9%9F%E5%B0%B1%E6%98%AF%E6%99%9A%E4%B8%8A%E6%8F%90%E4%BA%A4%E4%BB%BB%E5%8A%A1%EF%BC%8C%E7%99%BD%E5%A4%A9%E5%9B%9E%E6%9D%A5%E5%B9%B2%E6%B4%BB%E3%80%82">http://www.genome.jp/tools/kaas/选择合适的工具进行后续的分析。我上传的50M大小蛋白序列，在KEGG服务器上只需要运行8个小时，也就是晚上提交任务，白天回来干活。</a><br><img src="/GeekFocus/2022-03-18-annotation/11.png" alt="运行时间"></p><p><img src="/GeekFocus/./11.png" alt="运行时间"></p><p><strong>附录</strong></p><p>基因组注释的常用软件：</p><ul><li><p>重复区域</p><ul><li><p>RepeatMasker：识别基因组中的可能重复</p></li><li><p>RepeatModeler: 识别新的重复序列</p></li><li><p>LTR-FINDER: <a href="http://tlife.fudan.edu.cn/ltr_finder/">http://tlife.fudan.edu.cn/ltr_finder/</a></p></li></ul></li><li><p>从头预测</p><ul><li><strong>Augustus</strong></li><li>Fgenesh</li></ul></li><li><p>同源预测</p><ul><li>GeneWise</li><li><strong>Exonerate</strong></li><li>Trinity</li><li>GenomeThreader? failed</li></ul></li><li><p>注释合并</p><ul><li>GLEAN：已经落伍于时代了</li><li><strong>EvidenceModeler</strong>： 与时俱进</li></ul></li><li><p>流程</p><ul><li>PASA：真核生物基因的<strong>转录本可变剪切自动化注释项目</strong>，需要提供物种的EST或RNA-seq数据</li><li><strong>MAKER</strong></li><li><strong>BRAKER1</strong>: 使用GeneMark-ET和AUGUSTUS基于RNA-Seq注释基因结构</li><li>EuGene</li></ul></li><li><p>可视化</p><ul><li>IGV</li><li>JBrowse&#x2F;GBrowse</li></ul></li></ul><p><strong>参考文献和推荐阅读：</strong></p><ul><li>NCBI真核生物基因组注释流程<a href="https://www.ncbi.nlm.nih.gov/genome/annotation_euk/process/">https://www.ncbi.nlm.nih.gov/genome/annotation_euk/process/</a></li><li>真核基因组注释入门: “A beginner’s guide to eukaryotic genome annotation”</li><li>二代测序注释流程:Comparative Gene Finding: “Annotation Pipelines for Next-Generation Sequencing Projects”</li><li>基因组转录组注释策略: “Plant genome and transcriptome annotations: from misconceptions to simple solution”</li><li>重复序列综述: “Repetitive DNA and next-generation sequencing: computational challenges and solutions”</li><li>JGS流程: <a href="https://genome.jgi.doe.gov/programs/fungi/FungalGenomeAnnotationSOP.pdf">https://genome.jgi.doe.gov/programs/fungi/FungalGenomeAnnotationSOP.pdf</a></li></ul><p>环境准备</p><p>数据下载</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs awk"><span class="hljs-comment"># Cardamine hirsutat基因组数据</span><br>mkdir chi_annotation &amp;&amp; cd chi_annotation<br>wget http:<span class="hljs-regexp">//</span>chi.mpipz.mpg.de<span class="hljs-regexp">/download/</span>sequences/chi_v1.fa<br>cat chi_v1.fa | tr <span class="hljs-string">&#x27;atcg&#x27;</span> <span class="hljs-string">&#x27;ATCG&#x27;</span> &gt; chi_unmasked.fa<br><span class="hljs-comment"># Cardamine hirsutat转录组数据</span><br>wget -<span class="hljs-number">4</span> -q -A <span class="hljs-string">&#x27;*.fastq.gz&#x27;</span> -np -nd -r <span class="hljs-number">2</span> http:<span class="hljs-regexp">//</span>chi.mpipz.mpg.de<span class="hljs-regexp">/download/</span>fruit_rnaseq<span class="hljs-regexp">/cardamine_hirsuta/</span> &amp;<br>wget -<span class="hljs-number">4</span> -q -A <span class="hljs-string">&#x27;*.fastq.gz&#x27;</span> -np -nd -r <span class="hljs-number">2</span> http:<span class="hljs-regexp">//</span>chi.mpipz.mpg.de<span class="hljs-regexp">/download/</span>leaf_rnaseq<span class="hljs-regexp">/cardamine_hirsuta/</span> &amp;<br><br></code></pre></td></tr></table></figure><h2 id="软件安装"><a href="#软件安装" class="headerlink" title="软件安装"></a><strong>软件安装</strong></h2><h3 id="RepeatMasker√"><a href="#RepeatMasker√" class="headerlink" title="RepeatMasker√?"></a><strong>RepeatMasker</strong>√?</h3><p>用于注释基因组的重复区，需要安装RMBlast, TRF，以及在<a href="http://www.girinst.org/">http://www.girinst.org</a>注册以下载Repbase</p><p>安装RepeatMasker</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-comment">#useful</span><br><span class="hljs-comment">#cd ~/src</span><br><span class="hljs-built_in">cd</span> RepeatMasker<br>wget http://tandem.bu.edu/trf/downloads/trf409.linux64<br><span class="hljs-comment">#mv trf409.linux64 ~/opt/bin/trf</span><br><span class="hljs-built_in">mv</span> trf409.linux64 opt/bin/trf<br><span class="hljs-comment">#chmod a+x ~/opt/bin/trf</span><br><span class="hljs-built_in">chmod</span> a+x opt/bin/trf<br><br><span class="hljs-comment"># RMBlast -failed</span><br><span class="hljs-comment">#cd ~/src</span><br>wget ftp://ftp.ncbi.nlm.nih.gov/blast/executables/blast+/2.6.0/ncbi-blast-2.6.0+-src.tar.gz<br>wget http://www.repeatmasker.org/isb-2.6.0+-changes-vers2.patch.gz<br>tar xf ncbi-blast-2.6.0+-src<br>gunzip isb-2.6.0+-changes-vers2.patch.gz<br><span class="hljs-built_in">cd</span> ncbi-blast-2.6.0+-src<br>patch -p1 &lt; ../isb-2.6.0+-changes-vers2.patch<br><span class="hljs-built_in">cd</span> c++<br><span class="hljs-comment">#./configure --with-mt --prefix=~/opt/biosoft/rmblast --without-debug &amp;&amp; make &amp;&amp; make install</span><br><br>!!failed<br><span class="hljs-comment"># RepeatMasker</span><br><span class="hljs-built_in">cd</span> ~/src<br>wget http://repeatmasker.org/RepeatMasker-open-4-0-7.tar.gz<br>tar xf RepeatMasker-open-4-0-7.tar.gz<br><span class="hljs-built_in">mv</span> RepeatMasker ~/opt/biosoft/<br><span class="hljs-built_in">cd</span> ~/opt/biosoft/RepeatMasker<br><span class="hljs-comment">## 解压repbase数据到Libraries下</span><br><span class="hljs-comment">## 配置RepatMasker</span><br>perl ./configure<br><br>--my 【follow official web】<br>http://repeatmasker.org/RepeatMasker/<br>Latest Released Version: 04/1/21: RepeatMasker-4.1.2-p1.tar.gz<br>未更新Dfam【the complete dfam mey be download? 补充15G？后编译，与之前的结果比较】，RepBase RepeatMasker Edition用的老版本2017<br>【更新2018】https://www.jianshu.com/p/ffdbedae80fa<br>---RMBlast  上面的configure error<br>https://blog.csdn.net/woodcorpse/article/details/73148464<br>在RepeatMasker的页面上有最近ncbi-blast-2.6.0+-src源代码和补定，按要求安装，即本文中的操作，make编辑成功，但make install有错误，不过关键程序rmblastn已经成功，可正常使用；<br>如果新版安装失败，可尝试安装2.2.28的预译版<br><span class="hljs-built_in">cd</span> /usr/local<br>wget ftp://ftp.ncbi.nlm.nih.gov/blast/executables/blast+/2.2.28/ncbi-blast-2.2.28+-x64-linux.tar.gz<br>wget ftp://ftp.ncbi.nlm.nih.gov/blast/executables/rmblast/2.2.28/ncbi-rmblastn-2.2.28-x64-linux.tar.gz<br>tar zxvf ncbi-blast-2.2.28+-x64-linux.tar.gz<br>tar zxvf ncbi-rmblastn-2.2.28-x64-linux.tar.gz<br><span class="hljs-built_in">cp</span> -R ncbi-rmblastn-2.2.28/* ncbi-blast-2.2.28+/<br><span class="hljs-built_in">rm</span> -rf ncbi-rmblastn-2.2.28<br><span class="hljs-built_in">mv</span> ncbi-blast-2.2.28+ rmblast-2.2.28<br>/usr/local/rmblast-2.2.28/bin/rmblastn -h<br>---error Repeatmasker <span class="hljs-string">&quot;Can&#x27;t locate Text/Soundex.pm in @INC</span><br><span class="hljs-string">https://github.com/rmhubley/RepeatMasker/issues/81</span><br><span class="hljs-string">2.12版本好了</span><br><span class="hljs-string">https://anaconda.org/conda-forge/perl-text-soundex 安装也未解决</span><br><span class="hljs-string">---error ModuleNotFoundError: No module named &#x27;h5py&#x27;</span><br><span class="hljs-string">https://github.com/keras-team/keras/issues/3426；https://docs.h5py.org/en/latest/build.html</span><br><span class="hljs-string">【conda install -c anaconda h5py】</span><br><span class="hljs-string">---error Can&#x27;t locate strict.pm</span><br><span class="hljs-string">【perl的问题，loginal有问题，换自己的perl没问题】</span><br><span class="hljs-string">---</span><br><span class="hljs-string">如果反复提示以下关于“Text::Soundex module”模块的错误（即便你这个perl模块确实安装好了），建议将perl环境更改为/usr/bin下的perl（对，不建议使用conda中的perl），并sudo cpan重新安装该模块后，再重新安装RepeatMasker（安装时指定系统/usr/bin下的perl），就解决了。【4.12没问题】</span><br><span class="hljs-string"></span><br><span class="hljs-string"></span><br></code></pre></td></tr></table></figure><h3 id="Repeatmodeler√？"><a href="#Repeatmodeler√？" class="headerlink" title="Repeatmodeler√？"></a>Repeatmodeler√？</h3><p>在上面的基础上安装<strong>RepeatModel</strong></p><p><a href="https://www.jianshu.com/p/7cd5d8ab7290">https://www.jianshu.com/p/7cd5d8ab7290</a></p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><code class="hljs sh">【！！！！！！！！！必须fat no conda】【<span class="hljs-built_in">local</span> no conda error】<br>1-3、RepeatMasker、TRF、序列搜索引擎<br><span class="hljs-comment"># RECON</span><br><span class="hljs-built_in">cd</span> ~/src<br>wget -4 http://repeatmasker.org/RepeatModeler/RECON-1.08.tar.gz<br>tar xf RECON-1.08.tar.gz<br><span class="hljs-built_in">cd</span> RECON-1.08/src<br>make &amp;&amp; make install<br><span class="hljs-built_in">cd</span> ~/src<br><span class="hljs-built_in">mv</span> RECON-1.08 ~/opt/biosoft<br><span class="hljs-comment"># nesg</span><br><span class="hljs-built_in">cd</span> ~/src<br><span class="hljs-built_in">mkdir</span> nesg &amp;&amp; <span class="hljs-built_in">cd</span> nesg<br>wget -4 ftp://ftp.ncbi.nih.gov/pub/seg/nseg/*<br>make<br><span class="hljs-built_in">mv</span> nmerge nseg ~/opt/bin/<br><span class="hljs-comment"># RepeatScout</span><br>http://www.repeatmasker.org/RepeatScout-1.0.5.tar.gz<br><span class="hljs-comment">#github：https://github.com/mmcco/RepeatScout</span><br>git <span class="hljs-built_in">clone</span> https://github.com/mmcco/RepeatScout.git<br><span class="hljs-built_in">cd</span> RepeatScout<br><span class="hljs-built_in">chmod</span> 755 *<br>make <br><span class="hljs-comment">#添加环境变量，例如RepeatScout安装在“/home/my/software/RepeatScout”</span><br><span class="hljs-built_in">export</span> PATH=/home/my/software/RepeatScout:<span class="hljs-variable">$PATH</span><br><br><span class="hljs-comment"># RepeatModel</span><br>wget  http://repeatmasker.org/RepeatModeler/RepeatModeler-open-1.0.11.tar.gz<br>tar xf RepeatModeler-open-1.0.11.tar.gz<br><span class="hljs-built_in">mv</span> RepeatModeler-open-1.0.11 ~/opt/biosoft/<br><span class="hljs-built_in">cd</span> ~/opt/biosoft/RepeatModeler-open-1.0.11<br><span class="hljs-comment"># 配置</span><br>perl ./configure<br>---<br>conda perl error<br><br>“./configure”执行后，根据提示信息一步步来。<br><br>首先是perl环境，推荐使用/usr/bin环境下的perl，即系统perl，【【使用conda中的perl后面总出问题】】回车继续。<br>RepeatModeler安装路径，默认自动指定安装路径，回车继续。<br><br>指定RepeatMasker的安装路径，回车继续。<br>/software/biosoft/software/RepeatMasker/ 识别了也fail，不完整library<br>？？？？？自己路径识别不出来<br>MASKER checks xxx/RepeatMasker/Libraries/RepeatMaskerLib.embl <span class="hljs-keyword">for</span> Repbase.<br>If you have older versions of Repbase like RMRBSeqs.embl, create symlink <span class="hljs-keyword">in</span> xxx/RepeatMasker/Libraries/. For example, <span class="hljs-built_in">ln</span> -s RMRBSeqs.embl RepeatMaskerLib.embl. But <span class="hljs-keyword">in</span> that <span class="hljs-keyword">case</span>, model_org= should be <span class="hljs-built_in">set</span> to the org that exists <span class="hljs-keyword">in</span> the database, instead of all. CAUTION: I don<span class="hljs-string">&#x27;t know whether the result is reliable enough in this way.</span><br><span class="hljs-string"></span><br><span class="hljs-string"></span><br><span class="hljs-string">指定RECON的安装路径，回车继续。</span><br><span class="hljs-string">指定RepeatScout的安装路径，回车继续。</span><br><span class="hljs-string">指定NSEG的安装路径，回车继续。</span><br><span class="hljs-string">指定TRF的安装路径（这个同时也是RepeatMasker安装必需的），回车继续。</span><br><span class="hljs-string">最后是序列搜索引擎（这个同时也是RepeatMasker安装必需的），例如我们这里选择2，指定RMBlast主程序所在路径，回车返回主界面后，再选择3，就完成了。</span><br><span class="hljs-string">你也可以指定多种序列搜索引擎后，再选择3，不过实际运行时，一次只能选择一种序列比对方式。</span><br><span class="hljs-string">终于把一些列的环境添加完了，最后配置环境变量。</span><br><span class="hljs-string">Enter Selection: 3</span><br><span class="hljs-string"> -- Setting perl interpreter and version...</span><br><span class="hljs-string"></span><br><span class="hljs-string">Congratulations!  RepeatModeler is now ready to use.</span><br><span class="hljs-string">Simply place:</span><br><span class="hljs-string">   ~/software/opt/biosoft/RepeatModeler-open-1.0.11</span><br><span class="hljs-string">in your user&#x27;</span>s path and review the RepeatModeler documentation here:<br>   ~/software/opt/biosoft/RepeatModeler-open-1.0.11/README<br><br><span class="hljs-built_in">export</span> PATH=/home/my/software/RepeatModeler-open-1.0.11:<span class="hljs-variable">$PATH</span><br> <br><span class="hljs-comment">#这时候没啥问题的话应该可以看到帮助界面了</span><br>RepeatModeler -h<br><br></code></pre></td></tr></table></figure><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-comment">#建立基因组索引</span><br><span class="hljs-attribute">BuildDatabase</span> -name Silkworm -engine ncbi genomic.fna<br><br><span class="hljs-comment">#构建 library，这步非常耗时，好像提升线程也没啥用，#获得两个主要文件，*-families.fa、*-families.stk</span><br><span class="hljs-attribute">RepeatModeler</span> -pa <span class="hljs-number">4</span> -database Silkworm -engine ncbi<br><br><span class="hljs-comment">#下方作为测试，只使用了主要的参数，其中通过 -lib 参数指定本地库</span><br><span class="hljs-attribute">RepeatMasker</span> -pa <span class="hljs-number">4</span> -gff -lib Silkworm-families.fa -dir repeat2 genomic.fna<br></code></pre></td></tr></table></figure><p>fasta文件“-families.fa”为训练得到的共识重复序列，序列id后会标注它属于哪种重复序列家族，若无法归类则用标注为“Unkown”。<br>“-families.stk”为种子联配（Seed alignments）文件，是Dfam兼容的Stockholm格式，可以使用RepeatModeler 安装路径中自带的工具“RepeatModeler&#x2F;util&#x2F;dfamConsensusTool.pl”上传到Dfam_consensus数据库中。<br>详见：<a href="http://www.repeatmasker.org/RepeatModeler/dfamConsensusTool">http://www.repeatmasker.org/RepeatModeler/dfamConsensusTool</a>. 查看输出结果“*.tbl”。</p><p>RepeatModeler 预测基因组重复序列，为下一步的RepeatMasker建立重复序列数据库</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-comment">#建库，利用rice 一个实例fasta文件</span><br>BuildDatablase –name ricedb –engine ncbi  rice.sample.2.fa<br><br><span class="hljs-comment">#参数说明</span><br>-name &lt;database name&gt;<br>        The name of the database to create.<br>-engine &lt;engine name&gt;<br>        The name of the search engine we are using. I.e abblast/wublast or rmblast.<br>-<span class="hljs-built_in">dir</span> &lt;directory&gt;<br>        The name of a directory containing fasta files to be processed. The<br>        files are recognized by their suffix. Only *.fa and *.fasta files<br>        are processed.<br>-batch &lt;file&gt;<br>        The name of a file <span class="hljs-built_in">which</span> contains the names of fasta files to<br>        process. The files names are listed one per line and should be fully<br>        qualified.<br><br>RepeatModeler -database ricedb  -pa 5<br><br><span class="hljs-comment">#参数说明</span><br>-database<br>        The name of the sequence database to run an analysis on. This is the<br>        name that was provided to the BuildDatabase script using the <span class="hljs-string">&quot;-name&quot;</span><br>        option.<br>-pa <span class="hljs-comment">#</span><br>        Specify the number of parallel search <span class="hljs-built_in">jobs</span> to run. RMBlast <span class="hljs-built_in">jobs</span> will<br>        use 4 cores each and ABBlast <span class="hljs-built_in">jobs</span> will use a single core each. i.e.<br>        on a machine with 12 cores and running with RMBlast you would use<br>        -pa 3 to fully utilize the machine.<br>-recoverDir &lt;Previous Output Directory&gt;<br>        If a run fails <span class="hljs-keyword">in</span> the middle of processing, it may be possible<br>        recover some results and <span class="hljs-built_in">continue</span> <span class="hljs-built_in">where</span> the previous run left off.<br>        Simply supply the output directory <span class="hljs-built_in">where</span> the results of the failed<br>        run were saved and the program will attempt to recover and <span class="hljs-built_in">continue</span><br>        the run.<br></code></pre></td></tr></table></figure><p>（1.1）RepeatModeler结果文件</p><p>consensi.fa：自身比对找到的一致性序列<br>consensi.fa.classified：重复序列分类结果，“#”后面的字符串是分类结果<br>consensi.fa.masked：屏蔽后的序列，不太使用<br>（2）RepeatMasker；屏蔽DNA序列中转座子或者低复杂度重复序列，输出的序列把已知的重复序列都屏蔽成N或X，并给出相应的位置和统计信息</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-comment">#将上一步的结果文件（自动生成，以“RM”开头）里面的consensi.fa.classified为libirary，对参考序列进行序列屏蔽</span><br><span class="hljs-comment">#运行</span><br>RepeatMasker -nolow  -e ncbi -pa 5 -norna -<span class="hljs-built_in">dir</span> ./  -lib consensi.fa.classified rice.sample.fa<br><br><span class="hljs-comment">#重要参数</span><br>-nolow. (不屏蔽低复杂序列，担心屏蔽后使得基因结构受到影响)<br>        Does not mask low_complexity DNA or simple repeats<br>-lib [filename] 自己制定的重复序列库<br>        Allows use of a custom library (e.g. from another species)<br> -e(ngine) [crossmatch|wublast|abblast|ncbi|rmblast|hmmer]<br>        Use an alternate search engine to the default.<br>-pa(rallel) [number]<br>        The number of sequence batch <span class="hljs-built_in">jobs</span> [50kb minimum] to run <span class="hljs-keyword">in</span> parallel.<br>-norna<br>        Does not mask small RNA (pseudo) genes<br>-<span class="hljs-built_in">dir</span> [directory name] 输出文件位置<br>        Writes output to this directory (default is query file directory,<br>        <span class="hljs-string">&quot;-dir .&quot;</span> will write to current directory).<br>-gff<br>        Creates an additional Gene Feature Finding format output<br></code></pre></td></tr></table></figure><p>（2.1）RepeatMasker输出结果</p><figure class="highlight gams"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs gams"><span class="hljs-comment">*.out：重复序列详细比对结果</span><br><span class="hljs-comment">*.masked：屏蔽后的序列</span><br><span class="hljs-comment">*.tbl：重复序列统计文件</span><br><span class="hljs-comment">*.cat：和out差不多</span><br></code></pre></td></tr></table></figure><p>（2.2）*.out 每一列含义</p><figure class="highlight erlang"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs erlang">第一列：比对分值，SW score<br>第二列：替代率 perc <span class="hljs-keyword">div</span>.<br>第三列：碱基缺失百分率<br>第四列：在重复序列中碱基缺失百分率<br>第五列：<span class="hljs-keyword">query</span> sequence<br>第六列：查询序列起始位置<br>第七列：查询序列终止位置<br>第八列：查询区域中超出比对区域碱基的数目，也就是没有比对上的碱基数<br>第九列：+/-(C)<br>第十列：比上的重复序列名称，类型命名<br>第十一列：比上重复序列的分类，和repeatmolder 中*.classed 是一样的<br>第十二列：比上的在数据库中的起始位置<br>第十三列：比上的在数据库中的终止位置<br>第十四列：在第十列上超出比对区域碱基的数目，也就是没有比对上的碱基数<br>第十五列：比对区域的ID，随机给的<br></code></pre></td></tr></table></figure><p>（2.3）最后将out文件可转为GFF文件，即完成基因组重复序列的鉴定</p><p>BLAST**，BLAST有两个版本可供选择, WuBLAST或者NCBI-BLAST，我个人倾向于NCBI-BLAST，并且推荐使用编译后二进制版本，因为编译实在是太花时间了</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs awk">cd ~/src<br>wget ftp:<span class="hljs-regexp">//</span>ftp.ncbi.nlm.nih.gov<span class="hljs-regexp">/blast/</span>executables<span class="hljs-regexp">/blast+/</span>LATEST/ncbi-blast-<span class="hljs-number">2.7</span>.<span class="hljs-number">1</span>+-x64-linux.tar.gz<br>tar xf ncbi-blast-<span class="hljs-number">2.7</span>.<span class="hljs-number">1</span>+-x64-linux.tar.gz -C ~<span class="hljs-regexp">/opt/</span>biosoft<br><span class="hljs-comment"># 环境变量</span><br>export PATH=~<span class="hljs-regexp">/opt/</span>biosoft<span class="hljs-regexp">/ncbi-blast-2.7.1+/</span>bin:<span class="hljs-variable">$PATH</span><br><span class="hljs-comment"># 用于后续的BRAKER2</span><br>conda create -n annotation blast=<span class="hljs-number">2.2</span>.<span class="hljs-number">31</span><br><br></code></pre></td></tr></table></figure><h3 id="AUGUSTUS-√"><a href="#AUGUSTUS-√" class="headerlink" title="AUGUSTUS √?"></a><strong>AUGUSTUS</strong> √?</h3><p> 可以说是最好的预测软件，使用conda安装</p><p><a href="https://github.com/Gaius-Augustus/Augustus">https://github.com/Gaius-Augustus/Augustus</a></p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs sh">UnsatisfiableError: The following specifications were found to be incompatible with your system:?????<br><br>  - feature:/linux-64::__glibc==2.17=0<br>  - augustus=3.4.0 -&gt; libgcc-ng[version=<span class="hljs-string">&#x27;&gt;=9.3.0&#x27;</span>] -&gt; __glibc[version=<span class="hljs-string">&#x27;&gt;=2.17&#x27;</span><br></code></pre></td></tr></table></figure><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-built_in">source</span> activate annotation<br><span class="hljs-comment">#conda install augustus=3.3 failed</span><br>conda search -c bioconda augustus<br>conda install -c bioconda augustus=3.2.2 failed ： libboost_iostream.so.1.60.0<br>conda install -c bioconda augustus=3.1<br></code></pre></td></tr></table></figure><h3 id="GeneMark-ES-x2F-ET√"><a href="#GeneMark-ES-x2F-ET√" class="headerlink" title="GeneMark-ES&#x2F;ET√?"></a><strong>GeneMark-ES&#x2F;ET</strong>√?</h3><p>是唯一一款支持无监督训练模型, 软件下载需要登记</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs awk">cd ~/src<br>wget http:<span class="hljs-regexp">//</span>topaz.gatech.edu<span class="hljs-regexp">/GeneMark/</span>tmp<span class="hljs-regexp">/GMtool_Qg87n/gm</span>_et_linux_64.tar.gz<br>tar xf gm_et_linux_64.tar.gz<br>mv gm_et_linux_64<span class="hljs-regexp">/gmes_petap/</span> ~<span class="hljs-regexp">/opt/</span>biosoft<br>wget http:<span class="hljs-regexp">//</span>topaz.gatech.edu<span class="hljs-regexp">/GeneMark/</span>tmp<span class="hljs-regexp">/GMtool_Qg87n/gm</span>_key_64.gz<br>gzip -dc gm_key_64.gz &gt; ~/.gm_key<br>cpan YAML Hash::Merge Logger::Simple Parallel::ForkManager<br>echo <span class="hljs-string">&quot;export PATH=$PATH:~/opt/biosoft/gmes_petap/&quot;</span> &gt;&gt; ~/.bashrc<br><br></code></pre></td></tr></table></figure><h3 id="GlimmerHMM"><a href="#GlimmerHMM" class="headerlink" title="GlimmerHMM:"></a><strong>GlimmerHMM</strong>:</h3><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs awk">cd ~/src<br>wget -<span class="hljs-number">4</span> ftp:<span class="hljs-regexp">//</span>ccb.jhu.edu<span class="hljs-regexp">/pub/</span>software<span class="hljs-regexp">/glimmerhmm/</span>GlimmerHMM-<span class="hljs-number">3.0</span>.<span class="hljs-number">4</span>.tar.gz<br>tar xf GlimmerHMM-<span class="hljs-number">3.0</span>.<span class="hljs-number">4</span>.tar.gz -C ~<span class="hljs-regexp">/opt/</span>biosoft<br></code></pre></td></tr></table></figure><h3 id="SNAP-√"><a href="#SNAP-√" class="headerlink" title="SNAP: √?"></a><strong>SNAP</strong>: √?</h3><p>基因从头预测工具，在处理含有长内含子上的基因组上表现欠佳</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs awk"><span class="hljs-comment"># 安装</span><br>cd ~/src<br>git clone https:<span class="hljs-regexp">//gi</span>thub.com<span class="hljs-regexp">/KorfLab/</span>SNAP.git<br>cd SNP<br>make<br>cd ..<br>mv SNAP ~<span class="hljs-regexp">/opt/</span>biosoft<br><span class="hljs-comment"># 环境变量</span><br>export Zoe=~<span class="hljs-regexp">/opt/</span>biosoft<span class="hljs-regexp">/SNAP/</span>Zoe<br>export PATH=~<span class="hljs-regexp">/opt/</span>biosoft/SNAP:<span class="hljs-variable">$PATH</span><br><br></code></pre></td></tr></table></figure><h3 id="Exonerate-2-2-√-cluster"><a href="#Exonerate-2-2-√-cluster" class="headerlink" title="Exonerate 2.2: √? cluster"></a><strong>Exonerate 2.2</strong>: √? cluster</h3><p>配对序列比对工具，提供二进制版本, 功能类似于GeneWise，能够<font color="blue">将cDNA或蛋白以gao align的方式和基因组序列联配</font>。</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-built_in">cd</span> ~/src<br>wget http://ftp.ebi.ac.uk/pub/software/vertebrategenomics/exonerate/exonerate-2.2.0-x86_64.tar.gz<br>tar xf exonerate-2.2.0-x86_64.tar.gz<br><span class="hljs-built_in">mv</span> exonerate-2.2.0-x86_64 ~/opt/biosoft/exonerate-2.2.0<br><span class="hljs-comment"># .bashrc添加环境变量</span><br><span class="hljs-built_in">export</span> PATH=~/opt/biosoft/exonerate-2.2.0:<span class="hljs-variable">$PATH</span><br><span class="hljs-comment"># 或</span><br>conda install -c bioconda exonerate<br>---下载最新版本2.4.0<br>sudo?<br><br></code></pre></td></tr></table></figure><h3 id="GenomeThreader-1-703-failed-√"><a href="#GenomeThreader-1-703-failed-√" class="headerlink" title="GenomeThreader 1.703 failed: √?"></a>GenomeThreader 1.703 failed: √?</h3><p>同源预测软件，1.7.0版本更新于2018年2月</p><p><a href="https://genomethreader.org/download.html">https://genomethreader.org/download.html</a> 1.7.3-2020-01</p><p>error:gth: &#x2F;lib64&#x2F;libc.so.6: version &#96;GLIBC_2.27’ not found (required by gth)</p><p>1.7.1</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-comment">#wget -4 http://genomethreader.org/distributions/gth-1.7.0-Linux_x86_64-64bit.tar.gz</span><br><span class="hljs-comment">#tar xf gth-1.7.0-Linux_x86_64-64bit.tar.gz -C ~/opt/biosoft</span><br>tar xf gth-1.7.3-Linux_x86_64-64bit.tar.gz -C ./<br><span class="hljs-comment"># 修改.bashrc增加如下行</span><br><span class="hljs-built_in">export</span> PATH=<span class="hljs-variable">$PATH</span>:<span class="hljs-variable">$HOME</span>/opt/biosoft/gth-1.7.0-Linux_x86_64-64bit/bin<br><span class="hljs-built_in">export</span> BSSMDIR=<span class="hljs-string">&quot;<span class="hljs-variable">$HOME</span>/opt/biosoft/gth-1.7.0-Linux_x86_64-64bit/bin/bssm&quot;</span><br><span class="hljs-built_in">export</span> GTHATADIR=<span class="hljs-string">&quot;<span class="hljs-variable">$HOME</span>/opt/biosoft/gth-1.7.0-Linux_x86_64-64bit/bin/gthdata&quot;</span><br><br></code></pre></td></tr></table></figure><h3 id="BRAKER2"><a href="#BRAKER2" class="headerlink" title="BRAKER2:"></a><strong>BRAKER2</strong>:</h3><p>依赖AUGUSTUS 3.3, GeneMark-EX 4.33, BAMTOOLS 2.5.1, NCBI BLAST+ 2.2.31+(可选 SAMTOOLS 1.74+, GenomeThreader 1.70)</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs sh">cpan File::Spec::Functions Module::Load::Conditional POSIX Scalar::Util::Numeric YAML File::Which Logger::Simple Parallel::ForkManager<br><span class="hljs-built_in">cd</span> ~/src<br>wget -4 http://exon.biology.gatech.edu/GeneMark/Braker/BRAKER2.tar.gz<br>tar xf BRAKER2.tar.gz -C ~/opt/biosoft<br><span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;export PATH=<span class="hljs-variable">$PATH</span>:<span class="hljs-variable">$HOME</span>/opt/biosoft/BRAKER_v2.1.0/&quot;</span> &gt;&gt; ~/.bashrc<br><span class="hljs-comment"># 在~/.bashrc设置如下软件所在环境变量</span><br><span class="hljs-built_in">export</span> AUGUSTUS_CONFIG_PATH=<span class="hljs-variable">$HOME</span>/miniconda3/envs/annotation/config/<br><span class="hljs-built_in">export</span> AUGUSTUS_SCRIPTS_PATH=<span class="hljs-variable">$HOME</span>/miniconda3/envs/annotation/bin/<br><span class="hljs-built_in">export</span> BAMTOOLS_PATH=<span class="hljs-variable">$HOME</span>/miniconda3/envs/annotation/bin/<br><span class="hljs-built_in">export</span> GENEMARK_PATH=<span class="hljs-variable">$HOME</span>/opt/biosoft/gmes_petap/<br><span class="hljs-built_in">export</span> SAMTOOLS_PATH=<span class="hljs-variable">$HOME</span>/miniconda3/envs/annotation/bin/<br><span class="hljs-built_in">export</span> ALIGNMENT_TOOL_PATH=<span class="hljs-variable">$HOME</span>/opt/biosoft/gth-1.7.0-Linux_x86_64-64bit/bin/<br><br></code></pre></td></tr></table></figure><p>参考<a href="https://www.cnblogs.com/jessepeng/p/14806266.html">https://www.cnblogs.com/jessepeng/p/14806266.html</a></p><h3 id="TransDecoder"><a href="#TransDecoder" class="headerlink" title="TransDecoder"></a>TransDecoder</h3><p>编码区域预测工具，需要预先安装NCBI-BLAST</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">cpan</span> URI::Escape<br><span class="hljs-attribute">cd</span> ~/src<br><span class="hljs-attribute">wget</span> -<span class="hljs-number">4</span> https://github.com/TransDecoder/TransDecoder/archive/TransDecoder-v5.<span class="hljs-number">3</span>.<span class="hljs-number">0</span>.zip<br><span class="hljs-attribute">unzip</span> TransDecoder-v5.<span class="hljs-number">3</span>.<span class="hljs-number">0</span>.zip<br><span class="hljs-attribute">cd</span> TransDecoder-v5.<span class="hljs-number">3</span>.<span class="hljs-number">0</span><br><span class="hljs-attribute">make</span> test<br><br></code></pre></td></tr></table></figure><h3 id="MAKER"><a href="#MAKER" class="headerlink" title="MAKER:"></a><strong>MAKER</strong>:</h3><p>Conda failed</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs sh">conda create -n maker<br>conda activate<br>conda search -c bioconda maker<br>conda install -c bioconda maker=3.01.03<br>UnsatisfiableError: The following specifications were found to be incompatible with your system:<br><br>  - feature:/linux-64::__glibc==2.17=0<br>  - maker=3.01.03 -&gt; libgcc-ng[version=<span class="hljs-string">&#x27;&gt;=9.3.0&#x27;</span>] -&gt; __glibc[version=<span class="hljs-string">&#x27;&gt;=2.17&#x27;</span>]<br><br></code></pre></td></tr></table></figure><h3 id="PASA"><a href="#PASA" class="headerlink" title="PASA:"></a>PASA:</h3><p> 依赖于一个数据库(MySQL或SQLite), Perl模块(DBD::mysql或DBD::SQLite), GMAP, BLAT, Fasta3。由于MySQL在HPC集群中的表现不如SQLite，以及安装MySQL还需要各种管理员权限，于是就有人进行了修改，增加了feature&#x2F;sqlite分支, 见Add support for SQLite</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs awk">cpan DB_File URI::Escape DBI DBD::SQLite<br><span class="hljs-comment"># GMAP</span><br>wget http:<span class="hljs-regexp">//</span>research-pub.gene.com<span class="hljs-regexp">/gmap/</span>src/gmap-gsnap-<span class="hljs-number">2017</span>-<span class="hljs-number">11</span>-<span class="hljs-number">15</span>.tar.gz<br>tar xf gmap-gsnap-<span class="hljs-number">2017</span>-<span class="hljs-number">11</span>-<span class="hljs-number">15</span>.tar.gz<br>cd gmap-<span class="hljs-number">2017</span>-<span class="hljs-number">11</span>-<span class="hljs-number">15</span><br>.<span class="hljs-regexp">/configure --prefix=$HOME/</span>opt/gmap<br>make &amp;&amp; make install<br><span class="hljs-comment"># BLAT</span><br>cd ~<span class="hljs-regexp">/opt/</span>bin<br>wget http:<span class="hljs-regexp">//</span>hgdownload.soe.ucsc.edu<span class="hljs-regexp">/admin/</span>exe<span class="hljs-regexp">/linux.x86_64/</span>blat<span class="hljs-regexp">/blat &amp;&amp; chmod 755 ./</span>blat<br><span class="hljs-comment"># Fasta3</span><br>wget -<span class="hljs-number">4</span> http:<span class="hljs-regexp">//</span>faculty.virginia.edu<span class="hljs-regexp">/wrpearson/</span>fasta<span class="hljs-regexp">/fasta36/</span>fasta-<span class="hljs-number">36.3</span>.<span class="hljs-number">8</span>g.tar.gz &amp;&amp; \<br>        tar zxvf fasta-<span class="hljs-number">36.3</span>.<span class="hljs-number">8</span>g.tar.gz &amp;&amp; \<br>        cd .<span class="hljs-regexp">/fasta-36.3.8g/</span>src &amp;&amp; \<br>        make -f ..<span class="hljs-regexp">/make/</span>Makefile.linux_sse2 all &amp;&amp; \<br>        cp ..<span class="hljs-regexp">/bin/</span>fasta36 ~<span class="hljs-regexp">/opt/</span>bin<br><span class="hljs-comment"># 以上程序需添加到环境变量中</span><br><span class="hljs-comment"># PASApipeline</span><br>cd ~<span class="hljs-regexp">/opt/</span>biosoft<br>git clone https:<span class="hljs-regexp">//gi</span>thub.com<span class="hljs-regexp">/PASApipeline/</span>PASApipeline.git<br>cd PASApipeline &amp;&amp; \<br>git checkout feature/sqlite &amp;&amp; \<br>git submodule init &amp;&amp; git submodule update &amp;&amp; \<br>make<br><br></code></pre></td></tr></table></figure><p><a href="https://links.jianshu.com/go?to=http://weatherby.genetics.utah.edu/MAKER/wiki/index.php/The_MAKER_control_files_explained">http://weatherby.genetics.utah.edu/MAKER/wiki/index.php/The_MAKER_control_files_explained</a></p><h3 id="EVidenceModeler-√"><a href="#EVidenceModeler-√" class="headerlink" title="EVidenceModeler: √?"></a><strong>EVidenceModeler</strong>: √?</h3><p> 整合不同来源的注释结果，找到可靠的基因结构</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">cd</span> ~/src<br><span class="hljs-attribute">wget</span> -<span class="hljs-number">4</span> https://github.com/EVidenceModeler/EVidenceModeler/archive/v1.<span class="hljs-number">1</span>.<span class="hljs-number">1</span>.tar.gz<br><span class="hljs-attribute">tar</span> xf v1.<span class="hljs-number">1</span>.<span class="hljs-number">1</span>.tar.gz<br><span class="hljs-attribute">mv</span> EVidenceModeler-<span class="hljs-number">1</span>.<span class="hljs-number">1</span>.<span class="hljs-number">1</span> ~/opt/biosoft/<br><br></code></pre></td></tr></table></figure><hr><h1 id="The-NCBI-Eukaryotic-Genome-Annotation-Pipeline"><a href="#The-NCBI-Eukaryotic-Genome-Annotation-Pipeline" class="headerlink" title="The NCBI Eukaryotic Genome Annotation Pipeline"></a><a href="https://www.ncbi.nlm.nih.gov/genome/annotation_euk/process/">The NCBI Eukaryotic Genome Annotation Pipeline</a></h1><hr><p><a href="https://github.com/meiyang12/Genome-annotation-pipeline">https://github.com/meiyang12/Genome-annotation-pipeline</a></p><hr><p><a href="https://github.com/fohebert/GenomeAnnotation">https://github.com/fohebert/GenomeAnnotation</a></p><hr>]]></content>
    
    
    <categories>
      
      <category>Software</category>
      
    </categories>
    
    
    <tags>
      
      <tag>annotation</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Organelle assembly</title>
    <link href="/GeekFocus/2022/03/18/2022-03-18-mito-chro/"/>
    <url>/GeekFocus/2022/03/18/2022-03-18-mito-chro/</url>
    
    <content type="html"><![CDATA[<p>organelle assembly</p><span id="more"></span><h1 id="Mitochondrial-Genome-Assembly"><a href="#Mitochondrial-Genome-Assembly" class="headerlink" title="Mitochondrial Genome Assembly"></a><strong>Mitochondrial Genome Assembly</strong></h1><h2 id="植物线粒体基因组-特点，成因和后果"><a href="#植物线粒体基因组-特点，成因和后果" class="headerlink" title="植物线粒体基因组 特点，成因和后果"></a><a href="https://www.zhihu.com/question/65471820#:~:text=%E6%A4%8D%E7%89%A9%E7%BA%BF%E7%B2%92%E4%BD%93%E5%9F%BA%E5%9B%A0%E7%BB%84%E7%9A%84%E4%B8%BB%E8%A6%81%E7%89%B9%E7%82%B9%E6%98%AF%EF%BC%9A%20%E5%9F%BA%E5%9B%A0%E7%BB%84%E5%A4%A7%E5%B0%8F%E5%92%8C%E7%BB%93%E6%9E%84%E5%8F%98%E5%BC%82%E5%B7%A8%E5%A4%A7%EF%BC%8C%E5%9F%BA%E5%9B%A0%E5%8D%B4%E6%9E%81%E5%BA%A6%E4%BF%9D%E5%AE%88%EF%BC%9B%E5%9F%BA%E5%9B%A0%E5%88%86%E5%B8%83%E9%9D%9E%E5%B8%B8%E7%A8%80%E7%96%8F%EF%BC%8C%E5%90%AB%E6%9C%89%E5%A4%A7%E9%87%8F%E9%9D%9E%E7%BC%96%E7%A0%81%E5%BA%8F%E5%88%97%EF%BC%9B%E5%AD%98%E5%9C%A8%E5%A4%A7%E9%87%8F%E7%9A%84RNA%E7%BC%96%E8%BE%91%E3%80%82,%E5%A4%A7%E9%83%A8%E5%88%86%E5%8A%A8%E7%89%A9%E7%9A%84%E7%8E%AF%E7%8A%B6%E7%BA%BF%E7%B2%92%E4%BD%93%E5%9F%BA%E5%9B%A0%E7%BB%84%E7%9A%84%E5%A4%A7%E5%B0%8F%E7%BA%A615-17kb%EF%BC%8C%E4%B8%94%E7%BB%93%E6%9E%84%E7%9B%B8%E5%AF%B9%E4%BF%9D%E5%AE%88%EF%BC%8C%E5%9F%BA%E5%9B%A0%E6%8E%92%E5%88%97%E7%B4%A7%E5%87%91%EF%BC%8C%E8%BF%99%E4%BA%9B%E7%89%B9%E7%82%B9%E9%83%BD%E8%B7%9F%E6%A4%8D%E7%89%A9%E5%8F%B6%E7%BB%BF%E4%BD%93%E5%9F%BA%E5%9B%A0%E7%BB%84%E7%9B%B8%E4%BB%BF%EF%BC%8C%E6%A4%8D%E7%89%A9%E7%9A%84%E5%8F%B6%E7%BB%BF%E4%BD%93%E5%9F%BA%E5%9B%A0%E7%BB%84%E5%A4%A7%E5%B0%8F%E5%9C%A8100-200kb%E4%B9%8B%E9%97%B4%E3%80%82%20%E7%84%B6%E8%80%8C%E6%A4%8D%E7%89%A9%E7%BA%BF%E7%B2%92%E4%BD%93%E5%9F%BA%E5%9B%A0%E7%BB%84%E5%8D%B4%E8%B7%9F%E5%89%8D%E4%B8%A4%E8%80%85%E6%9C%89%E7%9D%80%E8%BF%A5%E7%84%B6%E4%B8%8D%E5%90%8C%E7%9A%84%E7%89%B9%E6%80%A7%EF%BC%8C%E5%85%B6%E5%A4%A7%E5%B0%8F%E4%B8%80%E8%88%AC%E5%9C%A8200-750kb%E4%B9%8B%E9%97%B4%E3%80%82">植物线粒体基因组 特点，成因和后果</a></h2><p>植物线粒体基因组主要特点是：<strong>基因组大小和结构变异巨大，基因却极度保守；基因分布非常稀疏，含有大量非编码序列；存在大量的RNA编辑。</strong></p><ul><li><p>大部分<strong>动物环状线粒体基因组</strong>大小约<strong>15-17kb</strong>，且<strong>结构相对保守</strong>，<strong>基因排列紧凑</strong></p></li><li><p>动物线粒体跟<strong>植物叶绿体基因组相仿</strong>，<strong>植物叶绿体基因组</strong>大小在<strong>100-200kb之间</strong></p></li><li><p><strong>植物线粒体基因组</strong>却跟前两者迥然不同，大小在<strong>200-750kb</strong>之间。<strong>黄瓜</strong>线粒体基因组达<strong>1556kb</strong>。<strong>近缘</strong>物种间<strong>也差异巨大</strong>。如蝇子草属（<em>Silene</em>）中，夜花蝇子草（<em>S. noctiflora</em>）线粒体基因组<strong>6.728kb</strong>，而叉枝条蝇子草（<em>S. latifolia</em>）线粒体基因组<strong>253kb</strong>，<strong>同属</strong>植物差异30倍。即使<strong>同一物种</strong>，差异也显著。如白玉草（<em>S. vulgaris</em>），任何<strong>不同种群</strong>两两之间只有约一半的线粒体基因组序列相同。</p></li><li><p>植物线粒体<strong>基因组庞大</strong>，但<strong>编码基因却不多</strong>，排列稀疏。<strong>植物叶绿体基因组</strong>上约<strong>100个基因</strong>，但比叶绿体基因组大的<strong>拟南芥线粒体基因组</strong>，却只有约<strong>50多个基因</strong>，而人线粒体基因组37个基因。拟南芥<strong>线粒体基因数量</strong>不到人的<strong>两倍</strong>，其<strong>基因组大小</strong>却是<strong>22倍</strong>。植物线粒体基因组大部分是<strong>非编码序列</strong>，这些序列占到<strong>60%以上</strong>。这些非编码序列由<strong>重复片段、叶绿体基因组和和基因组转移而来</strong>的序列，甚至是<strong>基因水平转移</strong>获得的其它物种序列。如最<strong>古老的被子植物互叶梅</strong>（<em>Amborella trichopoda</em>）的线粒体基因组中，就有<strong>大量来自苔藓、绿藻和其它被子植物的序列片段</strong>（Rice, 2013）。</p></li><li><p>植物线粒体基因组<strong>结构变异巨大</strong>，线粒体<strong>基因</strong>却<strong>极度保守</strong>，在<strong>植物三套基因组中最保守演化速率最慢</strong>。黄瓜如此庞大线粒体基因组只比拟南芥多四个基因。由于植物线粒体基因<strong>非常保守，区分度不足</strong>，一般<strong>不选作系统学研究</strong>的<strong>分子标记</strong>。跟动物正好相反，<strong>动物的线粒体基因演化速率较快</strong>，所以在动物系统学研究中，是<strong>最常用的分子标记</strong>。</p></li><li><p><strong>是什么导致植物线粒体基因组如此庞大，如此多非编码序列？线粒体基因组基因保守原因是？目前理论是发生在线粒体非编码区和编码区的两套不同DNA修复机制。</strong></p></li><li><p>植物线粒体<strong>编码区</strong>进行的是<strong>碱基剪切修复</strong>（Base excision repair）和<strong>基因转换</strong>（gene conversion）介导的<strong>精确</strong>修复，而在非编码区进行的是<strong>非同源性末端连接</strong>（non-homologous end joining）和<strong>断裂诱导复制</strong>（Break-induced replication）介导的<strong>非精确</strong>修复（Christensen, 2013）</p></li></ul><p><img src="/GeekFocus/./1.png" alt="img"></p><ul><li>编码区精确修复导致线粒体基因变异稀少，演化速率非常慢。非编码区非精确修复，修复过程带来很多外来序列，使得非编码区非常包容，不断吸收积累非编码序列</li><li>后果。植物线粒体基因组中大量非编码序列，其中很多重复片段，导致植物线粒体基因组 易重组。叶绿体基因组在细胞内常以完整环状存在，植物线粒体会重组形成线状结构，甚至很多大小不一的环。黄瓜有1.6M+84k+45k线粒体基因组(大小环)。完整测出的mito 远小于chro</li></ul><h2 id="植物线粒体基因组测序"><a href="#植物线粒体基因组测序" class="headerlink" title="植物线粒体基因组测序"></a>植物线粒体基因组测序</h2><p><a href="http://www.genepioneer.com/display.php?id=353">http://www.genepioneer.com/display.php?id=353</a></p><ul><li><p>动物线粒体基因组较小，通常在10-39kb，而植物线粒体基因组大小在200-750kb。植物线粒体基因组主要特点是：基因组大小和结构变异巨大；基因却极度保守；基因分布非常稀疏；含有大量非编码序列；存在大量的RNA编辑</p></li><li><p>公司套路：二代+三代植物线粒体基因组测序</p><ul><li><strong>基因组注释</strong>进行<strong>基因序列组成分析</strong>来研究<strong>物种功能特征</strong></li><li><strong>比较基因组学</strong>研究物<strong>种间基因组结构变化</strong>探讨物<strong>种的环境适应性特征</strong></li><li><strong>群体基因组研究</strong>内容更广：<strong>物种起源、亲缘分类、系统发育、谱系地理</strong>等</li></ul></li><li><p>公司常规分析</p><ul><li>线粒体基因组结构注释</li><li>线粒体基因组图谱</li><li>RSCU分析</li><li>散在重复序列分析</li><li>碱基偏移分析</li></ul></li><li><p>公司高级分析</p><ul><li>KaKs分析</li><li>线粒体结构比较分析</li><li>进化树分析</li><li>序列同源及共线性分析</li><li>基因水平转移分析</li></ul></li><li><p>案例1</p><ul><li><a href="doi.org/10.1186/s12862-020-1582-1">紫衫线粒体基因组</a>：8个蛋白基因转移到核基因组。对紫衫线粒体基因组测序，得到全长<font color="blue"><strong>468,924bp</strong></font>线粒体基因组序列与<strong>其它4个裸子植物谱系</strong>的<strong>线粒体基因组</strong>比较。结果表明裸子植物线粒体基因组在<strong>大小、结构、基因和内含子含量、外源序列、突变率</strong>等方面与<strong>被子植物</strong>线粒体基因组<strong>存在差异</strong>。</li><li><a href="DOI%EF%BC%9A10.7717/peerj.3148">红柳线粒体全基因组序列的组装与比较分析</a> : 组装得到全长<font color="blue"><strong>644,437bp</strong></font>完整的红柳线粒体 (mt) 序列。编码<font color="blue"><strong>58个独特基因</strong></font>（32个蛋白编码基因、23个tRNA基因和3个rRNA基因）。通过对35种杨树的23个蛋白编码基因<strong>系统发育分析</strong>，证明<strong>红柳是杨树的姊妹</strong>。</li></ul></li></ul><h2 id="software-2019review-DOI-10-16288-x2F-j-yczz-19-227"><a href="#software-2019review-DOI-10-16288-x2F-j-yczz-19-227" class="headerlink" title="[software-2019review](DOI: 10.16288&#x2F;j.yczz.19-227)"></a>[software-2019review](DOI: 10.16288&#x2F;j.yczz.19-227)</h2><ul><li>特殊且容易获取的遗传标记，高突变速率(not plant)、无基因重组、高拷贝数和母系遗传等</li><li>进化生物学、群体遗传学等揭示物种的起源和扩散历史发挥作用。核基因和线粒体表现不一致的谱系关系，特别是具有复杂的群体历史的类群(如<strong>基因交流</strong>、<strong>遗传漂变</strong>、<strong>偏向性迁徙</strong>和<strong>祖先谱系分拣</strong>等)。</li><li>有参：近缘物种的线粒体基因组或部分片段作为参考序列，从研究类群全基因组数据中捕获线粒体reads。(1)基于线粒体<strong>整个</strong>基因组的拼装策略；(2)基于线粒体<strong>片段</strong>的拼装策略。使用比对工具(如BWA)将总reads映射(mapping)到线粒体参考序列，根据<strong>序列的相似性捕获</strong>线粒体reads，然后使用不同序列延长策略对捕获的线粒体reads序列延伸，直到延长到完整的线粒体基因组长度。<strong>MIA</strong>用现代人线粒体基因组作参考研究尼安德特人。</li><li>denovo：线粒体contig分拣</li></ul><table><thead><tr><th>软件名称</th><th>是否需要参考序列&#x2F; 参考序列类型</th><th>适用 物种</th><th>输入文件格式、 类型</th><th>变异 注释</th><th>结构可 视化</th><th>运行 环境</th><th>编程 语言</th></tr></thead><tbody><tr><td>MIA</td><td>是&#x2F;自定义参考序列</td><td>任意 物种</td><td>Fastq、SE reads和 PE reads</td><td>×</td><td>×</td><td>CUI</td><td>C&#x2F;C++</td></tr><tr><td>MitoBamAnnotator</td><td>是&#x2F; rCRS</td><td>人</td><td>Bam</td><td>√</td><td>√</td><td>Web</td><td>Java</td></tr><tr><td>MitoSeek</td><td>是&#x2F;rCRS和hg19</td><td>人</td><td>Bam</td><td>√</td><td>×</td><td>GUI</td><td>Perl</td></tr><tr><td>mtDNA- profiler</td><td>是&#x2F;rCRS</td><td>人</td><td>Fasta</td><td>×</td><td>√</td><td>Web</td><td>Java</td></tr><tr><td>MITObim</td><td>是&#x2F;自定义参考序列</td><td>任意 物种</td><td>Bam</td><td>×</td><td>×</td><td>CUI</td><td>Perl</td></tr><tr><td>Mit-o-matic</td><td>是&#x2F;rCRS</td><td>人</td><td>Fastq、SE reads和 PE reads</td><td>√</td><td>√</td><td>Web&#x2F;GUI</td><td>Java</td></tr><tr><td>MToolBox</td><td>是&#x2F;rCRS和RSRS</td><td>人</td><td>Fastq&#x2F;Bam&#x2F;Sam、 SE reads和PE reads</td><td>√</td><td>×</td><td>Web&#x2F;CUI</td><td>Python</td></tr><tr><td>ARC</td><td>是&#x2F;自定义参考序列</td><td>任意 物种</td><td>Fastq、SE reads和 PE reads</td><td>×</td><td>×</td><td>Web&#x2F;CUI</td><td>Python</td></tr><tr><td>Phy-Mer</td><td>是&#x2F;自定义参考序列</td><td>任意 物种</td><td>Fasta&#x2F;fastq&#x2F;Bam、 SE reads和PE reads</td><td>×</td><td>√</td><td>CUI</td><td>Python</td></tr><tr><td>mtDNA- Server</td><td>是&#x2F;rCRS和RSRS</td><td>人</td><td>Fastq&#x2F;Bam&#x2F;VCF、 SE reads和PE reads</td><td>√</td><td>√</td><td>Web</td><td>Java</td></tr><tr><td>IOGA</td><td>是&#x2F;自定义参考序列</td><td>任意 物种</td><td>Fastq、SE reads和 PE reads</td><td>×</td><td>×</td><td>CUI</td><td>Python</td></tr><tr><td>NOVOPlasty</td><td>是&#x2F;自定义参考序列</td><td>任意 物种</td><td>Fastq&#x2F;fasta、SE reads 和PE reads</td><td>×</td><td>×</td><td>Web&#x2F;CUI</td><td>Perl</td></tr><tr><td>Norgal</td><td>否</td><td>任意 物种</td><td>Fastq、SE reads和 PE reads</td><td>×</td><td>×</td><td>CUI</td><td>Python&#x2F; Java</td></tr><tr><td>Organelle- PBA</td><td>是&#x2F;自定义参考序列</td><td>任意 物种</td><td>PacBio reads</td><td>×</td><td>×</td><td>CUI</td><td>Perl</td></tr><tr><td>MitoSuite</td><td>是&#x2F;rCRS, RSRS, hg19, GRCh37和38</td><td>人</td><td>Bam&#x2F;Sam</td><td>√</td><td>√</td><td>GUI</td><td>Python</td></tr><tr><td>ORG.Asm</td><td>是&#x2F;自定义参考序列</td><td>任意 物种</td><td>Fastq、SE reads和 PE reads</td><td>×</td><td>×</td><td>CUI</td><td>Python</td></tr><tr><td>MitoZ</td><td>否</td><td>任意 物种</td><td>Fastq、SE reads和 PE reads</td><td>√</td><td>√</td><td>CUI</td><td>Python</td></tr><tr><td><strong>GetOrganelle</strong></td><td>是&#x2F;自定义参考序列</td><td>任意 物种</td><td>Fastq、SE reads和 PE reads</td><td>×</td><td>×</td><td><strong>CUI</strong></td><td>Python</td></tr><tr><td>Trimitomics</td><td>是&#x2F;自定义参考序列</td><td>任意 物种</td><td>RNA-seq reads、 PE reads</td><td>×</td><td>×</td><td>Unknown</td><td>Unknown</td></tr></tbody></table><h2 id="软件GetOrganelle"><a href="#软件GetOrganelle" class="headerlink" title="软件GetOrganelle"></a>软件GetOrganelle</h2><p><a href="https://zhuanlan.zhihu.com/p/428949195">https://zhuanlan.zhihu.com/p/428949195</a></p><p><a href="https://github.com/Kinggerm/GetOrganelle">https://github.com/Kinggerm/GetOrganelle</a></p><p>GetOrganelle是中科院昆植所金建军和郁文彬老师共同开发的<strong>质体组装软件</strong>，<strong>2020-Genome Biology</strong>。</p><h3 id="核心流程"><a href="#核心流程" class="headerlink" title="核心流程"></a>核心流程</h3><p>1）通过“种子”序列获得部分目标相关reads；</p><p>2）延伸reads获得所有目标相关reads；</p><p>3）对reads进行从头组装得到组装图形；</p><p>4）过滤组装图形；</p><p>5）识别细胞器组分并自动导出所有可能的细胞器基因组结构。</p><p><img src="/GeekFocus/./2.png" alt="flowchart"></p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs sh">conda create -n getorganelle<br>conda activate getorganelle<br>conda install getorganelle<br></code></pre></td></tr></table></figure><p><strong>下载参考序列库</strong></p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs sh">get_organelle_config.py --add embplant_pt,embplant_mt<br><span class="hljs-comment">#embplant_pt(高等植物叶绿体)</span><br><span class="hljs-comment">#embplant_mt(高等植物线粒体)</span><br><span class="hljs-comment">#embplant_nr(高等植物核糖体 RNA)</span><br><span class="hljs-comment">#animal_mt (动物线粒体)</span><br><span class="hljs-comment">#fungus_mt (真菌线粒体)</span><br></code></pre></td></tr></table></figure><p>If connection keeps failing, please manually download the latest database from <a href="https://github.com/Kinggerm/GetOrganelleDB">GetOrganelleDB</a> and <a href="https://github.com/Kinggerm/GetOrganelle/wiki/Initialization#option-2-initialization-from-local-files">initialization from local files</a>.</p><p>The database will be located at <code>~/.GetOrganelle</code> by default, which can be changed via the command line parameter <code>--config-dir</code>, or via the shell environment variable <code>GETORG_PATH</code> (see more <a href="https://github.com/Kinggerm/GetOrganelle/wiki/Initialization">here</a>).</p><h3 id="参数"><a href="#参数" class="headerlink" title="参数"></a>参数</h3><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs sh">-1 双端测序的R1<br>-2 双端测序的R2<br>-o 结果文件，结果输出保存的目录(文件夹)名称<br>-F 数据库，设定要组装的基因组类型<br>-s 参考序列<br>-t 线程数<br>-R 最大的一个扩充循环的数，一般默认15，提取基因 reads 的轮次(轮次越多,耗时越长)<br>-k kmer的一个参数，调用SPAdes进行denovo组装的k-mer,数值必须是奇数, 最大值是127<br>-w 提取叶绿体基因reads 时使用的长度比例或实际长度<br><span class="hljs-comment">#word-size：提取叶绿体基因reads 时，可以使用reads 长度的比例(ratio)，也可以设置实际长度的word-size。例如：如果使用ratio=0.6, 即 reads长度是150bp时，设置的word-size = 90bp，等同于设置 “-w 90”。</span><br></code></pre></td></tr></table></figure><h3 id="基本用法"><a href="#基本用法" class="headerlink" title="基本用法"></a>基本用法</h3><p><strong>Starting from reads</strong></p><p>The <font color="green"><strong>green workflow</strong></font> in the flowchart  shows the processes of <code>get_organelle_from_reads.py</code>.</p><ul><li><p><strong>Input data</strong></p><p>Currently, <code>get_organelle_from_reads.py</code> was written for <strong>illumina pair-end&#x2F;single-end data</strong> (fastq or fastq.gz). We recommend using <strong>adapter-trimmed</strong> raw reads without quality control. Usually, <strong>&gt;1G</strong> per end is enough for <strong>plastome</strong> for most normal angiosperm samples, and <strong>&gt;5G</strong> per end is enough for <strong>mitochondria</strong> genome assembly. Since v1.6.2, <code>get_organelle_from_reads.py</code> will <strong>automatically estimate the read data it needs</strong>, without user assignment nor data reducing (see flags <code>--reduce-reads-for-coverage</code> and <code>--max-reads</code>).</p></li><li><p><strong>Main Options</strong></p><ul><li><code>-w</code> The value word size, like the kmer in assembly, is crucial to the <strong>feasibility and efficiency</strong> of this process. The <strong>best word size changes upon data and will be affected</strong> by read length, read quality, base coverage, organ DNA percent and other factors. By default, GetOrganelle would <strong>automatically estimate a proper word siz</strong>e based on the data characters. Although the automatically-estimated word size value does not ensure the best performance nor the best result, <font color="green">you do not need to adjust this value</font> (<code>-w</code>) if a complete&#x2F;circular organelle genome assembly is produced, because the circular result generated by GetOrganelle is highly consistent under different options and seeds. The automatically estimated word size may be screwy in some animal mitogenome data due to inaccurate coverage estimation, for which you fine-tune it instead.</li><li><code>-k</code> The best kmer(s) depend on a wide variety of factors too. Although more kmer values add the time consuming, you are recommended to use a wide range of kmers to benefit from the power of SPAdes. Empirically, you should include <strong>at least</strong> including <strong>one small</strong> kmer (e.g. <code>21</code>) and <strong>one large</strong> kmer (<code>105</code>) for a successful organelle genome assembly.</li><li><code>-s</code> GetOrganelle takes the seed (fasta format; if this was not provided, the default is <code>GetOrganelleLib/SeedDatabase/*.fasta</code>) as probe, the script would recruit target reads in successive rounds (extending process). <strong>The default seed works for most samples</strong>, but using a complete organelle genome sequence of a <strong>related species as the seed would help the assembly</strong> in many cases (e.g. degraded DNA samples, fastly-evolving in animal&#x2F;fungal samples; see more <a href="https://github.com/Kinggerm/GetOrganelle/wiki/FAQ#how-to-assemble-a-target-organelle-genome-using-my-own-reference">here</a>).</li></ul></li><li><p><strong>Key Results</strong></p><p>The key output files include</p><ul><li><code>*.path_sequence.fasta</code>, each fasta file represents one type of genome structure</li><li><code>*.selected_graph.gfa</code>, the <a href="https://github.com/Kinggerm/GetOrganelle/wiki/Terminology">organelle-only assembly graph</a></li><li><code>get_org.log.txt</code>, the log file</li><li><code>extended_K*.assembly_graph.fastg</code>, the raw assembly graph</li><li><code>extended_K*.assembly_graph.fastg.extend_embplant_pt-embplant_mt.fastg</code>, a simplified assembly graph</li><li><code>extended_K*.assembly_graph.fastg.extend_embplant_pt-embplant_mt.csv</code>, a tab-format contig label file for bandage visualization</li></ul><p>You may delete the files other than above if the resulting genome is complete (indicated in the log file and the name of the <code>*.fasta</code>). You are expected to obtain the complete organelle genome assembly for most animal&#x2F;fungal mitogenomes and plant chloroplast genomes (see <a href="https://github.com/Kinggerm/GetOrganelle/wiki/FAQ#why-does-getorganelle-generate-a-circular-genome-for-embplant_nrfungus_nr">here for nuclear ribosomal DNAs</a>) with the recommended recipes.</p><p>If GetOrganelle <strong>failed</strong> to <strong>generate the complete circular genome</strong> (produce <code>*scaffolds*path_sequence.fasta</code>), please follow <a href="https://github.com/Kinggerm/GetOrganelle/wiki/FAQ#what-should-i-do-with-incomplete-resultbroken-assembly-graph">here</a> to <strong>adjust your parameters for a second run</strong>. You could also use the incomplete sequence to conduct downstream analysis.</p></li></ul><p>#植物2G左右数据，<strong>组装叶绿体基因组</strong>用</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sh">get_organelle_from_reads.py -1 forward.fq -2 reverse.fq -o plastome_output -R 15 -k 21,45,65,85,105 -F embplant_pt<br></code></pre></td></tr></table></figure><p>#更快的方法</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sh">get_organelle_from_reads.py -1 forward.fq -2 reverse.fq -o plastome_output --fast -k 21,65,105 -w 0.68 -F embplant_pt<br></code></pre></td></tr></table></figure><p>#组装<strong>植物线粒体基因组</strong></p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs sh">get_organelle_from_reads.py -1 forward.fq -2 reverse.fq -o mitochondria_output -R 50 -k 21,45,65,85,105 -P 1000000 -F embplant_mt<br><span class="hljs-comment"># -P pre grouping value. default 20 0000</span><br><span class="hljs-comment"># 1. please use the 【FASTG file as the final output】 for downstream manual processing. until further updates, the FASTA output of plant mitochondria genome of numerous repeats may be error-prone</span><br><span class="hljs-comment"># 2. embplant_mt mode was not tested in the GetOrganelle paper due to the complexity of plant mitogenomes and the defects of short reads</span><br></code></pre></td></tr></table></figure><p>#组装<strong>植物核核糖体DNA</strong>片段</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sh">get_organelle_from_reads.py -1 forward.fq -2 reverse.fq -o nr_output -R 10 -k 35,85,115 -F embplant_nr<br></code></pre></td></tr></table></figure><p>#组装真菌线粒体</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sh">get_organelle_from_reads.py -1 forward.fq -2 reverse.fq -R 10 -k 21,45,65,85,105 -F fungus_mt -o fungus_mt_out<br></code></pre></td></tr></table></figure><p>#组装动物线粒体</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sh">get_organelle_from_reads.py -1 forward.fq -2 reverse.fq -R 10 -k 21,45,65,85,105 -F animal_mt -o animal_mt_out<br></code></pre></td></tr></table></figure><p>得到的文件有complete代表拼接成环。</p><p><strong>GetOrganelle –assembly 开始</strong></p><p>The <font color="blue"><strong>blue workflow</strong></font> in the chat shows the processes of <code>get_organelle_from_assembly.py</code>.</p><ul><li><p><strong>Input data &amp; Main Options</strong></p><ul><li><code>-g</code> The input must be a FASTG or GFA formatted assembly graph file.</li><li>If you input an assembly graph assembled from total DNA sequencing using third-party a de novo assembler (e.g. Velvet), the assembly graph may includes a great amount of non-target contigs. You may want to use <code>--min-depth</code> and <code>--max-depth</code> to greatly reduce the computational burden for target extraction.</li><li>If you input an <a href="https://github.com/Kinggerm/GetOrganelle/wiki/Terminology">organelle-equivalent assembly graph</a> (e.g. manually curated and exported using Bandage), you may use <code>--no-slim</code>.</li></ul></li><li><p><strong>Key Results</strong></p><p>The key output files include</p><ul><li><code>*.path_sequence.fasta</code>, one fasta file represents one type of genome structure</li><li><code>*.selected_graph.gfa</code>, the <a href="https://github.com/Kinggerm/GetOrganelle/wiki/Terminology">organelle-only assembly graph</a></li><li><code>get_org.log.txt</code>, the log file</li></ul></li></ul><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sh">get_organelle_from_assembly.py -g assembly_graph.fastg -F embplant_pt -o output-plastome<br></code></pre></td></tr></table></figure><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs sh">-g      SPAdes组装得到的FASTG的assembly graph<br>-F      设定要组装的基因组类型<br>-o      结果输出保存的目录(文件夹)名称<br>--min-depth  剔除graph中depth低于阈值的contigs<br>--max-depth    剔除graph中depth高于阈值的contigs<br>--min-depth 10 和“--max-depth10000”这两条命令是备选的，具体的depth需要可以自行设定。<br></code></pre></td></tr></table></figure><p><strong>GetOrganelle –graph.gfa开始</strong></p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs sh">gfa_to_fastg.py graph.gfa<br>get_organelle_from_assembly.py -g graph.gfa.fastg -F embplant_pt -o output-plastome --no-slim<br></code></pre></td></tr></table></figure><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs sh">-g     Bandage梳理后转换为fastg的graph*<br>-F     设定要组装的基因组类群:embplant_pt(叶绿体),embplant_mt(线粒体)和embplant_nr(核糖体 RNA)<br>-o     结果输出保存的目录(文件夹)名称<br></code></pre></td></tr></table></figure><blockquote><p>*，使用Bandage编辑后，可以“merge all possible nodes”，然后再输出的文件格式gfa图形文件，gfa文件可以用gfa_to_fastg.py做一下转换。虽然gfa也是图形文件，但是图形内容与fastg有差异些复杂图形会输出失败。</p></blockquote><h1 id="Chloroplast-Genome-Assembly"><a href="#Chloroplast-Genome-Assembly" class="headerlink" title="Chloroplast Genome Assembly**"></a>Chloroplast Genome Assembly**</h1>]]></content>
    
    
    <categories>
      
      <category>Software</category>
      
    </categories>
    
    
    <tags>
      
      <tag>assembly</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【hifi mapping】【purge_dups】</title>
    <link href="/GeekFocus/2022/03/18/2022-03-18-purgedups/"/>
    <url>/GeekFocus/2022/03/18/2022-03-18-purgedups/</url>
    
    <content type="html"><![CDATA[<p>purge haplotigs and overlaps in an assembly based on read depth</p><span id="more"></span><p><a href="https://github.com/dfguan/purge_dups">https://github.com/dfguan/purge_dups</a></p><h1 id="overview"><a href="#overview" class="headerlink" title="overview"></a>overview</h1><p>purge_dups is designed to remove haplotigs and contig overlaps in a <em>de novo</em> assembly based on read depth.</p><p><img src="/GeekFocus/./1.png" alt="img"></p><p><code>purge_dups</code>根据read深度分析组装中haplotigs和overlaps。相对于<code>purge_haplotigs</code>，运行速度更快，而且<strong>自动确定阈值</strong>。</p><p><code>purge_dups</code>分为三个部分，<strong>第一部分</strong>是将序列<strong>回贴</strong>到基因组并分析<strong>覆盖度确定阈值</strong>，<strong>第二部分</strong>是将<strong>组装自我比对</strong>，<strong>第三部分</strong>是利用前两部分得到的信息<strong>鉴定</strong>原来序列中的<strong>haplotigs和overlaps</strong>.</p><h1 id="Directory-Structure"><a href="#Directory-Structure" class="headerlink" title="Directory Structure"></a>Directory Structure</h1><ul><li>scripts&#x2F;pd_config.py: script to generate a configuration file used by run_purge_dups.py.</li><li>scripts&#x2F;run_purge_dups.py: script to run the <strong>purge_dups pipeline</strong>.</li><li>scripts&#x2F;run_busco: script to run busco, dependency: busco.</li><li>scripts&#x2F;run_kcm: script to make k-mer comparison plot.</li><li>scripts&#x2F;sub.sh: shell script to submit a <strong>farm</strong> job.</li><li>src: purge_dups source files.</li><li><font color="blue"><strong>src&#x2F;split_fa</strong></font>: split fasta file by ‘N’s.</li><li><font color="blue"><strong>src&#x2F;pbcstat</strong></font>: create <strong>read depth histogram and base-level read depth</strong> for an assembly based on <strong>pacbio</strong> data.</li><li><font color="blue"><strong>src&#x2F;ngstat</strong></font>: create read depth histogram and base-level read detph for an assembly based on <strong>illumina</strong> data.</li><li><font color="blue"><strong>src&#x2F;calcuts</strong></font>: <strong>calculate coverage cutoffs</strong>.</li><li><font color="blue"><strong>src&#x2F;purge_dups</strong></font>: <strong>purge haplotigs and overlaps</strong> for an <strong>assembly</strong>.</li><li><font color="blue"><strong>src&#x2F;get_seqs</strong></font>: <strong>obtain seqeuences after purging</strong>.</li><li>bin&#x2F;* : all purge_dups excutables.</li></ul><h1 id="installation"><a href="#installation" class="headerlink" title="installation"></a>installation</h1><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs sh">git <span class="hljs-built_in">clone</span> https://github.com/dfguan/purge_dups.git<br><span class="hljs-built_in">cd</span> purge_dups/src &amp;&amp; make<br><span class="hljs-comment">#脚本在scripts目录，编译程序在bin目录</span><br></code></pre></td></tr></table></figure><h1 id="Pipeline-Guide"><a href="#Pipeline-Guide" class="headerlink" title="Pipeline Guide"></a>Pipeline Guide</h1><p>Given a primary assembly <em><strong>pri_asm</strong></em> and an alternative assembly <em><strong>hap_asm</strong></em> (<strong>optional</strong>, if you have one), follow the steps shown below to build your own purge_dups pipeline, steps with same number can be run simultaneously. Among all the steps, although <strong>step 5 is optional</strong>, we <strong>highly recommend</strong> our users to do so, because <strong>assemblers may produce overrepresented seqeuences</strong>. In such a case, The final <strong>step 5</strong> can be applied to <strong>remove those seqeuences</strong>.</p><h2 id="Step-1-Run-minimap2-to-align-pacbio-data-and-generate-paf-files-then-calculate-read-depth-histogram-and-base-level-read-depth-根据覆盖度计算分界点-cutoff"><a href="#Step-1-Run-minimap2-to-align-pacbio-data-and-generate-paf-files-then-calculate-read-depth-histogram-and-base-level-read-depth-根据覆盖度计算分界点-cutoff" class="headerlink" title="Step 1. Run minimap2 to align pacbio data and generate paf files, then calculate read depth histogram and base-level read depth. 根据覆盖度计算分界点(cutoff)"></a>Step 1. Run minimap2 to align pacbio data and generate paf files, then calculate read depth histogram and base-level read depth. 根据覆盖度计算分界点(cutoff)</h2><p>For PacBio CLR reads</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-variable">$pb_list</span><br><span class="hljs-keyword">do</span><br>minimap2 -xmap-pb <span class="hljs-variable">$pri_asm</span> <span class="hljs-variable">$i</span> | gzip -c - &gt; <span class="hljs-variable">$i</span>.paf.gz<br><span class="hljs-keyword">done</span><br>bin/pbcstat *.paf.gz (produces PB.base.cov and PB.<span class="hljs-built_in">stat</span> files)<br>bin/calcuts PB.<span class="hljs-built_in">stat</span> &gt; cutoffs 2&gt;calcults.log<br></code></pre></td></tr></table></figure><p><strong>For PacBio CCS reads</strong></p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-comment"># gzip可以替换成pigz, 进行多线程压缩</span><br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-variable">$pb_list</span><br><span class="hljs-keyword">do</span><br>minimap2 -xasm20 <span class="hljs-variable">$pri_asm</span> <span class="hljs-variable">$i</span> | gzip -c - &gt; <span class="hljs-variable">$i</span>.paf.gz<br><span class="hljs-keyword">done</span><span class="hljs-comment"># 统计paf, 输出PB.base.cov和PB.stat文件</span><br>bin/pbcstat *.paf.gz (produces PB.base.cov and PB.<span class="hljs-built_in">stat</span> files)<br>bin/calcuts PB.<span class="hljs-built_in">stat</span> &gt; cutoffs 2&gt;calcults.log<br></code></pre></td></tr></table></figure><p><strong>Notice</strong> If you have a large genome, please set minimap2 <code>-I</code> option to ensure the genome can be indexed once, otherwise read depth can be wrong.</p><p>二代测序，用<code>bwa mem</code>进行比对，然后用<code>bin/ngscstat</code>统计bam覆盖度，然后用<code>bin/calcuts</code>计算分界点。</p><h2 id="Step-2-Split-an-assembly-and-do-a-self-self-alignment-Commands-are-following"><a href="#Step-2-Split-an-assembly-and-do-a-self-self-alignment-Commands-are-following" class="headerlink" title="Step 2. Split an assembly and do a self-self alignment. Commands are following:"></a>Step 2. Split an assembly and do a self-self alignment. Commands are following:</h2><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-comment">#将assembly【从N处打断】，如果assembly中没有N就不打断，然后用minimap2进行contig自我比对。</span><br><span class="hljs-comment"># Split an assembly</span><br>bin/split_fa <span class="hljs-variable">$pri_asm</span> &gt; <span class="hljs-variable">$pri_asm</span>.<span class="hljs-built_in">split</span><br><span class="hljs-comment"># do a self-self alignment</span><br>minimap2 -xasm5 -DP <span class="hljs-variable">$pri_asm</span>.<span class="hljs-built_in">split</span> <span class="hljs-variable">$pri_asm</span>.<span class="hljs-built_in">split</span> | gzip -c - &gt; <span class="hljs-variable">$pri_asm</span>.split.self.paf.gz<br></code></pre></td></tr></table></figure><p>run step1&amp;step2 simultaneously</p><h2 id="Step-3-Purge-haplotigs-and-overlaps-with-the-following-command"><a href="#Step-3-Purge-haplotigs-and-overlaps-with-the-following-command" class="headerlink" title="Step 3. Purge haplotigs and overlaps with the following command."></a>Step 3. Purge haplotigs and overlaps with the following command.</h2><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs sh">根据每个碱基覆盖度以及组装自我比对结果对contig分类<br><span class="hljs-comment"># purge haplotigs and overlap</span><br>bin/purge_dups -2 -T cutoffs -c PB.base.cov <span class="hljs-variable">$pri_asm</span>.split.self.paf.gz &gt; dups.bed 2&gt; purge_dups.log<br></code></pre></td></tr></table></figure><p>dups.bed<strong>第四列</strong>是每个<strong>contig的分类信息</strong>，分为**”JUNK”, “HIGHCOV”, “HAPLOTIG”, “PRIMARY”, “REPEAT”, “OVLP”** 6类，<code>purge_dups</code>可以先以默认参数运行，如果结果不理想，可以调整如下参数</p><ul><li><code>-f</code>默认是.8, 根据80%区域的覆盖度来对contig进行分类。例如80%的区域都低于5x，将该序列定义为JUNK。对应源码中的<code>classify_seq</code>函数的<code>min_frac</code>参数</li><li><code>-a</code>和<code>-b</code>过滤alignment, 对于源码中的<code>flt_by_bm_mm</code>的<code>min_bmf</code>和<code>min_mmf</code>参数</li><li><code>-m</code>表示将两个联配衔接时，最低的匹配碱基数</li><li><code>-M</code>和<code>-G</code>:分别表示第一轮和第二轮将前后两个联配衔接时最大空缺大小</li><li><code>-E</code>表示 如果合并之后的alignment在contig末尾的前15k内，那么就把alignment延伸至contig末尾</li><li><code>-l</code>: 用于控制overlap的大小，该值越小，overlap越多</li></ul><h2 id="Step-4-Get-purged-primary-and-haplotig-sequences-from-draft-assembly"><a href="#Step-4-Get-purged-primary-and-haplotig-sequences-from-draft-assembly" class="headerlink" title="Step 4. Get purged primary and haplotig sequences from draft assembly."></a>Step 4. Get purged primary and haplotig sequences from draft assembly.</h2><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs sh">bin/get_seqs -e dups.bed <span class="hljs-variable">$pri_asm</span> <br><span class="hljs-comment"># If you also want to remove the duplications in the middle, please remove 【`-e`】 option at your own risk, it may delete false positive duplications. For more options, please refer to `get_seqs -h`.</span><br></code></pre></td></tr></table></figure><p>这里的purged.fa就是最终结果，junk, haplotig和duplication都会在hap.fa中。</p><p>可选步骤: 将<strong>alternative assembly和输出hap.fa进行合并</strong>，然后运行上面四步，得到的<strong>purge.fa就是新的alternative assembly</strong>，而<strong>再次输出的hap.fa则是junk或overrepresented序列</strong>。</p><p>PS: 能不能用来过滤纯合基因组组装的垃圾序列呢？根据物种测试，过滤前后的BUSCO值，几乎没有变化，missing rate只提高了0.1%，</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-comment"># 运行前</span><br>C:98.8%[S:96.3%,D:2.5%],F:0.5%,M:0.7%,n:1375<br><span class="hljs-comment"># 运行后</span><br>C:98.7%[S:96.3%,D:2.4%],F:0.5%,M:0.8%,n:1375<br></code></pre></td></tr></table></figure><p>用法可行，且Canu的作者建议用<code>purge_dups</code>处理，参考<a href="https://links.jianshu.com/go?to=https://github.com/marbl/canu/issues/1717%23issuecomment-629644894">canu-issues-1717</a>。</p><p>作者尚未在ONT和Illumina数据中测试软件，但是作者认为只需要修改<code>minimap2</code>的<code>-x map-pb</code>为<code>-x map-ont</code>就可以用在ONT数据上。</p><p><strong>Notice</strong> this command will only remove haplotypic duplications at the ends of the contigs. If you also want to remove the duplications in the middle, please remove <code>-e</code> option at your own risk, it may delete false positive duplications. For more options, please refer to <code>get_seqs -h</code>.</p><h2 id="Step-5-Merge-hap-fa-and-hap-asm-and-redo-the-above-steps-to-get-a-decent-haplotig-set"><a href="#Step-5-Merge-hap-fa-and-hap-asm-and-redo-the-above-steps-to-get-a-decent-haplotig-set" class="headerlink" title="Step 5. Merge hap.fa and $hap_asm and redo the above steps to get a decent haplotig set."></a>Step 5. Merge hap.fa and $hap_asm and redo the above steps to get a decent haplotig set.</h2><h1 id="Limitation"><a href="#Limitation" class="headerlink" title="Limitation"></a>Limitation</h1><ul><li>Read depth cutoffs calculation: the coverage cutoffs can be larger for a low heterozygosity species, which causes the purged assembly size smaller than expected. In such a case, please use script&#x2F;hist_plot.py to make the histogram plot and set coverage cutoffs manually.</li><li>Repeats: purge_dups has a limited ability to process repeats.</li></ul><h1 id="FAQ"><a href="#FAQ" class="headerlink" title="FAQ"></a>FAQ</h1><p><strong>Q:</strong> Can I use purge_dups with <strong>short reads</strong>?</p><p><strong>A:</strong> Yes, purge_dups does have a program to process Illumina reads, it’s called <strong>ngscstat</strong> under the bin directory. But I have not got time to test it. If you want to play with it, please follow this workflow:</p><figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs nginx"><span class="hljs-attribute">bwa</span> mem <span class="hljs-variable">$pri_asm</span> <span class="hljs-variable">$sr_1</span>.fq <span class="hljs-variable">$sr_2</span>.fq | samtools view -b -o - &gt; <span class="hljs-variable">$sr</span>.bam <br>ngscstat <span class="hljs-variable">$sr</span>.bam... <span class="hljs-comment"># The program will generate two/three outputs, TX.stat and TX.base.cov which functions the same way as PB.stat and PB.base.cov respectively.  </span><br></code></pre></td></tr></table></figure><p>After you get the TX.stat and TX.base.cov file, you can following the normal purge_dups routine to clean your assembly.</p><p><strong>Q1:</strong> Can I validate the cutoffs used by purge_dups?</p><p><strong>A1:</strong> Yes, we also recommend this step. A script “hist_plot.py” under the scripts directory is available, you can also use it to manually select the cutoffs.</p><p><strong>Q2:</strong> How can I <strong>validate the purged assembly?</strong> Is it clean enough or overpurged?</p><p><strong>A2:</strong> There are many ways to validate the purged assembly. One way is to make a coverage plot for it which can also be <strong>hist_plot.py</strong>, the 2nd way is to run <strong>BUSCO</strong> and another way is to make a KAT plot with KAT (<a href="https://github.com/TGAC/KAT">https://github.com/TGAC/KAT</a>) or KMC (<a href="https://github.com/dfguan/KMC">https://github.com/dfguan/KMC</a>, use this if you only have a small memory machine) if short reads or some accurate reads are available.</p><p><strong>Q3:</strong> Why do I get <strong>much fewer haplotypic duplications</strong> than expected?</p><p><strong>A3:</strong> First check the original contig names, they should not contain any colons. Then check the cutoffs, if purge_dups automatically use <strong>a fairly low read depth for haplotypic duplications</strong>, it may <strong>remove nothing</strong>. In this case, you <strong>need to set the cutoffs manually.</strong></p><p><strong>Q4:</strong> why does purge_dups remove <strong>middle sequence in a contig?</strong></p><p><strong>A4:</strong> <strong>Some of them are real, while others may not</strong>. We are currently investigating them. Please use <code>-e</code> for <code>get_seqs</code> command if you <strong>only want to remove the duplications at the ends of the contigs.</strong></p><hr><p>Ref:<a href="https://www.jianshu.com/p/e218a1192d12">https://www.jianshu.com/p/e218a1192d12</a></p>]]></content>
    
    
    <categories>
      
      <category>Software</category>
      
    </categories>
    
    
    <tags>
      
      <tag>assembly</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【Hi-C】【Juicebox】</title>
    <link href="/GeekFocus/2022/03/17/2022-03-17-juicebox/"/>
    <url>/GeekFocus/2022/03/17/2022-03-17-juicebox/</url>
    
    <content type="html"><![CDATA[<p>Juicerbox guidline</p><span id="more"></span><ul><li><p>通过<code>File</code>-&gt;<code>open</code>导入后缀为<code>hic</code>的文件查看，可导入本地的文件，也可输入url。软件内置ENCODE的数据集</p></li><li><p>自动展示所有染色体的HI-C图谱，通过工具栏<font color="blue"><strong>选择染色质</strong></font>，<font color="blue"><strong>调整分辨率</strong></font>，对交互矩阵<font color="blue"><strong>归一化</strong></font>，调整显示的染色质区域。以17号染色质体为例，在<code>Chromosomes</code>一栏中，两列都选择17号染色体，代表交互矩阵的行和列都是17号染色体，然后点击刷新，结果如下</p></li></ul><p><img src="/GeekFocus/./1.png" alt="img"></p><ul><li>通过<font color="blue"><strong>Normalization</strong></font>工具调整归一化方法(推荐banlanced？)；通过<font color="blue"><strong>Resolution</strong></font>工具调整分辨率；通过<font color="blue"><strong>Goto</strong></font>工具调整显示的染色体区域。</li><li>通过简单操作就可查看和展示Hi-C图谱，除基本功能外，还支持导入<font color="blue">注释文件</font>，通过<code>View</code>-&gt;<font color="blue">Show Annotation Panel</font>可打开注释文件面板，注释信息分<strong>1D和2D</strong>两种，1D主要指chip_seq,RNA_seq等信息，2D指TAD,染色质环等信息，通过<code>Load ENCODE</code>以导入ENCODE<a href="https://cloud.tencent.com/solution/database?from=10680">数据库</a>中的一维注释，示意如下</li></ul><p><img src="/GeekFocus/./2.png" alt="img"></p><ul><li>勾选需要导入的注释信息，通过Load导入</li></ul><p><img src="/GeekFocus/./3.png" alt="img"></p><ul><li>每个导入的track的颜色等配置可在面板中调整</li></ul><p><img src="/GeekFocus/./4.png" alt="img"></p><ul><li>通过<code>Load Loops/Domain</code>可导入2D的注释信息</li></ul><p><img src="/GeekFocus/./5.png" alt="img"></p><ul><li>导入后在Hi-C图谱中看到对应的标记</li></ul><p><img src="/GeekFocus/./6.png" alt="img"></p><p>黄色区域标记的是TAD, 浅蓝色区域标记的是染色质环，调整好之后的图片也可以导出成PDF或者SVG格式。</p><ul><li>导入asm后蓝色区分假染色体，绿色区分scaffold</li><li>按住shift选中contig</li><li>绿色不能太碎</li></ul><p><strong>操作：</strong></p><ul><li><p>所有纠错操作都基于shift键</p></li><li><p>操作不熟练，你可能需要反复undo和redo（右键）</p></li><li><p>选框时，你只要在本框范围内拖动（按shift不要松），都会选中这个框（选中后为带黑黄色的线），并不要很精确地选在框边缘（因为你把握不好，有可能这个边缘是另一个框的范围，这时就会选错）</p></li><li><p>选择框时，尽可能放大（双击，或菜单栏BP，一般25kb-50kb）</p></li><li><p>如果你的染色体数目不对。拆分染色体：先选中要拆分区域，右击add染色体，再选中，右击remove染色体</p></li></ul><ul><li>从某一个地方剪掉框：选中，出现剪刀符号，单击</li><li>旋转框：选中，出现旋转符号，单击</li><li>从一个地方移动：选中，鼠标移到要插入的contig框顶点，单击</li></ul><p>Juice_box调图是个细致的体力活。一想到我的基因组是这么人为调出来的，我自己对结果都产生了怀疑。如果是3D-DNA，再简单的基因组也还是会有很多碎的，因为它手贱重新打碎了。所以说如果你原始组装的contig数目比3d-dna跑出的FINAL.fasta中的contig数目少，甚至比手工纠错后再跑3D-DNA的数目少，也不要感到惊讶。反正我是越纠越差，基因组越来越小。可能是我不会调细节吧，再次吐槽，这个软件我是真的讨厌。</p><hr><p>ref <a href="https://www.jianshu.com/p/4483eece598d">https://www.jianshu.com/p/4483eece598d</a></p><p>注意事项：</p><ol><li>Juicebox的编辑功能在导入了assembly文件后放大scaffold块，放大到足够大的时候才能出现编辑的剪刀，进行分割染色体区域</li><li>如果要去掉某些散在区块中的空白区域则需要放大到足够大后，用shift+左键选中空白的区域进行剪切去掉</li><li>这些需要剪切的空白区域其实是表明这些contig和谁都没有关联，会在1-3.hic的步骤中被去除，相应的最终的.hic文件得到的hic组装结果能挂载到的基因会减少</li></ol><ul><li><strong>但是如果0.hic的结果太差，可以试用3.hic的结果，也许会更好，有提升功能，如果挂载的基因不太少的话，会很好</strong></li></ul><ol start="4"><li>hic的最终assembly是（rawchrom.assembly）</li></ol><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs css"><span class="hljs-number">00</span><span class="hljs-selector-class">.nextpolish</span><span class="hljs-selector-class">.final</span><span class="hljs-selector-class">.assembly</span> -&gt; <span class="hljs-number">00</span><span class="hljs-selector-class">.nextpolish</span><span class="hljs-selector-class">.rawchrom</span><span class="hljs-selector-class">.assembly</span><br></code></pre></td></tr></table></figure><ol start="5"><li>通常来讲，用0.hic对应的结果去进行染色体区块编辑后再进行染色体水平的基因组组装<code>run-asm-pipeline-post-review.sh</code>，得到fasta的文件，然后再通过已经注释的contig版本的基因组基因的坐标信息，对应上染色体水平的基因组基因信息</li></ol><p>？关于ALLHiC组装，可以用3d-dna得到的最终基因组fasta结果再用ALLHiC进行组装，相当于基因组已经经过了3d-dna的纠错，得到的可能是更加准确的包含N的基因组序列，再经过ALLHiC进行打断去除N，得到更好的结果</p><hr><p><a href="https://www.bilibili.com/video/BV1ph411X7wj">https://www.bilibili.com/video/BV1ph411X7wj</a></p><p><img src="/GeekFocus/./7.png" alt="img"></p><p><strong>1. 挂载率</strong></p><p><img src="/GeekFocus/./8.png" alt="img"></p><p><strong>2. 基因组草图中组装错误太多</strong></p><p><img src="/GeekFocus/./9.png" alt="img"></p><p><strong>3. 样本杂质污染</strong></p><p><img src="/GeekFocus/./10.png" alt="img"></p><p><strong>4. 高杂合基因组</strong></p><p><img src="/GeekFocus/./11.png" alt="img"></p><p>HiC组装后续</p><p><img src="/GeekFocus/./12.png" alt="img"></p><p>两个contig之间可能是由500个N连接，hic关系决定</p><blockquote><p>Q: 3D-DNA 后的结果文件可继续用于ALLHiC</p></blockquote>]]></content>
    
    
    <categories>
      
      <category>Software</category>
      
    </categories>
    
    
    <tags>
      
      <tag>assembly</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【Hi-C】【Lachesis】</title>
    <link href="/GeekFocus/2022/03/17/2022-03-17-LACHESIS/"/>
    <url>/GeekFocus/2022/03/17/2022-03-17-LACHESIS/</url>
    
    <content type="html"><![CDATA[<p>Lachesis</p><span id="more"></span><p><a href="https://www.plob.org/article/24852.html">https://www.plob.org/article/24852.html</a></p><p><strong>染色体疆域</strong></p><p>染色质在细胞核内分布的并不是随机分布的，而是不同染色体占据不同的空间。</p><p><img src="/GeekFocus/./1.png" alt="三维基因组技术（二）：Hi-C辅助组装与Lachesis的使用"></p><p><strong>Hi-C实验原理</strong></p><p><img src="/GeekFocus/./2.png" alt="三维基因组技术（二）：Hi-C辅助组装与Lachesis的使用"></p><p><strong>基因组互作衰减</strong></p><p>染色体内互作强度较强，但也随着空间距离的增大互作强度在衰减。互作三定律</p><ul><li>1.<strong>染色体内互作富集</strong>（Intrachromosomal interaction enrichment）</li><li>2.<strong>互作随距离衰减</strong>（distance-dependent interaction decay）</li><li>3.<strong>局部互作平滑</strong>（local interaction smoothness）</li></ul><p><strong>Hic 优势</strong></p><ul><li>通过Scaffold间的交互频率大小，可以对已组装的基因组序列进行纠错。</li><li>基因信息不再仅仅是contig片段，而是被划分至染色体上，成为染色体水平。</li><li>无需辛苦的构建群体，单一一个体就能实现染色体定位。</li><li>相比遗传图谱，标记密度更大，序列定位更完整。</li><li>可以开展染色体重排等结构变异研究。</li><li>QTL、GWAS可以定位区间到某个染色体。</li><li>可以解析该物种的三维基因结构、染色体互作及动态变化。</li></ul><p><strong>HiC辅助组装</strong></p><p>将contigs组装到<strong>假染色体</strong>层面，实现基因组组装到染色体层面</p><p><strong>Lachesis辅助组装步骤</strong></p><ul><li>**Cluster(聚类)**。因为染色质内的互 作强度要高于染色质间的互作强度，所 以先对contig&#x2F;scaffold进行聚类成染色体群。</li><li>**Order(排序)**。确定每个染色体群中contig&#x2F;scaffold的顺序</li><li>**Orient(定向)**。确定每个 contig&#x2F;scaffold的方向三个步骤按照互作强度依次</li></ul><p><img src="/GeekFocus/./3.png" alt="三维基因组技术（二）：Hi-C辅助组装与Lachesis的使用"></p><p><strong>cluster聚类原理</strong></p><p><img src="/GeekFocus/./4.png" alt="三维基因组技术（二）：Hi-C辅助组装与Lachesis的使用"></p><p><strong>order排序原理</strong></p><p><img src="/GeekFocus/./5.png" alt="三维基因组技术（二）：Hi-C辅助组装与Lachesis的使用"></p><p><strong>orient定向原理</strong></p><p><img src="/GeekFocus/./6.png" alt="三维基因组技术（二）：Hi-C辅助组装与Lachesis的使用"></p><hr><p><a href="https://lxz9.com/2021/08/05/ALLHIC/">https://lxz9.com/2021/08/05/ALLHIC/</a> ALLHiC</p>]]></content>
    
    
    <categories>
      
      <category>Software</category>
      
    </categories>
    
    
    <tags>
      
      <tag>assembly</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【Hi-C】【3D-DNA】</title>
    <link href="/GeekFocus/2022/03/17/2022-03-17-3D-DNA/"/>
    <url>/GeekFocus/2022/03/17/2022-03-17-3D-DNA/</url>
    
    <content type="html"><![CDATA[<p>二倍体物种目前3D-DNA应该是组装效果比较好的软件。ALL-HiC对多倍体效果很好</p><span id="more"></span><h1 id="流程"><a href="#流程" class="headerlink" title="流程"></a>流程</h1><p>组装，Juicer分析Hi-C数据，3D-DNA scaffolding，JBAT 对组装结果手工纠正，最终得到准染色体水平基因组。</p><p><img src="/GeekFocus/./1.png" alt="img"></p><p><strong>CPU-version juicer installation</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">mkdir</span> ~/soft<br>git <span class="hljs-built_in">clone</span> https://github.com/theaidenlab/juicer.git<br><span class="hljs-built_in">cd</span> juicer<br><span class="hljs-built_in">ln</span> -s CPU scripts<br><span class="hljs-built_in">cd</span> scripts/common<br>wget https://hicfiles.tc4ga.com/public/juicer/juicer_tools.1.9.9_jcuda.0.8.jar<br><span class="hljs-built_in">ln</span> -s juicer_tools.1.9.9_jcuda.0.8.jar  juicer_tools.jar<br></code></pre></td></tr></table></figure><p>aligned目录，其中”merged_nodups.txt”是下一步3D-DNA的输入文件之一。</p><p><strong>3D-DNA installation</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">cd</span> ~/soft<br>git <span class="hljs-built_in">clone</span> https://github.com/theaidenlab/3d-dna.git<br></code></pre></td></tr></table></figure><hr><p>如果基因组<strong>不是复杂基因组</strong>，比如说高杂合，高重复序列，或者Hi-C数据测太少，那么3d-dna的流程更加简单, run-asm-pipeline.sh -h只有<font color="blue"><strong>四个参数需要改</strong></font>:</p><ul><li>-i|–input: 过滤长度低于给定阈值的contig&#x2F;scaffold, <strong>默认是15000</strong></li><li>-r|–round: 基因组中misjoin的<strong>纠错轮数</strong>，<strong>默认是2</strong>，当基因组<strong>比较准确</strong>，设置为<strong>0</strong>，然后在JABT中调整会更好</li><li>-m|–mode: 是否调用merge模块，<strong>当且仅当在杂合度比较高的情况下使用</strong>，也就是组装结果的单倍型基因组明显偏大（和预期estimated 比较）</li><li>-s|–stage: 从polish, split, seal, merge 或finalize 的某一个阶段开始</li></ul><hr><p><strong>基因组复杂</strong>，需要调整参数非常多, run-asm-pipeline.sh –help会输出更多的信息，你需要根据当前结果去确定每个阶段的参数应该如何调整。<br>最终的输出文件最关键的是下面三类:</p><ul><li>.fasta: 以<strong>FINAL标记的是最终结果</strong></li><li>.hic: <strong>各个阶段</strong>都会有输出结果，用于在JABT中展示</li><li>.assembly: <strong>各个阶段</strong>都会有输出，一共两列，存放contig的组装顺序</li></ul><hr><h1 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h1><p>Juicer的输出结果到3D-DNA，分析流程见下图。3D-DNA先根据Hi-C数据分析contig中的<strong>misjoin</strong>，对其进行纠错。之后通过四步,分别是Polish, Split, Seal和Merge, 得到最终的基因组序列</p><p><img src="/GeekFocus/./2.png" alt="3d-dna流程"></p><h1 id="使用juicerbox手工纠错"><a href="#使用juicerbox手工纠错" class="headerlink" title="使用juicerbox手工纠错"></a>使用juicerbox手工纠错</h1><p>关于juicerbox的用法，可以看hoptop的<a href="https://links.jianshu.com/go?to=https://www.bilibili.com/video/av65134634">https://www.bilibili.com/video/av65134634</a><br>最常见的几种组装错误:</p><ul><li>misjoin: 切割</li><li>translocations: 移动</li><li>inversions: 翻转</li><li>chromosome boundaries: 确定染色体的边界</li></ul><p>这些错误的判断依赖于经验，所以只能靠自己多试试了。<br>最后输出genome.review.assembly用于下一步的分析</p><h1 id="再次运行3d-dna"><a href="#再次运行3d-dna" class="headerlink" title="再次运行3d-dna"></a>再次运行3d-dna</h1><p>根据JABT手工纠正的结果, genome.review.assembly, 使用run-asm-pipeline-post-review.sh重新组装基因组。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs cpp">~/soft/<span class="hljs-number">3</span>d-dna/run-<span class="hljs-keyword">asm</span>-pipeline-post-review.sh \<br>    -r genome.review.assembly genome.fa aligned/merged_nodups.txt &amp;&gt; <span class="hljs-number">3</span>d.log &amp;<br></code></pre></td></tr></table></figure><p>这次使用<code>run-asm-pipeline-post-review.sh</code>脚本，用于在Juicebox Assembly Tools模块（由review.Assembly文件表示）中进行审阅，将程序集（由之前对齐的Hi-C reads和Juicer pipeline生成的）最终确定为染色体长度的fasta序列。该脚本将生成一个输出fasta文件、最终装配Hi-C map的assembly文件和一些补充注释文件，便于在Juicebox中查看结果。</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs sh">USAGE: ./run-asm-pipeline-post-review.sh [options] -r &lt;review.assembly&gt; &lt;path_to_input_fasta&gt; &lt;path_to_input_mnd&gt;<br><span class="hljs-comment"># &lt;review.assembly&gt; 输入juicebox调整之后得到的genome.rawchrom.assembly</span><br><span class="hljs-comment"># &lt;path_to_input_fasta&gt; 输入参考基因组序列文件</span><br><span class="hljs-comment"># &lt;path_to_input_mnd&gt; 之前得到的merged_nodups.txt</span><br><span class="hljs-comment"># -r 查看“.assembly”文件的路径。</span><br>可选参数<br><span class="hljs-comment"># -i input_size 指定阈值输入Contigs/scaffolds（默认值为15000）。小于输入阈值的Contigs/scaffolds的将被忽略。应与运行原始脚本时使用的相同。</span><br><span class="hljs-comment"># -g gap_size 要在最终染色体长度支架中的支架序列之间添加的间隙大小（默认值为500）。</span><br><span class="hljs-comment"># --sort-output 选择按大小按降序排列染色体长度支架。</span><br></code></pre></td></tr></table></figure><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-built_in">nohup</span> bash ~/software/3d-dna/run-asm-pipeline-post-review.sh -r genome.rawchrom.assembly genome.fa hic/aligned/merged_nodups.txt &amp;&gt; 3d.<span class="hljs-built_in">log</span><br></code></pre></td></tr></table></figure><p>得出最终的染色体水平文件 genome.FINAL.fasta</p><p><strong>最后一步提速</strong></p><p>因为<code>run-asm-pipeline-post-review.sh</code>原始的速度太慢了。所以建议去修改一下源文件内容，大大提升最后一步的速度，可以<a href="https://hub.fastgit.org/aidenlab/3d-dna/pull/58">参考链接</a></p><h1 id="评价"><a href="#评价" class="headerlink" title="评价"></a>评价</h1><p>juicer代码至少以下几个地方都需要改：</p><p>临时文件不及时删除<br>bwa得到的SAM文件处理方式有待优化，使用BAM能更快的并行计算<br>参数命令判断很差，用-z判断字符串是否为0，而不是用-f或-d去判断文件是否存在<br>Linux的sort支持多线程，但是没看到用<br>脚本中有些限速步骤的awk代码，不算高效<br>前两条导致了运行过程占用大量硬盘，所以<strong>不准备2T左右的硬盘，很容易出错</strong>。第三条是一些报错不会及时停止运算，也不容易排查。估计公司从效率角度出发，应该是写了很多脚本来替换原来的awk脚本</p><p>另外，juicer在多倍体物种表现很差，建议使用ALLHiC</p><hr><p>ref：<a href="https://blog.csdn.net/u012110870/article/details/115511969">https://blog.csdn.net/u012110870/article/details/115511969</a></p>]]></content>
    
    
    <categories>
      
      <category>Software</category>
      
    </categories>
    
    
    <tags>
      
      <tag>assembly</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【Hi-C】【Juicer】</title>
    <link href="/GeekFocus/2022/03/16/2022-03-16-juicer/"/>
    <url>/GeekFocus/2022/03/16/2022-03-16-juicer/</url>
    
    <content type="html"><![CDATA[<p>Juicer is a platform for analyzing kilobase resolution Hi-C data. In this distribution, we include the pipeline for <strong>generating Hi-C maps from fastq raw data</strong> files and <strong>command line tools for feature annotation on the Hi-C maps</strong>.</p><span id="more"></span><p><a href="https://github.com/aidenlab/juicer">https://github.com/aidenlab/juicer</a></p><h1 id="Read-this-first"><a href="#Read-this-first" class="headerlink" title="Read this first!!"></a>Read this first!!</h1><p>To access Juicer 1.6 (last <strong>stable</strong> release), please see <a href="https://github.com/aidenlab/juicer/releases/tag/1.6">the Github Release</a>. If you clone the Juicer repo directly from Github, it will clone Juicer 2, which is under active development. If you encounter any bugs, please let us know.</p><h1 id="About-Juicer"><a href="#About-Juicer" class="headerlink" title="About Juicer"></a>About Juicer</h1><p>Juicer is a platform for analyzing kilobase resolution Hi-C data. In this distribution, we include the pipeline for <strong>generating Hi-C maps from fastq raw data files</strong> and <strong>command line tools for feature annotation on the Hi-C maps</strong>.</p><p><strong>If you use Juicer in your research, please cite: Neva C. Durand, Muhammad S. Shamim, Ido Machol, Suhas S. P. Rao, Miriam H. Huntley, Eric S. Lander, and Erez Lieberman Aiden. “Juicer provides a one-click system for analyzing loop-resolution Hi-C experiments.” Cell Systems 3(1), 2016.</strong></p><h1 id="Documentation"><a href="#Documentation" class="headerlink" title="Documentation"></a>Documentation</h1><p>Please see <a href="https://github.com/aidenlab/juicer/wiki">the wiki</a> for extensive documentation.</p><h1 id="Questions"><a href="#Questions" class="headerlink" title="Questions?"></a>Questions?</h1><p>For FAQs, or for asking new questions, please see our forum: <a href="http://aidenlab.org/forum.html">aidenlab.org&#x2F;forum.html</a>.</p><hr><h2 id="Distribution"><a href="#Distribution" class="headerlink" title="Distribution"></a>Distribution</h2><p>In this repository, we include the scripts for running Juicer on AWS, LSF, Univa Grid Engine, SLURM, and a single CPU</p><p>&#x2F;AWS - scripts for running pipeline and postprocessing on AWS</p><p>&#x2F;UGER - scripts for running pipeline and postprocessing on UGER (Univa)</p><p>&#x2F;SLURM - scripts for running pipeline and postprocessing on SLURM</p><p>&#x2F;LSF - scripts for running pipeline and postprocessing on LSF <strong>BETA</strong></p><p>&#x2F;CPU - scripts for running pipeline and postprocessing on a single CPU <strong>BETA</strong></p><p>&#x2F;misc - miscellaneous helpful scripts</p><hr><h2 id="Hardware-and-Software-Requirements"><a href="#Hardware-and-Software-Requirements" class="headerlink" title="Hardware and Software Requirements"></a>Hardware and Software Requirements</h2><p>Juicer is a pipeline optimized for parallel computation on a cluster. Juicer consists of two parts: <strong>the pipeline that creates Hi-C files from raw data</strong>, and <strong>the post-processing command line tools</strong>.</p><h3 id="Cluster-requirements"><a href="#Cluster-requirements" class="headerlink" title="Cluster requirements:"></a>Cluster requirements:</h3><p>Juicer requires the use of a cluster, with <strong>ideally &gt;&#x3D; 4 cores</strong> (min 1 core) and <strong>&gt;&#x3D; 64 GB RAM</strong> (min 16 GB RAM)</p><p>Juicer currently works with the following resource management software:</p><ul><li><a href="http://www.openlava.org/">OpenLava</a></li><li><a href="https://www.ibm.com/systems/spectrum-computing/products/lsf">LSF</a></li><li><a href="https://slurm.schedmd.com/download.html">SLURM</a></li><li>GridEngine (Univa, etc. any flavor)</li></ul><h3 id="Juicer-tools-requirements"><a href="#Juicer-tools-requirements" class="headerlink" title="Juicer tools requirements"></a>Juicer tools requirements</h3><p>The minimum software requirement to run Juicer is a working Java installation (version &gt;&#x3D; 1.8) on Windows, Linux, and Mac OSX. We recommend using the latest Java version available, but please do not use the Java Beta Version. Minimum system requirements for running Java can be found at<a href="https://java.com/en/download/help/sysreq.xml">https://java.com/en/download/help/sysreq.xml</a></p><p>To download and install the latest Java Runtime Environment (JRE), please go to <a href="https://www.java.com/download">https://www.java.com/download</a></p><h3 id="GNU-CoreUtils"><a href="#GNU-CoreUtils" class="headerlink" title="GNU CoreUtils"></a>GNU CoreUtils</h3><p>The latest version of GNU coreutils can be downloaded from <a href="https://www.gnu.org/software/coreutils/manual/">https://www.gnu.org/software/coreutils/manual/</a></p><h3 id="Burrows-Wheeler-Aligner-BWA"><a href="#Burrows-Wheeler-Aligner-BWA" class="headerlink" title="Burrows-Wheeler Aligner (BWA)"></a>Burrows-Wheeler Aligner (BWA)</h3><p>The <strong>latest version of BWA</strong> should be installed from <a href="http://bio-bwa.sourceforge.net/">http://bio-bwa.sourceforge.net/</a></p><h3 id="CUDA-for-HiCCUPS-peak-calling"><a href="#CUDA-for-HiCCUPS-peak-calling" class="headerlink" title="CUDA (for HiCCUPS peak calling)"></a>CUDA (for HiCCUPS peak calling)</h3><p>You must have an NVIDIA GPU to install CUDA.</p><p>Instructions for installing the latest version of CUDA can be found on the <a href="https://developer.nvidia.com/cuda-downloads">NVIDIA Developer site</a>.</p><p>The native libraries included with Juicer are compiled for CUDA 7 or CUDA 7.5. See the <a href="https://github.com/theaidenlab/juicer/wiki/Download">download page for Juicer Tools</a>.</p><p>Other versions of CUDA can be used, but you will need to download the respective native libraries from <a href="http://www.jcuda.org/downloads/downloads.html">JCuda</a>.</p><p>For best performance, use a dedicated GPU. You may also be able to obtain access to GPU clusters through Amazon Web Services or a local research institution.</p><p>If you cannot access a GPU, you can run the <a href="https://github.com/aidenlab/juicer/wiki/CPU-HiCCUPS">CPU version of HiCCUPS</a> directly using the <code>.hic</code> file and Juicer Tools.</p><h3 id="Building-new-jars"><a href="#Building-new-jars" class="headerlink" title="Building new jars"></a>Building new jars</h3><p>See the Juicebox documentation at <a href="https://github.com/theaidenlab/Juicebox">https://github.com/theaidenlab/Juicebox</a> for details on building new jars of the juicer_tools.</p><hr><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a><font color="red">Quick Start</font></h2><p>Run the Juicer pipeline on your cluster of choice with “juicer.sh [options]”</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><code class="hljs sh">Usage: juicer.sh [-g genomeID] [-d topDir] [-q queue] [-l long queue] [-s site]<br>                 [-a about] [-R end] [-S stage] [-p chrom.sizes path]<br>                 [-y restriction site file] [-z reference genome file]<br>                 [-C chunk size] [-D Juicer scripts directory]<br>                 [-Q queue time <span class="hljs-built_in">limit</span>] [-L long queue time <span class="hljs-built_in">limit</span>] [-e] [-h] [-x]<br>* [-g genomeID] must be defined <span class="hljs-keyword">in</span> the script, e.g. <span class="hljs-string">&quot;hg19&quot;</span> or <span class="hljs-string">&quot;mm10&quot;</span> (default<br>  <span class="hljs-string">&quot;hg19&quot;</span>); alternatively, it can be defined using the -z <span class="hljs-built_in">command</span><br>* [<span class="hljs-string">&#x27;-d topDir&#x27;</span>] is the top level directory (default<br>  <span class="hljs-string">&quot;/Users/nchernia/Downloads/neva-muck/UGER&quot;</span>)<br>     [topDir]/fastq must contain the fastq files<br>     [topDir]/splits will be created to contain the temporary <span class="hljs-built_in">split</span> files<br>     [topDir]/aligned will be created <span class="hljs-keyword">for</span> the final alignment<br>* [-q queue] is the queue <span class="hljs-keyword">for</span> running alignments (default <span class="hljs-string">&quot;short&quot;</span>)<br>* [-l long queue] is the queue <span class="hljs-keyword">for</span> running longer <span class="hljs-built_in">jobs</span> such as the hic file<br>  creation (default <span class="hljs-string">&quot;long&quot;</span>)<br>* [site] must be defined <span class="hljs-keyword">in</span> the script, e.g.  <span class="hljs-string">&quot;HindIII&quot;</span> or <span class="hljs-string">&quot;MboI&quot;</span><br>  (default <span class="hljs-string">&quot;none&quot;</span>)<br>* [about]: enter description of experiment, enclosed <span class="hljs-keyword">in</span> single quotes<br>* [stage]: must be one of <span class="hljs-string">&quot;chimeric&quot;</span>, <span class="hljs-string">&quot;merge&quot;</span>, <span class="hljs-string">&quot;dedup&quot;</span>, <span class="hljs-string">&quot;final&quot;</span>, <span class="hljs-string">&quot;postproc&quot;</span>, or <span class="hljs-string">&quot;early&quot;</span>.<br>    -Use <span class="hljs-string">&quot;chimeric&quot;</span> when alignments are <span class="hljs-keyword">done</span> but chimeric handling has not finished<br>    -Use <span class="hljs-string">&quot;merge&quot;</span> when alignment has finished but the merged_sort file has not<br>     yet been created.<br>    -Use <span class="hljs-string">&quot;dedup&quot;</span> when the files have been merged into merged_sort but<br>     merged_nodups has not yet been created.<br>    -Use <span class="hljs-string">&quot;final&quot;</span> when the reads have been deduped into merged_nodups but the<br>     final stats and hic files have not yet been created.<br>    -Use <span class="hljs-string">&quot;postproc&quot;</span> when the hic files have been created and only<br>     postprocessing feature annotation remains to be completed.<br>    -Use <span class="hljs-string">&quot;early&quot;</span> <span class="hljs-keyword">for</span> an early <span class="hljs-built_in">exit</span>, before the final creation of the stats and<br>     hic files<br>* [<span class="hljs-string">&#x27;chrom.sizes path&#x27;</span>]: enter path <span class="hljs-keyword">for</span> chrom.sizes file<br>* [<span class="hljs-string">&#x27;restriction site file&#x27;</span>]: enter path <span class="hljs-keyword">for</span> restriction site file (locations of<br>  restriction sites <span class="hljs-keyword">in</span> genome; can be generated with the script<br>  (misc/generate_site_positions.py) )<br>* [<span class="hljs-string">&#x27;reference genome file&#x27;</span>]: enter path <span class="hljs-keyword">for</span> reference sequence file, BWA index<br>  files must be <span class="hljs-keyword">in</span> same directory<br>* [chunk size]: number of lines <span class="hljs-keyword">in</span> <span class="hljs-built_in">split</span> files, must be multiple of 4<br>  (default 90000000, <span class="hljs-built_in">which</span> equals 22.5 million reads)<br>* [<span class="hljs-string">&#x27;Juicer scripts directory&#x27;</span>]: <span class="hljs-built_in">set</span> the Juicer directory,<br>  <span class="hljs-built_in">which</span> should have scripts/ references/ and restriction_sites/ underneath it<br>  (default /broad/aidenlab)<br>* [queue time <span class="hljs-built_in">limit</span>]: time <span class="hljs-built_in">limit</span> <span class="hljs-keyword">for</span> queue, i.e. -W 12:00 is 12 hours<br>  (default 1200)<br>* [long queue time <span class="hljs-built_in">limit</span>]: time <span class="hljs-built_in">limit</span> <span class="hljs-keyword">for</span> long queue, i.e. -W 168:00 is one week<br>  (default 3600)<br>* -f: include fragment-delimited maps from hic file creation<br>* -e: early <span class="hljs-built_in">exit</span><br>* -h: <span class="hljs-built_in">print</span> this <span class="hljs-built_in">help</span> and <span class="hljs-built_in">exit</span><br></code></pre></td></tr></table></figure><hr><h2 id="Juicer-Usage"><a href="#Juicer-Usage" class="headerlink" title="Juicer Usage"></a>Juicer Usage</h2><ul><li><strong>Running Juicer with no arguments</strong> will run it with genomeID hg19 and site MboI</li><li><strong>Providing a genome ID</strong>: if not defined in the script, you can either directly modify the script or provide the script with the files needed. You would provide the script with the files needed via “-z reference_sequence_path” (needs to have the BWA index files in same directory), “-p chrom_sizes_path” (these are the chromosomes you want included in .hic file), and “-s site_file” (this is the listing of all the restriction site locations, one line per chromosome). Note that ligation junction won’t be defined in this case. The script (misc&#x2F;generate_site_positions.py) can help you generate the file</li><li><strong>Providing a restriction enzyme</strong>: if not defined in the script, you can either directly modify the script or provide the files needed via the “-s site_file” flag, as above. Alternatively, if you don’t want to do any fragment-level analysis (as with a DNAse experiment), you should assign the site “none”, as in <code>juicer.sh -s none</code></li><li><strong>Directory structure</strong>: Juicer expects the fastq files to be stored in a directory underneath the top-level directory. E.g. HIC001&#x2F;fastq. By default, the top-level directory is the directory where you are when you launch Juicer; you can change this via the -d flag. Fastqs can be zipped. [topDir]&#x2F;splits will be created to contain the temporary split files and should be deleted once your run is completed. [topDir]&#x2F;aligned will be created for the final files, including the hic files, the statistics, the valid pairs (merged_nodups), the collisions, and the feature annotations.</li><li><strong>Queues</strong> are complicated and it’s likely that you’ll have to modify the script for your system, though we did our best to avoid this. By default there’s a short queue and a long queue. We also allow you to pass in wait times for those queues; this is currently ignored by the UGER and SLURM versions. The short queue should be able to complete alignment of one split file. The long queue is for jobs that we expect to take a while, like writing out the merged_sort file</li><li><strong>Chunk size</strong> is intimitely associated with your queues; a smaller chunk size means more alignment jobs that complete in a faster time. If you have a hard limit on the number of jobs, you don’t want too small of a chunk size. If your short queue has a very limited runtime ceiling, you don’t want too big of a chunk size. Run time for alignment will also depend on the particulars of your cluster. We launch ~5 jobs per chunk. Chunk size must be a multiple of 4.</li><li><strong>Relaunch</strong> via the same script. Type <code>juicer.sh [options] -S stage</code> where “stage” is one of merge, dedup, final, postproc, or early. “merge” is for when alignment has finished but merged_sort hasn’t been created; “dedup” is for when merged_sort is there but not merged_nodups (this will relaunch all dedup jobs); “final” is for when merged_nodups is there and you want the stats and hic files; “postproc” is for when you have the hic files and just want feature annotations; and “early” is for early exit, before hic file creation. If your jobs failed at the alignment stage, run <code>relaunch_prep.sh</code> and then run juicer.sh.</li><li><strong>Miscelleaneous options</strong> include -a ‘experiment description’, which will add the experiment description to the statistics file and the meta data in the hic file; -r, which allows you to use bwa aln instead of bwa mem, useful for shorter reads; -R [end], in case you have one read end that’s short and one that’s long and you want to align the short end with bwa aln and the long end with bwa mem; and -D [Juicer scripts directory], to set an alternative Juicer directory; must have scripts&#x2F;, references&#x2F;, and restriction_sites&#x2F; underneath it</li></ul><hr><h2 id="Command-Line-Tools-Usage"><a href="#Command-Line-Tools-Usage" class="headerlink" title="Command Line Tools Usage"></a>Command Line Tools Usage</h2><p>Detailed documentation about the command line tools can be found on the wiki:</p><ul><li><a href="https://github.com/aidenlab/juicer/wiki/Feature-Annotation">Annotating features with Arrowhead, HiCCUPS, MotifFinder, APA, Eigenvector, and Pearsons</a></li><li><a href="https://github.com/aidenlab/juicer/wiki/Pre">Creating .hic with Pre</a></li><li><a href="https://github.com/aidenlab/straw">Extracting data from .hic files with straw</a></li></ul><p>To launch the command line tools, use the shell script “juicer_tools” on Unix&#x2F;MacOS or type</p><figure class="highlight mipsasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs mipsasm"><span class="hljs-keyword">java </span>-<span class="hljs-keyword">jar </span><span class="hljs-keyword">juicer_tools.jar </span>(command...) [flags...] &lt;parameters...&gt;`<br></code></pre></td></tr></table></figure><p>In the command line tools, there are several analysis functions:</p><ol><li><code>apa</code> for conducting aggregate peak analysis</li><li><code>hiccups</code> for annotating loops</li><li><code>motifs</code> for finding CTCF motifs</li><li><code>arrowhead</code> for annotating contact domains</li><li><code>eigenvector</code> for calculating the eigenvector (first PC) of the Pearson’s</li><li><code>pearsons</code> for calculating the Pearson’s</li></ol><p>The <code>juicer_tools</code> (Unix&#x2F;MacOS) script can be used in place of the unwieldy <code>java -Djava.library.path=path/to/natives/ -jar juicer_tools.jar</code></p><hr><h1 id="juicer的工作目录结构"><a href="#juicer的工作目录结构" class="headerlink" title="juicer的工作目录结构"></a>juicer的工作目录结构</h1><p>要求固定目录结构，新建<code>juicer</code>目录，该目录为软件安装目录，目录下必须有4个子目录</p><p><code>references</code>目录存放参考基因组文件，<code>work</code>存放样本序列文件和分析结果，<code>scripts</code>存放软件运行脚本，<code>restriction_sites</code>存放参考基因组酶切图谱。</p><h1 id="下载源码"><a href="#下载源码" class="headerlink" title="下载源码"></a>下载源码</h1><p>从github上下载juicer和jcuda的源代码，放置到<code>scripts</code>目录。</p><p>其中的<code>CPU</code>目录就是单机服务器，而<code>AWS</code>, <code>LSF</code>, <code>PBS</code>等对应公有云和不同的集群系统。</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">cd</span> scripts/common<br><span class="hljs-attribute">wget</span> https://hicfiles.tc4ga.com/public/juicer/juicer_tools.<span class="hljs-number">1</span>.<span class="hljs-number">9</span>.<span class="hljs-number">9</span>_jcuda.<span class="hljs-number">0</span>.<span class="hljs-number">8</span>.jar<br><span class="hljs-attribute">ln</span> -s juicer_tools.<span class="hljs-number">1</span>.<span class="hljs-number">9</span>.<span class="hljs-number">9</span>_jcuda.<span class="hljs-number">0</span>.<span class="hljs-number">8</span>.jar  juicer_tools.jar<br></code></pre></td></tr></table></figure><h1 id="参考基因组，酶切图谱"><a href="#参考基因组，酶切图谱" class="headerlink" title="参考基因组，酶切图谱"></a>参考基因组，酶切图谱</h1><p>fasta序列文件和bwa 索引</p><p>juicer&#x2F;misc&#x2F;generate_site_positions.py可以输出4种内切酶的酶切图谱。HindIII；DpnII；MboI；Sau3AI</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs awk">generate_site_positions.py HindIII hg19 hg19.fasta<br>python ..<span class="hljs-regexp">/juicer/mi</span>sc<span class="hljs-regexp">/generate_site_positions.py  MboI  hg38_MboI ../</span>references/Homo_sapiens_assembly38.fasta <span class="hljs-comment"># 生成了 hg38_MboI.txt 文件</span><br>awk <span class="hljs-string">&#x27;BEGIN&#123;OFS=&quot;\t&quot;&#125;&#123;print $1, $NF&#125;&#x27;</span> hg38_MboI.txt &gt; hg38.chrom.sizes<br></code></pre></td></tr></table></figure><p>第一个参数内切酶名称，第二个参数自定义基因组版本，第三个参数基因组fasta文件路径，输出文件名称为第二个参数和第一个参数用下划线链接，后缀为<code>txt</code></p><h1 id="序列"><a href="#序列" class="headerlink" title="序列"></a>序列</h1><p>软件运行时对样本文件的存放位置也有要求，必须位于<code>work</code>目录下，以样本名作为一个子目录，序列文件存放于<code>fastq</code>目录下，示意如下</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs awk"><span class="hljs-regexp">/opt/</span>juicer<span class="hljs-regexp">/work/</span>MBR19/fastq<br><span class="hljs-regexp">/opt/</span>juicer<span class="hljs-regexp">/work/</span>MBR19<span class="hljs-regexp">/fastq/</span>chr19_R1.fastq.gz<br><span class="hljs-regexp">/opt/</span>juicer<span class="hljs-regexp">/work/</span>MBR19<span class="hljs-regexp">/fastq/</span>chr19_R2.fastq.gz<br></code></pre></td></tr></table></figure><hr><h1 id="软件比较"><a href="#软件比较" class="headerlink" title="软件比较"></a>软件比较</h1><p><img src="/GeekFocus/./1.png" alt="img"></p><h1 id="脚本原理（juicer-sh）"><a href="#脚本原理（juicer-sh）" class="headerlink" title="脚本原理（juicer.sh）"></a>脚本原理（juicer.sh）</h1><p>fastq等文件输入 —》bwa比对 —》排序 —》合并 —》去PCR重复 —》生成 hic文件</p><p>Juicer的工作流程见下图，输入<strong>原始</strong>fastq文件，处理得到<strong>中间</strong>文件.hic, 之后对.hic文件用于<strong>下游</strong>分析，包括</p><p>Arrowhead: 寻找存在关联的区域<br>HiCCUPS: 分析局部富集peaks<br>MotifFinder: 用于锚定peaks<br>Persons: 计算观测&#x2F;期望的皮尔森相关系数矩阵<br>Eigenvector: 确定分隔</p><p><img src="/GeekFocus/./2.png" alt="juicer工作流程"></p><h1 id="结果文件"><a href="#结果文件" class="headerlink" title="结果文件"></a>结果文件</h1><p>结果文件都在 aligned 中，主要文件是 .hic 文件，其中inter_30.hic 是设置了 mapq threshold &gt;30 的结果。如果 GPU （cudd）可用，软件会自动使用自带 <strong>HiCCUPS</strong> 算法计算 contact domains 并保存在 inter_30_contact_domains 文件夹。如果GPU不可用，可手动用自带的 <strong>CPU HiCCUPS</strong> 算法来计算，后面章节有介绍。</p><p>hic文件格式请看 <a href="https://links.jianshu.com/go?to=https://github.com/theaidenlab/juicebox/blob/master/HiC_format_v8.docx">https://github.com/theaidenlab/juicebox/blob/master/HiC_format_v8.docx</a></p><h1 id="示例代码"><a href="#示例代码" class="headerlink" title="示例代码"></a>示例代码</h1><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs sh">juicer.sh \<br>-z references/hg19.fa \<br>-p restriction_sites/hg19.chrom.sizes \<br>-y restriction_sites/hg19_HindIII.txt \<br>-d /home/pub/software/juicer/work/HIC003/ \<br>-D /home/pub/software/juicer \<br>-t 5<br><br>-d: juicer的目录 安装在/soft/，设置为/soft/juicer<br>-D: juicer scripts的目录，安装在/soft/，设置为/soft/juicer/CPU<br></code></pre></td></tr></table></figure><p>需要注意, 指定文件路径时，最好指定绝对路径，特别是fastq文件路径。因为软件运行过程中会使用软链接，相对路径会出错。</p><p><code>splits</code>目录下存放中间结果，由于hi-C数据量很大，所以会将原始序列<strong>拆分成多份</strong>，<strong>并行运算加快速度</strong>。默认每份包含22.5M的reads, 可以通过<code>-C</code>参数调整，该参数指定拆分文件的行数，默认是90000000?， 注意fastq文件4行代表一条序列，所以这个参数的值必须是4的倍数。拆分后序列的R1和R2端分别通过bwa比对基因组，然后合并，筛选嵌合体序列，去重复，生成预处理后的结果文件。</p><p><code>aligned</code>目录下存放的是最终结果，包含了可以导入juicebox的后缀为<code>hic</code>的图谱文件, <code>inter.hic</code>和<code>inter_30.hic</code>， 30表示通过<code>MAPQ &gt; 30</code>过滤之后的结果。完整流程还会进行后续处理，包括识别TAD, 染色质环等结构。其中识别染色质环的HICCUPs算法必须通过<a href="https://cloud.tencent.com/product/gpu?from=10680">GPU</a>加速运行才可以，所以没有安装GPU卡的普通服务器无法运行这个步骤。</p><p>上述过程可看到，juicer使用简单。由于Hi-C数据测序量非常大，以及后续分析算法的复杂度，对服务器计算资源的要求相当高，必须高性能服务器才能满足要求，而该软件所需的GPU卡成本也非常高，一块的成本在2万元左右，这些因素一定程度制约了Hi-C的普及和发展。</p><h1 id="juicer下游分析"><a href="#juicer下游分析" class="headerlink" title="juicer下游分析"></a>juicer下游分析</h1><p><a href="https://zhuanlan.zhihu.com/p/341206245">https://zhuanlan.zhihu.com/p/341206245</a></p><p>目前针对Hi-C数据的研究主要是三个方面，分别是<code>A/B comparment</code> ，<code>TADS</code>，<code>Loops</code>。</p><p><code>juicer_tools.jar</code> 功能介绍</p><p><code>arrowhead</code> 注释TAD</p><p><code>hiccups</code> 注释loop</p><p><code>motigs</code> 定位CTCF元件</p><p><code>hiccupsdiff</code> 从多个loos文件中找到不同的loop</p><p><code>apa</code> 聚合峰的分析</p><p><code>pearsons</code> 计算O&#x2F;E的皮尔森相关系数</p><p><code>eigenvector</code> 计算特征向量的皮尔森相关系数</p><p><code>dump</code> .hic文件互作矩阵提取</p><p><code>pre</code> 非juicer数据转.hic文件</p><h1 id="hic数据可视化"><a href="#hic数据可视化" class="headerlink" title="hic数据可视化"></a>hic数据可视化</h1><ul><li><p><strong>加载.hic文件</strong></p></li><li><p><strong>加载一维注释</strong></p></li><li><p><strong>加载二维注释，黄的的是TAD，天蓝色的是loop</strong></p></li></ul>]]></content>
    
    
    <categories>
      
      <category>Software</category>
      
    </categories>
    
    
    <tags>
      
      <tag>assembly</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【long reads mapping】【minimap2】</title>
    <link href="/GeekFocus/2022/03/16/2022-03-16-minimap2/"/>
    <url>/GeekFocus/2022/03/16/2022-03-16-minimap2/</url>
    
    <content type="html"><![CDATA[<p>Minimap2 is a versatile sequence alignment program that aligns DNA or mRNA sequences against a large reference database. </p><span id="more"></span><p><a href="https://github.com/lh3/minimap2">https://github.com/lh3/minimap2</a></p><ul><li>将PacBio或OXford Nanopore的read和已有参考基因组（如人类）进行比对(<strong>long reads mapping</strong>)</li><li>寻找高错误率read(15%)之间的overlap</li><li>将PacBio Iso-Seq 或Nanopore cDNA或RNA序列比对到参考基因组(splicing aware)</li><li>将<strong>illumina</strong> 单端或者双端序列比对到参考基因组</li><li><strong>组装之间</strong>的比对</li><li><strong>临近物种</strong>的全基因组比对</li></ul><h2 id="Getting-Started"><a href="#Getting-Started" class="headerlink" title="Getting Started"></a>Getting Started</h2><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs sh">git <span class="hljs-built_in">clone</span> https://github.com/lh3/minimap2<br><span class="hljs-built_in">cd</span> minimap2 &amp;&amp; make<br><span class="hljs-comment"># long sequences against a reference genome</span><br>./minimap2 -a <span class="hljs-built_in">test</span>/MT-human.fa <span class="hljs-built_in">test</span>/MT-orang.fa &gt; test.sam<br><span class="hljs-comment"># create an index first and then map</span><br>./minimap2 -x map-ont -d MT-human-ont.mmi <span class="hljs-built_in">test</span>/MT-human.fa<br>./minimap2 -a MT-human-ont.mmi <span class="hljs-built_in">test</span>/MT-orang.fa &gt; test.sam<br><span class="hljs-comment"># use presets (no test data)</span><br>./minimap2 -ax map-pb ref.fa pacbio.fq.gz &gt; aln.sam       <span class="hljs-comment"># PacBio CLR genomic reads</span><br>./minimap2 -ax map-ont ref.fa ont.fq.gz &gt; aln.sam         <span class="hljs-comment"># Oxford Nanopore genomic reads</span><br>./minimap2 -ax map-hifi ref.fa pacbio-ccs.fq.gz &gt; aln.sam <span class="hljs-string">&#x27;PacBio HiFi/CCS genomic reads (v2.19 or later)&#x27;</span><br>./minimap2 -ax asm20 ref.fa pacbio-ccs.fq.gz &gt; aln.sam    <span class="hljs-string">&#x27;PacBio HiFi/CCS genomic reads (v2.18 or earlier)&#x27;</span><br>./minimap2 -ax sr ref.fa read1.fa read2.fa &gt; aln.sam      <span class="hljs-comment"># short genomic paired-end reads</span><br>./minimap2 -ax splice ref.fa rna-reads.fa &gt; aln.sam       <span class="hljs-comment"># spliced long reads (strand unknown)</span><br>./minimap2 -ax splice -uf -k14 ref.fa reads.fa &gt; aln.sam  <span class="hljs-comment"># noisy Nanopore Direct RNA-seq</span><br>./minimap2 -ax splice:hq -uf ref.fa query.fa &gt; aln.sam    <span class="hljs-comment"># Final PacBio Iso-seq or traditional cDNA</span><br>./minimap2 -ax splice --junc-bed anno.bed12 ref.fa query.fa &gt; aln.sam  <span class="hljs-comment"># prioritize on annotated junctions</span><br>./minimap2 -cx asm5 asm1.fa asm2.fa &gt; aln.paf             <span class="hljs-string">&#x27;intra-species asm-to-asm alignment&#x27;</span><br>./minimap2 -x ava-pb reads.fa reads.fa &gt; overlaps.paf     <span class="hljs-comment"># PacBio read overlap</span><br>./minimap2 -x ava-ont reads.fa reads.fa &gt; overlaps.paf    <span class="hljs-comment"># Nanopore read overlap</span><br><span class="hljs-comment"># man page for detailed command line options</span><br>man ./minimap2.1<br></code></pre></td></tr></table></figure><h2 id=""><a href="#" class="headerlink" title=""></a></h2><h2 id="Users’-Guide"><a href="#Users’-Guide" class="headerlink" title="Users’ Guide"></a>Users’ Guide</h2><p>Minimap2 is a versatile sequence alignment program that aligns <strong>DNA or mRNA</strong> sequences <strong>against</strong> a large <strong>reference</strong> database. </p><p>Typical use cases include: </p><p>(1) <strong>mapping PacBio</strong> or Oxford <strong>Nanopore</strong> genomic <strong>reads</strong> to the human genome;</p><p>(2) <strong>finding overlaps between long read</strong>s with <strong>error rate</strong> up to ~15%;</p><p>(3) <strong>splice-aware alignment</strong> of PacBio Iso-Seq or Nanopore cDNA or Direct RNA reads <strong>against</strong> a <strong>reference</strong> genome;</p><p>(4) aligning <strong>Illumina</strong> single- or paired-end reads; </p><p>(5) <strong>assembly-to-assembly alignment</strong>; </p><p>(6) <strong>full-genome alignment</strong> between <strong>two closely related species</strong> with <strong>divergence below ~15%</strong>.</p><p>For ~10kb noisy reads sequences, minimap2 is <strong>tens of times faster</strong> than mainstream long-read mappers such as BLASR, BWA-MEM, NGMLR and GMAP. It is <strong>more accurate</strong> on simulated long reads and produces biologically meaningful alignment ready for downstream analyses. For &gt;100bp <strong>Illumina short reads</strong>, minimap2 is <strong>three times</strong> as fast as <strong>BWA-MEM</strong> and <strong>Bowtie2</strong>, and as accurate on simulated data. Detailed evaluations are available from the <a href="https://doi.org/10.1093/bioinformatics/bty191">minimap2 paper</a> or the <a href="https://arxiv.org/abs/1708.01492">preprint</a>.</p><h3 id="Installation"><a href="#Installation" class="headerlink" title="Installation"></a>Installation</h3><figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs vim"><span class="hljs-keyword">cd</span> minimap2 &amp;&amp; <span class="hljs-keyword">make</span><br></code></pre></td></tr></table></figure><h3 id="PAF-a-Pairwise-mApping-Format"><a href="#PAF-a-Pairwise-mApping-Format" class="headerlink" title="PAF: a Pairwise mApping Format"></a>PAF: a Pairwise mApping Format</h3><p>PAF is a text format describing the <strong>approximate mapping positions</strong> between two set of sequences. PAF is TAB-delimited with each line consisting of the following predefined fields:</p><table><thead><tr><th>Col</th><th>Type</th><th>Description</th></tr></thead><tbody><tr><td>1</td><td>string</td><td>Query sequence name</td></tr><tr><td>2</td><td>int</td><td>Query sequence length</td></tr><tr><td>3</td><td>int</td><td>Query start (0-based; BED-like; closed)</td></tr><tr><td>4</td><td>int</td><td>Query end (0-based; BED-like; open)</td></tr><tr><td>5</td><td>char</td><td>Relative strand: “+” or “-“</td></tr><tr><td>6</td><td>string</td><td>Target sequence name</td></tr><tr><td>7</td><td>int</td><td>Target sequence length</td></tr><tr><td>8</td><td>int</td><td>Target start on original strand (0-based)</td></tr><tr><td>9</td><td>int</td><td>Target end on original strand (0-based)</td></tr><tr><td>10</td><td>int</td><td>Number of residue matches</td></tr><tr><td>11</td><td>int</td><td>Alignment block length</td></tr><tr><td>12</td><td>int</td><td>Mapping quality (0-255; 255 for missing)</td></tr></tbody></table><p>If PAF is generated from an alignment, <strong>column 10 equals the number of sequence matches</strong>, and <strong>column 11 equals the total number of sequence matches, mismatches, insertions and deletions in the alignment</strong>. If alignment is not available, column 10 and 11 are still required but may be highly inaccurate.</p><p>A PAF file may optionally contain SAM-like typed key-value pairs at the end of each line.</p><h3 id="General-usage"><a href="#General-usage" class="headerlink" title="General usage"></a>General usage</h3><p>Without any options, minimap2 takes a <strong>reference</strong> database and a <strong>query sequence</strong> file as input and produce approximate mapping, without base-level alignment (i.e. coordinates are only approximate and no CIGAR in output), in the PAF format:</p><figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs pgsql">minimap2 <span class="hljs-keyword">ref</span>.fa query.fq &gt; approx-<span class="hljs-keyword">mapping</span>.paf<br></code></pre></td></tr></table></figure><p>You can ask minimap2 to generate CIGAR at the <code>cg</code> tag of PAF with:</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs stylus">minimap2 -c ref<span class="hljs-selector-class">.fa</span> query<span class="hljs-selector-class">.fq</span> &gt; alignment.paf<br></code></pre></td></tr></table></figure><p>or to output alignments in the <a href="https://samtools.github.io/hts-specs/SAMv1.pdf">SAM format</a>:</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs stylus">minimap2 -<span class="hljs-selector-tag">a</span> ref<span class="hljs-selector-class">.fa</span> query<span class="hljs-selector-class">.fq</span> &gt; alignment.sam<br></code></pre></td></tr></table></figure><p>Minimap2 seamlessly works with <strong>gzip’d FASTA</strong> and <strong>FASTQ</strong> formats as input. You <strong>don’t need to convert</strong> between FASTA and FASTQ or decompress gzip’d files first.</p><p>For the human reference genome, minimap2 takes a few minutes to generate a minimizer index for the reference before mapping. To <strong>reduce indexing time</strong>, you can optionally save the index with option <strong>-d</strong> and <strong>replace the reference sequence file with the index file</strong> on the minimap2 command line:</p><figure class="highlight applescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs applescript">minimap2 -d <span class="hljs-keyword">ref</span>.mmi <span class="hljs-keyword">ref</span>.fa                     <span class="hljs-comment"># indexing</span><br>minimap2 -<span class="hljs-keyword">a ref</span>.mmi reads.fq &gt; alignment.sam   <span class="hljs-comment"># alignment</span><br></code></pre></td></tr></table></figure><p><em><strong>Importantly</strong></em>, it should be noted that once you build the index, indexing parameters such as <strong>-k</strong>, <strong>-w</strong>, <strong>-H</strong> and <strong>-I</strong> can’t be changed during mapping. If you are running minimap2 for <strong>different data types</strong>, you will probably need to keep <strong>multiple indexes generated</strong> with different parameters. This makes minimap2 different from BWA which always uses the same index regardless of query data types.</p><h3 id="Use-cases"><a href="#Use-cases" class="headerlink" title="Use cases"></a>Use cases</h3><p>Minimap2 uses the same base algorithm for all applications. However, due to the different data types it supports (e.g. short vs long reads; DNA vs mRNA reads), minimap2 needs to be tuned for optimal performance and accuracy. It is usually recommended to choose a preset with option <strong>-x</strong>, which <strong>sets multiple parameters</strong> at the same time. The default setting is the same as <code>map-ont</code>.</p><h4 id="Map-long-noisy-genomic-reads"><a href="#Map-long-noisy-genomic-reads" class="headerlink" title="Map long noisy genomic reads"></a>Map long noisy genomic reads</h4><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs sh">minimap2 -ax map-pb  ref.fa pacbio-reads.fq &gt; aln.sam   <span class="hljs-comment"># for 【PacBio CLR】 reads</span><br>minimap2 -ax map-ont ref.fa ont-reads.fq &gt; aln.sam      <span class="hljs-comment"># for 【Oxford Nanopore】 reads</span><br></code></pre></td></tr></table></figure><p>The difference between <code>map-pb</code> and <code>map-ont</code> is that <code>map-pb</code> uses homopolymer-compressed (HPC) minimizers as <strong>seeds</strong>, while <code>map-ont</code> uses ordinary minimizers as seeds. Emperical evaluation suggests HPC minimizers improve performance and sensitivity when aligning PacBio CLR reads, but hurt when aligning Nanopore reads.</p><h4 id="Map-long-mRNA-x2F-cDNA-reads"><a href="#Map-long-mRNA-x2F-cDNA-reads" class="headerlink" title="Map long mRNA&#x2F;cDNA reads"></a>Map long mRNA&#x2F;cDNA reads</h4><figure class="highlight perl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs perl">minimap2 -ax <span class="hljs-keyword">splice</span>:hq -uf ref.fa iso-seq.fq &gt; aln.sam       <span class="hljs-comment"># PacBio Iso-seq/traditional cDNA</span><br>minimap2 -ax <span class="hljs-keyword">splice</span> ref.fa nanopore-cdna.fa &gt; aln.sam        <span class="hljs-comment"># Nanopore 2D cDNA-seq</span><br>minimap2 -ax <span class="hljs-keyword">splice</span> -uf -k14 ref.fa direct-rna.fq &gt; aln.sam  <span class="hljs-comment"># Nanopore Direct RNA-seq</span><br>minimap2 -ax <span class="hljs-keyword">splice</span> --<span class="hljs-keyword">splice</span>-flank=<span class="hljs-keyword">no</span> SIRV.fa SIRV-seq.fa    <span class="hljs-comment"># mapping against SIRV control</span><br></code></pre></td></tr></table></figure><p>There are different long-read RNA-seq technologies, including tranditional full-length cDNA, EST, PacBio Iso-seq, Nanopore 2D cDNA-seq and Direct RNA-seq. They produce data of varying quality and properties. By default, <code>-x splice</code> <strong>assumes the read orientation relative to the transcript strand is unknown</strong>. It tries two rounds of alignment to infer the orientation and write the strand to the <code>ts</code> SAM&#x2F;PAF tag if possible. For <strong>Iso-seq, Direct RNA-seq</strong> and tranditional full-length <strong>cDNAs</strong>, it would be desired to apply <code>-u f</code> to force minimap2 to <strong>consider the forward transcript strand only</strong>. This speeds up alignment with slight improvement to accuracy. For <strong>noisy Nanopore Direct RNA-seq reads</strong>, it is recommended to use a smaller k-mer size for increased sensitivity to the first or the last exons.</p><p>Minimap2 rates an alignment by the score of the max-scoring sub-segment, <em>excluding</em> introns, and marks the best alignment as primary in SAM. When a <strong>spliced gene also has unspliced pseudogenes</strong>, minimap2 does not intentionally prefer spliced alignment, though in practice it more often marks the spliced alignment as the primary. By default, minimap2 outputs up to five secondary alignments (i.e. likely pseudogenes in the context of RNA-seq mapping). This can be tuned with option <strong>-N</strong>.</p><p>For <strong>long RNA-seq reads</strong>, minimap2 may produce chimeric alignments potentially caused by gene fusions&#x2F;structural variations or by an intron longer than the max intron length <strong>-G</strong> (200k by default). For now, it is not recommended to apply an excessively large <strong>-G</strong> as this slows down minimap2 and sometimes leads to false alignments.</p><p>It is worth noting that by default <code>-x splice</code> prefers GT[A&#x2F;G]..[C&#x2F;T]AG over GT[C&#x2F;T]..[A&#x2F;G]AG, and then over other splicing signals. Considering one additional base improves the junction accuracy for noisy reads, but reduces the accuracy when aligning against the widely used SIRV control data. This is because SIRV does not honor the evolutionarily conservative splicing signal. If you are studying <strong>SIRV</strong>, you may apply <code>--splice-flank=no</code> to let minimap2 only model GT..AG, ignoring the additional base.</p><p>Since v2.17, minimap2 can optionally <strong>take annotated genes as input</strong> and prioritize on annotated splice junctions. To use this feature, you can</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs stylus">paftools<span class="hljs-selector-class">.js</span> gff2bed anno<span class="hljs-selector-class">.gff</span> &gt; anno<span class="hljs-selector-class">.bed</span><br>minimap2 -ax splice <span class="hljs-attr">--junc-bed</span> anno<span class="hljs-selector-class">.bed</span> ref<span class="hljs-selector-class">.fa</span> query<span class="hljs-selector-class">.fa</span> &gt; aln.sam<br></code></pre></td></tr></table></figure><p>Here, <code>anno.gff</code> is the gene annotation in the GTF or GFF3 format (<code>gff2bed</code> automatically tests the format). The output of <code>gff2bed</code> is in the 12-column BED format, or the BED12 format. With the <code>--junc-bed</code> option, minimap2 adds a bonus score (tuned by <code>--junc-bonus</code>) if an aligned junction matches a junction in the annotation. Option <code>--junc-bed</code> also takes 5-column BED, including the strand field. In this case, each line indicates an oriented junction.</p><h4 id="Find-overlaps-between-long-reads"><a href="#Find-overlaps-between-long-reads" class="headerlink" title="Find overlaps between long reads"></a>Find overlaps between long reads</h4><figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs nginx"><span class="hljs-attribute">minimap2</span> -x ava-pb  reads.fq reads.fq &gt; ovlp.paf    <span class="hljs-comment"># PacBio 【CLR read】 overlap</span><br>minimap2 -x ava-ont reads.fq reads.fq &gt; ovlp.paf    <span class="hljs-comment"># Oxford 【Nanopore read】 overlap</span><br></code></pre></td></tr></table></figure><p>Similarly, <code>ava-pb</code> uses HPC minimizers while <code>ava-ont</code> uses ordinary minimizers. It is usually not recommended to perform base-level alignment in the overlapping mode because it is slow and may produce false positive overlaps. However, if performance is not a concern, you may try to add <code>-a</code> or <code>-c</code> anyway.</p><h4 id="Map-short-accurate-genomic-reads"><a href="#Map-short-accurate-genomic-reads" class="headerlink" title="Map short accurate genomic reads"></a>Map short accurate genomic reads</h4><figure class="highlight applescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs applescript">minimap2 -ax sr <span class="hljs-keyword">ref</span>.fa reads-se.fq &gt; aln.sam           <span class="hljs-comment"># single-end alignment</span><br>minimap2 -ax sr <span class="hljs-keyword">ref</span>.fa read1.fq read2.fq &gt; aln.sam     <span class="hljs-comment"># paired-end alignment</span><br>minimap2 -ax sr <span class="hljs-keyword">ref</span>.fa reads-interleaved.fq &gt; aln.sam  <span class="hljs-comment"># paired-end alignment</span><br></code></pre></td></tr></table></figure><p>When two read files are specified, minimap2 reads from each file in turn and merge them into an interleaved stream internally. Two reads are considered to be paired if they are adjacent in the input stream and have the same name (with the <code>/[0-9]</code> suffix trimmed if present). Single- and paired-end reads can be mixed.</p><p>Minimap2 <strong>does not work well with short spliced reads</strong>. There are many capable RNA-seq mappers for short reads.</p><h4 id="Full-genome-x2F-assembly-alignment"><a href="#Full-genome-x2F-assembly-alignment" class="headerlink" title="Full genome&#x2F;assembly alignment"></a><font color="blue">Full genome&#x2F;assembly alignment</font></h4><figure class="highlight d"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs d">minimap2 -ax asm5 <span class="hljs-keyword">ref</span>.fa <span class="hljs-keyword">asm</span>.fa &gt; aln.sam       # assembly to assembly/<span class="hljs-keyword">ref</span> alignment<br></code></pre></td></tr></table></figure><p>For <strong>cross-species</strong> full-genome alignment, the scoring system needs to be tuned according to the sequence divergence.</p><h3 id="Advanced-features"><a href="#Advanced-features" class="headerlink" title="Advanced features"></a>Advanced features</h3><h4 id="Working-with-gt-65535-CIGAR-operations"><a href="#Working-with-gt-65535-CIGAR-operations" class="headerlink" title="Working with &gt;65535 CIGAR operations"></a>Working with &gt;65535 CIGAR operations</h4><p>Due to a design flaw, BAM does not work with CIGAR strings with &gt;65535 operations (SAM and CRAM work). However, for <strong>ultra-long nanopore reads</strong> minimap2 may align ~1% of read bases with long CIGARs beyond the capability of BAM. If you convert such SAM&#x2F;CRAM to BAM, Picard and recent samtools will throw an error and abort. Older samtools and other tools may create corrupted BAM.</p><p>To avoid this issue, you can add option <code>-L</code> at the minimap2 command line. This option moves a long CIGAR to the <code>CG</code> tag and leaves a fully clipped CIGAR at the SAM CIGAR column. Current tools that don’t read CIGAR (e.g. merging and sorting) still work with such BAM records; tools that read CIGAR will effectively ignore these records. It has been decided that future tools will seamlessly recognize long-cigar records generated by option <code>-L</code>.</p><p><strong>TL;DR</strong>: if you work with ultra-long reads and use tools that only process BAM files, please add option <code>-L</code>.</p><h4 id="The-cs-optional-tag"><a href="#The-cs-optional-tag" class="headerlink" title="The cs optional tag"></a>The cs optional tag</h4><p>The <code>cs</code> SAM&#x2F;PAF tag encodes bases at mismatches and INDELs. It matches regular expression <code>/(:[0-9]+|\*[a-z][a-z]|[=\+\-][A-Za-z]+)+/</code>. Like CIGAR, <code>cs</code> consists of series of operations. Each leading character specifies the operation; the following sequence is the one involved in the operation.</p><p>The <code>cs</code> tag is enabled by command line option <code>--cs</code>. The following alignment, for example:</p><figure class="highlight gherkin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs gherkin">CGATCGATAAATAGAGTAG---GAATAGCA<br>||||||<span class="hljs-string">   </span>||||||||||<span class="hljs-string">   </span>||||<span class="hljs-string"> </span>|||<br>CGATCG---AATAGAGTAGGTCGAATtGCA<br></code></pre></td></tr></table></figure><p>is represented as <code>:6-ata:10+gtc:4*at:3</code>, where <code>:[0-9]+</code> represents an identical block, <code>-ata</code> represents a deletion, <code>+gtc</code> an insertion and <code>*at</code> indicates reference base <code>a</code> is substituted with a query base <code>t</code>. It is similar to the <code>MD</code> SAM tag but is standalone and easier to parse.</p><p>If <code>--cs=long</code> is used, the <code>cs</code> string also contains identical sequences in the alignment. The above example will become <code>=CGATCG-ata=AATAGAGTAG+gtc=GAAT*at=GCA</code>. The long form of <code>cs</code> <strong>encodes both reference and query sequences in one string</strong>. The <code>cs</code> tag also encodes <strong>intron positions</strong> and <strong>splicing signals</strong> (see the <a href="https://lh3.github.io/minimap2/minimap2.html#10">minimap2 manpage</a> for details).</p><h4 id="Working-with-the-PAF-format"><a href="#Working-with-the-PAF-format" class="headerlink" title="Working with the PAF format"></a><font color="red">Working with the PAF format</font></h4><p>Minimap2 also comes with a (java)script <a href="https://github.com/lh3/minimap2/blob/master/misc/paftools.js">paftools.js</a> that processes alignments in the PAF format. It calls variants from assembly-to-reference alignment, lifts over BED files based on alignment, converts between formats and provides utilities for various evaluations. For details, please see <a href="https://github.com/lh3/minimap2/blob/master/misc/README.md">misc&#x2F;README.md</a>.</p><h3 id="Algorithm-overview"><a href="#Algorithm-overview" class="headerlink" title="Algorithm overview"></a>Algorithm overview</h3><p>In the following, minimap2 command line options have a dash ahead and are highlighted in bold. The description may help to tune minimap2 parameters.</p><ol><li>Read <strong>-I</strong> [&#x3D;<em>4G</em>] reference bases, extract (<strong>-k</strong>,<strong>-w</strong>)-minimizers and index them in a hash table.</li><li>Read <strong>-K</strong> [&#x3D;<em>200M</em>] query bases. For each query sequence, do step 3 through 7:</li><li>For each (<strong>-k</strong>,<strong>-w</strong>)-minimizer on the query, check against the reference index. If a reference minimizer is not among the top <strong>-f</strong> [&#x3D;<em>2e-4</em>] most frequent, collect its the occurrences in the reference, which are called <em>seeds</em>.</li><li>Sort seeds by position in the reference. Chain them with dynamic programming. Each chain represents a potential mapping. For read overlapping, report all chains and then go to step 8. For reference mapping, do step 5 through 7:</li><li>Let <em>P</em> be the set of primary mappings, which is an empty set initially. For each chain from the best to the worst according to their chaining scores: if on the query, the chain overlaps with a chain in <em>P</em> by <strong>–mask-level</strong> [&#x3D;<em>0.5</em>] or higher fraction of the shorter chain, mark the chain as <em>secondary</em> to the chain in <em>P</em>; otherwise, add the chain to <em>P</em>.</li><li>Retain all primary mappings. Also retain up to <strong>-N</strong> [&#x3D;<em>5</em>] top secondary mappings if their chaining scores are higher than <strong>-p</strong> [&#x3D;<em>0.8</em>] of their corresponding primary mappings.</li><li>If alignment is requested, filter out an internal seed if it potentially leads to both a long insertion and a long deletion. Extend from the left-most seed. Perform global alignments between internal seeds. Split the chain if the accumulative score along the global alignment drops by <strong>-z</strong> [&#x3D;<em>400</em>], disregarding long gaps. Extend from the right-most seed. Output chains and their alignments.</li><li>If there are more query sequences in the input, go to step 2 until no more queries are left.</li><li>If there are more reference sequences, reopen the query file from the start and go to step 1; otherwise stop.</li></ol><h3 id="Getting-help"><a href="#Getting-help" class="headerlink" title="Getting help"></a>Getting help</h3><p>Manpage <a href="https://lh3.github.io/minimap2/minimap2.html">minimap2.1</a> provides detailed description of minimap2 command line options and optional tags. The <a href="https://github.com/lh3/minimap2/blob/master/FAQ.md">FAQ</a>page answers several frequently asked questions. If you encounter bugs or have further questions or requests, you can raise an issue at the <a href="https://github.com/lh3/minimap2/issues">issue page</a>. There is not a specific mailing list for the time being.</p><h2 id="Limitations"><a href="#Limitations" class="headerlink" title="Limitations"></a>Limitations</h2><ul><li>Minimap2 may produce <strong>suboptimal alignments</strong> through <strong>long low-complexity regions</strong> where seed positions may be suboptimal. This should not be a big concern because even the optimal alignment may be wrong in such regions.</li><li>Minimap2 requires SSE2 instructions on x86 CPUs or NEON on ARM CPUs. It is possible to add non-SIMD support, but it would make minimap2 slower by several times.</li><li>Minimap2 <strong>does not work</strong> with a single query or database sequence ~<strong>2 billion bases or longer</strong> (2,147,483,647 to be exact). The total length of all sequences can well exceed this threshold.</li><li>Minimap2 often <strong>misses small exons</strong>.</li></ul><h2 id="methods"><a href="#methods" class="headerlink" title="methods"></a>methods</h2><p>Minimap2 follows a typical <strong>seed-chain-align procedure</strong> as is used by most full-genome aligners. It <strong>collects minimizers</strong> (Roberts <em>et al</em>., 2004) of the <strong>reference sequences</strong> and <strong>indexes them in a hash table</strong>, with the <strong>key</strong> being the hash of a minimizer and the <strong>value</strong> being a list of locations of the minimizer copies. Then for <strong>each query sequence</strong>, minimap2 takes query minimizers as <em>seeds</em>, finds exact matches (i.e. <em>anchors</em>) to the reference, and identifies sets of colinear anchors as <em>chains</em>. If base-level alignment is requested, minimap2 applies <strong>dynamic programming</strong> (DP) to extend from the ends of chains and to close regions between adjacent anchors in chains.</p><p>Minimap2 uses indexing and seeding algorithms similar to minimap (Li, 2016), and furthers the predecessor with more accurate chaining, the ability to produce base-level alignment and the support of spliced alignment.</p><h1 id="asm-vs-asm"><a href="#asm-vs-asm" class="headerlink" title="asm vs asm"></a>asm vs asm</h1><h2 id="Difference-of-SNP-amp-indel-between-asm-vs-asm"><a href="#Difference-of-SNP-amp-indel-between-asm-vs-asm" class="headerlink" title="Difference of SNP&amp;indel between asm vs asm"></a>Difference of SNP&amp;indel between asm vs asm</h2><p><a href="https://bleepcoder.com/cn/minimap2/296555096/a-best-practices-document-for-assembly-to-assembly">ref</a></p><p><code>paftools.js call</code>现在支持 VCF 输出。 要使用它，请将<code>-f ref.fa</code>加到命令行中：</p><p>对同一物种的asm使用<code>asm5</code> 。 如果略有不同，请使用<code>asm10</code> 。 如果序列差异很大，请使用<code>-a</code> 。</p><p>variant calling</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs sh">git <span class="hljs-built_in">clone</span> https://github.com/lh3/minimap2   <span class="hljs-comment"># you need the latest version; not from conda</span><br><span class="hljs-built_in">cd</span> minimap2 &amp;&amp; make<br><br>curl -L https://github.com/attractivechaos/k8/releases/download/v0.2.4/k8-0.2.4.tar.bz2 | tar -jxf -<br><span class="hljs-built_in">cp</span> k8-0.2.4/k8-`<span class="hljs-built_in">uname</span> -s` k8   <span class="hljs-comment"># or copy it to a directory on you $PATH</span><br><br>./minimap2 -c --cs ref.fa query.fa \<br>  | <span class="hljs-built_in">sort</span> -k6,6 -k8,8n \<br>  | ./k8 misc/paftools.js call -f ref.fa -L20000 - &gt; var.vcf<br></code></pre></td></tr></table></figure><p>两asm差异太大。 可以先尝试：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sh">./minimap2 -c --cs ref.fa query.fa | <span class="hljs-built_in">sort</span> -k6,6 -k8,8n | ./k8 misc/paftools.js call -L20000 - &gt; var.txt<br></code></pre></td></tr></table></figure><p>生成vcf方法</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs sh">git <span class="hljs-built_in">clone</span> https://github.com/lh3/htsbox<br>(<span class="hljs-built_in">cd</span> htsbox &amp;&amp; make)<br>minimap2 -axasm5 wt_minion.fasta wt_pacbio.fasta | samtool <span class="hljs-built_in">sort</span> - &gt; sorted.bam<br>htsbox/htsbox pileup -q5 -S10000 -vcf wt_minion.fasta sorted.bam &gt; diff.vcf<br></code></pre></td></tr></table></figure><h2 id="convert-sam-asm-vs-asm-to-paf"><a href="#convert-sam-asm-vs-asm-to-paf" class="headerlink" title="convert sam(asm vs asm) to paf"></a>convert sam(asm vs asm) to paf</h2><p><a href="https://www.biostars.org/p/479287/">ref</a></p><p>Looks like no one has actually read the question correctly. <font color="blue"><strong>PAF is missing lots of information compared to SAM</strong></font>, because it is <font color="blue"><strong>a summary of alignment</strong></font>, but it also has <font color="blue">easy access to the <strong>alignment start</strong> and <strong>stop coordinates</strong>, <strong>sequences length</strong></font>, etc. Since <font color="blue">PAF is less information-dense you <strong>cannot convert in both directions</strong></font>.</p><p>There are several options:</p><ol><li>Use Heng Li’s experimental toolkit, <font color="blue">htsbox samview -p in.bam</font>: <a href="https://github.com/lh3/htsbox">https://github.com/lh3/htsbox</a></li><li>Use <font color="green"><strong>paftools.js sam2paf</strong></font>: <a href="https://github.com/lh3/minimap2/blob/master/misc/README.md#introduction">https://github.com/lh3/minimap2/blob/master/misc/README.md#introduction</a></li><li>Use this <font color="blue">python</font> library: <a href="https://bioconvert.readthedocs.io/en/master/_modules/bioconvert/sam2paf.html">https://bioconvert.readthedocs.io/en/master/_modules/bioconvert/sam2paf.html</a></li></ol><h2 id="visualization-of-PAF-file-obtained-from-asm-vs-asm-in-minimap2"><a href="#visualization-of-PAF-file-obtained-from-asm-vs-asm-in-minimap2" class="headerlink" title="visualization of PAF file obtained from asm_vs_asm in minimap2"></a>visualization of PAF file obtained from asm_vs_asm in minimap2</h2><p><a href="https://www.jianshu.com/p/befb3a440aed">Ref</a></p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs r">source<span class="hljs-punctuation">(</span><span class="hljs-string">&quot;.paf.R&quot;</span><span class="hljs-punctuation">)</span><br>df <span class="hljs-operator">&lt;-</span> read.paf<span class="hljs-punctuation">(</span><span class="hljs-string">&quot;./asm_vs_ref.paf&quot;</span><span class="hljs-punctuation">)</span><br>plot_synteny<span class="hljs-punctuation">(</span>df<span class="hljs-punctuation">)</span><br></code></pre></td></tr></table></figure><blockquote><p>grid系统里面的视图(viewport)可以继续分为多个图层，每个图层可有不同的坐标系统。</p></blockquote><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br></pre></td><td class="code"><pre><code class="hljs r">read.paf <span class="hljs-operator">&lt;-</span> <span class="hljs-keyword">function</span><span class="hljs-punctuation">(</span>file<span class="hljs-punctuation">,</span> sep <span class="hljs-operator">=</span> <span class="hljs-string">&quot;\t&quot;</span><span class="hljs-punctuation">,</span><br>                     header <span class="hljs-operator">=</span> <span class="hljs-literal">FALSE</span><span class="hljs-punctuation">,</span><br>                     MQ <span class="hljs-operator">=</span> <span class="hljs-number">10</span><span class="hljs-punctuation">,</span><br>                     ...<span class="hljs-punctuation">)</span><span class="hljs-punctuation">&#123;</span><br>  data <span class="hljs-operator">&lt;-</span> readLines<span class="hljs-punctuation">(</span>file<span class="hljs-punctuation">)</span><br>  <br>  dataSize <span class="hljs-operator">&lt;-</span> <span class="hljs-built_in">length</span><span class="hljs-punctuation">(</span>data<span class="hljs-punctuation">)</span><br>  <span class="hljs-comment"># initialize </span><br>  qName   <span class="hljs-operator">&lt;-</span> vector<span class="hljs-punctuation">(</span><span class="hljs-string">&quot;character&quot;</span><span class="hljs-punctuation">,</span> dataSize<span class="hljs-punctuation">)</span><br>  qLength <span class="hljs-operator">&lt;-</span> vector<span class="hljs-punctuation">(</span><span class="hljs-string">&quot;integer&quot;</span><span class="hljs-punctuation">,</span> dataSize<span class="hljs-punctuation">)</span><br>  qStart  <span class="hljs-operator">&lt;-</span> vector<span class="hljs-punctuation">(</span><span class="hljs-string">&quot;integer&quot;</span><span class="hljs-punctuation">,</span> dataSize<span class="hljs-punctuation">)</span><br>  qEnd    <span class="hljs-operator">&lt;-</span> vector<span class="hljs-punctuation">(</span><span class="hljs-string">&quot;integer&quot;</span><span class="hljs-punctuation">,</span> dataSize<span class="hljs-punctuation">)</span><br>  strand  <span class="hljs-operator">&lt;-</span> vector<span class="hljs-punctuation">(</span><span class="hljs-string">&quot;character&quot;</span><span class="hljs-punctuation">,</span> dataSize<span class="hljs-punctuation">)</span><br>  tName   <span class="hljs-operator">&lt;-</span> vector<span class="hljs-punctuation">(</span><span class="hljs-string">&quot;character&quot;</span><span class="hljs-punctuation">,</span> dataSize<span class="hljs-punctuation">)</span><br>  tLength <span class="hljs-operator">&lt;-</span> vector<span class="hljs-punctuation">(</span><span class="hljs-string">&quot;integer&quot;</span><span class="hljs-punctuation">,</span> dataSize<span class="hljs-punctuation">)</span><br>  tStart  <span class="hljs-operator">&lt;-</span> vector<span class="hljs-punctuation">(</span><span class="hljs-string">&quot;integer&quot;</span><span class="hljs-punctuation">,</span> dataSize<span class="hljs-punctuation">)</span><br>  tEnd    <span class="hljs-operator">&lt;-</span> vector<span class="hljs-punctuation">(</span><span class="hljs-string">&quot;integer&quot;</span><span class="hljs-punctuation">,</span> dataSize<span class="hljs-punctuation">)</span><br>  reMatch <span class="hljs-operator">&lt;-</span> vector<span class="hljs-punctuation">(</span><span class="hljs-string">&quot;integer&quot;</span><span class="hljs-punctuation">,</span> dataSize<span class="hljs-punctuation">)</span><br>  bLength <span class="hljs-operator">&lt;-</span> vector<span class="hljs-punctuation">(</span><span class="hljs-string">&quot;integer&quot;</span><span class="hljs-punctuation">,</span> dataSize<span class="hljs-punctuation">)</span><br>  mQuality<span class="hljs-operator">&lt;-</span> vector<span class="hljs-punctuation">(</span><span class="hljs-string">&quot;integer&quot;</span><span class="hljs-punctuation">,</span> dataSize<span class="hljs-punctuation">)</span><br><br>  i <span class="hljs-operator">&lt;-</span> 1<br>  j <span class="hljs-operator">&lt;-</span> 0<br>  <span class="hljs-keyword">for</span> <span class="hljs-punctuation">(</span>i <span class="hljs-keyword">in</span> seq<span class="hljs-punctuation">(</span>dataSize<span class="hljs-punctuation">)</span><span class="hljs-punctuation">)</span><span class="hljs-punctuation">&#123;</span><br>    items   <span class="hljs-operator">&lt;-</span> strsplit<span class="hljs-punctuation">(</span>data<span class="hljs-punctuation">[</span>i<span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span> split <span class="hljs-operator">=</span> sep<span class="hljs-punctuation">)</span><span class="hljs-punctuation">[[</span><span class="hljs-number">1</span><span class="hljs-punctuation">]</span><span class="hljs-punctuation">]</span><br>    <br>    quality <span class="hljs-operator">&lt;-</span> <span class="hljs-built_in">as.numeric</span><span class="hljs-punctuation">(</span>items<span class="hljs-punctuation">[</span><span class="hljs-number">12</span><span class="hljs-punctuation">]</span><span class="hljs-punctuation">)</span> <span class="hljs-comment">#Mapping Quality 0-255</span><br>    <span class="hljs-keyword">if</span> <span class="hljs-punctuation">(</span>quality <span class="hljs-operator">&lt;</span> MQ<span class="hljs-punctuation">)</span><br>      <span class="hljs-keyword">next</span><br>    j <span class="hljs-operator">&lt;-</span> j <span class="hljs-operator">+</span> <span class="hljs-number">1</span><br>    qName<span class="hljs-punctuation">[</span>j<span class="hljs-punctuation">]</span>   <span class="hljs-operator">&lt;-</span> items<span class="hljs-punctuation">[</span><span class="hljs-number">1</span><span class="hljs-punctuation">]</span> <span class="hljs-comment"># Query sequence name</span><br>    qLength<span class="hljs-punctuation">[</span>j<span class="hljs-punctuation">]</span> <span class="hljs-operator">&lt;-</span> <span class="hljs-built_in">as.integer</span><span class="hljs-punctuation">(</span>items<span class="hljs-punctuation">[</span><span class="hljs-number">2</span><span class="hljs-punctuation">]</span><span class="hljs-punctuation">)</span><br>    qStart<span class="hljs-punctuation">[</span>j<span class="hljs-punctuation">]</span>  <span class="hljs-operator">&lt;-</span> <span class="hljs-built_in">as.integer</span><span class="hljs-punctuation">(</span>items<span class="hljs-punctuation">[</span><span class="hljs-number">3</span><span class="hljs-punctuation">]</span><span class="hljs-punctuation">)</span> <span class="hljs-operator">+</span> <span class="hljs-number">1L</span><br>    qEnd<span class="hljs-punctuation">[</span>j<span class="hljs-punctuation">]</span>    <span class="hljs-operator">&lt;-</span> <span class="hljs-built_in">as.integer</span><span class="hljs-punctuation">(</span>items<span class="hljs-punctuation">[</span><span class="hljs-number">4</span><span class="hljs-punctuation">]</span><span class="hljs-punctuation">)</span> <span class="hljs-operator">+</span> <span class="hljs-number">1L</span> <span class="hljs-comment"># convert 0-based to 1-based</span><br>    strand<span class="hljs-punctuation">[</span>j<span class="hljs-punctuation">]</span>  <span class="hljs-operator">&lt;-</span> items<span class="hljs-punctuation">[</span><span class="hljs-number">5</span><span class="hljs-punctuation">]</span> <span class="hljs-comment"># Relative strand: &quot;+&quot; or &quot;-&quot;</span><br>    tName<span class="hljs-punctuation">[</span>j<span class="hljs-punctuation">]</span>   <span class="hljs-operator">&lt;-</span> items<span class="hljs-punctuation">[</span><span class="hljs-number">6</span><span class="hljs-punctuation">]</span> <span class="hljs-comment"># Target sequence name</span><br>    tLength<span class="hljs-punctuation">[</span>j<span class="hljs-punctuation">]</span> <span class="hljs-operator">&lt;-</span> <span class="hljs-built_in">as.integer</span><span class="hljs-punctuation">(</span>items<span class="hljs-punctuation">[</span><span class="hljs-number">7</span><span class="hljs-punctuation">]</span><span class="hljs-punctuation">)</span><br>    tStart<span class="hljs-punctuation">[</span>j<span class="hljs-punctuation">]</span>  <span class="hljs-operator">&lt;-</span> <span class="hljs-built_in">as.integer</span><span class="hljs-punctuation">(</span>items<span class="hljs-punctuation">[</span><span class="hljs-number">8</span><span class="hljs-punctuation">]</span><span class="hljs-punctuation">)</span> <span class="hljs-operator">+</span> <span class="hljs-number">1L</span><br>    tEnd<span class="hljs-punctuation">[</span>j<span class="hljs-punctuation">]</span>    <span class="hljs-operator">&lt;-</span> <span class="hljs-built_in">as.integer</span><span class="hljs-punctuation">(</span>items<span class="hljs-punctuation">[</span><span class="hljs-number">9</span><span class="hljs-punctuation">]</span><span class="hljs-punctuation">)</span> <span class="hljs-operator">+</span> <span class="hljs-number">1L</span><br>    reMatch<span class="hljs-punctuation">[</span>j<span class="hljs-punctuation">]</span> <span class="hljs-operator">&lt;-</span> <span class="hljs-built_in">as.integer</span><span class="hljs-punctuation">(</span>items<span class="hljs-punctuation">[</span><span class="hljs-number">10</span><span class="hljs-punctuation">]</span><span class="hljs-punctuation">)</span>  <span class="hljs-comment">#Number of residue matches</span><br>    bLength<span class="hljs-punctuation">[</span>j<span class="hljs-punctuation">]</span> <span class="hljs-operator">&lt;-</span> <span class="hljs-built_in">as.integer</span><span class="hljs-punctuation">(</span>items<span class="hljs-punctuation">[</span><span class="hljs-number">11</span><span class="hljs-punctuation">]</span><span class="hljs-punctuation">)</span> <span class="hljs-comment">#Alignment block length</span><br>    mQuality<span class="hljs-punctuation">[</span>j<span class="hljs-punctuation">]</span><span class="hljs-operator">&lt;-</span> <span class="hljs-built_in">as.integer</span><span class="hljs-punctuation">(</span>items<span class="hljs-punctuation">[</span><span class="hljs-number">12</span><span class="hljs-punctuation">]</span><span class="hljs-punctuation">)</span> <span class="hljs-comment">#Alignment block length</span><br>  <span class="hljs-punctuation">&#125;</span> <br>    pafDataframe <span class="hljs-operator">&lt;-</span> data.frame<span class="hljs-punctuation">(</span>qName <span class="hljs-operator">=</span> qName<span class="hljs-punctuation">[</span><span class="hljs-number">1</span><span class="hljs-operator">:</span>j<span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span> qStart <span class="hljs-operator">=</span> qStart<span class="hljs-punctuation">[</span><span class="hljs-number">1</span><span class="hljs-operator">:</span>j<span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span> qEnd <span class="hljs-operator">=</span> qEnd<span class="hljs-punctuation">[</span><span class="hljs-number">1</span><span class="hljs-operator">:</span>j<span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span><br>                               tName <span class="hljs-operator">=</span> tName<span class="hljs-punctuation">[</span><span class="hljs-number">1</span><span class="hljs-operator">:</span>j<span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span> tStart <span class="hljs-operator">=</span> tStart<span class="hljs-punctuation">[</span><span class="hljs-number">1</span><span class="hljs-operator">:</span>j<span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span> tEnd <span class="hljs-operator">=</span> tEnd<span class="hljs-punctuation">[</span><span class="hljs-number">1</span><span class="hljs-operator">:</span>j<span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span><br>                               qLength <span class="hljs-operator">=</span> qLength<span class="hljs-punctuation">[</span><span class="hljs-number">1</span><span class="hljs-operator">:</span>j<span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span> tLength <span class="hljs-operator">=</span> tLength<span class="hljs-punctuation">[</span><span class="hljs-number">1</span><span class="hljs-operator">:</span>j<span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span> <br>                               strand  <span class="hljs-operator">=</span> strand<span class="hljs-punctuation">[</span><span class="hljs-number">1</span><span class="hljs-operator">:</span>j<span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span><br>                               reMatch <span class="hljs-operator">=</span> reMatch<span class="hljs-punctuation">[</span><span class="hljs-number">1</span><span class="hljs-operator">:</span>j<span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span> bLength <span class="hljs-operator">=</span> bLength<span class="hljs-punctuation">[</span><span class="hljs-number">1</span><span class="hljs-operator">:</span>j<span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span><br>                               mQuality <span class="hljs-operator">=</span> mQuality<span class="hljs-punctuation">[</span><span class="hljs-number">1</span><span class="hljs-operator">:</span>j<span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span><br>                               stringsAsFactors <span class="hljs-operator">=</span> <span class="hljs-literal">FALSE</span><span class="hljs-punctuation">)</span><br>  <span class="hljs-built_in">return</span><span class="hljs-punctuation">(</span>pafDataframe<span class="hljs-punctuation">)</span> <br><span class="hljs-punctuation">&#125;</span><br><br><br>plot_synteny <span class="hljs-operator">&lt;-</span> <span class="hljs-keyword">function</span><span class="hljs-punctuation">(</span>df<span class="hljs-punctuation">,</span> contigs <span class="hljs-operator">=</span> <span class="hljs-number">20</span><span class="hljs-punctuation">,</span><br>                         lineSize <span class="hljs-operator">=</span> <span class="hljs-number">3</span><span class="hljs-punctuation">,</span><br>                         borderCol <span class="hljs-operator">=</span> <span class="hljs-string">&quot;#5496ff&quot;</span><span class="hljs-punctuation">,</span>... <span class="hljs-punctuation">)</span><span class="hljs-punctuation">&#123;</span><br>  <br>  <span class="hljs-comment"># select the top N contig</span><br>  x <span class="hljs-operator">&lt;-</span> df<span class="hljs-punctuation">[</span><span class="hljs-punctuation">,</span><span class="hljs-built_in">c</span><span class="hljs-punctuation">(</span><span class="hljs-string">&quot;qName&quot;</span><span class="hljs-punctuation">,</span><span class="hljs-string">&quot;qLength&quot;</span><span class="hljs-punctuation">)</span><span class="hljs-punctuation">]</span><br>  x <span class="hljs-operator">&lt;-</span> x<span class="hljs-punctuation">[</span><span class="hljs-operator">!</span>duplicated<span class="hljs-punctuation">(</span>x<span class="hljs-operator">$</span>qName<span class="hljs-punctuation">)</span><span class="hljs-punctuation">,</span><span class="hljs-punctuation">]</span><br>  x <span class="hljs-operator">&lt;-</span> x<span class="hljs-punctuation">[</span>order<span class="hljs-punctuation">(</span>x<span class="hljs-operator">$</span>qLength<span class="hljs-punctuation">,</span> decreasing <span class="hljs-operator">=</span> <span class="hljs-literal">TRUE</span><span class="hljs-punctuation">)</span><span class="hljs-punctuation">,</span><span class="hljs-punctuation">]</span><span class="hljs-punctuation">[</span><span class="hljs-number">1</span><span class="hljs-operator">:</span>contigs<span class="hljs-punctuation">,</span><span class="hljs-punctuation">]</span><br><br>  y <span class="hljs-operator">&lt;-</span> df<span class="hljs-punctuation">[</span><span class="hljs-punctuation">,</span><span class="hljs-built_in">c</span><span class="hljs-punctuation">(</span><span class="hljs-string">&quot;tName&quot;</span><span class="hljs-punctuation">,</span><span class="hljs-string">&quot;tLength&quot;</span><span class="hljs-punctuation">)</span><span class="hljs-punctuation">]</span><br>  y <span class="hljs-operator">&lt;-</span> y<span class="hljs-punctuation">[</span><span class="hljs-operator">!</span>duplicated<span class="hljs-punctuation">(</span>y<span class="hljs-operator">$</span>tName<span class="hljs-punctuation">)</span><span class="hljs-punctuation">,</span><span class="hljs-punctuation">]</span><br>  y <span class="hljs-operator">&lt;-</span> y<span class="hljs-punctuation">[</span>order<span class="hljs-punctuation">(</span>y<span class="hljs-operator">$</span>tLength<span class="hljs-punctuation">,</span> decreasing <span class="hljs-operator">=</span> <span class="hljs-literal">TRUE</span><span class="hljs-punctuation">)</span><span class="hljs-punctuation">,</span><span class="hljs-punctuation">]</span><span class="hljs-punctuation">[</span><span class="hljs-number">1</span><span class="hljs-operator">:</span>contigs<span class="hljs-punctuation">,</span><span class="hljs-punctuation">]</span><br>  <br>  <span class="hljs-comment"># make new page for ploting</span><br>  grid<span class="hljs-operator">::</span>grid.newpage<span class="hljs-punctuation">(</span><span class="hljs-punctuation">)</span><br>  <br>  <span class="hljs-comment"># allot the ratio of each contig</span><br>  x_frac <span class="hljs-operator">&lt;-</span> x<span class="hljs-operator">$</span>qLength <span class="hljs-operator">/</span> <span class="hljs-built_in">sum</span><span class="hljs-punctuation">(</span>x<span class="hljs-operator">$</span>qLength<span class="hljs-punctuation">)</span><br>  y_frac <span class="hljs-operator">&lt;-</span> y<span class="hljs-operator">$</span>tLength <span class="hljs-operator">/</span> <span class="hljs-built_in">sum</span><span class="hljs-punctuation">(</span>y<span class="hljs-operator">$</span>tLength<span class="hljs-punctuation">)</span><br>  <br>  <span class="hljs-comment"># draw the contig name</span><br>  grid<span class="hljs-operator">::</span>pushViewport<span class="hljs-punctuation">(</span>grid<span class="hljs-operator">::</span>viewport<span class="hljs-punctuation">(</span>height <span class="hljs-operator">=</span> <span class="hljs-number">0.7</span><span class="hljs-punctuation">,</span><br>                        width <span class="hljs-operator">=</span>  <span class="hljs-number">0.7</span><span class="hljs-punctuation">,</span><br>                        gp <span class="hljs-operator">=</span> grid<span class="hljs-operator">::</span>gpar<span class="hljs-punctuation">(</span>cex <span class="hljs-operator">=</span> <span class="hljs-number">0.75</span><span class="hljs-punctuation">)</span><span class="hljs-punctuation">,</span><br>                        name <span class="hljs-operator">=</span> <span class="hljs-string">&quot;contigName&quot;</span><span class="hljs-punctuation">)</span><span class="hljs-punctuation">)</span><br>  x_pos <span class="hljs-operator">&lt;-</span> <span class="hljs-built_in">c</span><span class="hljs-punctuation">(</span><span class="hljs-number">0</span><span class="hljs-punctuation">,</span> <span class="hljs-built_in">cumsum</span><span class="hljs-punctuation">(</span>x_frac<span class="hljs-punctuation">)</span><span class="hljs-punctuation">[</span><span class="hljs-number">1</span><span class="hljs-operator">:</span><span class="hljs-punctuation">(</span>contigs<span class="hljs-operator">-</span><span class="hljs-number">1</span><span class="hljs-punctuation">)</span><span class="hljs-punctuation">]</span><span class="hljs-punctuation">)</span><br>  y_pos <span class="hljs-operator">&lt;-</span> 1<span class="hljs-operator">-</span> <span class="hljs-built_in">c</span><span class="hljs-punctuation">(</span><span class="hljs-number">0</span><span class="hljs-punctuation">,</span> <span class="hljs-built_in">cumsum</span><span class="hljs-punctuation">(</span>y_frac<span class="hljs-punctuation">)</span><span class="hljs-punctuation">[</span><span class="hljs-number">1</span><span class="hljs-operator">:</span><span class="hljs-punctuation">(</span>contigs<span class="hljs-operator">-</span><span class="hljs-number">1</span><span class="hljs-punctuation">)</span><span class="hljs-punctuation">]</span><span class="hljs-punctuation">)</span><br>  <span class="hljs-keyword">for</span> <span class="hljs-punctuation">(</span>i <span class="hljs-keyword">in</span> <span class="hljs-built_in">seq.int</span><span class="hljs-punctuation">(</span><span class="hljs-number">1</span><span class="hljs-punctuation">,</span>contigs<span class="hljs-punctuation">)</span><span class="hljs-punctuation">)</span><span class="hljs-punctuation">&#123;</span><br>    grid<span class="hljs-operator">::</span>grid.text<span class="hljs-punctuation">(</span>label <span class="hljs-operator">=</span> x<span class="hljs-punctuation">[</span>i<span class="hljs-punctuation">,</span><span class="hljs-number">1</span><span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span> <br>              x <span class="hljs-operator">=</span> grid<span class="hljs-operator">::</span>unit<span class="hljs-punctuation">(</span>x_pos<span class="hljs-punctuation">[</span>i<span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;npc&quot;</span><span class="hljs-punctuation">)</span><span class="hljs-punctuation">,</span><br>              y <span class="hljs-operator">=</span> grid<span class="hljs-operator">::</span>unit<span class="hljs-punctuation">(</span><span class="hljs-number">1</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;npc&quot;</span><span class="hljs-punctuation">)</span><span class="hljs-punctuation">,</span><br>              just <span class="hljs-operator">=</span> <span class="hljs-built_in">c</span><span class="hljs-punctuation">(</span><span class="hljs-string">&quot;left&quot;</span><span class="hljs-punctuation">,</span><span class="hljs-string">&quot;bottom&quot;</span><span class="hljs-punctuation">)</span><span class="hljs-punctuation">,</span><br>              rot <span class="hljs-operator">=</span> <span class="hljs-number">35</span><br>              <span class="hljs-punctuation">)</span><br>    grid<span class="hljs-operator">::</span>grid.text<span class="hljs-punctuation">(</span>label <span class="hljs-operator">=</span> y<span class="hljs-punctuation">[</span>i<span class="hljs-punctuation">,</span> <span class="hljs-number">1</span><span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span><br>              x <span class="hljs-operator">=</span> grid<span class="hljs-operator">::</span>unit<span class="hljs-punctuation">(</span><span class="hljs-number">1</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;npc&quot;</span><span class="hljs-punctuation">)</span><span class="hljs-punctuation">,</span><br>              y <span class="hljs-operator">=</span> grid<span class="hljs-operator">::</span>unit<span class="hljs-punctuation">(</span>y_pos<span class="hljs-punctuation">[</span>i<span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;npc&quot;</span><span class="hljs-punctuation">)</span><span class="hljs-punctuation">,</span><br>              just <span class="hljs-operator">=</span> <span class="hljs-built_in">c</span><span class="hljs-punctuation">(</span><span class="hljs-string">&quot;left&quot;</span><span class="hljs-punctuation">)</span><br>              <span class="hljs-punctuation">)</span><br>    <br>  <span class="hljs-punctuation">&#125;</span><br>  <br>  vplay <span class="hljs-operator">&lt;-</span> grid<span class="hljs-operator">::</span>grid.layout<span class="hljs-punctuation">(</span>contigs<span class="hljs-punctuation">,</span> contigs<span class="hljs-punctuation">,</span> <br>                       widths  <span class="hljs-operator">=</span> x_frac<span class="hljs-punctuation">,</span><br>                       heights <span class="hljs-operator">=</span> y_frac<span class="hljs-punctuation">)</span><br>  grid<span class="hljs-operator">::</span>pushViewport<span class="hljs-punctuation">(</span>grid<span class="hljs-operator">::</span>viewport<span class="hljs-punctuation">(</span>layout <span class="hljs-operator">=</span> vplay<span class="hljs-punctuation">,</span><br>                        name <span class="hljs-operator">=</span> <span class="hljs-string">&quot;vplay&quot;</span><span class="hljs-punctuation">)</span><span class="hljs-punctuation">)</span><br>  <br>  <br>  <span class="hljs-comment"># line represent the synteny</span><br>  <span class="hljs-keyword">for</span> <span class="hljs-punctuation">(</span> i <span class="hljs-keyword">in</span> seq<span class="hljs-punctuation">(</span><span class="hljs-number">1</span><span class="hljs-punctuation">,</span> contigs<span class="hljs-punctuation">)</span><span class="hljs-punctuation">)</span><span class="hljs-punctuation">&#123;</span><br>    <span class="hljs-keyword">for</span> <span class="hljs-punctuation">(</span>j <span class="hljs-keyword">in</span> seq<span class="hljs-punctuation">(</span><span class="hljs-number">1</span><span class="hljs-punctuation">,</span> contigs<span class="hljs-punctuation">)</span><span class="hljs-punctuation">)</span><span class="hljs-punctuation">&#123;</span><br>      <br>      <span class="hljs-comment"># get the name and length for subsetting</span><br>      xName   <span class="hljs-operator">&lt;-</span> x<span class="hljs-punctuation">[</span>i<span class="hljs-punctuation">,</span><span class="hljs-number">1</span><span class="hljs-punctuation">]</span><br>      xLength <span class="hljs-operator">&lt;-</span> x<span class="hljs-punctuation">[</span>i<span class="hljs-punctuation">,</span><span class="hljs-number">2</span><span class="hljs-punctuation">]</span><br>      yName   <span class="hljs-operator">&lt;-</span> y<span class="hljs-punctuation">[</span>j<span class="hljs-punctuation">,</span><span class="hljs-number">1</span><span class="hljs-punctuation">]</span> <br>      yLength <span class="hljs-operator">&lt;-</span> y<span class="hljs-punctuation">[</span>j<span class="hljs-punctuation">,</span><span class="hljs-number">2</span><span class="hljs-punctuation">]</span><br>      <br>      <span class="hljs-comment"># push view port for plot Collinearity</span><br>      grid<span class="hljs-operator">::</span>pushViewport<span class="hljs-punctuation">(</span>grid<span class="hljs-operator">::</span>viewport<span class="hljs-punctuation">(</span>layout.pos.col <span class="hljs-operator">=</span> i<span class="hljs-punctuation">,</span><br>                            layout.pos.row <span class="hljs-operator">=</span> j<span class="hljs-punctuation">,</span><br>                            xscale <span class="hljs-operator">=</span> <span class="hljs-built_in">c</span><span class="hljs-punctuation">(</span><span class="hljs-number">1</span><span class="hljs-punctuation">,</span> xLength<span class="hljs-punctuation">)</span><span class="hljs-punctuation">,</span><br>                            yscale <span class="hljs-operator">=</span> <span class="hljs-built_in">c</span><span class="hljs-punctuation">(</span><span class="hljs-number">1</span><span class="hljs-punctuation">,</span> yLength<span class="hljs-punctuation">)</span><span class="hljs-punctuation">,</span><br>                            name <span class="hljs-operator">=</span> paste0<span class="hljs-punctuation">(</span><span class="hljs-string">&quot;pos&quot;</span><span class="hljs-punctuation">,</span>i<span class="hljs-punctuation">,</span>j<span class="hljs-punctuation">)</span><span class="hljs-punctuation">)</span><span class="hljs-punctuation">)</span><br>  <br>      grid<span class="hljs-operator">::</span>grid.rect<span class="hljs-punctuation">(</span>gp<span class="hljs-operator">=</span>grid<span class="hljs-operator">::</span>gpar<span class="hljs-punctuation">(</span>col<span class="hljs-operator">=</span>borderCol<span class="hljs-punctuation">)</span><span class="hljs-punctuation">)</span><br>      <span class="hljs-comment"># select the data</span><br>      plot_df <span class="hljs-operator">&lt;-</span> df<span class="hljs-punctuation">[</span>df<span class="hljs-operator">$</span>qName <span class="hljs-operator">==</span> xName <span class="hljs-operator">&amp;</span> df<span class="hljs-operator">$</span>tName <span class="hljs-operator">==</span> yName<span class="hljs-punctuation">,</span><span class="hljs-punctuation">]</span> <br>      blocks <span class="hljs-operator">&lt;-</span> nrow<span class="hljs-punctuation">(</span>plot_df<span class="hljs-punctuation">)</span><br>      <span class="hljs-comment">#cat(sprintf(&quot;block size is %d\n&quot;, blocks))</span><br>      <br>      <span class="hljs-keyword">if</span> <span class="hljs-punctuation">(</span>blocks <span class="hljs-operator">==</span> <span class="hljs-number">0</span><span class="hljs-punctuation">)</span> <span class="hljs-punctuation">&#123;</span><br>        grid<span class="hljs-operator">::</span>upViewport<span class="hljs-punctuation">(</span><span class="hljs-punctuation">)</span> <br>        <span class="hljs-keyword">next</span><br>      <span class="hljs-punctuation">&#125;</span><br>      <br>      <span class="hljs-comment"># plot the line</span><br>      <span class="hljs-keyword">for</span> <span class="hljs-punctuation">(</span>k <span class="hljs-keyword">in</span> seq<span class="hljs-punctuation">(</span><span class="hljs-number">1</span><span class="hljs-punctuation">,</span> blocks<span class="hljs-punctuation">)</span><span class="hljs-punctuation">)</span><span class="hljs-punctuation">&#123;</span><br>        <span class="hljs-keyword">if</span> <span class="hljs-punctuation">(</span>plot_df<span class="hljs-operator">$</span>strand<span class="hljs-punctuation">[</span>k<span class="hljs-punctuation">]</span> <span class="hljs-operator">==</span> <span class="hljs-string">&quot;+&quot;</span><span class="hljs-punctuation">)</span><span class="hljs-punctuation">&#123;</span><br>          grid<span class="hljs-operator">::</span>grid.lines<span class="hljs-punctuation">(</span>x <span class="hljs-operator">=</span> <span class="hljs-built_in">c</span><span class="hljs-punctuation">(</span>plot_df<span class="hljs-operator">$</span>qStart<span class="hljs-punctuation">[</span>k<span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span> plot_df<span class="hljs-operator">$</span>qEnd<span class="hljs-punctuation">[</span>k<span class="hljs-punctuation">]</span><span class="hljs-punctuation">)</span><span class="hljs-punctuation">,</span><br>                     y <span class="hljs-operator">=</span> <span class="hljs-built_in">c</span><span class="hljs-punctuation">(</span>plot_df<span class="hljs-operator">$</span>tStart<span class="hljs-punctuation">[</span>k<span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span> plot_df<span class="hljs-operator">$</span>tEnd<span class="hljs-punctuation">[</span>k<span class="hljs-punctuation">]</span><span class="hljs-punctuation">)</span><span class="hljs-punctuation">,</span><br>                     gp<span class="hljs-operator">=</span>grid<span class="hljs-operator">::</span>gpar<span class="hljs-punctuation">(</span>lwd <span class="hljs-operator">=</span> lineSize<span class="hljs-punctuation">)</span><span class="hljs-punctuation">,</span><br>                     default.units <span class="hljs-operator">=</span> <span class="hljs-string">&quot;native&quot;</span><span class="hljs-punctuation">)</span><br>        <span class="hljs-punctuation">&#125;</span> <span class="hljs-keyword">else</span> <span class="hljs-punctuation">&#123;</span><br>          grid<span class="hljs-operator">::</span>grid.lines<span class="hljs-punctuation">(</span>x <span class="hljs-operator">=</span> <span class="hljs-built_in">c</span><span class="hljs-punctuation">(</span>plot_df<span class="hljs-operator">$</span>qStart<span class="hljs-punctuation">[</span>k<span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span> plot_df<span class="hljs-operator">$</span>qEnd<span class="hljs-punctuation">[</span>k<span class="hljs-punctuation">]</span><span class="hljs-punctuation">)</span><span class="hljs-punctuation">,</span><br>                     y <span class="hljs-operator">=</span> <span class="hljs-built_in">c</span><span class="hljs-punctuation">(</span>plot_df<span class="hljs-operator">$</span>tEnd<span class="hljs-punctuation">[</span>k<span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span> plot_df<span class="hljs-operator">$</span>tStart<span class="hljs-punctuation">[</span>k<span class="hljs-punctuation">]</span><span class="hljs-punctuation">)</span><span class="hljs-punctuation">,</span><br>                     gp<span class="hljs-operator">=</span>grid<span class="hljs-operator">::</span>gpar<span class="hljs-punctuation">(</span>lwd <span class="hljs-operator">=</span> lineSize<span class="hljs-punctuation">)</span><span class="hljs-punctuation">,</span><br>                     default.units <span class="hljs-operator">=</span> <span class="hljs-string">&quot;native&quot;</span><span class="hljs-punctuation">)</span><br>        <span class="hljs-punctuation">&#125;</span><br><br>      <span class="hljs-punctuation">&#125;</span><br>      <br>      grid<span class="hljs-operator">::</span>upViewport<span class="hljs-punctuation">(</span><span class="hljs-punctuation">)</span> <br>    <span class="hljs-punctuation">&#125;</span><br>  <span class="hljs-punctuation">&#125;</span><br><span class="hljs-punctuation">&#125;</span><br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>Software</category>
      
    </categories>
    
    
    <tags>
      
      <tag>denovo-III</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>HiFi-7-[HiFi+HiC-assembly-method]</title>
    <link href="/GeekFocus/2022/03/16/2022-03-16-HiFi-7-HiC-assembly2/"/>
    <url>/GeekFocus/2022/03/16/2022-03-16-HiFi-7-HiC-assembly2/</url>
    
    <content type="html"><![CDATA[<p>辅助组装案例2</p><span id="more"></span><p>search：HiFi Hi-C  <a href="https://pubmed.ncbi.nlm.nih.gov/?term=HiFi%20Hi-C&amp;page=2">https://pubmed.ncbi.nlm.nih.gov/?term=HiFi%20Hi-C&amp;page=2</a></p><h1 id="1-2021-09-亚麻纤维"><a href="#1-2021-09-亚麻纤维" class="headerlink" title="1. 2021.09 亚麻纤维"></a>1. 2021.09 亚麻纤维</h1><p><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8473814/#">Front Genet.</a> 2021; 12: 735690.  cite1</p><p>Published online 2021 Sep 13. doi: <a href="https://dx.doi.org/10.3389%2Ffgene.2021.735690">10.3389&#x2F;fgene.2021.735690</a></p><blockquote><p>Chromosome-Level Genome Assembly and Annotation of the Fiber Flax (<em>Linum usitatissimum</em>) Genome</p></blockquote><p><strong>Genome Assembly</strong></p><p>The HiFi long reads were assembled by <strong>Hifiasm</strong> v0.13-r308 with the <strong>default parameters</strong>. Then the <strong>HiFi reads were mapped back to the assembly</strong> to generate a <strong>coverage distribution plot</strong> using <strong>minimap2</strong> 2.17-r941. According to the <strong>covering depth</strong>, <strong>purge_dups</strong> v1.2.5 (Guan et al., <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8473814/#B22">2020</a>) was applied to <strong>remove redundant haplotigs</strong>. The <strong>Juicer v1.6</strong> (Durand et al., <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8473814/#B15">2016</a>) and <strong>3D-DNA</strong> v180922 (Dudchenko et al., <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8473814/#B13">2017</a>) pipelines were used to process the <strong>Hi-C data and scaffold the assembly</strong>. The results were polished using the <strong>Juicebox Assembly Tools</strong> v1.11.08 (Dudchenko et al., <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8473814/#B14">2018</a>). The CDC Bethune v2 assembly has made most use of the long continuity of optical maps. To further improve the accuracy of order and orient in our assembly, we integrated information from the <strong>Hi-C scaffolding</strong> and the CDC Bethune v2 assembly using the ALLMAPS pipeline (Tang et al., <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8473814/#B55">2015b</a>) implemented in jcvi utility libraries (Tang et al., <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8473814/#B54">2015a</a>).</p><h1 id="2-2021-06-玫瑰🌹"><a href="#2-2021-06-玫瑰🌹" class="headerlink" title="2. 2021.06 玫瑰🌹"></a>2. 2021.06 玫瑰🌹</h1><p><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8213826/#">Hortic Res.</a> 2021; 8: 141.  cite4</p><p>Published online 2021 Jun 18. doi: <a href="https://dx.doi.org/10.1038%2Fs41438-021-00594-z">10.1038&#x2F;s41438-021-00594-z</a></p><blockquote><p>A chromosome-level genome assembly of rugged rose (<em>Rosa rugosa</em>) provides insights into its evolution, ecology, and floral characteristics</p></blockquote><p><strong>Genome assembly and quality evaluation</strong></p><p>Approximately 59.2 Gb of raw HiFi sequencing reads was obtained from the rosa DNA library. We first used <strong>HiCanu</strong> v2.2.1 for preliminary assembly of the rosa genome. Then, <strong>Redundans</strong> v 0.14a<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8213826/#CR27">27</a> was performed to <strong>remove the redundant sequences</strong>. A total of 150.6 Gb of <strong>Hi-C data</strong> were obtained to <strong>anchor</strong> the contig onto the chromosome. We <strong>aligned Hi-C</strong> reads to assembly by <strong>BWA</strong> v 0.7.17-r1188<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8213826/#CR28">28</a>. Next, the <strong>draft assembly genome</strong> was <strong>scaffolded with Hi-C reads by 3D-DNA</strong> v180114<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8213826/#CR29">29</a>. Then, <strong>Juicer</strong> was used to <strong>filter the sequence and cluster it</strong>, and the <strong>Juicerbox tool</strong><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8213826/#CR30">30</a> was applied to <strong>manually adjust chromosome construction</strong>. We finally <strong>anchored the scaffolds on seven chromosomes</strong>. In addition, the <strong>BUSCO</strong> v3.0.2pipeline was used to assess the completeness and accuracy of the <em>R. rugosa</em> genome with the embryophyte_odb10 dataset, which contains 1614 BUSCO gene sets.</p><h1 id="3-2022-02-香菇"><a href="#3-2022-02-香菇" class="headerlink" title="3. 2022.02 香菇"></a>3. 2022.02 香菇</h1><p><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8877449/#">J Fungi (Basel).</a> 2022 Feb; 8(2): 167. </p><p>Published online 2022 Feb 9. doi: <a href="https://dx.doi.org/10.3390%2Fjof8020167">10.3390&#x2F;jof8020167</a></p><blockquote><p>Haplotype-Resolved Genome Analyses Reveal Genetically Distinct Nuclei within a Commercial Cultivar of <em>Lentinula edodes</em></p></blockquote><p><strong>Genome Sequencing and Assembly</strong></p><p>SMRTbell libraries were sequenced on a PacBio Sequel II system, and consensus reads (HiFi reads) were generated using ccs software (<a href="https://github.com/pacificbiosci-ences/unanimity">https://github.com/pacificbiosci-ences/unanimity</a>, accessed on 22 December 2021) with the parameter “–inPasses 3”. We generated 8.65 Gb and 5.35 Gb PacBio HiFi reads of SP3 and SP30, respectively. These long (~15 kb) and highly accurate (&gt;99%) HiFi reads were assembled using <strong>HiCanu</strong> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8877449/#B18-jof-08-00167">18</a>] for both strains with <strong>default parameters</strong>.</p><p>The vegetative mycelia of SP3 and SP30 were also used to generate Hi-C DNA libraries at the Frasergen Enterprise (Wuhan, China). The Hi-C libraries were quantified and sequenced on the Illumina Nova-seq platform (San Diego, CA, USA). The chimeric fragments from the original cross-linked long-distance physical interactions were then isolated and processed into libraries. For anchored contigs, 34,909,404 and 31,267,524 clean <strong>reads</strong> were generated from the Hi-C library and were <strong>mapped</strong> to the SP3 and SP30 <strong>preliminary assembly</strong> using <strong>Juicer</strong> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8877449/#B20-jof-08-00167">20</a>] with default parameters. Paired reads mapped to different contigs were used for the Hi-C associated scaffolding. Self-ligated, non-ligated, and other invalid reads were filtered out. We applied <strong>3D-DNA</strong> to <strong>order</strong> and <strong>orient</strong> the clustered contigs. Then, <strong>Juicer</strong> was used to filter the sequences and cluster them, and the <strong>Juicebox</strong> was applied to <strong>adjust chromosome construction manually</strong> (<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8877449/#app1-jof-08-00167">Figure S2</a>). We finally <strong>anchored the scaffolds on ten chromosomes</strong>. In addition, the BUSCO v3.0.231 pipeline was used to assess the completeness and accuracy of the SP3 and SP30 genomes.</p><p><img src="/GeekFocus/./1.png" alt="截屏2022-03-16上午10.03.37"></p><h1 id="4-2021-04-benchmark"><a href="#4-2021-04-benchmark" class="headerlink" title="4 2021.04 benchmark"></a>4 2021.04 benchmark</h1><p><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7893683/#">Mol Med Rep.</a> 2021 Apr; 23(4): 251. </p><p>Published online 2021 Feb 2. doi: <a href="https://dx.doi.org/10.3892%2Fmmr.2021.11890">10.3892&#x2F;mmr.2021.11890</a></p><blockquote><p>Benchmarking of next and third generation sequencing technologies and their associated algorithms for <em>de novo</em> genome assembly</p></blockquote><p><strong>Genome assembly</strong> </p><p>In order to assess the hybrid assembly strategy, the present study chose to evaluate two pipelines, MaSuRCA (version 3.3.5) (<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7893683/#b27-mmr-0-0-11890">27</a>,<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7893683/#b28-mmr-0-0-11890">28</a>) and Wengan (version 0.1) (<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7893683/#b29-mmr-0-0-11890">29</a>). MaSuRCA workflow offers three different assemblers, CABOG (<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7893683/#b30-mmr-0-0-11890">30</a>), SOAPdenovo (<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7893683/#b31-mmr-0-0-11890">31</a>) and Flye (<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7893683/#b32-mmr-0-0-11890">32</a>). The pipeline was tested using CABOG and Flye assemblers, which are designed for long-read assembly. Wengan pipeline is based on DiscovarDenovo assembler (<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7893683/#b33-mmr-0-0-11890">33</a>).</p><p>Canu (version 2.0) (<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7893683/#b34-mmr-0-0-11890">34</a>) is a long-read assembler, designed to use long high-noise single-molecule sequencing data, such as Nanopore and PacBio reads. Its workflow is based on the Celera assembler (<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7893683/#b35-mmr-0-0-11890">35</a>) which was used in the Human Genome Project to produce the first draft of the human genome. <strong>Hifiasm</strong> (version 0.13) (<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7893683/#b36-mmr-0-0-11890">36</a>) and <strong>HiCanu</strong> (Canu version 2.1.1) (<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7893683/#b37-mmr-0-0-11890">37</a>) are long-read assemblers exclusively <strong>for HiFi reads.</strong> The <strong>main difference</strong> between HiFi assemblers and the ones mentioned previously, is that <strong>Hifiasm and HiCanu produce phased assemblies</strong>. A phased assembly is a <strong>haplotype-resolved assembly</strong>, where <strong>high complexity regions</strong>, such as <strong>genes</strong>, will be <strong>separated into two different alleles</strong> (<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7893683/#b36-mmr-0-0-11890">36</a>,<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7893683/#b38-mmr-0-0-11890">38</a>). HiCanu is a modified version of Canu, adapted to take advantage of the characteristics of HiFi reads. <strong>Hifiasm</strong> produces <strong>two different files</strong> for the <strong>primary</strong> and <strong>alternative</strong> assembly, whereas <strong>HiCanu</strong> <strong>combines</strong> the <strong>primary and the alternative</strong> assembly in the <strong>same FASTA file</strong>.</p><p><strong>Scaffolding</strong> </p><p>In order to test the necessity of scaffolding, a scaffolder was used to improve the assembly <strong>continuity</strong> and <strong>completeness</strong>, as follows: <strong>Hi-C data are mapped</strong> to the <strong>primary assembly</strong> by <strong>Arima</strong> mapping pipeline (<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7893683/#b39-mmr-0-0-11890">39</a>), to produce a BAM file which is consequently converted to a BED file. <strong>SALSA</strong> (version 2.2) (<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7893683/#b40-mmr-0-0-11890">40</a>) uses this BED file which contains the mapping information of Hi-C reads on the assembly, <strong>to scaffold</strong> the primary assembly.</p><p><strong>Quality control metrics</strong></p><p>QUAST (version 5.0.2)</p><p><strong>Genome consistency plots</strong></p><p>JupiterPlot (version 1.0) </p><h1 id="5-2022-02-PJ-番茄🍅"><a href="#5-2022-02-PJ-番茄🍅" class="headerlink" title="5. 2022.02-PJ 番茄🍅"></a>5. 2022.02-PJ 番茄🍅</h1><blockquote><p>A chromosome scale tomato genome built from complementary PacBio and Nanopore sequences alone reveals extensive linkage drag during breeding</p></blockquote><p><a href="https://pubmed.ncbi.nlm.nih.gov/35106855/">https://pubmed.ncbi.nlm.nih.gov/35106855/</a></p><p>PacBio HiFi reads were independently assembled using Hifiasm and Canu, with respective N50 values of 31.3 and 17 Mbp (Table <a href="https://onlinelibrary.wiley.com/doi/10.1111/tpj.15690#tpj15690-tbl-0002">2</a>). Both HiFi assemblies <strong>contained single contigs that spanned the full length of the SL4.0 reference chromosome 5</strong> (Figure <a href="https://onlinelibrary.wiley.com/doi/10.1111/tpj.15690#support-information-section">S1</a>). We checked for the completeness of the assembly of gene sequences by Benchmarking Universal Single Copy Orthologs (BUSCO) analysis which showed both assemblies were almost gene complete (both 98.4%), slightly improving upon the SL4.0 genome and comparable to the <em>S. pimpinellifolium</em> ‘LA2093’ genome.</p><p><strong>Hifiasm</strong> v0.14.2 (Cheng et al., <a href="https://onlinelibrary.wiley.com/doi/10.1111/tpj.15690#tpj15690-bib-0013">2021</a>) was used to assemble the HiFi reads with default settings. Canu v2.1.1 was used to assemble the HiFi reads in ‘HiCanu’ mode (Nurk et al., <a href="https://onlinelibrary.wiley.com/doi/10.1111/tpj.15690#tpj15690-bib-0050">2020</a>) with an estimated genome size of 916 Mbp based on kmer counting of the raw HiFi data using Jellyfish v2.2.6 (Marçais &amp; Kingsford, <a href="https://onlinelibrary.wiley.com/doi/10.1111/tpj.15690#tpj15690-bib-0044">2011</a>).</p><p><strong>Quast</strong> v5.0.2 (Mikheenko et al., <a href="https://onlinelibrary.wiley.com/doi/10.1111/tpj.15690#tpj15690-bib-0047">2018</a>) and GAAS v1.1.0 (<a href="https://github.com/NBISweden/GAAS">https://github.com/NBISweden/GAAS</a>) were used to <strong>calculate statistics on fasta files</strong>. BUSCO was calculated using BUSCO v5.2.1 (Seppey et al., <a href="https://onlinelibrary.wiley.com/doi/10.1111/tpj.15690#tpj15690-bib-0068">2019</a>) depending on hmmsearch v3.1, and metaeuk v4.a0f584d was used with lineage datasets solanales (<a href="https://busco-data.ezlab.org/v5/data/lineages/solanales_odb10.2020-08-05.tar.gz">https://busco-data.ezlab.org/v5/data/lineages/solanales_odb10.2020-08-05.tar.gz</a>) and eudicots (<a href="https://busco-data.ezlab.org/v5/data/lineages/eudicots_odb10.2020-09-10.tar.gz">https://busco-data.ezlab.org/v5/data/lineages/eudicots_odb10.2020-09-10.tar.gz</a>) to obtain evolutionarily informed expectations of gene content. To assess the LAI, LTR retriever v2.9.0 (Ou et al., <a href="https://onlinelibrary.wiley.com/doi/10.1111/tpj.15690#tpj15690-bib-0051">2018</a>) was run with default settings on the respective genome assemblies.</p><p>We ran one single round of <strong>Salsa</strong> v2.2 (Ghurye et al., <a href="https://onlinelibrary.wiley.com/doi/10.1111/tpj.15690#tpj15690-bib-0026">2019</a>) with optional settings: <strong>-e DNASE -m yes -p yes</strong>.</p><p>A modified version of the <strong>convert.sh</strong> script was used to convert the Salsa2 output to a Hi-C file, which was used within a local installation of <strong>Juicebox</strong> (<a href="https://github.com/aidenlab/Juicebox">https://github.com/aidenlab/Juicebox</a>) v1.11.08 to generate a <strong>Hi-C contact plot.</strong></p><p>The MbTMV genome assembly was aligned to SL4.0 (Hosmani et al., <a href="https://onlinelibrary.wiley.com/doi/10.1111/tpj.15690#tpj15690-bib-0030">2019</a>) using <strong>Minimap2</strong> v2.17 (Li, <a href="https://onlinelibrary.wiley.com/doi/10.1111/tpj.15690#tpj15690-bib-0039">2018</a>) with default settings, followed by running RaGOO v1.11 (Alonge et al., <a href="https://onlinelibrary.wiley.com/doi/10.1111/tpj.15690#tpj15690-bib-0003">2019</a>) with default options.</p><h1 id="6-2021-09-gpb-拟南芥"><a href="#6-2021-09-gpb-拟南芥" class="headerlink" title="6. 2021.09-gpb 拟南芥"></a>6. 2021.09-gpb 拟南芥</h1><blockquote><p>High-quality Arabidopsis thaliana Genome Assembly with Nanopore and HiFi Long Reads</p></blockquote><p><a href="https://pubmed.ncbi.nlm.nih.gov/34487862/">https://pubmed.ncbi.nlm.nih.gov/34487862/</a></p><p><strong>HiFi sequencing and assembly</strong></p><p>Sequencing was performed on a PacBio Sequel II instrument with Sequencing Primer V2 and Sequel II Binding Kit 2.0 at the Genome Center of Grandomics. A total of 22.90 Gb of HiFi reads with ∼157 × coverage were generated, and N50 of the reads was 15,424 bp. HiFi reads were assembled using <strong>hifiasm</strong> v. 0.14-r312 [<a href="https://www.sciencedirect.com/science/article/pii/S1672022921001741?via=ihub#b0085">17]</a>with <strong>default parameters</strong>, and the <strong>gfatools</strong> (<a href="https://github.com/lh3/gfatools">https://github.com/lh3/gfatools</a>) was used to convert sequence graphs in the <strong>GFA to FASTA</strong> format.</p><p><strong>Hi-C sequencing and scaffolding</strong></p><p>Hi-C library was prepared from cross-linked chromatins of plant cells using a standard Hi-C protocol; the library was then sequenced using Illumina NovaSeq 6000. A total of 21.14 Gb of Hi-C reads with ∼158 × coverage were generated. The Hi-C sequencing data were used to <strong>anchor</strong> all contigs using <strong>Juicer</strong> v. 1.5 [<a href="https://www.sciencedirect.com/science/article/pii/S1672022921001741?via=ihub#b0220">44]</a>, <strong>followed by a 3D-DNA scaffolding pipeline</strong> [<a href="https://www.sciencedirect.com/science/article/pii/S1672022921001741?via=ihub#b0225">45]</a>. Scaffolds were then <strong>manually checked and refined</strong> with <strong>Juicebox</strong> v. 1.11.08 [<a href="https://www.sciencedirect.com/science/article/pii/S1672022921001741?via=ihub#b0230">46]</a>.</p><h1 id="7-2021-11-J-Hered-茱萸"><a href="#7-2021-11-J-Hered-茱萸" class="headerlink" title="7. 2021.11-J Hered 茱萸"></a>7. 2021.11-J Hered 茱萸</h1><p><strong>Nuclear Genome Assembly</strong></p><p>We assembled the genome of the big berry manzanita following a <strong>protocol</strong> adapted from <strong>Rhie et al</strong>. (2021) as part of the CCGP assembly efforts. The CCGP assembly protocol version 1.0 uses PacBio <strong>HiFi</strong> reads and <strong>Hi-C</strong> chromatin capture data for the generation of high-quality and highly contiguous nuclear genome assemblies. The output corresponding to a diploid assembly consists of <strong>two pseudo haplotypes</strong> (<strong>primary</strong> and <strong>alternate</strong>). The <strong>primary</strong> assembly is <strong>more complete</strong> and consists of <strong>longer phased blocks</strong>. The <strong>alternate</strong> consists of <strong>haplotigs</strong> (contigs of clones with the same haplotype) in <strong>heterozygous regions</strong> and is not as complete and more fragmented. Given the characteristics of the latter, it <strong>cannot be considered on its own</strong> but as <strong>a complement of the primary assembly</strong> (<a href="https://lh3.github.io/2021/04/17/concepts-in-phased-assemblies">https://lh3.github.io/2021/04/17/concepts-in-phased-assemblies</a>, <a href="https://www.ncbi.nlm.nih.gov/grc/help/definitions/">https://www.ncbi.nlm.nih.gov/grc/help/definitions/</a>).</p><p>To generate this assembly, we <strong>removed remnant adapter</strong> sequences from the PacBio HiFi dataset using <strong>HiFiAdapterFilt</strong> and assembled the initial set of contigs with the filtered PacBio reads using <strong>HiFiasm</strong> (see Table 1 for assembly pipeline and relevant software). Next, we <strong>identified sequences corresponding to haplotypic duplications and contig overlaps</strong> on the <strong>primary assembly</strong> with <strong>purge_dups</strong> [Version 1.0.1] (Guan et al. 2020) and transferred them to the alternate assembly. We a<strong>ligned the Hi-C data</strong> to both <strong>primary and alternate assemblies</strong> using the <strong>Arima Genomics Mapping Pipeline</strong> (<a href="https://github.com/ArimaGenomics/mapping_pipeline">https://github.com/ArimaGenomics/mapping_pipeline</a>) and <strong>scaffolded</strong> the genomes using <strong>SALSA</strong> [Version 2, options –e GATCGATC] (Ghurye et al. 2017; Ghurye et al. 2019). We <strong>closed the generated gaps</strong> in both <strong>assemblies</strong> using the PacBio <strong>HiFi</strong> reads and <strong>YAGCloser</strong> (<a href="https://github.com/merlyescalona/yagcloser">https://github.com/merlyescalona/yagcloser</a>). The <strong>primary assembly</strong> was <strong>manually curated</strong> by <strong>iteratively generating and analyzing</strong> Hi-C <strong>contact maps</strong>. To generate the contact maps, we <strong>aligned</strong> the <strong>Hi-C</strong> data against the corresponding reference with <strong>bwa</strong> mem, identified ligation junctions, and generated <strong>Hi-C pairs</strong> using <strong>pairtools</strong> [Version 0.3.0] (Goloborodko et al. 2018). We generated a multi-resolution <strong>Hi-C matrix</strong> in binary form with <strong>cooler</strong> [Version 0.8.10] (Abdennur and Mirny 2020) and balanced it with <strong>hicExplorer</strong> [Version 3.6] (Ramírez et al. 2018). We used <strong>HiGlass</strong> [Version 2.1.11] (Kerpedjiev et al. 2018) and the <strong>PretextSuite</strong> (<a href="https://github.com/wtsi-hpag/PretextView">https://github.com/wtsi-hpag/PretextView</a>; <a href="https://github.com/wtsihpag/PretextMap">https://github.com/wtsihpag/PretextMap</a>; <a href="https://github.com/wtsi-hpag/PretextSnapshot">https://github.com/wtsi-hpag/PretextSnapshot</a>) to <strong>visualize the contact maps</strong>. Assemblies were then checked for contamination using the <strong>BlobToolKit Framework</strong> [Version 2.3.3] (Challis et al. 2020), and <strong>trimmed</strong> for remnants of sequence adaptors and <strong>mitochondrial</strong> contamination.</p><p>Table1 Assembly pipeline and software usage. Software citations are listed in the text</p><table><thead><tr><th>Assembly</th><th align="left">Software</th><th align="left">Version</th></tr></thead><tbody><tr><td>Filtering PacBio HiFi adapters</td><td align="left">HiFiAdapterFilt   <a href="https://github.com/sheinasim/HiFiAdapterFilt">https://github.com/sheinasim/HiFiAdapterFilt</a></td><td align="left">Commit 64d1c7b</td></tr><tr><td>K-mer counting</td><td align="left">Meryl</td><td align="left">1</td></tr><tr><td>Estimation of genome size and heterozygosity</td><td align="left"><font color="green"><strong>GenomeScope</strong> </font></td><td align="left">2</td></tr><tr><td><em>De novo</em> assembly (contiging)</td><td align="left"><font color="green"><strong>HiFiasm</strong> </font></td><td align="left">0.13-r308</td></tr><tr><td>Long read, genome-genome alignment</td><td align="left"><font color="green"><strong>minimap2</strong> </font></td><td align="left">2.16</td></tr><tr><td>Remove low-coverage, duplicated contigs</td><td align="left"><font color="green"><strong>purge_dups</strong></font></td><td align="left">1.0.1</td></tr><tr><td><strong>Scaffolding</strong></td><td align="left"></td><td align="left"></td></tr><tr><td>Hi-C mapping for SALSA</td><td align="left"><font color="green"><strong>Arima</strong></font> Genomics mapping pipeline   <a href="https://github.com/ArimaGenomics/mapping_pipeline">https://github.com/ArimaGenomics/mapping_pipeline</a></td><td align="left">2e74ea4</td></tr><tr><td>Hi-C Scaffolding</td><td align="left"><font color="green"><strong>SALSA</strong> </font></td><td align="left">2</td></tr><tr><td>Gap closing</td><td align="left">YAGCloser?   <a href="https://github.com/merlyescalona/yagcloser">https://github.com/merlyescalona/yagcloser</a></td><td align="left">20e2769</td></tr><tr><td><strong>Hi-C contact map generation</strong></td><td align="left"></td><td align="left"></td></tr><tr><td>Short-read alignment</td><td align="left">bwa</td><td align="left">0.7.17-r1188</td></tr><tr><td>SAM&#x2F;BAM processing</td><td align="left">samtools</td><td align="left">1.11</td></tr><tr><td>SAM&#x2F;BAM filtering</td><td align="left">pairtools</td><td align="left">0.3.0</td></tr><tr><td>Pairs indexing</td><td align="left">pairix</td><td align="left">0.3.7</td></tr><tr><td>Matrix generation</td><td align="left">Cooler</td><td align="left">0.8.10</td></tr><tr><td>Matrix balancing</td><td align="left">hicExplorer</td><td align="left">3.6</td></tr><tr><td>Contact map visualization</td><td align="left">HiGlass</td><td align="left">2.1.11</td></tr><tr><td></td><td align="left">PretextMap</td><td align="left">0.1.4</td></tr><tr><td></td><td align="left">PretextView</td><td align="left">0.1.5</td></tr><tr><td></td><td align="left">PretextSnapshot</td><td align="left">0.0.3</td></tr><tr><td><strong>Organelle assembly</strong></td><td align="left"></td><td align="left"></td></tr><tr><td>Sequence similarity search</td><td align="left"><font color="green">BLAST+ </font></td><td align="left">2.10</td></tr><tr><td>Long read alignment</td><td align="left"><font color="green">Pbmm2</font> (<a href="https://github.com/PacificBiosciences/pbmm2">https://github.com/PacificBiosciences/pbmm2</a>)</td><td align="left">1.4.0</td></tr><tr><td>Variant calling and consensus</td><td align="left">bcftools</td><td align="left">1.11-5</td></tr><tr><td>Extraction of sequences</td><td align="left">seqtk</td><td align="left">1.3-r115</td></tr><tr><td>Circular-aware long-read alignment</td><td align="left"><font color="green">racon </font></td><td align="left">1.4.19</td></tr><tr><td>Sequence polishing</td><td align="left">raptor</td><td align="left">0.20.3</td></tr><tr><td>Sequence alignment</td><td align="left">lastz</td><td align="left">1.04.08</td></tr><tr><td>Gene annotation</td><td align="left">MitoFinder</td><td align="left">1.4</td></tr><tr><td><strong>Genome quality assessment</strong></td><td align="left"></td><td align="left"></td></tr><tr><td>Basic assembly metrics</td><td align="left"><font color="green"><strong>QUAST</strong> </font></td><td align="left">5.0.2</td></tr><tr><td>Assembly completeness</td><td align="left"><font color="green"><strong>BUSCO</strong> </font></td><td align="left">5.0.0</td></tr><tr><td></td><td align="left">Merqury</td><td align="left">1</td></tr><tr><td><strong>Contamination screening</strong></td><td align="left"></td><td align="left"></td></tr><tr><td>General contamination screening</td><td align="left">BlobToolKit</td><td align="left">2.3.3</td></tr></tbody></table><p><strong>Mitochondrial Genome Assembly</strong></p><p>We identified <strong>a subset of mitochondrial reads from the PacBio HiFi</strong> dataset using <strong>BLAST+</strong>  by identifying regions of similarity between the reads and the mitochondrial <strong>(mito) database</strong> (NCBI). These mitochondrial reads were used as input in <strong>HiFiasm</strong> [Version 0.13-r308] to generate the <strong>mitochondrial</strong> <strong>assembly</strong>. Given the circularity of the mitochondrial genome, we carried out self-alignment of the sequence using <strong>lastz</strong> [Version 1.04.08] (Harris 2007) to <strong>manually identify and remove duplicated regions</strong>. We aligned the subset of mitochondrial reads to the assembly using <strong>raptor</strong> [Version 0.20.3-171e0f1] (<a href="https://github.com/isovic/raptor">https://github.com/isovic/raptor</a>) and <strong>polished</strong> it with <strong>racon</strong> [Version 1.14.] (<a href="https://github.com/isovic/racon">https://github.com/isovic/racon</a>). We searched for <strong>matches</strong> of the resulting <strong>mitochondrial assembly</strong> sequence in the nuclear genome assembly using <strong>BLAST+</strong> and <strong>filtered out scaffolds from the nuclear genome</strong> with a percentage of <strong>sequence identity &gt;99%</strong> and <strong>size smaller than the mitochondrial assembly sequence</strong>. From the <strong>subset of mitochondrial reads</strong> used for the assembly, we analyzed the <strong>BLAST</strong> output and <strong>the species of the closest mitochondrial sequence</strong> available in the NCBI GenBank database, <em>Vaccinium macrocarpon</em> (Accession number: <a href="https://www.ncbi.nlm.nih.gov/nuccore/NC_023338.1">NC_023338.1</a>). We used the mitochondrial assembly of <em>V. macrocarpon</em> as a <strong>guide</strong> for the <strong>mitochondrial gene annotation</strong> generated with <strong>MitoFinder</strong> [Version 1.4] (Allio et al. 2020).</p><p><strong>Chloroplast Genome Assembly</strong></p><p>We identified chloroplast reads from the PacBio HiFi dataset with BLAST+ using the plastids RefSeq genomes [v4.1] (O’Leary et al. 2016). From this subset, we analyzed the matches and identified the species of the closest chloroplast sequence available in the NCBI database as <em>Camellia taliensis</em> (NC_022264.1). Next, we found matches of the <em>C. taliensis</em> chloroplast genome sequence in the nuclear genome assembly with BLAST+ and filtered out scaffolds from the nuclear genome assembly with length smaller than the <em>C. taliensis</em> length, sequence identity &gt;90%, and <em>e</em>-value &lt;0.00001. We aligned the filtered scaffolds to the <em>C. taliensis</em> chloroplast genome with minimap2 (Li 2018) and generated a consensus sequence with bcftools (Li 2011). We manually curated the sequence using lastz. Finally, we polished the last assembly version using raptor and racon and annotated it using the web platform GeSeq (Tillich et al. 2017).</p><h1 id="8-2022-02-pj-澳洲坚果-value"><a href="#8-2022-02-pj-澳洲坚果-value" class="headerlink" title="8. 2022.02-pj 澳洲坚果 value"></a>8. 2022.02-pj 澳洲坚果 value</h1><blockquote><p> De novo chromosome level assembly of a plant genome from long read sequence data</p></blockquote><p><a href="https://pubmed.ncbi.nlm.nih.gov/34784084/">https://pubmed.ncbi.nlm.nih.gov/34784084/</a></p><p>We now report the use of <strong>HiFiasm</strong> to assemble the genome of Macadamia jansenii, a genome that has been used as a model to test sequencing and assembly. This achieved <strong>almost complete chromosome level assembly</strong> from the sequence data alone <strong>without</strong> the need for <strong>higher level chromosome map information</strong>. <strong>Eight of the 14 chromosomes were represented by a single large contig</strong> (six with telomere repeats at both ends) and the <strong>other six assembled from two to four main contigs</strong>. The small number of chromosome breaks appears to be the result of <strong>highly repetitive regions</strong> including ribosomal genes that cannot be assembled by these approaches. </p><p>Table 1. HiFiasm contigs in different size categories and comparison of primary and haploid assemblies generated from HiFiasm genome assembler tool</p><table><thead><tr><th align="left">Number of contigs</th><th align="left">Assembly length (Mb)</th><th align="left">N50 (Mb)</th><th align="left">N75 (Mb)</th><th align="left">busco(%)</th><th></th></tr></thead><tbody><tr><td align="left">HiFiasm assembly</td><td align="left"></td><td align="left"></td><td align="left"></td><td align="left"></td><td></td></tr><tr><td align="left">Total contigs</td><td align="left">779</td><td align="left">826</td><td align="left">46</td><td align="left">25</td><td>99.6</td></tr><tr><td align="left">Contigs &gt;40 Mb</td><td align="left">10</td><td align="left">524</td><td align="left">50</td><td align="left">46</td><td>68.7</td></tr><tr><td align="left">Contigs &gt;10 Mb</td><td align="left">19</td><td align="left">746</td><td align="left">48</td><td align="left">39</td><td>93.9</td></tr><tr><td align="left">Contigs &gt;1 Mb</td><td align="left">30</td><td align="left">784</td><td align="left">46</td><td align="left">30</td><td>99.1</td></tr><tr><td align="left">Contigs &gt;100 kb</td><td align="left">94</td><td align="left">805</td><td align="left">46</td><td align="left">27</td><td>99.0</td></tr><tr><td align="left">Between 100 kb and 1 Mb</td><td align="left">64</td><td align="left">20</td><td align="left">0.49</td><td align="left">0.22</td><td>0.20</td></tr><tr><td align="left">Between 10 kb and 100 kb</td><td align="left">685</td><td align="left">22</td><td align="left">0.032</td><td align="left">0.028</td><td>0.00</td></tr><tr><td align="left">Comparison of HiFiasm primary and haploid assemblies</td><td align="left"></td><td align="left"></td><td align="left"></td><td align="left"></td><td></td></tr><tr><td align="left">Primary assembly</td><td align="left">779</td><td align="left">827</td><td align="left">46.1</td><td align="left">25</td><td>99.60</td></tr><tr><td align="left">Hap 1_assembly</td><td align="left">879</td><td align="left">816</td><td align="left">24.4</td><td align="left">8.9</td><td>98.80</td></tr><tr><td align="left">Hap 2_assembly</td><td align="left">363</td><td align="left">776</td><td align="left">14.3</td><td align="left">5.4</td><td>97.90</td></tr><tr><td align="left">Hap 1 &gt;1 Mb</td><td align="left">96</td><td align="left">736</td><td align="left">16.4</td><td align="left">6.8</td><td>96.70</td></tr><tr><td align="left">Hap 2 &gt;1 Mb</td><td align="left">72</td><td align="left">766</td><td align="left">24.5</td><td align="left">12.3</td><td>98.10</td></tr></tbody></table><p><strong>HiFiasm assembly</strong></p><p>For assembly, <strong>24 core</strong> processing units and <strong>120 Gb of memory</strong> was employed. Default settings of the HiFiasm assembler were used to assemble heterozygous genomes with <strong>built-in duplication purging parameters</strong>. The HiFiasm output directory consists of two haploid (1 and 2), one primary contig and one alternate haplotig GFA graph files. Each halplotig and one primary contig GFA file was converted to FASTA format using the <strong>awk</strong> command.</p><p><strong>Analysis of assembly</strong></p><p>The primary HiFiasm assembly of <em>M. jansenii</em> included 779 contigs that were categorised into three subsets: (i) contigs &lt;1 Mb size; (ii) contigs &lt;1 Mb and more than 100 kb size; and (iii) contigs &lt;100 kb size. Along with the <strong>main primary and two haploid assemblies</strong>, all <strong>three</strong> sets of primary contig subsets were <strong>passed</strong> through analysis using <strong>quast</strong> (Gurevich et al., <a href="https://onlinelibrary.wiley.com/doi/10.1111/tpj.15583#tpj15583-bib-0010">2013</a>), <strong>busco</strong> (Simão et al., <a href="https://onlinelibrary.wiley.com/doi/10.1111/tpj.15583#tpj15583-bib-0028">2015</a>) and <strong>repeatmodeler</strong> (Humann et al., <a href="https://onlinelibrary.wiley.com/doi/10.1111/tpj.15583#tpj15583-bib-0012">2019</a>). The <strong>telomere sequences</strong> in the HiFiasm <strong>contigs</strong> were identified using the <strong>bioserf platform</strong> (<a href="https://bioserf.org/">https://bioserf.org</a>) (Somanathan and Baysdorfer, <a href="https://onlinelibrary.wiley.com/doi/10.1111/tpj.15583#tpj15583-bib-0029">2018</a>). <strong>Ribosomal RNA</strong> and <strong>other protein coding genes</strong> at the <strong>terminal</strong> end of the HiFiasm contigs were identified using an <strong>ncbi blast search</strong> (<a href="https://blast.ncbi.nlm.nih.gov/">https://blast.ncbi.nlm.nih.gov</a>). Ribosomal RNA in the contigs was identified using <strong>Barrnap</strong> (<a href="https://github.com/tseemann/barrnap">https://github.com/tseemann/barrnap</a>) (Seemann, <a href="https://onlinelibrary.wiley.com/doi/10.1111/tpj.15583#tpj15583-bib-0023">2013</a>) with default settings for eukaryotes.</p><p><strong>Comparison with Hi-C assembly</strong></p><p>The HiFiasm contigs were compared with the <em>M. jansenii</em> 14 pseudo-molecules from the Hi-C assembly (Sharma et al., <a href="https://onlinelibrary.wiley.com/doi/10.1111/tpj.15583#tpj15583-bib-0026">2021b</a>) using the online interactive D-Genies dotplot tool (Cabanettes and Klopp, <a href="https://onlinelibrary.wiley.com/doi/10.1111/tpj.15583#tpj15583-bib-0003">2018</a>) to <strong>compare two genomes using Minimap2</strong> and, for <strong>alignments</strong>, dotplot images were created after selecting the ‘sort contigs’ option, selecting the ‘minimum identity’ parameter at 0.75 and checking the ‘strong precision’ tick box.</p><p><strong>Characterisation of organelle genomes content of HiFiasm contigs</strong></p><p>A reference <font color="red"><strong>mitochondrial</strong> genome, <strong>chloroplast</strong> genome and <strong>nuclear ribosomal RNA</strong> sequence</font> from this sample were assembled from <strong>Illumina raw reads</strong> (Murigneux et al., <a href="https://onlinelibrary.wiley.com/doi/10.1111/tpj.15583#tpj15583-bib-0020">2020</a>) using the <strong>GetOrganelle toolkit</strong> (Jin et al., <a href="https://onlinelibrary.wiley.com/doi/10.1111/tpj.15583#tpj15583-bib-0013">2020</a>) with default parameters. The <strong>HiFiasm contigs</strong> (779) were <strong>compared with</strong> the <strong>organellar and ribosomal sequences</strong> in dotplots.</p><h1 id="9-2021-04-Mol-Ecol-Resour-百香果"><a href="#9-2021-04-Mol-Ecol-Resour-百香果" class="headerlink" title="9. 2021.04-Mol Ecol Resour 百香果"></a>9. 2021.04-Mol Ecol Resour 百香果</h1><p><a href="https://onlinelibrary.wiley.com/doi/10.1111/1755-0998.13310">https://onlinelibrary.wiley.com/doi/10.1111/1755-0998.13310</a></p><blockquote><p>Chromosome-level reference genome assembly provides insights into aroma biosynthesis in passion fruit (Passiflora edulis)</p></blockquote><p>The assembled reference genome is 1.28 Gb size with a scaffold N50 of 126.4 Mb and 99.22% sequences anchored onto nine pseudochromosomes. 以往的核型分析表明百香果是一种二倍体，9对染色体</p><p><strong>Genome survey and assembly</strong><br>A total of 89.12 Gb of high-quality paired-end reads were obtained by <strong>Illumina</strong> genomic sequencing (~70.35X coverage, Table S1). The genome size, heterozygosity and repeat content were estimated based on k-mer distribution using <strong>21-mers</strong> extracted from the Illumina short reads. The estimated genome size was further validated using <strong>flow cytometr</strong>y. A total of 223.91 Gb raw PacBio subreads were filtered and corrected using pbccs pipeline with default parameters (<a href="https://github.com/PacificBiosciences/ccs">https://github.com/PacificBiosciences/ccs</a>). The resulted CCS reads were subjected to hifiasm for de novo assembly. We <font color="red"><strong>corrected</strong> the <strong>primary contigs</strong> by the <strong>Pilon</strong></font> (version1.18) (Utturkar, Klingeman, Hurt, &amp; Brown, 2017) program <strong>using 89.12 Gb (70.35×) of Illumina paired-end reads</strong>. BWA (version0.7.10-r789) (Li, 2013) and SAMtools (version1.9) (Li et al., 2009) were used for reads alignment and SAM&#x2F;BAM format conversion. <strong>BUSCO</strong> (version3.0) (Simao, Waterhouse, Ioannidis, Kriventseva, &amp; Zdobnov, 2015) program with embryophyta_odb10 database were used to assess the completeness of genome and gene annotation .</p><p><strong>Chromosome assembly using Hi-C</strong></p><p>Approximately 96.4 Gb of Hi-C data were generated. The raw data were filtered using perl script as implemented in the software <strong>LACHESIS</strong> (Burton et al., 2013). BWA software was used to <strong>map the Hi-C reads to the draft assembly</strong> and <strong>uniquely mapped reads were selected for furtheranalysis</strong>. We further applied our newly developed <strong>ALLHiC pipeline</strong> to link the contigs into <strong>nine pseudo-chromosomes</strong>. <strong>HiC-pro</strong> (version2.10.0) (Servant et al., 2015) program was used to <strong>calculate Hi-C mapping rate and evaluate the quality of Hi-C scaffolding</strong>.</p><h1 id="10-2021-10-MolEcolResour-牡蛎🦪"><a href="#10-2021-10-MolEcolResour-牡蛎🦪" class="headerlink" title="10. 2021-10-MolEcolResour 牡蛎🦪"></a>10. 2021-10-MolEcolResour 牡蛎🦪</h1><blockquote><p>Chromosome-level genome and population genomic analysis provide insights into the evolution and environmental adaptation of Jinjiang oyster Crassostrea ariakensis</p></blockquote><p><a href="https://pubmed.ncbi.nlm.nih.gov/34800349/">https://pubmed.ncbi.nlm.nih.gov/34800349/</a></p><p>The C. ariakensis genome was 662.9 Mb with contig N50 length of 5.9 Mb using PacBio HiFi-CCS long reads, and 99.83% sequences were anchored onto 10 pseudochromosomes using Hi-C data.</p><h1 id="11-2021-10-Front-Genet-思茅松毛虫"><a href="#11-2021-10-Front-Genet-思茅松毛虫" class="headerlink" title="11. 2021.10-Front Genet 思茅松毛虫"></a>11. 2021.10-Front Genet 思茅松毛虫</h1><blockquote><p>Chromosome-Level Genome Assembly Reveals Significant Gene Expansion in the Toll and IMD Signaling Pathways of <em>Dendrolimus kikuchii</em></p></blockquote><p>forest pests</p><p>Overall, a final genome assembly of 705.51 Mb with contig and scaffold N50 values of 20.89 and 24.73 Mb, respectively, was obtained. Of these contigs, 95.89% had unique locations on 29 chromosomes.</p><p><strong>Genome Assembly and Polish</strong></p><p>After quality control of raw reads, the pass reads were used for <em>de novo</em> genome assembly of using an <strong>OLC (overlap layout-consensus)&#x2F;string graph method</strong> with NextDenovo (v2.3.0) with reads_cutoff:1 k and seed_cutoff:30 k. Firstly, self-correction of the original subreads was finished by NextCorrect to obtain consistent sequences (CNS reads). Then, CNS reads were used to obtain preliminary assembly through NextGraph (default parameter). The ONT, CCS and Hi-C data were used to correct the preliminary assembly using Racon (v1.3.1, default, CCS data) (<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8589036/#B66">Vaser et al., 2017</a>)and Nextpolish (v1.2.4, default, ONT and Hi-C data) (<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8589036/#B24">Hu et al., 2020</a>). <strong>BlastN was used to check the genome contamination</strong> (<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8589036/#s10">Supplementary information S2</a>).</p><p>Completeness of the genome assembly was assessed using <strong>BUSCO</strong> v4.0.5 (Benchmarking universal Single-Copy Orthologs) (<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8589036/#B58">Simao et al., 2015</a>) and CEGMA (Core Eukaryotic Gene Mapping Approach) (<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8589036/#B55">Parra et al., 2007</a>). <strong>To evaluate the accuracy of the assembly</strong>, all <strong>paired-end reads were mapped to the assembled</strong> genome using <strong>BWA</strong>  (<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8589036/#B39">Li and Durbin, 2010</a>) and the <strong>mapping rate</strong> and the genome coverage of sequencing reads were both assessed using SAMtools v0.1.1855 (<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8589036/#B40">Li et al., 2009</a>). In addition, the base accuracy of the assembly was calculated using bcftools (<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8589036/#B13">Danecek and Mccarthy, 2017</a>). Coverage of the expressed genes of the assembly was examined by aligning all the RNA-seq reads against the assembly using HISAT with default parameters. <strong>To ensure that mitochondrial sequences were not included in the assembly,</strong> the draft genome assembly was submitted to the <strong>NT library</strong> and matching sequences were eliminated.</p><p><strong>Genome Anchoring to Chromosome</strong></p><p>The read quality (370 million paired-end reads) was controlled using Hi-C-Pro. Firstly low-quality sequences (quality scores &lt;20), adaptor sequences, and sequences shorter than 30 bp were filtered out using <strong>fastp</strong> (<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8589036/#B10">Chen et al., 2018</a>). Next, clean reads were mapped to the draft assembled sequence using <strong>bowtie2</strong> (v2.3.2) (-end-to-end –very-sensitive -L 30) (<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8589036/#B37">Langmead and Salzberg, 2012</a>) to obtain the unique mapped paired-end reads. Invalid read pairs were filtered using <strong>HiC-Pro</strong> (v2.8.1) (<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8589036/#B57">Servant et al., 2015</a>). The scaffolds were further <strong>clustered, ordered, and oriented onto chromosomes</strong> by <strong>LACHESIS</strong> (<a href="https://github.com/shendurelab/LACHESIS">https://github.com/shendurelab/LACHESIS</a>), with parameters <strong>CLUSTER_MIN_RE_SITES &#x3D; 100, CLUSTER_MAX_LINK_DENSITY &#x3D; 2.5, CLUSTER NONINFORMATIVE RATIO &#x3D; 1.4, ORDER MIN N RES IN TRUNK &#x3D; 60, ORDER MIN N RES IN SHREDS &#x3D; 60.</strong> Lastly, placement and orientation errors exhibiting obvious discrete chromatin interaction patterns were <strong>manually adjusted</strong>.</p><p><strong>Synteny</strong> of the <em>D. kikuchii</em> <strong>genome</strong> with the <em>D. punctatus</em> <strong>genomes</strong> was analyzed using <strong>Minimap2</strong> and <strong>dotPlotly</strong> to identify chromosome structural changes among the two species.</p>]]></content>
    
    
    <categories>
      
      <category>Biology</category>
      
    </categories>
    
    
    <tags>
      
      <tag>assembly</tag>
      
      <tag>paper</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>HiFi-6-[HiFi-HiC-assembly-method]</title>
    <link href="/GeekFocus/2022/03/14/2022-03-14-HiFi-6-HiC-assembly/"/>
    <url>/GeekFocus/2022/03/14/2022-03-14-HiFi-6-HiC-assembly/</url>
    
    <content type="html"><![CDATA[<p>辅助组装案例</p><span id="more"></span><h1 id="1-2016-05-np-碧冬茄"><a href="#1-2016-05-np-碧冬茄" class="headerlink" title="1. 2016.05-np 碧冬茄"></a>1. 2016.05-np 碧冬茄</h1><p><strong>Insight into the evolution of the Solanaceae from the parental genomes of Petunia hybrida</strong></p><h2 id="Genome-sequencing-assembly-and-annotation"><a href="#Genome-sequencing-assembly-and-annotation" class="headerlink" title="Genome sequencing, assembly and annotation."></a>Genome sequencing, assembly and annotation.</h2><p>Plants were grown and DNA was extracted following the methods described at Supplementary Note 1.</p><p>Illumina libraries with 0.17-, 0.35-, 0.5-, 0.8-, 1-, 2-, 5-, 8- and 15-kb inserts were sequenced at BGI-Shenzghen and University of Illinois, Roy J. Carver Biotechnology. PacBio P. axillaris DNA library was sequenced with P4&#x2F;C2 chemistry.</p><p>Illumina reads were processed using <strong>Fastq-mcf</strong> (<strong>quality filtering</strong>; <a href="https://code.google.com/p/eautils/wiki/FastqMcf">https://code.google.com/p/eautils/wiki/FastqMcf</a>), <strong>PRINSEQ</strong> (<strong>duplication filtering</strong>; http:&#x2F;&#x2F; prinseq.sourceforge.net&#x2F;) and <strong>Musket</strong> (<strong>error correction</strong>; <a href="http://musket.sourceforge/">http://musket.sourceforge</a>. net&#x2F;). <strong>Pacbio reads</strong> were processed using the <strong>SMRT Analysis pipeline</strong> (v.2.0.1; <a href="https://github.com/PacificBiosciences/SMRT-Analysis">https://github.com/PacificBiosciences/SMRT-Analysis</a>).</p><p>Both genomes were assembled with <strong>SOAPdenovo</strong> with different k-mer sizes. For both genomes, <strong>k-mer &#x3D; 79</strong> showed the best statistics. Gaps between contigs were completed using <strong>GapCloser</strong> . Additionally for P. axillaris, <strong>PacBio reads</strong> were integrated in <strong>four different steps</strong>: (1) <strong>Rescaffolding</strong> of the <strong>Illumina contigs</strong> using the <strong>PacBio reads</strong> and the <strong>AHA assembler</strong>; (2) <strong>Gap filling</strong> using <strong>PBJelly</strong>; (3) <strong>Rescaffolding</strong> using the Illumina <strong>pair data</strong> and <strong>SSPACE</strong>; (4) Last round of <strong>gap filling</strong> using <strong>PBJelly</strong> . </p><p><strong>Genome size estimation</strong> was performed through the k-mers abundance distribution (<strong>k-mer &#x3D; 31</strong>). <strong>Heterozygosity</strong> was <strong>estimated</strong> mapping the Illumina reads to the assemblies using <strong>Bowtie2</strong>, calling SNPs using <strong>FreeBayes</strong> and  annotating the SNPs using <strong>SnpEff</strong> .</p><p>The genome structural annotation was performed using <strong>Maker-P</strong>: (1) <strong>SNAP</strong> and <strong>Augustus</strong> as ab initio gene predictors; (2) Exonerate as experimental based predictor with 454 and Illumina RNASeq reads and protein sequences from different protein datasets. RNAseq Illumina data was mapped using <strong>Tophat2</strong> . tRNAs were annotated using <strong>tRNAscan</strong> (<a href="http://lowelab.ucsc.edu/tRNAscan-SE/">http://lowelab.ucsc.edu/tRNAscan-SE/</a>).</p><p>The <strong>gene functional annotation</strong> was performed by <strong>sequence homology search</strong> with different protein datasets using <strong>BlastP</strong> and protein domains search using <strong>InterProScan</strong> . Functional annotations were integrated using <strong>AHRD</strong> (<a href="https://github.com/groupschoof/AHRD">https://github.com/groupschoof/AHRD</a>). See Supplementary Note 1.</p><h2 id="Repetitive-elements-analysis"><a href="#Repetitive-elements-analysis" class="headerlink" title="Repetitive elements analysis"></a>Repetitive elements analysis</h2><p>Repeat annotation was performed using RepeatModeler (v1.0.8; <a href="http://www.repeatmasker.org/RepeatModeler.html">http://www.repeatmasker.org/RepeatModeler.html</a>), RepeatMasker (v4.0.5; <a href="http://www.repeatmasker.org/">http://www.repeatmasker.org</a>) with the repeat database Repbase (release 20140131; <a href="http://www.girinst.org/repbase/">http://www.girinst.org/repbase/</a>) and Geneious (v7.1.4; <a href="http://www.geneious.com/">http://www.geneious.com</a>). Identification of PVCV-like and EPRV elements was performed using BlastN and TBlastN . The identified sequences were aligned with ClustalW (MEGA5 package;<a href="http://www.megasoftware.net/">http://www.megasoftware.net/</a>) and then manually curated. RepeatExplorer (<a href="http://www.repeatexplorer.org/">http://www.repeatexplorer.org/</a>) and other methods were used to extend the analysis to unassembled repeats. Fluorescent in situ hybridization was performed in root tips from young P. axillaris and P. inflata plants for 5S rDNA and three PVCV viral probes following the procedure described in Supplementary Note 2.</p><p>The detection of dTph1 loci in P. hybrida W138 was performed through a BLAST40 search of the P. axillaris and P. inflata dTph1 elements including the 500 bp of flanking sequence against the TFS W138 collection. Polymorphisms found in the genomic flanking regions were used to identify the species of origin. dTph1 elements were identified in a P. axillaris population using a modification of the methodology described in Supplementary Note 3.</p><p>##Whole-genome duplication, tandem duplications and gene family analysis</p><p>Whole-genome collinear analysis was performed using SynMap and microsynteny analysis were performed using GEvo in the comparative genomics platform, CoGe .See Supplementary Note 5.</p><p>The gene family analysis included Solanum lycopersicum, S. tuberosum, Nicotiana benthamiana and Arabidopsis thaliana protein sets using BlastP (v2.2.27) on an all-versus-all comparison and grouping the genes into families with OrthoMCL, v2.0.8. See Supplementary Note 4.</p><h2 id="Gene-data-mining"><a href="#Gene-data-mining" class="headerlink" title="Gene data mining"></a>Gene data mining</h2><p>The specific identification of genes for P. axillaris and P. inflata genomes for colour and scent, root-specific pathways, self-incompatibility and circadian clock was performed through a BlastN&#x2F;BlastP sequence homology search. Blast GUI, JBrowser (<a href="http://jbrowse.org/">http://jbrowse.org/</a>) and WebApollo (<a href="http://genomearchitect/">http://genomearchitect</a>. org&#x2F;) were installed in a server to search and manually curate the gene structures of the identified genes. See Supplementary Notes 7, 8 and 10–12.</p><h1 id="2-2017-04-ng-山羊🐐"><a href="#2-2017-04-ng-山羊🐐" class="headerlink" title="2. 2017.04-ng 山羊🐐"></a>2. 2017.04-ng 山羊🐐</h1><p>Published in final edited form as:Nat Genet. 2017 April ; 49(4): 643–650. doi:10.1038&#x2F;ng.3802.</p><p><strong>Single-molecule sequencing and chromatin conformation capture enable</strong> <strong>de novo</strong> <strong>reference assembly of the domestic goat genome</strong></p><p>​首次在人之外的物种中直接de novo组装出染色体水平的基因组。利用<font color="blue"><strong>Pacbio+BioNano+Hi-C+Illumina</strong> 多层级</font>的策略，组装了一只山羊(Capra hircus)的基因组，获得<font color="blue"><strong>31</strong>个<strong>scaffold</strong>，<strong>663</strong>个<strong>gap</strong>区，scaffold <strong>N50</strong> 惊人地达到<strong>87M</strong>，几乎<strong>one scaffold one chromosome</strong></font>，并且成功地组装出<font color="blue"><strong>免疫基因区</strong>和<strong>大部分重复序列家族</strong></font>。</p><p>​<font color="red">人的GRCh38版本有<strong>24</strong>个<strong>scaffold</strong>，<strong>169</strong>个<strong>unplacedscaffold</strong>，<strong>832个gap</strong>区</font>。</p><p>​从<strong>96头</strong>山羊(<strong>6个品种</strong>)中，利用Illumina的 Caprine53K <font color="blue"><strong>SNP 芯片筛选</strong></font>出<font color="blue"><strong>基因型纯和度最高</strong></font>的个体用来<font color="blue"><strong>组装</strong></font>(San Clemente breed)。</p><h2 id="data"><a href="#data" class="headerlink" title="data"></a>data</h2><ol><li><p>Pacbio数据</p><p>一共产生465个SMRT cell的数据。其中使用P5-C3试剂的311个cell;使用P4-C2试剂的142个cell，XL-C2试剂的12个cell。数据量194G，覆盖深度达<strong>69X</strong>，<strong>subread</strong>的<strong>平均</strong>长度为<strong>5,110bp</strong>。</p></li><li><p>BioNano 数据</p><p>由于采样所用山羊意外死亡，其DNA不能满足Irsy optical mapping 测序需求，只好用其<strong>雄性后代</strong>采样。Optical map一共产生256Gb数据，覆盖<strong>98 X</strong>。</p></li><li><p>Hi-C数据</p><p>采样动物是最初那只山羊。Hi-C建库，序列用物理方法打断成300-500bp长度，PE101测序，产生<strong>115M reads</strong>的数据量。</p></li><li><p>Illumina 数据</p><p>采样最初那只山羊，PE251建库测序，获得<strong>23X</strong>的数据覆盖，用来做最后的<font color="red"><strong>错误校正</strong></font></p></li></ol><h2 id="组装策略及组装结果"><a href="#组装策略及组装结果" class="headerlink" title="组装策略及组装结果"></a><strong>组装策略及组装结果</strong></h2><ul><li><p>先用Pacbio的 long-read 数据构建contig， 使用<font color="blue"><strong>Celera Assembler</strong> PacBio corrected Reads 流程</font>组装。获得<font color="blue"><strong>3,074</strong>个contig(2.63G)，<strong>N50 4.159M</strong>b</font>。</p></li><li><p>接下来采用<font color="blue"><strong>Irys optical mapping</strong>数据构建<strong>scaffold</strong></font>，使用软件为<font color="blue"><strong>IrysView</strong></font>. 产生<font color="blue"><strong>842</strong>个scaffold，scaffold N50为<strong>13.4M</strong>b，contig N50为10.858M，最长scaffold为66.728Mb</font>。 利用<font color="red"><strong>radiation hybrid(RH) map比较</strong>发现</font>，<font color="blue">PacBio-Irys 联合</font>的方法已经<font color="blue">完整组装出<strong>20号染色体</strong></font>。</p></li><li><p>接下来用Hi-C数据，调用用<font color="red"><strong>Lachesis软件包</strong></font>，结合PacBio-Irys的结果，即整合的PacBio-Irys-PGA (PBIP)方法，获得较完美的组装结果。<font color="blue">Scaffold N50</font> 达到惊人的<font color="blue"><strong>87.347Mb</strong></font>(远超今年尖吻鲈，大猩猩N50 20Mb的高起点)，总共获得<font color="blue"><strong>31条</strong>scaffold</font>，(<font color="red">31,261条&lt;50kbp的**degenerate scaffold**不计入</font> )。</p></li><li><p>最后利用Illumina数据做<font color="red"><strong>一致性校正</strong>和最后的<strong>补洞</strong></font>，最后使得contig的数目下降到680条，产生的gap数目为663个。</p></li><li><p>利用Kraken v0.10.5 <font color="red">去除有<strong>病毒和细菌污染</strong>的序列</font>，去掉有NCBI vector污染的序列。获得最终的基因组 版本<strong>ARS1</strong>。</p></li></ul><h2 id="组装评估及比较分析"><a href="#组装评估及比较分析" class="headerlink" title="组装评估及比较分析"></a><strong>组装评估及比较分析</strong></h2><p>由于山羊之前已经产生过两个基因组版本<strong>CHIR_1.0、CHIR_2.0</strong>，可以用来做比较 分析，并且有RH mapping数据用来评估、校正ARS1的组装版本。 <strong>通过各种参数比较发现，ARS1均优于CHIR_2.0版本。</strong></p><p>1、通过比对发现，CHIR_2.0 比CHIR_1.0有更少的putative deletion(2,735 vs 1 0,256)和duplication(115 vs 290)。而2.0版本相较1.0有更多的inversion(215 v s 4)。通过比较，发现ARS1版本有大幅度地提升，较2.0版本少4倍的deletion， 少50倍inversion。</p><p>2、CHIR_2.0能填补CHIR_1.0 94.6%的gap，而剩下的那些gap通过分析ARS1得知，是CHIR_1.0的组装错误，而RH数据也支持了这一论断。 3、BUSCO是利用单拷贝ortholog来评估组装的可靠性，和CHIR_2.0相比，ARS1有更高的BUSCO score。</p><p>4、山羊52k SNP 芯片中，有1,723个SNP探针目前只能定位在CHIR_2.0组装版本 中的unplaced contigs上。而ARS1版本能把其中的90%(1,552&#x2F;1,723)以上的S NP探针定位在染色体上。另外发现有26个low call-rate 的SNPmarker在ARS1组装版本上定位比较模棱两可。这也就解释了为什么这些maker在芯片上有较差的call -rate. </p><p>5、通过比较发现，CHIR_2.0版本中的3,495个内含子或外显子有gap的基因，在ARS1中都得到补全。同时也确认1,926个预测的外显子在CHIR_1.0或者2.0中有gap， 但在ARS1中得到修复。 </p><p>6、由于免疫基因区高度多态性和重复性，用二代测序数据很难组装起来，但是通过 分析发现，ARS1版本就很好地把LRC和NKC基因(免疫功能相关基因)定位在一个独立的常染色体scaffold上。 </p><p>7、通过和一代、二代组装策略相比，ARS1版本在重复序列的组装上获得了极大进步。对某些异染色体或异染色质的区域也获得了较好的组装覆盖。比如，在6条常 染色体上组装出&gt;5kbp的端粒序列。通过分析发现， 15条染色体scaffold，在着丝粒区域组装出大于2kbp长度的重复区，而其中的7条，更是装出来8kbp以上的重复区。更令人惊讶的是，19号和23号染色体都组装出高度重复的着丝粒和端粒区域， 贯通了有结构性异染色质区的染色体。 </p><p>8、在ARS1版本中鉴定出大于12kbp的重复模式序列多达105条。对于重复序列家 族的鉴定，在ARS1中获得的接近全长的BovB LINE 序列比CHIR_2.0多60%以上。 在CHIR_2.0版本里，被ARS1成功补全的gap中的43.6%与BovB重复序列一致(长 度大于3.5kbp)，即意味着二代测序的gap区大多都是重复序列，用三代就能较容易测通。 </p><p>9、关于性染色体的分析。通过比对发现，两个不同的scaffold比对到X染色体的不同但连续的区域，占预期X染色体大小(150Mb)的86%左右。通过和自己的、跨物种牛的Y染色体比对，最终确定出10Mb区域的序列，占Y染色体预估大小的50% 左右。通过比对牛和羊的Y染色体上的基因，发现在目前的scaffold中能找到16%， 而在先前过滤掉的degenerate contig中能找到84%的基因。考虑到Y染色体的异染 色质属性及X,Y染色体的拟常染色区域经常发现交换，实在太过复杂，超出目前的组装和认知水平，表示实在无能为力。</p><p>10、利用之前RH mapping data，对组装的大部分环节进行了校正及评估。比如多次辅助解决scaffold conflict的问题。</p><h2 id="基因组注释"><a href="#基因组注释" class="headerlink" title="基因组注释"></a><strong>基因组注释</strong></h2><p>多种方法结合注释基因集。<br>1.<strong>RNA-seq的方法:</strong> 6个组织(大多和脑组织相关)RNA-seq测序、13个SRA下载 数据，利用stringtie、cufflinks和Trinity(基于无参组装)。最后用PASA软件整合在一起;</p><p>2.<strong>用exonerate和tblastn 软件</strong>比对到几个近缘物种的Ensembl基因集上，获得同 源预测基因集;</p><p>3.<strong>用Braker1做Ab initio 预测</strong>;</p><p>4.<strong>CHIR_1.0 版本的注释基因集</strong>; 最后用<strong>EVM+PASA</strong>把以上4种数据整合成一个最终的基因集(设置的权重为RNAseq &gt; cDNA&#x2F;protein &gt; ab initio gene predictions)。</p><h2 id="启示录"><a href="#启示录" class="headerlink" title="启示录"></a><strong>启示录</strong></h2><p>1、Pacbio RSII是一个较为理想组装平台，产生平均14Kbp左右的读长，最高到60 Kbp，可以组装出较为理想的基因组版本。由于三代的长读长优势，同时可以较好地组装出基因组中大部分高度重复区(主要集中在着丝粒和端粒区域);</p><p>2、BioNano 的Irys optical mapping 是一种非常有效的，成本比较适中的构建scaffold的平台。和Hi-C比优势在于定位错误较少，缺点是对N50的提高并不是特别显著，一般在2倍左右。如果正反链的Nt.BsqI酶切位点离得比较近，常常导致双链 断裂，限制了Optical Map scaffold的大小。所以，BioNano对较长的scaffold效果比较好。由于Optical map和pacbio产生的错误特征并不一样，两者结合，可以 相互校正，获得较好的组装指标;</p><p>3、Hi-C是目前非常火爆的一个技术，在多个领域都有很好的应用。在组装方面， 它能获得染色体级别的scaffold，但是也容易获得较高的contig定向错误。这也是 为什么文章中，先用optical mapping，后用Hi-C做scaffolding的重要原因之一。 作者建议在以后的实验中，可以选择较短的识别位点的限制内切酶(或者DNase Hi -C)来提高Hi-C交联的密度，降低定向错误。</p><p>4、利用同样的方法和平台，做类似的基因组项目，用Pacbio平台和scaffolding平 台，目前大约花费在$100,000上下,而一般的短reads平台测序加scaffolding 平台，只需要其三分之一的价格。但是用Pacbio平台却获得了高质量的、连续性好的基因组序列。目前Pacbio 新一代的sequel平台已经推出，单个cell的产量比RSII提 高7倍以上，测序成本将会得到大幅度降低，相信会成为未来基因组研究的主流工具之一。</p><p>5、本文的研究策略确实会启迪后来的研究者，为de novo组装树立新标杆。Pacbio 测序技术联合多种scaffolding 平台(比如BioNano、Hi-C，mating-pairedlibr ary，10X genomics)的使用， 会引领de novo 组装进入 near finished genome 或者finished genome的新时代。</p><p>6、但是，尽管做了很多努力，ARS1仍然是一个单体型混合型的组装版本。在未来，可以利用single molecule和Hi-C技术获得单体型分期(haplotype phasing) 的参考基因组。对于组成型异染色质区，尤其是着丝粒和端粒部分，仍然是组装的盲区，即使在人的基因组中这些区域也没有被完整组装出来。</p><h1 id="3-2020-09-cell-大豆泛基因组"><a href="#3-2020-09-cell-大豆泛基因组" class="headerlink" title="3. 2020.09-cell 大豆泛基因组"></a>3. 2020.09-cell 大豆泛基因组</h1><p>Pan-Genome of Wild and Cultivated Soybeans</p><p>Soybean is one of the most important vegetable oil and protein feed crops. To capture the entire genomic diversity, it is needed to construct a complete high-quality pan-genome from diverse soybean accessions. In this study, we performed individual de novo genome assemblies for <strong>26 representative soybeans</strong> that were selected from <strong>2,898 deeply sequenced accessions</strong>. Using these assembled genomes together with <strong>three previously reported genomes</strong>, we constructed a <strong>graph-based genome</strong> and performed pan-genome analysis, which identified <strong>numerous genetic variations that cannot be detected by direct mapping of short sequence reads onto a single reference genome</strong>. The <strong>structural variations</strong> from the 2,898 accessions that were <strong>genotyped</strong> based on the graph-based genome and the <strong>RNA-seq data</strong> from the representative 26 accessions helped to <strong>link genetic variations to candidate genes</strong> that are responsible for important traits. This pan-genome resource will promote evolutionary and functional genomics studies in soybean.</p><h2 id="SNP-Calling-and-Phylogenetic-Analyses"><a href="#SNP-Calling-and-Phylogenetic-Analyses" class="headerlink" title="SNP Calling and Phylogenetic Analyses"></a>SNP Calling and Phylogenetic Analyses</h2><h2 id="Genome-Assembly"><a href="#Genome-Assembly" class="headerlink" title="Genome Assembly"></a>Genome Assembly</h2><p><em>De novo</em> assembly was conducted referring to a <font color="blue"><strong>reported pipeline</strong></font> (Du and Liang, 2019; Shen et al., 2019). In brief, <font color="red"><strong>Canu</strong></font> (Koren et al., 2017) v1.7.1 was used to assemble PacBio subreads to PacBio contigs, after which <font color="red"><strong>HiSeq</strong></font> reads were used for <font color="red"><strong>error correction</strong></font>. <strong>Bio-nano optical maps</strong> were assembled into consensus physical maps by <strong>BioNano Solve</strong> v3.0.1 (<a href="https://bionanogenomics.com/">https://bionanogenomics.com/</a>, Solve_06082017Rel). Then <font color="red"><strong>HERA</strong></font> (Du and Liang, 2019) was used to combine PacBio contigs and Bionano based physical maps to <font color="blue"><strong>PacBio-BioNano hybrid scaffolds</strong></font>. To <font color="red"><strong>anchor</strong></font> hybrid scaffolds <font color="blue">into <strong>chromosomes</strong></font>, the <font color="blue"><strong>Hi-C</strong></font> sequencing data were <font color="red"><strong>aligned into scaffolds</strong></font> by <font color="red"><strong>Juicer</strong></font> (Durand et al., 2016) v1.5 and <font color="red"><strong>3D-DNA</strong></font> (Dudchenko et al., 2017).</p><h2 id="Repeat-Analysis-and-Gene-Annotation"><a href="#Repeat-Analysis-and-Gene-Annotation" class="headerlink" title="Repeat Analysis and Gene Annotation"></a>Repeat Analysis and Gene Annotation</h2><h2 id="Synteny-Analysis"><a href="#Synteny-Analysis" class="headerlink" title="Synteny Analysis"></a>Synteny Analysis</h2><p>Structural Variation Identification</p><p>Genetic Variation Analysis</p><p>Gene and miRNA Expression</p><p>Core and Dispensable Gene Family Clustering</p><p>CHS gene unit identification</p><p>Gene Fusion Event Identification</p><p>QUANTIFICATION AND STATISTICAL ANALYSIS</p><h1 id="4-2019-nc-大豆泛基因组-组装参考1"><a href="#4-2019-nc-大豆泛基因组-组装参考1" class="headerlink" title="4. 2019-nc 大豆泛基因组-组装参考1"></a>4. 2019-nc 大豆泛基因组-组装参考1</h1><p>HERA</p><h1 id="5-2019-09-scienceChina-大豆泛基因组-组装参考2"><a href="#5-2019-09-scienceChina-大豆泛基因组-组装参考2" class="headerlink" title="5. 2019.09-scienceChina 大豆泛基因组-组装参考2"></a>5. 2019.09-scienceChina 大豆泛基因组-组装参考2</h1><p><img src="/GeekFocus/./1.png" alt="1"></p><p>For genome assembly, we sequenced additional 40 Gb SMRT reads from 5 cells for this update. Therefore, a total of <strong>120× PacBio reads</strong>, <strong>365× Bionano optical maps</strong> marked by BssSI, <strong>275× Bionano optical maps</strong> marked by BspQI, <strong>45× HiSeq</strong> reads and <strong>125×</strong> chromosome conformation capture sequencing (<strong>Hi-C</strong>) reads were used for the new genome assembly (Figure 1A). To make best of the sequencing data, we also <font color="red"><strong>adopted a new genome assembly pipeline</strong> by <strong>adding HERA</strong></font> (Du and Liang, 2018) to improve the sequence contiguity and reduce errors by accurately assembling the repetitive genome regions (Figure 1A). Briefly, <font color="blue">the whole assembly process <strong>differed from</strong> previous pipeline</font> at </p><p>(1) using <font color="red"><strong>CANU</strong></font> (v1.7.1) to replace Smrtmake for assembling PacBio subreads to PacBio contigs; </p><p>(2) using <font color="red"><strong>HERA</strong></font> to generate longer contigs; </p><p>(3) using <font color="red"><strong>Juicer and 3D-DNA to replace HiC-Pro and LACHESIS</strong></font> to anchor the hybrid scaffolds into chromosomes with Hi-C reads.</p><h1 id="6-2020-05-nc-同源四倍体紫花苜蓿"><a href="#6-2020-05-nc-同源四倍体紫花苜蓿" class="headerlink" title="6. 2020.05-nc 同源四倍体紫花苜蓿"></a>6. 2020.05-nc 同源四倍体紫花苜蓿</h1><p>HiFi助力同源四倍体紫花苜蓿基因组组装，NC</p><blockquote><p>Allele-aware chromosome-level genome assembly and efficient transgene-free genome editing for the autotetraploid cultivated alfalfa</p></blockquote><p>（1）使用Canu默认参数，利用CCS clean reads组装contigs。组装得到的Contig N50值为459kb，总长度为3.15GB。</p><blockquote><p>We assembled contigs from CCS clean reads using Canu, with default parameters. The N50 values of the contig sets were 459 kb, with total lengths 3154 Mb.</p></blockquote><p>（2）使用HiC-Pro将Hi-C reads与contigs 进行比对，产生比对BAM文件。</p><blockquote><p>Hi-C reads were aligned to contigs using <a href="https://pubmed.ncbi.nlm.nih.gov/26619908/">HiC-Pro(2015)</a>, yielding an alignment BAM file.</p></blockquote><p>（3）使用注释的蒺藜苜蓿蛋白作为参考，完全基于同源的策略注释contigs。对138,729个同源基因进行了结构注释。用MCscan用于鉴定contigs和参考基因组之间的共线性。显示紫花苜蓿和蒺藜苜蓿之间的高共线性。【下载父母本petunia ref】</p><blockquote><p>Contigs were annotated with a <font color="red"><strong>solely homology-based strategy</strong></font>, using annotated Medicago truncatula proteins as references. 138,729 homologous genes were structurally annotated. <font color="red"><strong>MCscan</strong> in <strong>Jcvi</strong></font> (<a href="https://zenodo.org/record/31631#.XpkUyTOeask">https://zenodo.org/record/31631#.XpkUyTOeask</a>) was used to identify <font color="red"><strong>synteny blocks</strong></font> between <strong>contigs and the reference</strong> genome. <font color="red"><strong>Contigs syntenic</strong> to M. truncatula were <strong>stacked and aligned</strong> to M. truncatula chromosomes</font>. The syntenic contigs are summarized in Supplementary Table 4.</p></blockquote><p>（4）使用内部脚本处理BAM文件，去除等位基因contigs之间的links。使用ALLHiC软件，<font color="red">提取、聚类和重排Contigs</font> (Contigs syntenic与蒺藜苜蓿染色体一致)，得到原始的scaffolds。</p><blockquote><p>An <strong>in-house script</strong> was used to <font color="red">prune the BAM</font> file and <font color="red">discard links between allelic contigs</font>. Contigs syntenic to one chromosome of M. truncatula, e.g., chr1, were extracted, sub-clustered and reordered using <font color="red">ALLHiC</font>, yielding a raw scaffold set.</p></blockquote><p>（5）<a href="https://pubmed.ncbi.nlm.nih.gov/27467250/">Juicebox</a>用于以图形和交互方式微调组装的scaffolds。剪裁了40个总长度达1800Mb的scaffolds 。</p><blockquote><p>Juicebox45 was used for fine-tuning assembled scaffolds in a graphic and inter-active fashion. Forty scaffolds with a total length of 1800 Mb were cropped (Supplementary Table 5).</p></blockquote><p>（6） 基于组装的scaffold，通过Hi-C数据，每个unplaced contig被分配到互作最强的那些contig cluster里。</p><blockquote><p>Based on this scaffold assembly, each unplaced contig was assigned to the contig cluster, to which the contig was most connected by Hi-C data.</p></blockquote><p>（7）使用ALLHiC对那些contig clusters再次进行重排和构建scaffold。</p><blockquote><p>Those contig clusters were reordered and scaffolded using ALLHiC. </p></blockquote><p>（8）使用Juicebox对scaffolds进行微调，并从scaffolds上去除不一致的contigs，产生最终的染色体基因组，其包含32条染色体(8个同源组，每个组中有4个等位基因染色体)，总长度为2738Mb，和419Mb未挂载到染色体水平的序列。</p><blockquote><p>Using Juicebox, scaffolds were fine-tuned and discordant contigs were removed from scaffolds, and the final chromosome assembly was generated, containing 32 chromosomes with a total length of 2738 Mb (Supplementary Table 6).</p></blockquote><h1 id="7-2021-11-gb-椰子🥥"><a href="#7-2021-11-gb-椰子🥥" class="headerlink" title="7. 2021.11-gb 椰子🥥"></a>7. 2021.11-gb 椰子🥥</h1><p>High-quality reference genome sequences of two coconut cultivars provide insights into evolution of monocot chromosomes and differentiation of fiber content and plant height</p><p>该研究绘制两个参考级别椰子基因组。揭示单子叶植物染色体的进化过程和椰子染色体的形成过程，分析高矮两种椰子耐盐，株高，纤维和脂质含量等关键性状的遗传差异，同时发现椰子进化过程中约在400万年前自然发生的绿色革命。高椰子2.39G矮椰子2.40G。基于椰子，紫萍，菠萝等基因组的共线性关系，重新构建了含有10条染色体的古单子叶植物基因组核型，并对基因组核型的进化路线进行推断。进一步利用叶间距表型进行全基因组关联分析，鉴定出12号染色体上GA20ox基因与椰子株高显著相关，并存在拷贝数变异；整合多种手段验证HA20ox以及赤霉素代谢途径在高矮种的差异并导致株高差异。400万年前，绿色革命。</p><h2 id="Hi-C-based-genome-assembly"><a href="#Hi-C-based-genome-assembly" class="headerlink" title="Hi-C-based genome assembly"></a>Hi-C-based genome assembly</h2><p>Both Cn. tall and Cn. dwarf genomes were assembled de novo using SMARTdenovo (<a href="https://github.com/ruanjue/smartdenovo">https://github.com/ruanjue/smartdenovo</a>) [-k 19 -J 3000] based on <font color="red"><strong>Nanopore long reads</strong></font> <strong>corrected</strong> with <font color="red"><strong>NextDenovo</strong></font> (<a href="https://github.com/Nextomics/NextDenovo">https://github.com/Nextomics/NextDenovo</a>). Raw contigs were <font color="blue"><strong>polished</strong></font> using <font color="blue"><strong>Nanopore long reads</strong></font> and <font color="blue"><strong>Illumina short reads</strong></font> with <font color="red"><strong>Next-Polish</strong></font> (v1.2.2) [49]. Then polished contigs were <font color="blue"><strong>anchored</strong></font> into chromosomes by using <font color="red"><strong>HiC-Pro (v2.11.1)</strong></font> [50] and <font color="red"><strong>LACHESIS</strong></font>[51]. Finally, the assembled genomes were <font color="blue"><strong>manual correction</strong></font> with <font color="red"><strong>Juicebox</strong></font> (v1.11.08).</p><p>To assess the quality of assembled genomes, raw Illumina <font color="blue"><strong>paired-end</strong> reads and <strong>RNA-seq</strong></font> reads from multiple tissues were <font color="blue"><strong>mapping</strong></font> to the genomes using <font color="red"><strong>BWA (v0.7.17-r1188)</strong></font> [52] and <font color="red"><strong>HISAT2 (v2.1.0)</strong></font> [53], respectively. In addition, Benchmarking Universal Single-Copy Orthologs (<font color="red"><strong>BUSCO</strong></font>) was also used to assess the genome completeness base on Embryophyta Plant database (odb10) [54].</p><h1 id="8-2021-11-nc-金粟兰基因组"><a href="#8-2021-11-nc-金粟兰基因组" class="headerlink" title="8. 2021.11-nc 金粟兰基因组"></a>8. 2021.11-nc 金粟兰基因组</h1><p>填补核心被子植物最后主要分支-金粟兰目的基因组信息，提供被子植物早期演化证据。刘建全团队致力于解析类群演化，探究不同物种间分化适应遗传机制。</p><p>被子植物（Angiosperms or flowering plants）是地球上分布范围最广、多样化最高、适应性最强的陆生植物类群，极大地影响了其他生物类群的演化进程，然而，由于被子植物在早期经历了快速的辐射进化，其内部演化关系迟迟未被解决，这一问题也被称为达尔文的“恼人之谜”。经过前人长时期的努力，目前被子植物被划分为：无油樟目、睡莲目、木兰藤目和核心被子植物（Mesangiospermae）。无油樟目、睡莲目、木兰藤目共同被称为ANA grade，是被子植物的基部类群，系统发育关系相对稳定，而核心被子植物包含了~99.95%的被子植物，又可被划分为5大类群：双子叶、单子叶、木兰类、金鱼藻目和金粟兰目，它们之间的演化关系一直存在争议。近年来，随着各类群代表物种全基因组测序相继完成，其各自的进化历程均有了坚实而可靠的证据，刘建全团队在2020年首次报道了金鱼藻和芡实的基因组，证明了核心被子植物内部存在广泛的不完全谱系分选和杂交事件是导致树形冲突的主要原因。但是金粟兰目一直未有基因组报道，其演化历程以及整个核心被子植物的演化过程还有待深入分析。为此该团队再次利用Nanopore、Illumina和Hi-C技术，构建了第一个金粟兰目植物（四川金粟兰，<em>Chloranthus sessilifolius</em>）的高质量染色体级别基因组，Contig N50高达53.74 Mb（图1），使用多种分析方法对上述问题进行了深入的阐述。</p><p>通过使用多种系统发育基因组学分析，包括单拷贝基因、低拷贝基因和共线性基因数据集，进行了串联树和溯祖树的构建，同时评估了长枝吸引、物种选择和同源聚类方法等的影响，使用多套数据集合和多种分析方法，获得了高可信度的拓扑结构，即金粟兰目和木兰类具有最近的亲缘关系，且他们一起与金鱼藻目+双子叶植物构成姊妹关系，而单子叶植物是其它所有核心被子植物的姊妹枝（图2）。</p><p>同时，作者也发现了大量的基因树或叶绿体树与物种树不一致的情况，因此着重评估了不完全谱系分选（ILS）和杂交事件对此冲突的贡献。通过PhyloNetworks分析鉴定到了三次可能的杂交事件，可以解析部分的树形冲突。然而值得注意的是五大类群之间的分化时间仅有23个百万年（158~135 Mya），如此短的分化时间，ILS可能发挥了更为主要的作用。使用theta参数对每个内部分支发生ILS的概率进行评估发现，除了木兰类和金粟兰目的姊妹关系较为稳定外，其他类群间都具有较高的theta值，而金鱼藻目+双子叶的祖先分枝具有较高的tehta值，均表明了ILS在核心被子植物内部的演化中发挥了重要作用（图3 a和b）。基于Phyabse和DendroPy进行树形模拟表明，当存在ILS时模拟的树形和真实树形具有高度一致性（R2＞0.99），而不存在ILS的模拟树形与真实树形则具有较低的相关性，进一步表明了ILS在核心被子植物的快速辐射中发挥了重要作用（图3 c-f）。进一步对树形异质性进行区分表明，ILS可基本解释金鱼藻目+双子叶的祖先枝上的树形冲突，也就是金鱼藻目+双子叶、木兰类+金粟兰和单子叶之间的冲突，而其他核心被子植物类群间的冲突还有其他因素（例如杂交）的参与。</p><p>此外，本研究还鉴定了四川金粟兰独有的一次WGD事件，同时5大核心被子植物分枝的加倍事件都不共享；鉴定了花发育相关的基因家族，解析了其特有花器官的可能形成原因；鉴定了萜类合成和木质部形成相关的基因家族，为今后研究其简单木质部形成和萜类物种合成通路演化提供了基础。</p><p>综上所述，该研究报道了高质量的四川金粟兰基因组，填补了核心被子植物金粟兰目的基因组信息，并通过多种分析策略和方法，深入的揭示了核心被子植物间的复杂演化历程，该成果对于早期被子植物的起源、辐射进化以及适应性演化提供数据支撑和理论基础。</p><h2 id="Genome-size-estimate-and-assembly"><a href="#Genome-size-estimate-and-assembly" class="headerlink" title="Genome size estimate and assembly."></a>Genome size estimate and assembly.</h2><p>To estimate the genome size of C. sessilifolius, we surveyed 150 bp paired-end reads, computed 21 bp K-mer frequencies using <font color="red"><strong>Jellyfish</strong></font>, and exported the resulting histogram into <font color="red">findGSE</font>. <font color="red"><strong>Nextdenovo</strong></font> (https:&#x2F;&#x2F; github.com&#x2F;Nextomics&#x2F;Nextdenovo) was selected for <font color="blue"><strong>correcting reads</strong></font> with para- meters “read_cutoff&#x3D;2k, seed_cutoff&#x3D;30k, blocksize&#x3D;1.5g” and then <font color="red"><strong>Smartdenovo</strong></font> (<a href="https://github.com/ruanjue/smartdenovo">https://github.com/ruanjue/smartdenovo</a>) for <font color="blue"><strong>de novo assembly</strong></font> with parameters “wtpre -J 3,000; wtzmo-k 21 -z 10 -Z 16 -U -1 -m 0.1 -A 1000; wtclp -d 3 -k 300 -m 0.1 -FT; wtlay -w 300 -s 200 -m 0.1 -r 0.95 -c 1”. <font color="blue">The preliminary contigs were further <strong>polished</strong> by aligning the Illumina <strong>short</strong> <strong>reads</strong> to the contigs</font> using <font color="red"><strong>Nextpolish</strong></font>. After four rounds of successive iterative correction, the final genome sequence was obtained. The GC content and sequencing coverage analyses were applied to evaluate the presence of contamination. The quality of the genome assembly was also assessed using <font color="red"><strong>BUSCO</strong></font> (Benchmarking Universal Single-Copy Orthologs) with the embry- ophyta_odb10 database. The clean <font color="blue">Hi-C</font> data were mapped to contig sequences by <font color="red"><strong>Bowtie2</strong></font> and 354 Mb valid interaction pairs were extracted. Based on those chromatin interactions, <font color="red"><strong>LACHESIS</strong></font> was employed to <font color="blue"><strong>cluster</strong>, <strong>order</strong>, and <strong>orient</strong> the <strong>contigs</strong> into <strong>pseudo-chromosomes</strong></font>.</p><h1 id="9-2022-01-gb-油茶"><a href="#9-2022-01-gb-油茶" class="headerlink" title="9. 2022.01-gb 油茶"></a>9. 2022.01-gb 油茶</h1><blockquote><p>The genome of oil-Camellia and population genomics analysis provide insights into seed oil domestication</p></blockquote><p>油茶是我国传统木本油料树种，具有2300余年栽培食用历史。自上世纪起，经过四代科技工作者艰苦努力，我国油茶主栽良种衍生出数百个品种。但受制于<font color="blue">多倍性、长时效</font>特性，油茶育种工作效率不高。</p><p>2022年1月10日，中国林业科学研究院亚热带林业研究所（亚林所）研究员<strong>姚小华团队</strong>和<strong>殷恒福团队</strong>在<strong>《基因组生物学》（Genome Biology）</strong>发表最新论文。</p><p>该研究成功组装全球首个染色体级别高质量油茶基因组，揭示<font color="red">油茶物种<strong>进化历史</strong>及其<strong>种子含高油脂</strong>、<strong>高不饱和脂肪酸</strong>的<strong>驯化机制</strong></font>，建立了油脂性状早期选择技术体系，为加快良种选育效率、保障我国粮油安全奠定了基础。</p><h2 id="抱子怀胎的油茶良种育种缓慢"><a href="#抱子怀胎的油茶良种育种缓慢" class="headerlink" title="抱子怀胎的油茶良种育种缓慢"></a>抱子怀胎的油茶良种育种缓慢</h2><p>良种是农业生产的“芯片”。作为我国四大油料作物之一，油茶是农民增收、粮油安全、生态建设的“重要法宝”。我国油茶育种历经了选择育种和定向杂交育种阶段，主栽良种由家系品种、农家品种走向无性系良种，衍生出数百个品种，构成了我国油茶产业的发展基础。</p><p>但由于油茶结实之前要经历漫长的童期，而且从<font color="blue">开花到果实成熟需要整整1年时间</font>，俗称‘抱子怀胎’，导致油茶育种年限长，新品种选育缓慢，良种选育速度无法满足产业发展的需求，已成为阻碍油茶产业发展的重要因素。</p><p>我国长期面临食用油供需压力，对外依存度高达60%。油茶能够利用我国亚热带区域的宜林山地种植，不与粮争地，是保障我国粮油安全、实现乡村振兴的重要抓手。</p><p>油茶泛指山茶科山茶属植物中油脂含量高，具有一定栽培面积的，有经济栽培价值的物种的总称，是我国主推的重要木本油料树种。我国现有油茶种植面积7000万亩，以普通油茶（Camellia oleifera）为主，年总产值1200亿元左右。</p><p>油茶籽油中不饱和脂肪酸达90%以上，其中以单不饱和脂肪酸油酸为主，富含角鲨烯、维生素E、甾醇、多酚等功能成分，具有极高的保健价值，被誉为“液体黄金”。</p><p>然而研究发现, 油茶基因组具有<font color="red"><strong>杂合率高、重复序列占比大</strong>的特点，其杂合率达到了<strong>2.52%</strong></font>，远高于大部分已测序的物种，这为基因组组装带来了巨大挑战。</p><h2 id="染色体级别组装"><a href="#染色体级别组装" class="headerlink" title="染色体级别组装"></a>染色体级别组装</h2><p>经过四年多的努力，该团队获得大小为<font color="red">2.95 GB，Contig N50为<strong>1.002 MB</strong></font>的二倍体油茶（CON）的基因组图谱，并将基因组<font color="red">锚定到15条染色体</font>，锚定率达到<font color="red">91.33%</font>，获得了质量优良的油茶基因组图谱。</p><p><img src="/GeekFocus/./2.png" alt="油茶基因组图谱及其进化"></p><p>同时，利用控制杂交的群体建立<font color="red"><strong>高密度的遗传标记连锁图谱</strong></font>，对<font color="red">基因组<strong>图谱组装</strong>进行进一步<strong>校正</strong></font>，为未来重要性状的基因定位提供支撑。</p><p>油茶物种起源与分布主要集中在我国南方亚热带地区。通过对油茶基因组的比较分析，发现油茶基因组共发生<font color="red"><strong>两次全基因组复制</strong>事件</font>：第一次为古老的<font color="red">γ复制</font>，第二次发生在<font color="red"><strong>山茶属与猕猴桃属</strong>分化前不久</font>。</p><p>而山茶属形成之后并没有发生特殊的全基因组复制事件。通过山茶—猕猴桃、山茶—柿、柿—猕猴桃<font color="red"><strong>属间同源突变率的比较</strong></font>印证这一观点。</p><p><img src="/GeekFocus/./3.png" alt="油茶基因组重复序列分析"></p><p>山茶属包括200多个物种，包括以<strong>普通油茶</strong>为代表的油茶组、以<strong>茶</strong>为代表的茶组和以<strong>山茶花</strong>为代表的山茶组等。系统发育和分子钟标定分析发现，<strong>油茶和茶的分化</strong>发生在大约17.3百万年前。</p><p>在长期栽培驯化中，区别于以叶用为目的的茶和以观赏为目的的山茶，油茶在人工选择作用下进化成以种子油脂为主要栽培目的的木本油料树种，使得油茶成为研究植物种子<font color="red"><strong>油脂性状驯化</strong></font>的绝佳材料。</p><p>为进一步揭示油茶油脂性状驯化的分子机制，该团队利用全国分布区内的<font color="red">221个代表品种</font>开展<font color="red"><strong>群体转录组测序和关联分析</strong></font>。结果发现在长期<strong>驯化</strong>过程中，油茶果实逐渐<strong>增大</strong>，种仁油脂含量显著<strong>提高</strong>，油脂品质不断<strong>优化</strong>，形成了目前主栽的果大、含油率高、油脂品质优良的栽培类型。</p><p>进一步分析发现驯化过程中，油茶基因组中<font color="red"><strong>油脂代谢通路</strong>中的多个<strong>基因</strong>受到了<strong>显著的人工选择</strong></font>。此外，<font color="red">胁迫应答、激素生物合成</font>等通路也受到显著选择。</p><p>为了挖掘高度可信的油脂代谢关键基因，联合采用<font color="red"><strong>基因组遗传变异、基因表达水平和表型性状变异关联分析</strong></font>。令人惊讶的是，在<font color="red">筛选出的<strong>21个候选</strong>基因</font>中，有<font color="red"><strong>14个</strong></font>属于油脂合成和分解代谢通路基因。</p><p><img src="/GeekFocus/./4.png" alt="油茶品种群体关联分析发掘油脂产量与品质的调控基因"></p><p>其中，油脂代谢通路中的8个基因和植物激素相关转录因子IAA26在长期<strong>栽培驯化</strong>过程中<strong>形成</strong><font color="red"><strong>显著</strong>的<strong>单核苷酸多态性</strong>和<strong>表达水平差异</strong></font>。“这8个基因既包括<font color="red">油脂合成</font>基因，也有<font color="red">油脂分解代谢</font>基因，这表明油茶<font color="red"><strong>油脂性状</strong></font>是由参与合成和分解的<font color="red"><strong>两类基因协同调控</strong></font>的结果。</p><h2 id="Genome-sequencing-de-novo-assembly-and-annotation"><a href="#Genome-sequencing-de-novo-assembly-and-annotation" class="headerlink" title="Genome sequencing, de novo assembly, and annotation"></a>Genome sequencing, de novo assembly, and annotation</h2><p>The genomic DNA of CON was prepared by using the young <strong>leaves</strong>. Ten 20 kb de novo SMRTbell libraries were constructed according to the standard manufacturer’s protocol and used for <font color="red">SMRT PacBio</font> genome sequencing. A total of 27,876,348 reads (total size of <strong>320 G</strong>) were generated and used for initial assembly by the <font color="red"><strong>Falcon</strong></font> (v0.3.0) pipeline. The <font color="red"><strong>HaploMerger2</strong></font> (v20180603) program (default parameters) was used to <strong>reduce the redundancy</strong>, and <font color="red"><strong>Arrow program</strong></font> with default parameters was used to <strong>correct</strong> the sequencing <strong>errors</strong>. Further, a total of <font color="red">210 G</font> clean data generated by the <strong>Illumina</strong> Nova- Seq6000 platform was used to <font color="red">correct</font> the PacBio reads.</p><p>To circumvent the high heterozygosity of the CON genome, a <font color="red"><strong>hybrid assembly of strategy</strong></font> was used to construct the high-quality reference genome. The details of the <font color="red"><strong>BioNano, 10X Genomics, and Hi-C</strong></font> sequencing procedures were described in the Additional File 3: Method S1; and the hybrid assembly approach was described in <strong>Additional File 2</strong>: Fig. S3. Finally, to construct a chromosome-scale reference genome, the Hi-C chromosomal interaction was created using HiC-pro [38] software (v2.5.0) (<strong>Additional File 2</strong>: Fig. S4). </p><p>The <font color="red">repetitive elements</font> in the CON genome, including tandem repeats and interspersed repeats, were identified. Tandem repeats were discovered by <font color="red"><strong>Tandem Repeats Finder</strong></font> v4.07b. Interspersed repeats in the genome were identified using an integration of <strong>independent homology searching and de novo predictions</strong> (See details in Additional File 3: Method S2). Non-coding RNA genes (ncRNA) were annotated in this study (see details in Additional File 3: Method S2) and the results were shown in Additional File 1: Table S4.</p><p>We <font color="red">annotated</font> the assembled genome through combining three different approaches: <font color="red"><strong>ab initio prediction, homology-based prediction,</strong> and <strong>transcriptome alignment</strong></font>. To ob- tain the transcriptome data, the total RNA of seven different tissues from CON was se- quenced using the Illumina NovaSeq platform. The transcripts homolog prediction was performed initially by MAKER (v2.31.10); Augustus (v3.3.1) and SNAP (v2006-07-28) were used for de novo prediction. Finally, both homolog and de novo prediction results were integrated using MAKER and resulted in the final gene models (Additional File 1: Table S5; see details in Additional File 3: Method S2)</p><p><font color="red"><strong>Functional annotation</strong></font> was achieved by comparing predicted proteins against public databases, including NCBI non-redundant protein sequences database (Nr), SwissProt (201709) [39], eggNOG [39], KEGG (v84) [40], Interpro (v5.16-55.0) [41], and GO [42] using Blast (v2.2.3) [43].</p><p><img src="/GeekFocus/./5.png" alt="5"></p><p>PacBio+illumina : Falcon+Arrow+BWA+Pilon+HaploMerger-&gt;contigs</p><p>scaffold+HiC : <font color="red"><strong>JUICER+3D-DNA</strong></font></p><h1 id="10-2022-01-HorticRes-甘菊"><a href="#10-2022-01-HorticRes-甘菊" class="headerlink" title="10. 2022.01-HorticRes 甘菊"></a>10. 2022.01-HorticRes 甘菊</h1><p><strong>The</strong> <em><strong>chrysanthemum lavandulifolium</strong></em> <strong>genome and the molecular mechanism underlying diverse capitulum types</strong></p><p><strong>菊花</strong>(<em>Chrysanthemum ×morifolium</em> Ramat.)是世界著名的观赏植物，具有千姿百态的花型。实际菊花的花是指由<font color="red"><strong>外围的舌状花</strong></font>和<font color="red"><strong>盘心的管状花</strong></font>共同构成的<font color="red"><strong>头状花序</strong></font>。其花型由头状花序上舌状花和管状花的形态和相对数量决定。解析同一头状花序上舌状花和管状花分化的分子调控机制不仅可以为阐明菊花复杂的头状花序形态奠定基础，也将为菊科植物头状花序发育提供新见解。但目前关于菊花花型的研究受到其复杂遗传背景的限制，导致无法充分利用菊花丰富的基因资源进行花型定向育种。因此，获得高质量的菊花及其近缘种的基因组信息并在此基础上<font color="red">研究<strong>头状花序发育</strong>的<strong>分子调控机制</strong></font>显得尤为必要。</p><p>近日，<em><strong>Horticulture Research</strong></em>在线发表了<strong>北京林业大学戴思兰团队</strong>题为<em><strong>The Chrysanthemum lavandulifolium genome and the molecular mechanism underlying diverse capitulum types</strong></em> 的研究论文。该论文完成<font color="red"><strong>菊花近缘野生种</strong>之一<strong>甘菊</strong></font>(C. lavandulifolium)的全基因测序工作，获得了染色体水平上的高质量甘菊参考基因组，结合<font color="red"><strong>3种不同类型菊科植物头状花序</strong>的<strong>转录组数据</strong></font>初步解析了头状花序发育的<strong>分子调控机制</strong>，为实现人工调控菊花花型奠定了坚实的分子理论基础。</p><p>甘菊为菊属植物中的<strong>二倍体物种</strong>，采用<strong>Illumina + Pacbio + Hi-C</strong>测序技术对其进行全基因测序，获得了2.60 Gb的染色体水平的参考基因组。其中<font color="red">94.46%的序列锚定到<strong>9条染色体</strong>上</font>。甘菊基因组中重复序列占基因组的67.69%，<em>Cypsy</em>和<em>Copia</em>的占比分别为37.92%和29.06%，插入时间在1.25百万年前。<font color="red"><strong>比较基因组分析</strong></font>结果表明，甘菊经历了<font color="red"><strong>两次全基因组复制(WGD)事件</strong></font>，其中<font color="red"><strong>最近一次</strong>是所有<strong>菊科植物共有</strong></font>，而<font color="red"><strong>较早一次</strong>是核心双子叶植物共有的<strong>γ事件</strong></font>，**甘菊自身没有发生WGD，其基因组演化的动力来源主要是<font color="red">串联重复事件</font>**。</p><p><img src="/GeekFocus/./6.png" alt="overview and genome evolution"></p><p>基于<font color="blue">甘菊头状花序发育的6个重要时期</font>和<font color="blue">其他菊科植物不同类型头状花序发育关键时期</font>的<font color="red">转录组</font>有参分析发现，MADS-box、TCP、NAC和LOB基因家族<font color="red">可能参与<strong>管状花和舌状花的分化</strong></font>。值得注意的是，<em>NAM</em>和<em>LOB30</em>高表达于舌管兼备型的头状花序中，而在全舌型和全管型的头状花序中表达量相对较低，这表明其可能是参与两类小花分化的关键基因。结合关键基因在全舌型、全管型以及舌管兼备型的头状花序中的表达模式和蛋白互作模式，初步推测并构建了不同类型头状花序发育可能的调控机制。在全管型头状花序中，<em>CUC2</em>与<em>LFY</em>和<em>AG</em><font color="red"><strong>共同调控</strong>管状花原基的起始</font>。而CUC2和CUC3的<font color="red"><strong>互作及协同表达</strong>则会<strong>促进</strong>全舌型头状花序中舌状花原基的起始</font>。在舌管兼备型的头状花序中，<em>NAM</em>和<em>LOB30</em>的表达则参与<font color="red"><strong>调控</strong>舌状花和管状花原基的分化</font>。LOB30可以与LFY, TFL1, CUC2, CUC3和NAM互作，表明其在基因调控网络中的核心位置。总之，<em>NAM</em>和<em>LOB</em>不仅可以与花序分生组织相关基因如<em>LFY</em> 等互作，也可以与两类小花身份决定基因如<em>CYC2</em>-<em>LIKE</em>等基因互作，这表明<em><strong>NAM</strong></em><strong>和LOB30在头状花序上舌状花和管状花原基分化调控中的关键角色</strong>。</p><p><img src="/GeekFocus/./7.png" alt="The expression patterns of NAM/CUC and LOB30 homologous genes in ten asteraceae species"></p><p><img src="/GeekFocus/./8.png" alt="the probable gene regulation mechanism in the development of different capitula types"></p><p><strong>高质量甘菊参考基因组的获得不仅可以为栽培菊花基因组的破译提供有效的参考，更为解析菊花乃至菊科植物多样的生物学性状提供丰富的基因资源。</strong></p><p>北京林业大学戴思兰课题组一直致力于菊花研究，基于<font color="blue">植物系统学研究方法</font>对<font color="blue">菊属植物种间<strong>亲缘关系</strong>和菊花<strong>品种起源</strong></font>进行探索，在<font color="red"><strong>种质资源评价，花色、花型、开花期</strong>和<strong>抗逆性</strong>等观赏性状形成的<strong>分子机理</strong></font>，菊花<font color="blue">优异种质创制</font>以及<font color="blue">产业化栽培技术</font>等开展全面研究，取得了一系列重要突破性进展和研究成果。</p><p>2.6G：scaffold Num 178；scaN50 300M；N90 212M；Longest 322M</p><h2 id="Genome-assembly-and-quality-assessment"><a href="#Genome-assembly-and-quality-assessment" class="headerlink" title="Genome assembly and quality assessment"></a><strong>Genome assembly and quality assessment</strong></h2><p>For the <font color="blue">PacBio RSII</font> platform data, <font color="blue">longer subreads were <strong>selected</strong></font> by the <font color="blue">error correction module</font> of <font color="red"><strong>canu v1.5</strong></font> [35]. <font color="blue">Raw overlapping subreads were <strong>detected</strong></font> through the highly sensitive overlap detection program <font color="red"><strong>MHAP v2.1</strong></font> [36], and the <font color="blue">error correction of these data was <strong>carried</strong></font> out by the <font color="red"><strong>Falcon</strong></font> sense method v0.40 (“correct- edErrorRate &#x3D; 0.025”) [37]. The error-corrected subreads were used to <font color="blue">generate a <strong>draft assembly</strong></font> in <font color="red"><strong>WTDBG v2.5</strong></font> (<a href="https://github.com/ruanjue/wtdbg">https://github.com/ruanjue/wtdbg</a>). <font color="blue"><strong>Iterative polishing</strong></font> by <font color="red"><strong>Pilon v1.22</strong></font> [38] was achieved by <font color="blue"><strong>aligning</strong></font> adapter-trimmed and paired-end <font color="blue">Illumina <strong>reads</strong> to the <strong>PacBio draft genome</strong></font>. <font color="red"><strong>Clean nanopore data</strong></font> were acquired via sequencing on the PromethION platform, and these data were <font color="blue">corrected with the same method</font> described above. The draft genome assembled by <font color="red"><strong>WTDBG v2.5</strong></font> (https:&#x2F;&#x2F; github.com&#x2F;ruanjue&#x2F;wtdbg) was <font color="blue"><strong>corrected</strong> three times</font> by <font color="red"><strong>Racon v1.3.3</strong></font> [39] by aligning adapter-trimmed and paired-end Illumina reads to the <font color="blue"><strong>Nanopore draft genome</strong></font>. Then, the <font color="blue">PacBio draft genome as a <strong>query input</strong></font> was <font color="blue"><strong>aligned against</strong> the <strong>Nanopore draft genome</strong></font> using <font color="red"><strong>MUMmer v4.0.0</strong></font> [40]. The PacBio draft genome and Nanopore <font color="blue"><strong>draft genome</strong></font> were then <font color="blue"><strong>merged</strong></font> using <font color="red"><strong>quickmerge v0.3.0</strong></font> [21]. This <font color="blue"><strong>merged draft genome</strong></font> was <font color="blue"><strong>polished</strong></font> by <font color="red"><strong>Racon v1.3.3</strong></font> [39] and <font color="red"><strong>Pilon v1.22</strong></font> [38]. The <font color="blue">mapping depth</font> was obtained by <font color="blue"><strong>aligning</strong> corrected Nanopore sequencing data</font> to the merged assembly by <font color="red"><strong>minimap2 v2.17</strong></font> [41] with default parameters. Then, <font color="red"><strong>purge haplotigs v1.0.4</strong></font> [22] was used to <font color="blue"><strong>eliminate</strong> redundancy according to the <strong>coverage depth</strong></font> and obtain the <font color="blue"><strong>purged haplotig genome</strong></font>. Ultimately, a <em>C. lavandulifolium</em> genome with a total length of <strong>3.10 G</strong>b was obtained. The second-generation sequencing data, core gene completeness and BUSCOs were evaluated to verify the accuracy of the genome assembly.</p><h2 id="Hi-C-sequencing-and-assistant-assembly"><a href="#Hi-C-sequencing-and-assistant-assembly" class="headerlink" title="Hi-C sequencing and assistant assembly"></a><strong>Hi-C sequencing and assistant assembly</strong></h2><p>Hi-C is a technology derived from chromosome conformation capture technology that utilizes high- throughput sequencing data and is mainly used to assist in genome assembly. We constructed Hi-C fragment libraries with insert sizes of 300–700 bp, as illustrated in Rao et al. [42], and sequenced them using the Illumina platform [42]. <font color="blue"><strong>Before</strong> <strong>chromosome assembly</strong>, we first performed a <strong>preassembly</strong> for the <strong>error correction of scaffolds</strong>, which required <strong>splitting the scaffolds into segments of 50 kb</strong>, on average</font>. Then, the Hi-C data were <font color="blue">mapped</font> to these segments using <font color="red"><strong>BWA</strong></font> aligner v0.7.10-r789 [43]. We <font color="red"><strong>retained</strong> the <strong>uniquely mapped</strong> data</font> to assemble the genome using <font color="red"><strong>LACHESIS</strong></font> [44] with the following <font color="green"><strong>parameters</strong>: CLUSTER_MIN_RE_SITES &#x3D; 80; CLUSTER_MAX_LINK_DENSITY &#x3D; 2; CLUSTER_NONINFORMATIVE_RATIO &#x3D; 2; ORDER_MIN_N_RES_IN_TRUN &#x3D; 16; ORDER_MIN_N_RES_IN_SHREDS &#x3D; 16</font>. To further address the redundant sequences, we manually checked any two segments that showed inconsistent connections with the raw scaffold. The detailed workflow schema for the assembly pipeline of the chromosome-scale <em>C. lavandulifolium</em> genome is shown in Supplementary Figure 24.</p><p><img src="/GeekFocus/./9.png" alt="9"></p><h1 id="11-2022-01-HorticRes-粉葛"><a href="#11-2022-01-HorticRes-粉葛" class="headerlink" title="11. 2022.01-HorticRes 粉葛"></a>11. 2022.01-HorticRes 粉葛</h1><p><em><strong>Chromosomal-level genome and multi-omics dataset of Pueraria lobata var. thomsonii provide new insights into legume family and the isoflavone and puerarin biosynthesis pathways</strong></em> </p><p>粉葛基因组及多组学分析为<font color="red">葛根素</font>等功效成分的生物合成研究提供新见解</p><p>广西壮族自治区农业科学院经济作物研究所严华兵团队。该研究利用<strong>PacBio</strong>、<strong>Illumina</strong>测序以及<strong>Hi-C</strong>技术测序组装，<strong>获得了首个<font color="red">豆科葛属药食同源植物粉葛</font>染色体级别的基因组</strong>，标志着粉葛研究迈入基因组时代，开启了<font color="blue">葛属<strong>进化</strong>、野葛<strong>驯化</strong>、粉葛<strong>品种改良</strong></font>之旅，助力广西特色优势粉葛产业高质量发展。</p><p>鉴于粉葛<font color="blue">杂合度较高</font>，研究者选用了PacBio和Hi-C测序，构建的粉葛基因组大小为<strong>1.38Gb</strong>，<font color="blue">Contig N50&#x3D;598kb</font>，并将<font color="blue">99.3%的序列<strong>锚定</strong>到11条染色体上</font>，BUSCO评估<font color="blue">92.9%</font>。通过注释，共获得45270个蛋白编码基因，其中<font color="blue"><strong>94.4%的基因</strong>可以得到<strong>功能注释</strong></font>，基因组中<font color="blue">重复序列</font>占比为62.7%。将粉葛<font color="red">与<strong>16个近缘物种</strong>(包含5个豆科植物)进行<strong>比较基因组</strong>分析</font>，结果表明6个豆科植物共有基因家族为11204个，粉葛基因组中<font color="blue"><strong>显著扩张的4743个基因家族</strong>主要富集在与<strong>类黄酮、生物碱、甾醇和萜类</strong>等生物合成相关的通路</font>；粉葛<font color="red"><strong>特有</strong>基因家族</font>为2373个，主要<font color="blue">富集在与<strong>萜类</strong>生物合成相关的通路</font>；粉葛基因组中受到<font color="blue"><strong>显著正选择</strong>的基因</font>共有34个，富集在<font color="blue"><strong>昼夜节律、同源重组、淀粉代谢和蔗糖代谢</strong></font>等途径。</p><p><font color="red"><strong>系统进化分析</strong></font>表明，粉葛<strong>与大豆亲缘关系最近</strong>，两者在20.1个百万年前产生分化。通过<font color="red"><strong>Ks</strong>和<strong>4DTV分析</strong></font>，<strong>粉葛共经历两次WGD事件</strong>，一次WGD事件是<font color="blue">大豆与粉葛<strong>共有</strong></font>，发生在44.5个百万年前；另一次WGD事件是在粉葛与大豆分化后，<font color="blue">粉葛<strong>独自</strong>经历</font>，发生时间大致在4.8个百万年前。</p><p>通过对高葛根素ZG-19和低葛根素ZG-39进行<font color="red"><strong>转录组</strong>和<strong>代谢组</strong>分析</font>，研究者检测到了614种225种差异代谢物(DMs)，1814个差异表达基因(DEG)，DMs和DEG的丰富功能类别<strong>重叠</strong>，这说明它们都是与<font color="blue">类黄酮、异黄酮和ABC转运相关的基因或代谢物</font>。进一步分析代谢物与基因表达的相关系数，结果表明代谢物和基因对在样本中高度相关，60%的显著相关性涉及上调的代谢物和下调或不变的基因，在15%的显著相关性中，代谢物和基因表达的变化方向相同。此外，研究者在异黄酮生物合成途径中发现了大量的DMs和DEG。<strong>这充分解析了粉葛中异黄酮的生物合成途径。</strong></p><p>通过<font color="red"><strong>同源基因搜索</strong></font>，研究者发现<font color="blue">编码<strong>葛根素合成途径</strong>中关键酶的9个基因家族</font>在粉葛中都有所<font color="blue">扩张</font>；通过分析糖基转移酶家族中催化糖基化修饰的基因，共鉴定出104个GT基因，有13个基因与8-C-葡萄糖基转移酶(8-C-GT)同源，其中6个与先前研究的催化大豆苷元C-糖基化为葛根素的PIUGT43基因同源；编码大豆异黄酮合酶(IFS)的基因(CHR11G3854.1)催化着葛根素合成的中间代谢物大豆苷元的合成，被鉴定为与葛根素的合成途径高度相关。总之，上述分析<strong>初步解析了粉葛中葛根素的生物合成途径。</strong></p><p><strong>综上，该研究通过构建高质量的粉葛基因组解析了粉葛基因组的<font color="red">进化特征</font>；通过多组学分析深入解析了粉葛中<font color="red">重要次生代谢物异黄酮、葛根素等生物合成途径</font>，从而为粉葛的资源利用、遗传育种等研究提供了新见解。</strong></p><p><strong>严华兵研究员团队在葛根上的研究进展：</strong></p><p><strong>严华兵</strong>团队近年<strong>在全球葛根资源收集与鉴定评价、葛属资源分类、葛根<font color="red">基因组与分子生物学</font>、粉葛和野葛品种选育、健康种苗生产、高产高效栽培等方面取得了一系列的成果</strong>。团队目前广泛收集全球葛属种质资源419份，包括野葛、粉葛、葛麻姆、大花葛、泰葛、苦葛、红葛、须弥葛、食用葛等；通过开发<strong>葛SSR分子标记</strong>，构建了广西葛核心种质库；通过<strong>广泛靶向代谢组</strong>解析葛属葛种野葛、粉葛和葛麻姆等3个变种块根中影响<strong>食用品质和药用品质</strong>的<strong>代谢差异</strong>；结合表型鉴定通过叶绿体基因组研究，揭示了葛及其<strong>近缘种之间的系统发育关系</strong>；挖掘了调控<strong>葛根素合成代谢相关的结构基因和转录因子</strong>，并正在开展相关基因功能验证工作；选育出适合开发葛花茶、高葛根素粉葛、无渣粉葛、药用野葛等系列葛根新品种，并逐步建立配套种苗繁育和高效栽培技术。</p><p>1.37G：contig Num 5145；conN50 593kb；</p><h2 id="Genome-survey"><a href="#Genome-survey" class="headerlink" title="Genome survey"></a>Genome survey</h2><p>Short reads produced by the Illumina 6000 platform were <font color="blue">quality-filtered</font> by <font color="red"><strong>HTQC</strong></font> [23] (version v1.92.310) using the following method. Adaptors were firstly removed from the sequencing reads, and read pairs with any one end having an average quality &lt;20 were discarded. Ends of reads were trimmed if average quality was &lt;20 in the sliding window size of 5 bp, and read pairs with <font color="red">any end <strong>shorter than 75 bp</strong> were removed</font>. The quality-filtered reads were used for estimation of genome size. The <strong>17-mer</strong> occurrence distribution of sequencing reads was generated from short libraries with <font color="red"><strong>Jellyfish</strong></font> [24] (v2).</p><h2 id="Genome-assembly"><a href="#Genome-assembly" class="headerlink" title="Genome assembly"></a>Genome assembly</h2><p>Subreads generated with the above long-read third-generation sequencing were used for genome assembly of <em>P. lobata</em>. The draft assembly of the genome was made using <font color="red"><strong>Falcon (v0.3.0)</strong></font> [25]. To <font color="blue"><strong>correct</strong> errors</font> in the primary assembly, <font color="red"><strong>Racon</strong></font> (v1.44) tools were used to <font color="blue"><strong>polish</strong></font> the genome [26]. <font color="blue">Illumina-derived <strong>short reads</strong></font> were used to <font color="blue"><strong>correct</strong></font> any <font color="blue"><strong>remaining errors</strong></font> by <font color="red"><strong>NextPolish (v1.1.0)</strong></font> [27].</p><p><font color="blue">To scaffold the contigs</font>, 425 011 698 clean-read pairs were sequenced from the Hi-C library. <font color="red"><strong>Fastp</strong></font> (0.19.5) [28] was used to filter Hi-C data, including <font color="blue"><strong>removing adaptors</strong> and l<strong>ow-quality</strong> reads</font>. <font color="red"><strong>HiC-Pro</strong></font> Proto was used to obtain effective reads [29]. After filtering, <font color="blue">6%【?】 of high-quality and effective Hi-C data was retained</font>. The <font color="blue">resulting <strong>effective reads</strong></font> were <strong>mapped</strong> to the <strong>assembled and polished</strong> <em>P. thomsonii</em> <strong>genome</strong> using <font color="red"><strong>BWA</strong></font> (bwa-0.7.17) [30] with default parameters. <font color="red"><strong>ALL-HiC</strong></font> software was used to <font color="blue"><strong>anchor</strong> scaffolds to chromosomes</font> to obtain the chromosome-level <em>P. thomsonii</em> assembly.</p><h1 id="12-2022-03-ng-四倍体土豆"><a href="#12-2022-03-ng-四倍体土豆" class="headerlink" title="12. 2022.03-ng 四倍体土豆"></a>12. 2022.03-ng 四倍体土豆</h1><blockquote><p>Chromosome-scale and haplotype-resolved genome assembly of a tetraploid potato cultivar</p></blockquote><p>##<strong>Genome size estimation.</strong> </p><p>After <strong>trimming</strong> off 10× genomics <font color="blue"><strong>barcodes and hexamers</strong></font> from the 370.3-Gb reads combined from the 10× single-cell CNV libraries and single-molecule libraries, <em>k</em>-mer counting (<em>k</em> &#x3D; 21) was performed with <font color="red"><strong>Jellyfish</strong></font> (v.2.2.10). The <em>k</em>-mer histogram was provided to <font color="red"><strong>findGSE</strong></font> (v.1.0)39 to estimate the haploid&#x2F;tetraploid genome size of ‘Otava’ under the <font color="blue">heterozygous mode</font> (with ‘exp_hom &#x3D; 200’; Extended Data Fig. 1).</p><p>##<strong>Initial tetraploid genome assembly, polishing and purging.</strong> </p><p>The initial assembly of the tetraploid genome was performed using <font color="red"><strong>hifiasm (v.0.7)</strong></font> with <strong>default settings</strong> with the 102 Gb raw PacBio HiFi reads of ‘Otava’, where the output consisting of <font color="red"><strong>unitigs</strong> (locally haplotype-resolved contigs)</font> was selected for <strong>further processing</strong>. </p><p>Then the <font color="blue">short reads</font> from the two 10× single-cell CNV libraries were <font color="blue"><strong>aligned</strong> to the assembly</font> using <font color="red"><strong>bowtie2 (v.2.2.8)</strong></font>. These <font color="blue">alignments were used to <strong>polish</strong> the <strong>assembly</strong></font> with <font color="red"><strong>pilon (v.1.22)</strong></font> with <font color="green"><strong>options</strong> of <strong>–fixbases –changes –diploid –mindepth 0.8</strong></font>. </p><p>Further, <font color="blue"><strong>short</strong> reads</font> of the two 10× single-cell CNV libraries, additional 10× single-molecule libraries <strong>and</strong> PacBio <font color="blue"><strong>HiFi</strong> reads</font> were <font color="blue"><strong>all aligned</strong> to the <strong>polished assembly</strong></font> (using <font color="red"><strong>bowtie2</strong></font> and <font color="red"><strong>minimap2</strong></font> (v.2.17-r491) respectively). Among <font color="blue">17,153 raw contigs, <strong>9,041 contigs</strong></font> which were <font color="blue">longer than <strong>50 kb</strong></font> and with an <font color="blue">average sequencing depth over <strong>80×</strong> were <strong>kept</strong></font>. </p><p><font color="blue">HiFi reads were <strong>re-aligned</strong> to the purged assembly and contigs covered less than 3× were <strong>removed</strong></font>. </p><p>The HiFi reads-based <font color="red"><strong>purging process</strong></font> was repeated for <font color="blue"><strong>five rounds</strong></font> to get an initial assembly of <font color="blue">6,366 contigs</font> for subsequent analysis (Supplementary Fig. 1).</p><p>##<strong>Haplotype-specific PacBio HiFi read separation and haplotype assembly.</strong></p><p>HiFi reads were <font color="blue">classified into 48 groups</font> on the basis of alignments to the 50-kb coverage markers using customized code. Specifically, to assign a read to a marker, at least 500 bp of the read had to be aligned to the marker (reads aligning two neighboring markers were assigned to the marker with a larger overlapping size). Reads overlapping non-haplotig marker were randomly assigned to one of the marker-associated groups.</p><p><font color="red"><strong>Each set</strong> of HiFi reads</font> was independently assembled using <font color="red"><strong>hifiasm</strong></font> (v.0.7) with default settings. The resulting contigs were first polished with <font color="red">short reads using <strong>pilon</strong></font> with <font color="green"><strong>–fix bases –changes –diploid –mindepth 0.8</strong></font> and then with <font color="red">HiFi reads using <strong>racon</strong></font> (v.1.4.10)46 with<font color="green"> <strong>-u –no-trimming</strong></font>.</p><p>##<strong>Evaluation of haplotyping accuracy.</strong> </p><p>For <font color="blue">each haplotype assembly</font> and the sequencing data of the parental genomes, <em>k</em>-mers (<em>k</em> &#x3D; 21) were counted using <font color="red"><strong>KMC</strong></font>. Specifically, <em>k</em>-mers found in ‘Hera’ but not in ‘Stieglitz’ (with a coverage<br>of 6–12), as well as <em>k</em>-mers found in ‘Stieglitz’ but not in ‘Hera’ (with a coverage of 5–11) were selected using kmc_tools simple. For each haplotype, the sets of assembled <em>k</em>-mers were intersected with the two sets of parental-specific <em>k</em>-mers (using kmc_tools simple with subfunction intersect), which revealed <strong><em>k</em>-mers common with either of the parental genomes</strong>. </p><p>As a haplotype can only be inherited from one of the parents, it is expected to find parental-specific *k-*mers only of one parent. The overall haplotyping precision was determined as the total number of correctly phased <em>k</em>-mers divided by the total number of <em>k</em>-mers investigated in the <font color="red"><strong>48 haplotype assemblies</strong></font>. Note, this was done <font color="rblueed">before and after contig <strong>polishing</strong></font>, where we observed the same haplotyping accuracy.</p><p>##<strong>Haplotype-specific contig scaffolding using group-specific Hi-C reads.</strong> </p><p><font color="blue">Each haplotype-specific contig-level assembly</font> was indexed with <font color="red"><strong>bwa index</strong></font> (with -a bwtsw) (v.0.7.15-r1140) and <font color="red"><strong>samtools faidx</strong></font>. The haplotype-specific Hi-C read pairs were aligned using <font color="red"><strong>bwa aln</strong> and <strong>bwa sampe</strong></font>. Aligned reads (in pairs) were <strong>converted into BAM</strong> files using samtools view with options of <font color="green">-b -F12</font>. The BAM files were filtered with <font color="red"><strong>filterBAM_forHiC.pl</strong></font> (from ALLHiC package, v.0.9.13) to <font color="blue"><strong>remove nonuniquely mapped reads</strong></font>. Then BAM files were converted to bed files using <font color="red"><strong>bamToBed</strong></font> (from bedtools package) and <font color="blue"><strong>sorted</strong> by read name</font>. The <strong>bed files</strong> were provided to <font color="red"><em><strong>SALSA2</strong></em></font> (run with <font color="green">-s 100000000 -m yes -i 10 -e DNASE</font>). Potential chimeric contigs were broken at the chimeric sites given by SALSA2 output file of input_breaks, leading to a <font color="blue"><strong>new set</strong> of contigs for each of the 48 original groups</font>.</p><p>For <font color="blue">each new group of contigs</font>, the above process of <font color="red"><strong>contig indexing, Hi-C read alignment</strong> and <strong>BAM filtering</strong></font> was repeated. Then, for each haplotype, <font color="red"><strong>ALLHiC_ partition</strong></font> was run with <font color="green">-e GATC -k 1 -m 25</font>; <font color="red"><strong>allhic extract</strong></font> was run with <font color="green">–RE GATC</font>; allhic optimize and <font color="red"><strong>ALLHiC_build</strong></font> were run with <font color="green">default settings</font>; the chromosome contact map was visualized with <font color="red"><strong>ALLHiC_plot</strong></font> at <font color="green">1-Mb</font> resolution, where obvious mis-placement&#x2F;orientation of large contigs were visually identified and manually corrected (Extended Data Fig. 3).</p><h1 id="13-2022-03-ng-六倍体小麦"><a href="#13-2022-03-ng-六倍体小麦" class="headerlink" title="13. 2022.03-ng 六倍体小麦"></a>13. 2022.03-ng 六倍体小麦</h1><blockquote><p>Long-read genome sequencing of bread wheat facilitates disease resistance gene cloning</p></blockquote><table><thead><tr><th>Genomic feature</th><th>Value</th></tr></thead><tbody><tr><td><em><strong>Length of HiFi assembly</strong></em></td><td>14.66 Gb</td></tr><tr><td>Number of contigs</td><td>5,055</td></tr><tr><td>Length of contig N50</td><td>30.22 Mb</td></tr><tr><td>Length of contig N90</td><td>5.5 Mb</td></tr><tr><td><strong><em>Length of hybrid assembly</em>a</strong></td><td>14.68 Gb</td></tr><tr><td><em><strong>Length of hybrid scaffolds</strong></em></td><td>14.46 Gb</td></tr><tr><td>Number of hybrid scaffolds</td><td>324</td></tr><tr><td>Length of hybrid scaffold N50</td><td>204.26 Mb</td></tr><tr><td>Gap size</td><td>18.8 Mb (0.13%)</td></tr><tr><td><em><strong>Length of pseudomolecule assembly</strong></em></td><td>14.68 Gb</td></tr><tr><td><em><strong>Total length of anchored pseudomolecules</strong></em></td><td>14.45 Gb</td></tr><tr><td>Number of anchored hybrid scaffolds or contigs</td><td>717</td></tr><tr><td>Gap size</td><td>11.6 Mb (0.08%)</td></tr><tr><td>Number of high-confidence genes</td><td>110,383</td></tr><tr><td><em><strong>Total length of unanchored chromosome</strong></em></td><td>224.01 Mb</td></tr><tr><td>Number of unanchored hybrid scaffolds or contigs</td><td>3,910</td></tr><tr><td>Gap size</td><td>8.1 Mb (3.6%)</td></tr><tr><td>Number of high-confidence genes</td><td>6,455</td></tr><tr><td><em><strong>BUSCO</strong></em></td><td></td></tr><tr><td>Complete</td><td>99.4%</td></tr><tr><td>Duplicated</td><td>96.3%</td></tr><tr><td>Fragmented</td><td>0.1%</td></tr><tr><td>Missing</td><td>0.5%</td></tr></tbody></table><h2 id="Genome-assembly-and-validation"><a href="#Genome-assembly-and-validation" class="headerlink" title="Genome assembly and validation."></a><strong>Genome assembly and validation.</strong></h2><p>The PacBio HiFi reads were assembled using <font color="red"><strong>hifiasm12 (v.0.11)</strong></font> with <font color="green">default parameters</font>. Hybrid scaffolding incorporating the PacBio contigs and the <font color="blue">optical map</font> was performed using the <font color="red"><strong>hybridScaffold pipeline</strong></font> (Bionano Solve 3.6) with default parameters. For the pseudomolecule construction, the Omni-C reads were incorporated using <font color="red"><strong>Juicer tools (v.1.6)</strong></font> and <font color="red"><strong>3D-DNA (v.180114)</strong></font>. </p><p>In brief, the preprocessing of the Omni-C reads was performed with juicer.sh (parameter: -s none). The ‘merged_nodups.txt’ output file corresponding to the Hi-C contacts with duplicates removed was subsequently used with run-asm-pipeline.sh (parameter: -r 0) as input to produce the ‘.hic’ and ‘.assembly’ files. These files were uploaded into Juicebox (v.1.11.08) to visualize the Hi-C map and for manual curation. </p><p>As a final step, the script <font color="red"><strong>run-asm-pipeline-post-review.sh</strong></font> (default parameters) was used to save the final Hi-C contact map and to output the final Kariega assembly (21 pseudomolecules and 1 unanchored pseudochromosome). To <font color="blue"><strong>validate</strong> the genome assembly</font>, we remapped the optical map onto the pseudomolecule using the <font color="red"><strong>hybridScaffold pipeline</strong></font> (Bionano Solve 3.6), and the final pseudomolecules were compared with the recent bread wheat assemblies of Chinese Spring (IWGSC RefSeq v.2.1) and the assemblies of the 10+ Wheat Genomes Project using <font color="red"><strong>MashMap</strong></font> (v.2.0; parameter: -s 300000–pi 98).</p><h1 id="14-2019-10-二倍体巴特利特梨-【四倍体土豆参考hic组装1】"><a href="#14-2019-10-二倍体巴特利特梨-【四倍体土豆参考hic组装1】" class="headerlink" title="14.  2019.10 二倍体巴特利特梨 【四倍体土豆参考hic组装1】"></a>14.  2019.10 二倍体巴特利特梨 【四倍体土豆参考hic组装1】</h1><blockquote><p>Pseudo-chromosome–length genome assembly of a double haploid “Bartlett” pear (<em>Pyrus communis</em> L.)</p></blockquote><p><strong>Genome assembly and scaffolding</strong></p><p>The genome assembly workflow began with <em>de novo</em> assembly of contigs from the PacBio long reads using 2 tools, <font color="red"><strong>Canu</strong></font> (version 1.5) and <font color="red"><strong>Falcon</strong></font> (version 0.5). For each assembler the most important assembly parameters were systematically varied (Supplementary Methods), as defined by the tool developers, and by consideration of assembly theory (e.g., overlap length, overlap identity for overlap layout consensus assembly). <font color="blue"><strong>Optimal settings</strong> were <strong>selected</strong></font> by <strong>comparison of assembly statistics</strong> (total size assembled and contig N50) and by <strong>alignment of Illumina PE</strong> data to the assembly with <font color="red"><strong>bowtie2</strong></font> (using the “very fast” pre-set). For <font color="blue">all PacBio assemblies</font> the consensus step was performed by running <font color="red"><strong>Quiver纠错</strong></font> (Genomic Consensus version 2.3.3) (with default parameters) on <font color="blue">raw PacBio contigs</font> and using the full 63× of PacBio data.</p><p>Assembled contigs were further joined into scaffolds using a combination of <strong>BioNano optical mapping</strong> data, <strong>Hi-C</strong> chromatin conformation capture data, and <strong>genetic maps.</strong> The best <font color="blue">assemblies from Canu and Falcon</font> were <font color="blue">independently combined with</font> BioNano optical mapping data using the <font color="red">IrysView</font> software to develop the Canu + BioNano (CB) and Falcon + BioNano (FB) assemblies, respectively. The BioNano scaffolding process identified conflicts between the assembled contigs and the optical map, indicating some degree of misassembly in both Canu and Falcon results.</p><p><strong>Assembly polishing</strong></p><p><font color="red"><strong>Pilon</strong></font> (version1.21) [31] was <font color="blue">run iteratively</font> on the assembly, with <font color="blue">Illumina sequence realigned to the polished assembly</font> at each iteration and then <font color="blue">alignments passed to Pilon to call the next consensus</font>. Alignments for Pilon were produced using <font color="red"><strong>BWA mem</strong></font> (v0.7.17) with default settings. <em>k</em>-mer spectrum comparisons were made using the <em>k</em>-mer analysis toolkit (<font color="red"><strong>KAT</strong></font>) (version 2.3.4) [13] (KAT comp) at a <em>k</em>-mer size of 32, and <font color="blue">the metric used to assess each iteration was the number of <strong>k-mers shared between</strong> the <strong>assembly</strong> and the <strong>Illumina</strong> reads</font>. </p><p>In a second consensus phase, <font color="blue">RNA-Seq</font> reads were aligned as single end (SE), to the genome using <font color="red"><strong>Hisat</strong></font> (version 2.1.0)  with default parameters. This time the effectiveness of consensus calling was <font color="blue">assessed by analysis of <strong>full-length alignments</strong> of assembled RNA-Seq transcripts</font>. All transcripts designated as “complete” by Evigene  were aligned to the genome with BLAT  (version 3.4, with [34] minimum match identity 90%). Alignments were filtered to <strong>retain only full-length alignments</strong> (i.e., from query start to query end). </p><p>Finally, the number of gaps in the alignments (query gaps + target gaps) was used as a metric with the rationale that this serves as a proxy for the number of indels in alignments of assembled messenger RNA sequence.</p><p><strong>Scaffold clustering and genome anchoring using Hi-C</strong></p><p>Hi-C reads were aligned to the polished scaffolds in CB with <font color="red"><strong>Bowtie2</strong></font> (version 2.3.3.1) . Each of the paired reads was aligned independently; then these SE alignments were subsequently merged as recommended by the LACHESIS developers. Based on the alignments, <font color="red">CB scaffolds were <strong>arranged</strong> into <strong>17 ordered</strong> and <strong>oriented</strong> <strong>clusters</strong> using the <strong>LACHESIS</strong> software</font>. As an <font color="blue">internal check</font>, the process was completed on <font color="blue">2 different random 95% sub-samplings of the Hi-C data</font>, as well as on the full data set. The clusters produced by <strong>all 3</strong> of these LACHESIS runs were <font color="blue">identical</font>. <font color="blue">LACHESIS produces groups of scaffolds</font> that are ordered and oriented relative to each other. These scaffold groupings were <font color="blue">compared with the genetic map</font> and the <strong>consistency</strong> of these sources of information was <strong>assessed</strong>. <font color="blue">The SNP probe mapping </font>at the scaffold <strong>validation step</strong> was compared with the clusters produced by LACHESIS.</p><p><strong>Illumina assembly</strong></p><p>The Illumina data were also assembled on their own, using the de Bruijn graph–based assembler <font color="red"><strong>SOAPdenovo2</strong></font> (version 2.04). <font color="blue"><strong>This assembly</strong></font> was <font color="blue"><strong>used in various ways</strong></font> during the course of the pear genome project (for further scaffold validation, for training the <em>ab initio</em> gene predictors, etc.). <font color="red"><strong>【借鉴】The Illumina data were assembled twice</strong></font>. The <font color="red">first pass</font> contigs were screened using the Kraken software and an index built from the entire RefSeq database. <font color="red">Reads aligning to contaminant contigs were <strong>removed</strong></font> and the remaining data were assembled again.</p><h1 id="15-2021-05-nbt-人-【四倍体土豆参考hic组装2】"><a href="#15-2021-05-nbt-人-【四倍体土豆参考hic组装2】" class="headerlink" title="15.  2021.05-nbt 人 【四倍体土豆参考hic组装2】"></a>15.  2021.05-nbt 人 【四倍体土豆参考hic组装2】</h1><blockquote><p>Chromosome-scale, haplotype-resolved assembly of human genomes</p></blockquote><p><img src="/GeekFocus/./10.png" alt="10"></p><p>outline of the phased assembly algorithm, <font color="red"><strong>DipAsm</strong></font></p><p>Assemble HiFi reads into unphased contigs using <font color="red"><strong>Peregrine</strong></font> (1);</p><p> <font color="blue"><strong>group</strong> and <strong>order</strong></font> contigs into scaffolds with <font color="blue"><strong>Hi-C</strong> data</font> using <font color="blue"><strong>Hirise&#x2F;3D-DNA</strong></font> (3D de novo assembly) (2);</p><p> <font color="blue"><strong>map HiFi reads</strong> to scaffolds</font> and <font color="blue"><strong>call heterozygous SNPs</strong></font> using <font color="red"><strong>DeepVariant</strong></font> (3);</p><p> <font color="blue"><strong>phase</strong></font> heterozygous SNP calls with both HiFi and Hi-C data using <font color="red"><strong>WhatsHap plus HapCUT2</strong></font> (4);</p><p> partition reads based on their phase using <font color="red"><strong>WhatsHap</strong></font> (5);</p><p> assemble partitioned reads into <font color="blue"><strong>phased contigs</strong></font> using <font color="red"><strong>Peregrine</strong></font> (6).</p><p><strong>Phased sequence assembly.</strong> </p><p>We ran <font color="red"><strong>Peregrine v.0.1.5.2</strong></font> with the following command line: ‘peregrine asm reads.lst 24 24 24 24 24 24 24 24 24 –with-consensus –shimmer-r 3 –best_n_ovlp 8–output asm’, where file ‘reads. lst’ gives the list of input read files and directory ‘asm’ holds the output assembly. </p><p>We <font color="blue"><strong>mapped Hi-C reads to contigs</strong></font> with <font color="red"><strong>BWA-MEM</strong></font> v.0.7.17 and <font color="blue"><strong>scaffolded</strong></font> the Peregrine contigs with <font color="red"><strong>juicer v.1.5</strong></font> and <font color="red"><strong>3D-DNA v.180922</strong></font>. We preprocessed data with <font color="green"><strong>‘juicer.sh -d juicer -p chrom.sizes -y cut-sites.txt -z contigs.fa -D’</strong></font>, where file <strong>‘cut-sites.txt’</strong> was <strong>generated</strong> using the <strong>generate_site_positions_Arima. py</strong> script, which <strong>outputs merged_nodups.txt</strong>. The scaffolds were produced with <font color="green"><strong>‘run-asm-pipeline.sh -m haploid contigs.fa merged_nodups.txt’</strong></font>. </p><p>We then called small variants using DeepVariant v.0.8.0 with the pretrained PacBio model. </p><p>We mapped Hi-C reads to the scaffolds and ran HapCUT2 v.1.1 over heterozygous SNP sites to obtain sparse phasing at the chromosome scale. The resulting haplotypes were then combined with PacBio HiFi data using WhatsHap v.0.18, with default parameters, to generate fine-scale, chromosome-long phasing. </p><p>We partitioned HiFi reads based on the phases of SNPs residing on these reads, and ran Peregrine again for reads on the same haplotype from the same scaffold. This provided the final phased assembly.</p><h1 id="16-2018-11-ng-同源多倍体甘蔗-【四倍体土豆参考hic组装3】"><a href="#16-2018-11-ng-同源多倍体甘蔗-【四倍体土豆参考hic组装3】" class="headerlink" title="16.  2018.11-ng 同源多倍体甘蔗 【四倍体土豆参考hic组装3】"></a>16.  2018.11-ng 同源多倍体甘蔗 【四倍体土豆参考hic组装3】</h1><blockquote><p>Allele-defined genome of theautopolyploid sugarcane <em>Saccharum spontaneum</em> L.</p></blockquote><p><strong>材料</strong></p><p>栽培甘蔗的<font color="blue">单倍型个体</font><em>S.spontaneum</em>“AP85-441”(1n &#x3D; 4x &#x3D; 32) 进行基因组<em>denovo</em>测序研究。<br>64份甘蔗（<em>Saccharum spontaneum</em>）群体材料进行<font color="blue">遗传多样性研究</font>。</p><p><strong>方法</strong></p><p>二代280-bp和500-bp(PE) 小片段文库（Illumina HiSeq 2500）<br>BAC文库（Illumina HiSeq 2500，PE250）；三代大片段文库~20kb SMRTbellTM（<font color="blue">PacbioRSII</font>）<br>Hi-C文库（<font color="blue">HindIII酶切</font>），500-700bp小片段文库（HiSeqX ten，PE150）</p><p><strong>主要结果</strong>：</p><p><strong>甘蔗基因组denovo</strong><br>利用BAC文库进行二代测序，ALLPATH-LG,SPAdes 和SOAPdenovo2进行初步组装，进一步利用<font color="blue">87X 三代PacBio数据进行<strong>纠错</strong></font>，<font color="red"><strong>CANU</strong></font>组装，组装基因组3.13G，<font color="blue">contigN50&#x3D;45 kb</font>（流式评估基因组大小：3.36G）；通过Hi-C染色体挂载技术，针对<font color="red"><strong>多倍体染色挂载最新算法ALLHIC</strong></font>，进一步将contig水平提升至染色体水平，<strong>挂载率达到93%<strong>；通过BUSCO和二代数据回比评估基因组完整性高达</strong>97.3%<strong>。再通过<font color="red"><strong>MAKER</strong></font>对同源多倍体甘蔗<font color="blue">特异等位基因进行</strong>手动注释</strong></font>，以获得高质量的甘蔗基因组</p><p>**基础染色体数目的减少 *<em>禾本科染色体数进化（高粱n&#x3D; 10到甘蔗n&#x3D; 8）<br>AP85-441基因组的组装显示了</em>S.spontaneum*的染色体数目从10降到8，而这与频繁复制的古复制染色体对相关，通过与高粱的聚类比对，发现高粱祖先5染色体和8号染色体同源物经历了染色体裂变（图2）。SbChr05（A12）的祖先染色体断裂分为两个主要部分，即C5S（A12S）和C5L（A12L），分别转移到SbChr06（A2）和SbChr07（A5）的祖先染色体；SbChr8（A11）的祖先染色体断裂为两个主要的部分，即C8S（A11S）和C8L（A11L），分别转移到SbChr09（A6）和SbChr02（A7+ A9）的祖先染色体中。SbChr8和SsChr5之间及SbChr5和SsChr7之间近乎同源的短片段是在高粱与甘蔗分化前，高粱SSA形成于13.4MYA同源基因的残留物，同时发现，S5中较小的SSA区域和S8中SSA的较大区域在重排的AP85-441基因组中也是保守的。</p><p><strong>S.spontaneum的多倍体化分析</strong><br>进一步研究发现了甘蔗（<em>Saccharum spontaneum</em> L.）染色体由高粱（<em>Sorghum</em>）演变进化过程中经历了染色体断裂与融合后，发生了两次WGD事件（图3）；对甘蔗的基因组的多倍化研究中发现，通过两次全基因组复制事件的发生，导致了甘蔗染色体的自发加倍过程；对同源多倍体甘蔗的特异等位基因的鉴定作为本研究的另一亮点，文章在鉴定等位基因的同时，进一步分析研究了等位基因的表达模式，结果发现不同单倍型表达模式相似，并无明显差异；对甘蔗C4光合作用的研究中鉴定了24个基因，7种关键酶参与NADP-MEC4途径；在甘蔗中蔗糖对的积累的研究中发现与高粱相比甘蔗中的液泡膜糖转运蛋白（TSTs，一种蔗糖转运蛋白）发生了基因家族的扩张，所以推测TSTs参与蔗糖在液泡中的积累；<em>S.spontaneum</em>为现代栽培甘蔗提供了抗病性基因，在对其研究中发现，甘蔗中的80％的NBS编码基因位于四个重排染色体（Ss02，Ss05，Ss06和Ss07）上，其中51％位于重排区域。</p><p><strong>S.spontaneum的起源与遗传多样性分析</strong><br>通过对64份甘蔗（<em>Saccharum spontaneum</em>）群体材料遗传多样性研究，发现其具有广泛的自然部分范围，遍及亚洲，印度次大陆，地中海和非洲，且自然种群具有广泛的表型，遗传和倍性水平多样性（图4）。研究发现，与高粱相比具有大规模染色体重排的<em>S. spontaneum</em>区域具有比非重排区域更高的遗传多样性，并且可能经历了更强的平衡选择。虽然几条单独的染色体没有显示出显著差异，但是比较所有染色体上的平均值显示重排区域中的核苷酸多样性（0.00025±0.00003）远高于非重排区域中的核苷酸多样性（0.00021±0.00001），染色体重排区域的Tajima’s D（-0.659±0.052）远远高于非重排区（-0.720±0.011），重排区的SNP密度(360.27±48.41) 高于非重排区域（297.46±12.65, P&#x3D;0.001798）；此外，GO富集显示，染色体非重排区主要富集到与基本生命周期，光合作用，呼吸作用和ATP合成的通路上。重排区主要富集在GO生物合成和代谢，跨膜转运和离子结合通路上。</p><p><em>S. spontaneum</em>重排区具有高度的遗传多样性将更适应环境压力，例如对各种非生物胁迫（干旱，盐度，碱性，金属离子等）的反应，这些受到次生细胞生物合成和代谢，跨膜转运和离子结合的控制的基因在这些区域可以检测到。在多倍化事件后，重排区域经历了更强的平衡选择。</p><p><strong>讨论</strong></p><p>本研究利用复杂基因组Hi-C建库测序技术，并结合ALLHiC算法成功组装了高复杂同源多倍体甘蔗基因组AP85-441，高质量的甘蔗基因组的获得，为后续研究其蔗糖含量，抗性等性状及农业育种基础奠定了基础。</p><p><strong>Genome assembly overview.</strong> </p><p>The sugarcane AP85-441 contig-level assembly incorporated sequencing data from a mixture of sequencing technologies (Supplementary Fig. 1), including BAC pools sequenced with Illumina HiSeq 2500 and whole-genome shotgun sequencing with PacBio RS II as well as Hi-C reads, followed by Illumina short reads polishing. Each BAC pool was independently assembled using <font color="red">ALLPATHS-LG, SPAdes and SOAPdenovo2</font>, and best results were retained. For PacBio assembly, <font color="red"><strong>Canu v1.511</strong></font> was used, as it is capable<br>of avoiding collapsed repetitive regions and haplotypes. Self-correction was performed with parameter corOutCoverage &#x3D; 100, which allowed us to correct all of the input PacBio reads. The corrected reads, along with BAC-assembled contigs, were imported to the assembly step. <font color="blue">Chromosomal assembly</font> was constructed based on proximity-guided assembly using our newly developed program, <font color="red"><strong>ALLHIC</strong>, which is designed for <strong>polyploid</strong> genome scaffolding</font> (see Supplementary Note for details).</p><p><img src="/GeekFocus/./11.png" alt="11"></p><h1 id="17-2019-08-np-ALLHiC【四倍体土豆参考hic组装4】"><a href="#17-2019-08-np-ALLHiC【四倍体土豆参考hic组装4】" class="headerlink" title="17.  2019.08-np ALLHiC【四倍体土豆参考hic组装4】"></a>17.  2019.08-np ALLHiC【四倍体土豆参考hic组装4】</h1><blockquote><p>Assembly of allele-aware, chromosomal-scale autopolyploid genomes based on Hi-C data</p></blockquote><p><strong>existing approaches are mostly designed for diploid genomes and often with the aim of reconstructing a haploid representation, thereby having limited power to reconstruct chromosomes for autopolyploid genomes. We developed a novel algorithm (ALLHiC) that is capable of building allele-aware, chromosomal-scale assembly for <font color="red">auto-polyploid genomes</font> using Hi-C paired-end reads with innovative ‘prune’ and ‘optimize’ steps. Application on simulated data showed that ALLHiC can phase allelic contigs and substantially improve ordering and orientation when compared to other mainstream Hi-C assemblers</strong></p><h1 id="18-2020-05-nc-紫花苜蓿同源四倍体-06【四倍体土豆参考hic组装5】"><a href="#18-2020-05-nc-紫花苜蓿同源四倍体-06【四倍体土豆参考hic组装5】" class="headerlink" title="18. 2020.05-nc 紫花苜蓿同源四倍体-06【四倍体土豆参考hic组装5】"></a>18. 2020.05-nc 紫花苜蓿同源四倍体-06【四倍体土豆参考hic组装5】</h1><h1 id="19-2020-10-ng-二倍体土豆-【四倍体土豆参考hic组装6】"><a href="#19-2020-10-ng-二倍体土豆-【四倍体土豆参考hic组装6】" class="headerlink" title="19. 2020.10-ng 二倍体土豆 【四倍体土豆参考hic组装6】"></a>19. 2020.10-ng 二倍体土豆 【四倍体土豆参考hic组装6】</h1><blockquote><p>Haplotype-resolved genome analyses of a heterozygous diploid potato</p></blockquote><p>ref of 12: Hi-C-genetic-maps-for-<font color="red">correction</font></p><p>马铃薯(Solanum tuberosum L.)是全球重要的块茎作物。人们正在努力将这种作物从无性繁殖的四倍体转化为种子繁殖的、自交系为基础的杂交作物，但这一过程需要对马铃薯基因组有更好的了解。</p><p><strong>Genome assembly and phasing using PacBio CCS reads.</strong> </p><p>A total of 29 Gb CCS reads were assembled using <font color="red"><strong>Canu</strong></font> (v1.91) with the <font color="green"><strong>parameter</strong> –pacbio-hifi</font>.<br>Canu <font color="blue">generated <strong>two</strong> assemblies</font> composed of contigs and unitigs (Supplementary Table 4), and the <font color="blue"><strong>unitig</strong> assembly consisted of the <strong>contigs that split at any alternative paths</strong> in the assembly graph</font>. The contig assembly had longer continuity but more chimeric fragments嵌合体片段 as revealed in the genetic mapping analysis. To avoid the mis-joining of two haplotypes, <font color="red"><strong>the unitig assembly</strong></font> rather than the contig assembly was chosen for the <font color="red"><strong>subsequent analysis</strong></font>. The unitigs were then <font color="blue"><strong>polished</strong> iteratively using <strong>two rounds</font></strong> of <font color="red"><strong>Pilon</strong></font> with ~150 Gb of WGS <strong>Illumina</strong> data, generating the genome <strong>draft RHgv2</strong>.</p><p>Similarly, the sequenced reads of RH selfing progeny后代 were mapped to unitigs of RHgv2 to perform <font color="blue"><strong>genetic grouping</strong></font>. Because the unitigs were relatively long (N50 &#x3D; 2 Mb), windows with a size of 200 kb rather than the whole unitig were used. If the adjacent windows of one unitig showed contrary read distribution, the unitig was defined as chimeric and broken between windows; 40 chimeric unitigs with a total length of 95 Mb were broken. In total, <font color="blue">1.31 Gb of 1.53 Gb sequences were assigned to 24 linkage groups</font>.</p><p>After merging, 141 Mb sequences and 5,252 annotated genes of RHgv1 were added to the RHgv2, yielding a 1.67 Gb genome draft with 1.54 Gb sequences assigned to 24 groups, termed RHgv3 (Supplementary Table 6). The sequences from the RHgv1 and RHgv2 assemblies were named as ontctg* and unitig* in the AGP file, respectively (Supplementary Data 3).</p><p><strong>Construction of pseudochromosomes.</strong> </p><p>As no approach generated satisfactory results on the RH genome, we introduced the group information derived from the genetic mapping to assist the Hi-C application on chromosome-level assembly. The process was performed on RHgv3 including three steps as follows:</p><ol><li><font color="blue"><strong>Align</strong></font>. The 24 previously determined groups were divided into <font color="blue"><strong>two haplotypes</strong> to <strong>generate</strong> <strong>two</strong> <strong>pseudohaploid genome drafts</strong></font>. The 132 Mb sequences that could not be assigned to any group were added to two pseudohaploid genomes. Total <font color="blue">Hi-C reads were <strong>aligned</strong> to <strong>each</strong> pseudohaploid genome using <strong>HiC-Pro</strong> to calculate the <strong>contact frequency</strong></font>. This step <font color="blue">yielded <strong>two bam files</strong> for the two pseudohaploid genomes</font>.</li><li><font color="blue"><strong>Rescue</strong></font>. Using the <font color="blue">bam file as input</font>, the <em>rescue</em> function in <font color="red"><strong>ALLHiC</strong></font> was applied to assign unplaced sequences to known groups. Because the 132 Mb <strong>unplaced sequences</strong> were <strong>added</strong> to two pseudohaploid genomes and <strong>processed twice</strong>, the rescued <strong>results were redundant</strong>. For every <strong>unplaced sequence</strong>, we <strong>considered its best Hi-C signal density</strong> to decide the group to which it belonged. After this step, the sequence content of 24 groups was updated with an <strong>extra 75.6 Mb</strong> sequences assigned to proper groups.</li><li><font color="blue"><strong>Optimize and build</strong></font>. For each pseudohaploid genome, using <font color="red">the bam file and the updated group file as input</font>, the <font color="red"><strong><em>optimize</em> function in ALLHiC</strong></font> decidedthe <strong>order</strong> and <strong>orientation</strong> of scaffolds for each group; thus, the <font color="red"><strong><em>build</em> function</strong></font> generated fasta sequences on that basis. By performing this step, we identified the pseudochromosomes for 24 groups. The order and orientation of scaffolds on chromosomes are provided in Supplementary Data 3.</li></ol><h1 id="20-2021-12-gb-杏树【四倍体土豆参考hic组装7】"><a href="#20-2021-12-gb-杏树【四倍体土豆参考hic组装7】" class="headerlink" title="20. 2021.12-gb 杏树【四倍体土豆参考hic组装7】"></a>20. 2021.12-gb 杏树【四倍体土豆参考hic组装7】</h1><blockquote><p>Gamete binning: chromosome-level and haplotype-resolved genome assembly enabled by high-throughput single-cell sequencing of gamete genomes</p></blockquote><p>ref of 12: Hi-C-genetic-maps-for-correction</p><p>一种基于单倍体配子单细胞测序的方法。基于445个个体花粉粒的全基因组测序，组装了一株二倍体杏树的两个基因组。</p><p><strong>Genome size estimation</strong></p><p>After trimming off 10x Genomics barcodes and hexamers from the 61.7 Gb reads of the two 10x sc-CNV libraries, k-mer counting (k&#x3D;21) was performed with <font color="red"><strong>Jellyfish</strong></font>. The k-mer histogram was provided to<font color="red"> <strong>findGSE</strong></font> to estimate the size of the “Rojo Pasión” genome under the heterozygous mode (with “exp_hom&#x3D;200”; Add- itional file 1: Fig. S3).</p><p><strong>Preliminary diploid-genome assembly and curation</strong></p><p>With the 19.9 G raw PacBio reads of “Rojo Pasión” (Additional file 1: Fig. S2), a pre-liminary diploid assembly was constructed using <font color="red"><strong>Canu</strong></font> (with options “genome- Size&#x3D;242500000 corMhapSensitivity&#x3D;high corMinCoverage&#x3D;0 corOutCoverage&#x3D;100 correctedErrorRate&#x3D;0.105”).</p><p>All raw <strong>Illumina reads</strong> from the 10x libraries were <font color="red">firstly <strong>aligned</strong> to the <strong>initial assembly</strong></font> using <font color="red"><strong>bowtie2</strong></font>. Then, the purge haplotigs pipeline was used to remove haplotigs (i.e., haplotype-specific contigs inflating the true haploid genome) based on statistical analysis of sequencing depth and identify primary contigs to build up a curated haploid assembly. To reduce the false-positive rate in defining haplotigs, each haplotig was blasted to the curated assembly; if over 50% of the haplotig could not be covered by any primary contigs, it was re-collected as a primary contig.</p>]]></content>
    
    
    <categories>
      
      <category>Biology</category>
      
    </categories>
    
    
    <tags>
      
      <tag>assembly</tag>
      
      <tag>paper</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>HiFi-5-[HiC-Pro]-[MCscan]-[ALLHiC]</title>
    <link href="/GeekFocus/2022/03/09/2022-03-09-HiFi-5-HiC-Pro/"/>
    <url>/GeekFocus/2022/03/09/2022-03-09-HiFi-5-HiC-Pro/</url>
    
    <content type="html"><![CDATA[<p>HiC-Pro将fq文件处理成互作allValidPairs，再转化成可视化hic文件(for juicer)</p><span id="more"></span><h1 id="HiC简介"><a href="#HiC简介" class="headerlink" title="HiC简介"></a>HiC简介</h1><ul><li><p><strong>1.1 Hi-C技术</strong>高通量染色体构象捕获技术(<code>High-throughput chromosome conformation capture</code>)研究全基因组三维构象及分析染色质片段相互作用的实验技术</p></li><li><p><strong>1.2 Hi-C目的</strong>了解核内染色质的三维构象、获得细胞核内空间位置非常接近或存在相互作用的染色质测序片段更好地研究染色质内或染色质间的互作、基因调控元件在全基因组范围内调控的情况</p></li><li><p><strong>1.3 Hi-C应用方向</strong>辅助基因组组装、揭示空间调控、揭示物种进化、疾病研究、三维结构差异分析、还原染色体三维结构、构建染色体跨度单体型</p></li><li><p><strong>1.4 互作本质</strong>统计学上基因组两点之间发生空间接触的概率</p></li><li><p><strong>1.5 Hi-C实验原理</strong></p></li><li><p><strong>1.6 二代文库构建及测序</strong></p></li><li><p><strong>1.7 Hi-C实际文库类型</strong>将HIC数据进行比对是会出现不同的比对情况，需要的是<font color="blue">双端唯一匹配</font>。对单端匹配、多处比对、未比对的reads进行过滤。</p><p><img src="/GeekFocus/./5.png" alt="HiC-Pro的使用"></p><p>Hi-C文库构建产生多种分子类型，包括 re-ligation、Dangling ends、self circle 、dump reads 及valid pairs reads等类型。 在 Hi-C 分析中，<font color="red">仅valid pair可以反映基因组上位点与位点间的互作</font>。因此，<font color="blue">非重复的valid pair</font>所占比例是评估Hi-C文库质量重要指标</p><p><img src="/GeekFocus/./6.png" alt="三维基因组技术（三）：Hi-C 数据比对及HiC-Pro的使用"></p></li><li><p><strong>互作矩阵的生成</strong>由于计算资源，数据量等因素，<font color="blue">需要确定一个互作单位：bin</font>。将基因组按照一定大小分成bin。<font color="red">将过滤后的有效序列分配到这些bin中</font></p><p><img src="/GeekFocus/./7.png" alt="三维基因组技术（三）：Hi-C 数据比对及HiC-Pro的使用"></p></li><li><p><strong>互作矩阵的矫正</strong>Hi-C数据中由于<font color="blue">内切酶偏好性、基因组本身质量、基因组序列特异性</font> 导致其在基因组不同位置间存在偏差。因此，<font color="red">对互作矩阵校正，使其数据在基因组上每个位点的覆盖度一致</font>。常用矫正方式有<font color="red"><strong>迭代矫正、归一化</strong></font>等</p><p><img src="/GeekFocus/./8.png" alt="三维基因组技术（三）：Hi-C 数据比对及HiC-Pro的使用"></p></li></ul><h2 id="HiC常规软件"><a href="#HiC常规软件" class="headerlink" title="HiC常规软件"></a>HiC常规软件</h2><table><thead><tr><th align="left">软件名</th><th align="left">hiclib</th><th align="left">HiC-Pro</th><th align="left">HICUP</th><th align="left">Juice</th></tr></thead><tbody><tr><td align="left">比对软件</td><td align="left">Bowtie2</td><td align="left">Bowtie2</td><td align="left">Bowtie2</td><td align="left">BWA-mem</td></tr><tr><td align="left">比对策略</td><td align="left">迭代比对</td><td align="left">全局、局部比对</td><td align="left">先截短后比对</td><td align="left">Pair-end，嵌合reads过滤</td></tr><tr><td align="left">嵌合reads处理</td><td align="left">√</td><td align="left">√</td><td align="left">√</td><td align="left">√</td></tr><tr><td align="left">构建矩阵</td><td align="left">√</td><td align="left">√</td><td align="left">×</td><td align="left">√</td></tr><tr><td align="left">标准化</td><td align="left">ICE</td><td align="left">ICE</td><td align="left">×</td><td align="left">KR</td></tr><tr><td align="left">结果文件</td><td align="left">hdf5、hm、bychr(HDF5)</td><td align="left">SAM、validpair</td><td align="left">SAM</td><td align="left">SAM、MND、.hic</td></tr><tr><td align="left">特点</td><td align="left">比对结果可靠，存储消耗小</td><td align="left">简单易用，输出结果可读</td><td align="left">过滤非常严格</td><td align="left">后续分析接口多，juicebox可视化</td></tr></tbody></table><h1 id="案例"><a href="#案例" class="headerlink" title="案例"></a>案例</h1><p>HiFi助力同源四倍体紫花苜蓿基因组组装，NC</p><blockquote><p>Allele-aware chromosome-level genome assembly and efficient transgene-free genome editing for the autotetraploid cultivated alfalfa</p></blockquote><p>（1）使用Canu默认参数，利用CCS clean reads组装contigs。组装得到的Contig N50值为459kb，总长度为3.15GB。</p><blockquote><p>We assembled contigs from CCS clean reads using Canu, with default parameters. The N50 values of the contig sets were 459 kb, with total lengths 3154 Mb.</p></blockquote><p>（2）使用HiC-Pro将Hi-C reads与contigs 进行比对，产生比对BAM文件。</p><blockquote><p>Hi-C reads were aligned to contigs using <a href="https://pubmed.ncbi.nlm.nih.gov/26619908/">HiC-Pro(2015)</a>, yielding an alignment BAM file.</p></blockquote><p>（3）使用注释的蒺藜苜蓿蛋白作为参考，完全基于同源的策略注释contigs。对138,729个同源基因进行了结构注释。用MCscan用于鉴定contigs和参考基因组之间的共线性。显示紫花苜蓿和蒺藜苜蓿之间的高共线性。【下载父母本petunia ref】</p><blockquote><p>Contigs were annotated with a <font color="red"><strong>solely homology-based strategy</strong></font>, using annotated Medicago truncatula proteins as references. 138,729 homologous genes were structurally annotated. <font color="red"><strong>MCscan</strong> in <strong>Jcvi</strong></font> (<a href="https://zenodo.org/record/31631#.XpkUyTOeask">https://zenodo.org/record/31631#.XpkUyTOeask</a>) was used to identify <font color="red"><strong>synteny blocks</strong></font> between <strong>contigs and the reference</strong> genome. <font color="red"><strong>Contigs syntenic</strong> to M. truncatula were <strong>stacked and aligned</strong> to M. truncatula chromosomes</font>. The syntenic contigs are summarized in Supplementary Table 4.</p></blockquote><p><img src="/GeekFocus/./1.png" alt="STable4"></p><p>（4）使用内部脚本处理BAM文件，去除等位基因contigs之间的links。使用ALLHiC软件，<font color="red">提取、聚类和重排Contigs</font> (Contigs syntenic与蒺藜苜蓿染色体一致)，得到原始的scaffolds。</p><blockquote><p>An <strong>in-house script</strong> was used to <font color="red">prune the BAM</font> file and <font color="red">discard links between allelic contigs</font>. Contigs syntenic to one chromosome of M. truncatula, e.g., chr1, were extracted, sub-clustered and reordered using <font color="red">ALLHiC</font>, yielding a raw scaffold set.</p></blockquote><p>（5）<a href="https://pubmed.ncbi.nlm.nih.gov/27467250/">Juicebox</a>用于以图形和交互方式微调组装的scaffolds。剪裁了40个总长度达1800Mb的scaffolds 。</p><blockquote><p>Juicebox45 was used for fine-tuning assembled scaffolds in a graphic and inter-active fashion. Forty scaffolds with a total length of 1800 Mb were cropped (Supplementary Table 5).</p></blockquote><p><img src="/GeekFocus/./2.png" alt="STable5"></p><p>（6） 基于组装的scaffold，通过Hi-C数据，每个unplaced contig被分配到互作最强的那些contig cluster里。</p><blockquote><p>Based on this scaffold assembly, each unplaced contig was assigned to the contig cluster, to which the contig was most connected by Hi-C data.</p></blockquote><p>（7）使用ALLHiC对那些contig clusters再次进行重排和构建scaffold。</p><blockquote><p>Those contig clusters were reordered and scaffolded using ALLHiC. </p></blockquote><p>（8）使用Juicebox对scaffolds进行微调，并从scaffolds上去除不一致的contigs，产生最终的染色体基因组，其包含32条染色体(8个同源组，每个组中有4个等位基因染色体)，总长度为2738Mb，和419Mb未挂载到染色体水平的序列。</p><blockquote><p>Using Juicebox, scaffolds were fine-tuned and discordant contigs were removed from scaffolds, and the final chromosome assembly was generated, containing 32 chromosomes with a total length of 2738 Mb (Supplementary Table 6).</p></blockquote><p><img src="/GeekFocus/./3.png" alt="STable6"></p><h1 id="HiC-Pro-install"><a href="#HiC-Pro-install" class="headerlink" title="HiC-Pro install"></a>HiC-Pro install</h1><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs sh">conda <span class="hljs-built_in">env</span> create -f ./HiC-Pro/environment.yml -p ///software/HiC_Pro_ENV<br><span class="hljs-comment">#【install env in my software dir】</span><br>conda activate <span class="hljs-built_in">env</span><br><br>tar -zxvf HiC-Pro-master.tar.gz<br><span class="hljs-built_in">cd</span> HiC-Pro-master<br><span class="hljs-comment">## Edit config-install.txt file if necessary</span><br>make configure<br>make install<span class="hljs-comment"># failed </span><br><span class="hljs-comment">#(g++ -Wall -O2 -std=c++0x -o build_matrix /xtdisk/xueyb_group/wangchenA/software/HiC-Pro-3.1.0/scripts/src/build_matrix.cpp; mv build_matrix /xtdisk/xueyb_group/wangchenA/software/HiC-Pro-3.1.0/scripts)</span><br><span class="hljs-comment">#(g++ -Wall -O2 -std=c++0x -o cutsite_trimming /xtdisk/xueyb_group/wangchenA/software/HiC-Pro-3.1.0/scripts/src/cutsite_trimming.cpp; mv cutsite_trimming /xtdisk/xueyb_group/wangchenA/software/HiC-Pro-3.1.0/scripts)</span><br><span class="hljs-comment">#cp -Ri /xtdisk/xueyb_group/wangchenA/software/HiC-Pro-3.1.0 /usr/local/bin//HiC-Pro_3.1.0</span><br><span class="hljs-comment">#cp: cannot create directory ‘/usr/local/bin//HiC-Pro_3.1.0’: Permission denied</span><br><span class="hljs-comment">#make: *** [Makefile:78: cp] Error 1</span><br><br>but <span class="hljs-keyword">in</span> the bin file,it can be use?<br></code></pre></td></tr></table></figure><p>Make configure and make install, whats the function of those two steps?</p><h1 id="HiC-Pro-GitHub"><a href="#HiC-Pro-GitHub" class="headerlink" title="HiC-Pro-GitHub"></a><a href="https://github.com/nservant/HiC-Pro">HiC-Pro-GitHub</a></h1><p><a href="https://doi.org/10.1186/s13059-015-0831-x">Genome Biology 2015</a></p><p>HiC-Pro was designed to process Hi-C data, from <font color="red"><strong>raw fastq files</strong></font> (paired-end Illumina data) to <font color="red"><strong>normalized contact maps</strong></font>. It supports the main Hi-C protocols, including digestion protocols as well as protocols that do not require restriction enzymes such as DNase Hi-C. In practice, HiC-Pro was successfully <font color="blue"><strong>applied to many data-sets</strong></font> including dilution Hi-C, in situ Hi-C, DNase Hi-C, Micro-C, capture-C, capture Hi-C or HiChip data.<br>The pipeline is flexible, scalable and optimized. It can operate either on a single laptop or on a computational cluster. HiC-Pro is sequential and each step of the workflow can be run independantly.<br>HiC-Pro includes a fast implementatation of the iterative correction method (see the <a href="https://github.com/hiclib/iced">iced python package</a> for more information). Finally, HiC-Pro can use phasing data to build <a href="https://github.com/nservant/HiC-Pro/blob/master/doc/AS.md">allele-specific contact maps</a>.</p><h2 id="HiC-Pro-annotation-files"><a href="#HiC-Pro-annotation-files" class="headerlink" title="HiC-Pro annotation files"></a>HiC-Pro annotation files</h2><p>In order to process the raw data, HiC-Pro requires three annotation files. Note that the pipeline is provided with some Human and Mouse annotation files.<br><strong>Please be sure that the chromosome names are the same than the ones used in your bowtie indexes !</strong></p><ul><li><strong>A BED file</strong> of the <font color="blue"><strong>restriction fragments after digestion</strong></font>. This file <font color="blue">depends</font> both of the <font color="blue"><strong>restriction enzyme</strong></font> and the <font color="blue"><strong>reference genome</strong></font>. See the <a href="https://github.com/nservant/HiC-Pro/blob/master/doc/FAQ.md">FAQ</a> and the <a href="https://github.com/nservant/HiC-Pro/blob/master/doc/UTILS.md">HiC-Pro utilities</a> for details about <font color="blue"><strong>how to generate</strong></font> this file. A few annotation files are provided with the HiC-Pro sources as examples. 根据限制性内切酶消化的参考基因组信息 .bed文件。酶切图谱</li></ul><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-comment">#example：/PATH/TO/HiC-Pro_2.11.1/annotation</span><br> <span class="hljs-built_in">head</span> HindIII_resfrag_hg19.bed<br> chr1   0       16007   HIC_chr1_1    0   +<br> chr1   16007   24571   HIC_chr1_2    0   +<br> chr1   24571   27981   HIC_chr1_3    0   +<br> (...)<br></code></pre></td></tr></table></figure><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-comment">#GENOME_FRAGMENT = # 储存消化碎片位置信息的bed文件，一般在HiC-Pro的annotation文件夹下</span><br><span class="hljs-comment">#LIGATION_SITE = # 酶切位点重连接后的序列</span><br><span class="hljs-comment">#注：GENOME_FRAGMENT 和 LIGATION_SITE 完全取决于使用了什么酶，一般HiC建库的酶是Hind III，所以要仔细检查数据来源的说明。 </span><br>digest_genome.py -r A^AGCTT -o HindIII_resfrag_hg19.bed hg19_rCRSchrm.fa  <br></code></pre></td></tr></table></figure><p>通过软件脚本产生基因组酶切图谱，输入内切酶名称或者酶切位点序列都可以，用法：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs sh">digest_genome.py -r A^AGCTT -o mm9_hindiii.bed mm9.fasta<br>digest_genome.py -r hindiii -o mm9_hindiii.bed mm9.fasta<br></code></pre></td></tr></table></figure><p>NcoI、BamHI、EcoRI、HindIII、NdeI、XhoI, 参考：<a href="https://www.biomart.cn/experiment/430/457/741/43956.htm"><font color="red"><strong>常见限制性内切酶识别序列(酶切位点)</strong></font></a></p><table><thead><tr><th align="left">限制性内切酶</th><th align="left">酶切位点，<code>^</code>为切割位点</th></tr></thead><tbody><tr><td align="left">MboI</td><td align="left">^GATC</td></tr><tr><td align="left">DpnII</td><td align="left">^GATC</td></tr><tr><td align="left">BglII</td><td align="left">A^GATCT</td></tr><tr><td align="left">HindIII</td><td align="left">A^AGCTT</td></tr></tbody></table><ul><li><strong>A table file</strong> of chromosomes’ size. This file can be easily find on the <font color="blue">UCSC genome browser</font>. Of note, pay attention to the contigs or scaffolds, and be aware that HiC-pro will generate a map per chromosomes pair. For model organisms such as Human or Mouse, which are well annotated, we usually recommand to remove all scaffolds. 染色体大小的表格文件。从UCSC下载染色体长度文件，或自己根据fasta序列统计长度</li></ul><figure class="highlight dns"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs dns">#example：/PATH/TO/HiC-Pro_2.<span class="hljs-number">11</span>.<span class="hljs-number">1</span>/annotation<br>head chrom_hg19.sizes<br>   chr1    <span class="hljs-number">249250621</span><br>   chr2    <span class="hljs-number">243199373</span><br>   chr3    <span class="hljs-number">198022430</span><br>   chr4    <span class="hljs-number">191154276</span><br>   chr5    <span class="hljs-number">180915260</span><br>   chr6    <span class="hljs-number">171115067</span><br>   chr7    <span class="hljs-number">159138663</span><br>   ...<br></code></pre></td></tr></table></figure><p><font color="green"><strong>how?</strong></font> </p><figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs nginx"><span class="hljs-attribute">samtools</span> faidx genome.fa<br>awk ‘&#123;<span class="hljs-attribute">print</span> <span class="hljs-variable">$1</span> <span class="hljs-string">&quot;t&quot;</span> <span class="hljs-variable">$2</span>&#125;‘ genome.fa.fai &gt; genome_sizes.bed<br></code></pre></td></tr></table></figure><ul><li><p><strong>The bowtie2 indexes</strong>. See the <a href="http://bowtie-bio.sourceforge.net/bowtie2/index.shtml">bowtie2 manual page</a> for details about how to create such indexes.</p></li><li><pre><code class="sh">bowtie2-build hg19.fasta hg19<figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs pgsql"><br>## how <span class="hljs-keyword">to</span> use<br><br>```sh<br>  HiC-Pro <span class="hljs-comment">--help</span><br>  <span class="hljs-keyword">usage</span> : HiC-Pro -i <span class="hljs-keyword">INPUT</span> -o OUTPUT -c CONFIG [-s ANALYSIS_STEP] [-p] [-h] [-v]<br>  Use <span class="hljs-keyword">option</span> -h|<span class="hljs-comment">--help for more information</span><br><br>  HiC-Pro <span class="hljs-number">3.1</span><span class="hljs-number">.0</span><br>  <span class="hljs-comment">---------------</span><br>  <span class="hljs-keyword">OPTIONS</span><br><br>   -i|<span class="hljs-comment">--input INPUT : &#x27;input data folder&#x27;; contains a folder per sample with input files</span><br>   -o|<span class="hljs-comment">--output OUTPUT : &#x27;output folder&#x27;</span><br>   -c|<span class="hljs-comment">--conf CONFIG : &#x27;configuration file&#x27; for Hi-C processing</span><br>   [-p|<span class="hljs-comment">--parallel] : if specified run HiC-Pro on a cluster&#x27;?&#x27;</span><br>   [-s|<span class="hljs-comment">--step ANALYSIS_STEP] : run only a subset of the HiC-Pro workflow; &#x27;if not specified the complete workflow is run&#x27;</span><br>      <span class="hljs-keyword">mapping</span>: <span class="hljs-keyword">perform</span> reads <span class="hljs-string">&#x27;alignment&#x27;</span> - require fast files<br>      proc_hic: <span class="hljs-keyword">perform</span> Hi-C <span class="hljs-string">&#x27;filtering&#x27;</span> - require BAM files<br>      quality_checks: run Hi-C <span class="hljs-string">&#x27;quality control&#x27;</span> plots<br>      merge_persample: <span class="hljs-string">&#x27;merge&#x27;</span> multiple inputs <span class="hljs-keyword">and</span> remove duplicates <span class="hljs-keyword">if</span> specified - require .validPairs files<br>      build_contact_maps: <span class="hljs-string">&#x27;Build raw inter/intrachromosomal contact maps&#x27;</span> - require .allValidPairs files<br>      ice_norm : run ICE <span class="hljs-string">&#x27;normalization&#x27;</span> <span class="hljs-keyword">on</span> contact maps - require .matrix files<br>   [-h|<span class="hljs-comment">--help]: help</span><br>   [-v|<span class="hljs-comment">--version]: version</span><br></code></pre></td></tr></table></figure></code></pre></li><li><p><font color="blue"><strong>Copy and edit</strong></font> the configuration file <font color="blue"><strong>‘config-hicpro.txt’</strong> </font> in your <font color="blue"><strong>local folder</strong></font>. See the <a href="https://github.com/nservant/HiC-Pro/blob/master/doc/MANUAL.md">manual</a> for details about the configuration file</p></li><li><p>Put <font color="blue"><strong>all input files in a rawdata folder</strong></font>. The input files have to be organized with <font color="blue"><strong>one folder per sample</strong></font>, such as;</p></li></ul><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs sh">+ PATH_TO_MY_DATA<br>  + sample1<br>    ++ file1_R1.fastq.gz<br>    ++ file1_R2.fastq.gz<br>    ++ ...<br>  + sample2<br>    ++ file1_R1.fastq.gz<br>    ++ file1_R2.fastq.gz<br>  *...<br></code></pre></td></tr></table></figure><ul><li>Run HiC-Pro on your <font color="blue"><strong>laptop</strong></font> in standalone model</li></ul><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sh">MY_INSTALL_PATH/bin/HiC-Pro -i <span class="hljs-string">&#x27;FULL&#x27;</span>_PATH_TO_DATA_FOLDER -o FULL_PATH_TO_OUTPUTS -c MY_LOCAL_CONFIG_FILE<br></code></pre></td></tr></table></figure><ul><li>Run HiC-Pro on a <font color="blue"><strong>cluster</strong></font> (TORQUE&#x2F;SGE&#x2F;SLURM&#x2F;LSF)</li></ul><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sh">MY_INSTALL_PATH/bin/HiC-Pro -i FULL_PATH_TO_DATA_FOLDER -o FULL_PATH_TO_OUTPUTS -c MY_LOCAL_CONFIG_FILE -p<br></code></pre></td></tr></table></figure><ul><li>In the latter <font color="blue">case[cluster]</font>, you will have the following message :</li></ul><figure class="highlight stata"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs stata">Please <span class="hljs-keyword">run</span> HiC-<span class="hljs-keyword">Pro</span> <span class="hljs-keyword">in</span> <span class="hljs-keyword">two</span> steps :<br> 1- The following command will launch the parallel workflow through 12 torque jobs:<br> qsub HiCPro_step1.<span class="hljs-keyword">sh</span><br> 2- The second command will <span class="hljs-keyword">merge</span> all outputs to <span class="hljs-keyword">generate</span> the contact maps:<br> qsub HiCPro_step2.<span class="hljs-keyword">sh</span><br></code></pre></td></tr></table></figure><p>Execute the displayed command from the <font color="blue"><strong>output folder</strong></font>:</p><figure class="highlight armasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs armasm"><span class="hljs-keyword">qsub</span> HiCPro_step1.sh<br></code></pre></td></tr></table></figure><p>Once executed succesfully (may take several hours), run the step using:</p><figure class="highlight armasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs armasm"><span class="hljs-keyword">qsub</span> HiCPro_step2.sh<br></code></pre></td></tr></table></figure><h2 id="config-editing"><a href="#config-editing" class="headerlink" title="config editing"></a>config editing</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment">#######################################################################</span><br><span class="hljs-comment">## SYSTEM AND SCHEDULER - Start Editing Here !!</span><br><span class="hljs-comment">#######################################################################</span><br>N_CPU = 2<br>LOGFILE = hicpro.log<br>JOB_NAME =<br>JOB_MEM =<br>JOB_WALLTIME =<br>JOB_QUEUE =<br>JOB_MAIL =<br></code></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs undefined">BOWTIE2_IDX_PATH =<br></code></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment">#######################################################################</span><br><span class="hljs-comment">## Digestion Hi-C</span><br><span class="hljs-comment">#######################################################################</span><br>GENOME_FRAGMENT = HindIII_resfrag_hg19.bed<br>LIGATION_SITE = AAGCTAGCTT<br>MIN_FRAG_SIZE =<br>MAX_FRAG_SIZE =<br>MIN_INSERT_SIZE =<br>MAX_INSERT_SIZE =<br>MIN_MAPQ: 最低的质量分数，用于筛选，表示低于该MAPQ值会被过滤<br>BOWTIE2_IDX_PATH: 基因组bowtie2索引路径，eg:/path/hg19<br>BOWTIE2_GLOBAL_OPTIONS: 默认GLOBAL比对设置<br>BOWTIE2_LOCAL_OPTIONS: 默认LOCAL比对设置<br>REFERENCE_GENOME： Bowtie2索引前缀<br>GENOME_SIZE： 基因组sizes bed文件<br>GENOME_FRAGMENT: 基因组酶切文件,eg. /path/hg19_HindIII.bed<br>LIGATION_SITE: 酶切位点末端补平再次连接后形成的嵌合序列，eg. AAGCTAGCTT<br>MIN_FRAG_SIZE: 最小的理论酶切片段大小,eg. 100<br>MAX_FRAG_SIZE: 最大的理论酶切片段大小,eg. 100000<br>MIN_INSERT_SIZE: 最小的文库片段大小,eg.100<br>MAX_INSERT_SIZE: 最大的文库片段大小,eg.1000<br><span class="hljs-string">&#x27;BIN_SIZE:需要生成的矩阵分辨率（bp)&#x27;</span><br>MATRIX_FORMAT：矩阵的形式，upper表示保留上半部分<br></code></pre></td></tr></table></figure><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs sh">BOWTIE2_IDX_PATH = <span class="hljs-comment"># bowtie2索引文件目录，索引文件提前下载或用bowtie2-build生成</span><br>REFERENCE_GENOME = <span class="hljs-comment"># bowtie2索引的文件名</span><br>GENOME_SIZE = <span class="hljs-comment"># 染色体大小文件，可从http://hgdownload.cse.ucsc.edu/goldenPath/ 下载</span><br>GENOME_FRAGMENT = <span class="hljs-comment"># 储存消化碎片位置信息的bed文件，一般在HiC-Pro的annotation文件夹下</span><br>LIGATION_SITE = AAGCTAGCTT<span class="hljs-comment"># 酶切位点重连接后的序列</span><br><span class="hljs-comment"># 注：GENOME_FRAGMENT 和 LIGATION_SITE 完全取决于使用了什么酶，一般来说是Hind III，所以要仔细检查数据来源的说明。 </span><br>PAIR2_EXT = <span class="hljs-comment"># 根据文件名称，分别输入双端数据文件名称，不用输入后缀</span><br></code></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment">#???GENOME_SIZE = 在建立的索引目录下新建一个txt文件：</span><br><span class="hljs-built_in">cat</span> &gt;chrom_bacteria.sizes  <span class="hljs-comment">#创建一个新的文件cat &gt; filename，文件名我是参考hicpro的配置示例 </span><br>Chromosome 4016942  <span class="hljs-comment">#在文件中写入内容，表明这个参考基因的大小是4016942bp,1bp即为1个碱基对（base pair）</span><br></code></pre></td></tr></table></figure><h2 id="test"><a href="#test" class="headerlink" title="test"></a>test</h2><p>The test dataset and associated results are available <a href="https://zerkalo.curie.fr/partage/HiC-Pro/">here</a>. Small fastq files (2M reads) extracted from the Dixon et al. 2012 paper are available for test.</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-comment">## Get the data. Will download a test_data folder and a configuration file</span><br> wget https://zerkalo.curie.fr/partage/HiC-Pro/HiCPro_testdata.tar.gz &amp;&amp; tar -zxvf HiCPro_testdata.tar.gz<br><br> <span class="hljs-comment">## Edit the configuration file and set the path to Human bowtie2 indexes</span><br><br> <span class="hljs-comment">## Run HiC-Pro</span><br> time HICPRO_INSTALL_DIR/bin/HiC-Pro -c config_test_latest.txt -i test_data -o hicpro_latest_test<br></code></pre></td></tr></table></figure><h1 id="HIC-PRO’S-DOC"><a href="#HIC-PRO’S-DOC" class="headerlink" title="HIC-PRO’S DOC"></a><a href="http://nservant.github.io/HiC-Pro/">HIC-PRO’S DOC</a></h1><h1 id="分步原理"><a href="#分步原理" class="headerlink" title="分步原理"></a>分步原理</h1><p>ref：<a href="https://www.jianshu.com/p/76533e6d6152">https://www.jianshu.com/p/76533e6d6152</a></p><p><img src="/GeekFocus/./4.png" alt="img"></p><ul><li><p><font color="red"><strong>比对、过滤HiC比对结果、检测有效HiC序列、结果合并、构建HiC关联图谱、关联图谱标准化。</strong></font></p></li><li><p>HiC-Pro可输出各个尺度的HiC<font color="red">标准化互作图谱</font>，从每个<font color="red">窗口5Kb到1Mb</font>，窗口越大，生成互作关系越少，计算时间就越少，反之越多。同时HiC-Pro能与下游可视化软件<font color="red"><strong>HiCPlotter</strong></font>等兼容，输出文件可直接用于可视化分析。</p></li><li><p>HiC-Pro<font color="red">自动化比对，标准化和构建相互作用矩阵</font>，在处理多样化的测序数据时，HiC-Pro能够<strong>检测和自动过滤</strong>测序数量差的reads和无效片段。</p></li></ul><h2 id="1-Reads-Mapping"><a href="#1-Reads-Mapping" class="headerlink" title="1.Reads Mapping"></a>1.Reads Mapping</h2><p>将fastq文件用bowtie2 mapping一次，查看log：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-built_in">cat</span> mapping_step1.log<br><span class="hljs-comment">###mapping fastq to reference genome , 将unmapping的read 另存为 unmap.fastq</span><br>/PATH/TO/bowtie2/bowtie2-2.3.3.1/bowtie2 --very-sensitive -L 30 --score-min L,-0.6,-0.2 --end-to-end --reorder --un bowtie_results/bwt2_global/dixon_2M/SRR400264_00_R2_hg19.bwt2glob.unmap.fastq --rg-id BMG --rg SM:SRR400264_00_R2 -p 20 -x /PATH/TO/HiC-Pro_2.11.1/Bowtie2Index/hg19 -U rawdata/dixon_2M/SRR400264_00_R2.fastq.gz 2&gt;&gt; logs/dixon_2M/SRR400264_00_R2_bowtie2.<span class="hljs-built_in">log</span>| /PATH/TO/samtools/samtools-1.6/bin/samtools view -F 4 -bS - &gt; bowtie_results/bwt2_global/dixon_2M/SRR400264_00_R2_hg19.bwt2glob.bam<br><br>/PATH/TO/bowtie2/bowtie2-2.3.3.1/bowtie2 --very-sensitive -L 30 --score-min L,-0.6,-0.2 --end-to-end --reorder --un bowtie_results/bwt2_global/dixon_2M/SRR400264_00_R1_hg19.bwt2glob.unmap.fastq --rg-id BMG --rg SM:SRR400264_00_R1 -p 20 -x /PATH/TO/HiC-Pro_2.11.1/Bowtie2Index/hg19 -U rawdata/dixon_2M/SRR400264_00_R1.fastq.gz 2&gt;&gt; logs/dixon_2M/SRR400264_00_R1_bowtie2.<span class="hljs-built_in">log</span>| /PATH/TO/samtools/samtools-1.6/bin/samtools view -F 4 -bS - &gt; bowtie_results/bwt2_global/dixon_2M/SRR400264_00_R1_hg19.bwt2glob.bam<br></code></pre></td></tr></table></figure><p>结果文件</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs sh">|   |-- bwt2_global<br>|   |   |-- dixon_2M<br>|   |   |   |-- SRR400264_00_R1_hg19.bwt2glob.bam<br>|   |   |   |-- SRR400264_00_R1_hg19.bwt2glob.unmap.fastq<br>|   |   |   |-- SRR400264_00_R2_hg19.bwt2glob.bam<br>|   |   |   |-- SRR400264_00_R2_hg19.bwt2glob.unmap.fastq<br>|   |   `-- dixon_2M_2<br>|   |       |-- SRR400264_01_R1_hg19.bwt2glob.bam<br>|   |       |-- SRR400264_01_R1_hg19.bwt2glob.unmap.fastq<br>|   |       |-- SRR400264_01_R2_hg19.bwt2glob.bam<br>|   |       |-- SRR400264_01_R2_hg19.bwt2glob.unmap.fastq<br></code></pre></td></tr></table></figure><p>有mapping和unmapping。因为read是嵌合基因。mapping上的是背景基因组。<font color="blue">unmapping需要下一步处理</font>。</p><h2 id="2-片段分配和过滤"><a href="#2-片段分配和过滤" class="headerlink" title="2. 片段分配和过滤"></a>2. 片段分配和过滤</h2><p>查看log</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-built_in">cat</span> mapping_step2.log<br><span class="hljs-comment">### 酶切</span><br>/PATH/TO/HiC-Pro/HiC-Pro_2.11.1/scripts/cutsite_trimming --fastq bowtie_results/bwt2_global/dixon_2M/SRR400264_00_R1_hg19.bwt2glob.unmap.fastq --cutsite AAGCTAGCTT --out bowtie_results/bwt2_local/dixon_2M/SRR400264_00_R1_hg19.bwt2glob.unmap_trimmed.fastq &gt; logs/dixon_2M/SRR400264_00_R1_hg19.bwt2glob.unmap_readsTrimming.<span class="hljs-built_in">log</span> 2&gt;&amp;1<br>/PATH/TO/HiC-Pro/HiC-Pro_2.11.1/scripts/cutsite_trimming --fastq bowtie_results/bwt2_global/dixon_2M/SRR400264_00_R2_hg19.bwt2glob.unmap.fastq --cutsite AAGCTAGCTT --out bowtie_results/bwt2_local/dixon_2M/SRR400264_00_R2_hg19.bwt2glob.unmap_trimmed.fastq &gt; logs/dixon_2M/SRR400264_00_R2_hg19.bwt2glob.unmap_readsTrimming.<span class="hljs-built_in">log</span> 2&gt;&amp;1<br><span class="hljs-comment">### 再用bowtie2 mapping一次</span><br>/PATH/TO/bowtie2/bowtie2-2.3.3.1/bowtie2 --very-sensitive -L 20 --score-min L,-0.6,-0.2 --end-to-end --reorder --rg-id BML --rg SM:SRR400264_00_R1_hg19.bwt2glob.unmap -p 20 -x /PATH/TO/HiC-Pro/HiC-Pro_2.11.1/Bowtie2Index/hg19 -U bowtie_results/bwt2_local/dixon_2M/SRR400264_00_R1_hg19.bwt2glob.unmap_trimmed.fastq 2&gt;&gt; logs/dixon_2M/SRR400264_00_R1_hg19.bwt2glob.unmap_bowtie2.log | /PATH/TO/samtools/samtools-1.6/bin/samtools view -bS - &gt; bowtie_results/bwt2_local/dixon_2M/SRR400264_00_R1_hg19.bwt2glob.unmap_bwt2loc.bam<br>/PATH/TO/bowtie2/bowtie2-2.3.3.1/bowtie2 --very-sensitive -L 20 --score-min L,-0.6,-0.2 --end-to-end --reorder --rg-id BML --rg SM:SRR400264_00_R2_hg19.bwt2glob.unmap -p 20 -x /PATH/TO/HiC-Pro/HiC-Pro_2.11.1/Bowtie2Index/hg19 -U bowtie_results/bwt2_local/dixon_2M/SRR400264_00_R2_hg19.bwt2glob.unmap_trimmed.fastq 2&gt;&gt; logs/dixon_2M/SRR400264_00_R2_hg19.bwt2glob.unmap_bowtie2.log | /PATH/TO/samtools/samtools-1.6/bin/samtools view -bS - &gt; bowtie_results/bwt2_local/dixon_2M/SRR400264_00_R2_hg19.bwt2glob.unmap_bwt2loc.bam<br></code></pre></td></tr></table></figure><p>这一步将unmapping结果，用酶切位点分割，然后将分割结果，再mapping一次。得到结果</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs sh">|   |-- bwt2_local<br>|       |-- dixon_2M<br>|       |   |-- SRR400264_00_R1_hg19.bwt2glob.unmap_bwt2loc.bam<br>|       |   |-- SRR400264_00_R1_hg19.bwt2glob.unmap_trimmed.fastq<br>|       |   |-- SRR400264_00_R2_hg19.bwt2glob.unmap_bwt2loc.bam<br>|       |   |-- SRR400264_00_R2_hg19.bwt2glob.unmap_trimmed.fastq<br>|       |-- dixon_2M_2<br>|           |-- SRR400264_01_R1_hg19.bwt2glob.unmap_bwt2loc.bam<br>|           |-- SRR400264_01_R1_hg19.bwt2glob.unmap_trimmed.fastq<br>|           |-- SRR400264_01_R2_hg19.bwt2glob.unmap_bwt2loc.bam<br>|           |-- SRR400264_01_R2_hg19.bwt2glob.unmap_trimmed.fastq<br></code></pre></td></tr></table></figure><h2 id="3-mapping-combine-log"><a href="#3-mapping-combine-log" class="headerlink" title="3. mapping_combine.log"></a>3. mapping_combine.log</h2><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-built_in">cat</span> mapping_combine.log<br><br><span class="hljs-comment">### 将global的bam与local的bam用samtools merge</span><br>/PATH/TO/samtools/samtools-1.6/bin/samtools merge -@ 20 -n -f bowtie_results/bwt2/dixon_2M/SRR400264_00_R1_hg19.bwt2merged.bam bowtie_results/bwt2_global/dixon_2M/SRR400264_00_R1_hg19.bwt2glob.bam bowtie_results/bwt2_local/dixon_2M/SRR400264_00_R1_hg19.bwt2glob.unmap_bwt2loc.bam<br>/PATH/TO/samtools/samtools-1.6/bin/samtools merge -@ 20 -n -f bowtie_results/bwt2/dixon_2M/SRR400264_00_R2_hg19.bwt2merged.bam bowtie_results/bwt2_global/dixon_2M/SRR400264_00_R2_hg19.bwt2glob.bam bowtie_results/bwt2_local/dixon_2M/SRR400264_00_R2_hg19.bwt2glob.unmap_bwt2loc.bam<br><br><span class="hljs-comment">### sort</span><br>/PATH/TO/samtools/samtools-1.6/bin/samtools <span class="hljs-built_in">sort</span> -@ 20 -n -T tmp/SRR400264_00_R2_hg19 -o bowtie_results/bwt2/dixon_2M/SRR400264_00_R2_hg19.bwt2merged.sorted.bam bowtie_results/bwt2/dixon_2M/SRR400264_00_R2_hg19.bwt2merged.bam<br>/PATH/TO/samtools/samtools-1.6/bin/samtools <span class="hljs-built_in">sort</span> -@ 20 -n -T tmp/SRR400264_00_R1_hg19 -o bowtie_results/bwt2/dixon_2M/SRR400264_00_R1_hg19.bwt2merged.sorted.bam bowtie_results/bwt2/dixon_2M/SRR400264_00_R1_hg19.bwt2merged.bam<br><br>[bam_sort_core] merging from 0 files and 20 in-memory blocks...<br>[bam_sort_core] merging from 0 files and 20 in-memory blocks...<br><br><span class="hljs-comment">### 改名</span><br><span class="hljs-built_in">mv</span> bowtie_results/bwt2/dixon_2M/SRR400264_00_R1_hg19.bwt2merged.sorted.bam bowtie_results/bwt2/dixon_2M/SRR400264_00_R1_hg19.bwt2merged.bam<br><span class="hljs-built_in">mv</span> bowtie_results/bwt2/dixon_2M/SRR400264_00_R2_hg19.bwt2merged.sorted.bam bowtie_results/bwt2/dixon_2M/SRR400264_00_R2_hg19.bwt2merged.bam<br></code></pre></td></tr></table></figure><h2 id="4、merge"><a href="#4、merge" class="headerlink" title="4、merge"></a>4、merge</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment">### 将R1与R2 merge为一个文件。</span><br><span class="hljs-built_in">cat</span> mergeSAM.<span class="hljs-built_in">log</span><br>/PATH/TO/python/python-2.7.10/bin/python /PATH/TO/HiC-Pro/HiC-Pro_2.11.1/scripts/mergeSAM.py -q 0 -t -v -f bowtie_results/bwt2/dixon_2M/SRR400264_00_R1_hg19.bwt2merged.bam -r bowtie_results/bwt2/dixon_2M/SRR400264_00_R2_hg19.bwt2merged.bam -o bowtie_results/bwt2/dixon_2M/SRR400264_00_hg19.bwt2pairs.bam<br><span class="hljs-comment">## mergeBAM.py</span><br><span class="hljs-comment">## forward= bowtie_results/bwt2/dixon_2M/SRR400264_00_R1_hg19.bwt2merged.bam</span><br><span class="hljs-comment">## reverse= bowtie_results/bwt2/dixon_2M/SRR400264_00_R2_hg19.bwt2merged.bam</span><br><span class="hljs-comment">## output= bowtie_results/bwt2/dixon_2M/SRR400264_00_hg19.bwt2pairs.bam</span><br><span class="hljs-comment">## min mapq= 0</span><br><span class="hljs-comment">## report_single= False</span><br><span class="hljs-comment">## report_multi= False</span><br><span class="hljs-comment">## verbose= True</span><br><span class="hljs-comment">## Merging forward and reverse tags ...</span><br></code></pre></td></tr></table></figure><h2 id="5、利用HiCPro的mapped-2hic-fragments-py程序将比对结果转化为Hi-C片段信息"><a href="#5、利用HiCPro的mapped-2hic-fragments-py程序将比对结果转化为Hi-C片段信息" class="headerlink" title="5、利用HiCPro的mapped_2hic_fragments.py程序将比对结果转化为Hi-C片段信息"></a>5、利用HiCPro的mapped_2hic_fragments.py程序将比对结果转化为Hi-C片段信息</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">cat</span> mapped_2hic_fragments.log<br>/PATH/TO/python /PATH/TO/HiC-Pro/HiC-Pro_2.11.1/scripts/mapped_2hic_fragments.py -v -S -t 100 -m 100000 -s 100 -l 600 -a -f /PATH/TO/HiC-Pro_2.11.1/annotation/HindIII_resfrag_hg19.bed -r bowtie_results/bwt2/dixon_2M/SRR400264_00_hg19.bwt2pairs.bam -o hic_results/data/dixon_2M<br><span class="hljs-comment">## overlapMapped2HiCFragments.py</span><br><span class="hljs-comment">## mappedReadsFile= bowtie_results/bwt2/dixon_2M/SRR400264_00_hg19.bwt2pairs.bam</span><br><span class="hljs-comment">## fragmentFile= /PATH/TO/HiC-Pro/HiC-Pro_2.11.1/annotation/HindIII_resfrag_hg19.bed</span><br><span class="hljs-comment">## minInsertSize= 100</span><br><span class="hljs-comment">## maxInsertSize= 600</span><br><span class="hljs-comment">## minFragSize= 100</span><br><span class="hljs-comment">## maxFragSize= 100000</span><br><span class="hljs-comment">## allOuput= True</span><br><span class="hljs-comment">## SAM ouput= True</span><br><span class="hljs-comment">## verbose= True</span><br></code></pre></td></tr></table></figure><p>再对输出的valid pairs文件排序：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sh">LANG=en; <span class="hljs-built_in">sort</span> -T tmp -k2,2V -k3,3n -k5,5V -k6,6n -o hic_results/data/sample/sample_sample_genome_ref.bwt2pairs.validPairs hic_results/data/sample/sample_sample_genome_ref.bwt2pairs.validPairs<br></code></pre></td></tr></table></figure><h2 id="6-对所有的valid-pairs进行合并"><a href="#6-对所有的valid-pairs进行合并" class="headerlink" title="6 对所有的valid pairs进行合并"></a>6 对所有的valid pairs进行合并</h2><figure class="highlight dart"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs dart">LANG=en; sort -T tmp -S <span class="hljs-number">50</span>% -k2,<span class="hljs-number">2</span>V -k3,<span class="hljs-number">3</span>n -k5,<span class="hljs-number">5</span>V -k6,<span class="hljs-number">6</span>n -m hic_results/data/dixon_2M_2/SRR400264_01_hg19.bwt2pairs.validPairs | awk -F<span class="hljs-string">&quot;\t&quot;</span> <span class="hljs-string">&#x27;BEGIN&#123;c1=0;c2=0;s1=0;s2=0&#125;(c1!=<span class="hljs-subst">$2</span> || c2!=<span class="hljs-subst">$5</span> || s1!=<span class="hljs-subst">$3</span> || s2!=<span class="hljs-subst">$6</span>)&#123;print;c1=<span class="hljs-subst">$2</span>;c2=<span class="hljs-subst">$5</span>;s1=<span class="hljs-subst">$3</span>;s2=<span class="hljs-subst">$6</span>&#125;&#x27;</span> &gt; hic_results/data/dixon_2M_2/dixon_2M_2.allValidPairs<br></code></pre></td></tr></table></figure><p>生成最终文件dixon_2M_2.allValidPairs。</p><p>这个文件还不能可视化，如果要可视化，一般在jucebox里面查看。需要用配套的hicpro2juicebox.sh来转化：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment">## e.g.1</span><br>HICPRO_PATH/bin/utils/hicpro2juicebox.sh -i hicpro_res/hic_results/data/dixon_2M/dixon_2M_allValidPairs -g hg19 -j /usr/local/juicebox/juicebox_clt_1.4.jar<br></code></pre></td></tr></table></figure><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs sh">-j jar<br>/PATH/TO/juicer/juicer/UGER/scripts/juicer_tools.jar<br></code></pre></td></tr></table></figure><h1 id="HiC-Pro-输出"><a href="#HiC-Pro-输出" class="headerlink" title="HiC-Pro 输出"></a>HiC-Pro 输出</h1><p>共有<strong>bowtie_results</strong>和<strong>hic_results</strong>两个结果文件夹。</p><p>其中<strong>bowtie_results</strong>下三个文件夹：bwt2、bwt2_global和bwt2_local，分别是序列比对结果、<font color="blue">染色体间</font>关联比对结果和<font color="blue">染色体内</font>部关联比对结果。bwt2文件夹有数据统计结果输出文件，如mpairstat文件。</p><p><strong>hic_results</strong>文件夹下共有data、matrix以及pic三个文件夹。</p><ul><li><p>data文件夹下是比对上的有效序列对，文件末尾为_allValidPairs合并后的pairs数据</p><p><code>DEPairs</code>:Dangling end pairs数据</p><p><code>DumpPairs</code>:实际片段长度和理论片段长度不同的数据</p><p><code>REPairs</code>：酶切片段重新连接的pairs</p><p><code>FiltePairs</code>:MAPQ过低的pairs</p><p><code>SCPairs</code>：片段自连的pairs</p></li><li><p>pic文件夹下是各类结果数据统计；存放统计分析图片</p><p>HiC文库片段分布文件</p><p>双端比对过滤质控图</p><p>有效数据过滤质控图</p><p>配对数据不同类型数据比例展示图</p></li><li><p>matrix文件夹下分为 iced(标准化) 和 raw(原始) 两个文件夹，分别标准化后的关联矩阵和初始的关联矩阵。存放不同分辨率矩阵文件</p></li></ul><p>后续compartment，TAD和loop？</p><h1 id="可视化"><a href="#可视化" class="headerlink" title="可视化"></a>可视化</h1><p><a href="https://mp.weixin.qq.com/s?__biz=MzUyMTk4ODM0OQ==&mid=2247483678&idx=1&sn=a1aa97892723f6fb51bd3b01a6441e6c&chksm=f9d3f08ccea4799af0a4401e938307a3f6e860239e905deb6963a82a8fc799a4af504e96bc10&scene=178&cur_album_id=1399424041152528385#rd">微信公众号</a></p><p><a href="https://weixin.sogou.com/weixin?type=2&query=%E6%9F%93%E8%89%B2%E8%B4%A8%E9%AB%98%E7%BA%A7%E7%BB%93%E6%9E%84%E7%A0%94%E7%A9%B6%E4%B9%8BHi-C%E6%8A%80%E6%9C%AF%EF%BC%88%E4%B8%8B%E7%AF%87%EF%BC%89%E2%80%94%E2%80%94%E5%8F%AF%E8%A7%86%E5%8C%96%E5%AE%9E%E6%88%98&ie=utf8&s_from=input&_sug_=n&_sug_type_=&w=01019900&sut=935&sst0=1646835948011&lkt=2,1646835946980,1646835947908">染色质高级结构研究之Hi-C技术（下篇）——可视化实战</a></p><h1 id="Error-debug"><a href="#Error-debug" class="headerlink" title="Error debug"></a>Error debug</h1><blockquote><p>HIC-PRO DOES NOT GENERATE ANY MAPS<br>HiC-Pro is using the chrom.sizes files to build the map.<br>Be sure that your chromosome names are the same in all annotations files (bowtie2 indexes, restriction fragments, chromosome sizes, etc.)</p></blockquote><blockquote><p>hiclib and mirnylib are not compatible with python 2.5 and 3.x, but work fine with py 2.6, 2.7</p><p>hiclib主要用于数据标准化，hicpro可以，为什么还要安装hiclib? 或者是想比较两者分析的结果？</p><p>HiC-Pro需要python版本&gt;&#x3D;3.7, 安装3.9</p></blockquote><p><strong>Error1</strong>：directly use hicpro on the cluster,  —qual 多一个-无法解决，自己安装<br>&#x2F;software&#x2F;biosoft&#x2F;software&#x2F;bowtie2-2.2.9&#x2F;bowtie2-align-s: <font color="red"><strong>unrecognized option ‘—quals’</strong></font><br>Bowtie 2 version 2.2.9 by Ben Langmead (<a href="mailto:&#108;&#x61;&#x6e;&#103;&#109;&#x65;&#97;&#64;&#99;&#115;&#46;&#106;&#x68;&#x75;&#x2e;&#x65;&#x64;&#117;">&#108;&#x61;&#x6e;&#103;&#109;&#x65;&#97;&#64;&#99;&#115;&#46;&#106;&#x68;&#x75;&#x2e;&#x65;&#x64;&#117;</a>, <a href="http://www.cs.jhu.edu/~langmea">www.cs.jhu.edu/~langmea</a>)<br>Usage:<br>  bowtie2 [options]* -x <bt2-idx> {-1 <m1> -2 <m2> | -U <r>} [-S <sam>]</p><p>Encountered internal Bowtie 2 exception (#1)<br>Command: &#x2F;software&#x2F;biosoft&#x2F;software&#x2F;bowtie2-2.2.9&#x2F;bowtie2-align-s –wrapper basic-0 –very-sensitive -L 30 –score-min L,-0.6,-0.2 –end-to-end –reorder –rg-id BMG –rg SM:L3_R1 <font color="red"><strong>—quals</strong></font> -p 10 -x &#x2F;xtdisk&#x2F;xueyb_group&#x2F;wangchenA&#x2F;Petunia_denovo&#x2F;HiFi&#x2F;02.bwa_mapping&#x2F;primary&#x2F;&#x2F;HiFi.p_ctg –passthrough -U &#x2F;tmp&#x2F;34683.unp<br>(ERR): bowtie2-align exited with value 1</p><p>自己安装时，先创建conda环境，再tar xzvf，然后<font color="red"><strong>编辑config-install.txt的prefix 再make configure &amp;&amp; make install</strong></font><br><strong>Error2</strong>在错误产生output文件夹时再次运行直接报错stat: <font color="red"><strong>Bad file descriptor，先删除output_dir</strong></font><br>设置config-install.txt 的prefix时设置成&#x2F;&#x2F;&#x2F;software&#x2F;HiC-Pro<font color="red"><strong>&#x2F;</strong></font><br>报错：<br><strong>Error3</strong>：install in another dir HiC-Pro， PREFIX &#x3D; &#x2F;xtdisk&#x2F;xueyb_group&#x2F;wangchenA&#x2F;software&#x2F;HiC-Pro&#x2F;<br>&#x2F;xtdisk&#x2F;xueyb_group&#x2F;wangchenA&#x2F;software&#x2F;HiC-Pro&#x2F;HiC-Pro-3.1.0&#x2F;bin&#x2F;..&#x2F;scripts&#x2F;&#x2F;Makefile:48: &#x2F;xtdisk&#x2F;xueyb_group&#x2F;wangchenA&#x2F;software&#x2F;HiC-Pro<font color="red"><strong>&#x2F;&#x2F;</strong></font>config-system.txt: No such file or directory<br>make:  No rule to make target ‘&#x2F;xtdisk&#x2F;xueyb_group&#x2F;wangchenA&#x2F;software&#x2F;HiC-Pro<font color="red"><strong>&#x2F;&#x2F;</strong></font>config-system.txt’.  Stop.<br>The config-system.txt file is a file which should be within the installation folder.<br>检查config-system.txt 发现多了&#x2F;&#x2F;<br>设置config-install.txt 的prefix时设置成&#x2F;&#x2F;&#x2F;software&#x2F;HiC-Pro时会<font color="red"><strong>自动产生软件名文件夹</strong></font>，后面<font color="red">多加斜杠&#x2F;直接报错</font></p><p><strong>successfully installed</strong>  </p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs sh">(HiC_Pro_ENV) [HiC-Pro-3.1.0]$ vi config-install.txt <br>PREFIX = ////software<br>(HiC_Pro_ENV) [HiC-Pro-3.1.0]$ make configure<br>make -f ./scripts/install/Makefile CONFIG_SYS=./config-install.txt<br>make[1]: Entering directory <span class="hljs-string">&#x27;/xtdisk/group/wangchenA/HiC-Pro-3.1.0&#x27;</span><br>./scripts/install/install_dependencies.sh -c ./config-install.txt -p /xtdisk/group/wangchenA/software -o /xtdisk/group/wangchenA/software/HiC-Pro_3.1.0 -q<br>Make sure internet connection works <span class="hljs-keyword">for</span> your shell prompt under current user<span class="hljs-string">&#x27;s privilege ...</span><br><span class="hljs-string">Starting HiC-Pro installation !</span><br><span class="hljs-string">Checking dependencies</span><br><span class="hljs-string">- Python libraries ...OK</span><br><span class="hljs-string">- R installation ...OK</span><br><span class="hljs-string">- Bowtie2 installation ...OK</span><br><span class="hljs-string">- Samtools installation ...OK</span><br><span class="hljs-string">Checking HiC-Pro configuration</span><br><span class="hljs-string">- Configuration for TORQUE/PBS system ...OK</span><br><span class="hljs-string">done !</span><br><span class="hljs-string">make[1]: Leaving directory &#x27;</span>/xtdisk/group/wangchenA/HiC-Pro-3.1.0<span class="hljs-string">&#x27;</span><br><span class="hljs-string"></span><br><span class="hljs-string">(/HiC_Pro_ENV) [HiC-Pro-3.1.0]$ make install</span><br><span class="hljs-string">(g++ -Wall -O2 -std=c++0x -o build_matrix /xtdisk/group/wangchenA/HiC-Pro-3.1.0/scripts/src/build_matrix.cpp; mv build_matrix /xtdisk/group/wangchenA/HiC-Pro-3.1.0/scripts)</span><br><span class="hljs-string">(g++ -Wall -O2 -std=c++0x -o cutsite_trimming /xtdisk/group/wangchenA/HiC-Pro-3.1.0/scripts/src/cutsite_trimming.cpp; mv cutsite_trimming /xtdisk/group/wangchenA/HiC-Pro-3.1.0/scripts)</span><br><span class="hljs-string">cp -Ri /xtdisk/group/wangchenA/HiC-Pro-3.1.0 /xtdisk/group/wangchenA/software/HiC-Pro_3.1.0</span><br><span class="hljs-string">HiC-Pro installed in /xtdisk/group/wangchenA/software/HiC-Pro_3.1.0 !</span><br></code></pre></td></tr></table></figure><p>Issue from: <a href="https://github.com/nservant/HiC-Pro/issues/289">https://github.com/nservant/HiC-Pro/issues/289</a></p><blockquote><p>you <font color="green"><strong>do not have the rigths</strong></font> to install HiC-Pro in <font color="green"><strong>&#x2F;usr&#x2F;local&#x2F;bin</strong></font><br>Update the <font color="green"><strong>PREFIX&#x3D; in the config-install.txt</strong></font> file before running the installation</p><p>You <font color="green"><strong>cannot install it in the path where you have downloaded it</strong> </font>!Please <font color="green"><strong>set another prefix</strong></font>.Note that it will <font color="green"><strong>create the HiC-Pro_3.0.0 folder by itself</strong></font></p></blockquote><p><font color="red"><strong>NOTICE</strong></font></p><ul><li>.&#x2F;configure –prefix&#x3D;  &amp;&amp;  make  &amp;&amp;  make install</li><li>Vim config-install.txt PREFIX  &amp;&amp;  make configure  &amp;&amp;  make install</li></ul><hr><p><strong>bowtie_pairing] Error 1</strong><br><a href="https://github.com/nservant/HiC-Pro/issues/482">https://github.com/nservant/HiC-Pro/issues/482</a></p><p>Thu Sep 23 04:23:58 CST 2021<br>Pairing of R1 and R2 tags …<br>Logs: logs&#x2F;sample1&#x2F;mergeSAM.log<br>make: *** [bowtie_pairing] Error 1</p><p>the mergeSAM.log<br>~&#x2F;miniconda3&#x2F;envs&#x2F;hic-pro_env&#x2F;bin&#x2F;python ~&#x2F;02_software&#x2F;hic-pro&#x2F;HiC-Pro-3.1.0&#x2F;scripts&#x2F;mergeSAM.py -q 10 -t -v -f bowtie_results&#x2F;bwt2&#x2F;sample1&#x2F;XB_R1_merged_canu_asm.fasta.bwt2merged.bam -r bowtie_results&#x2F;bwt2&#x2F;sample1&#x2F;XB_R2_merged_canu_asm.fasta.bwt2merged.bam -o bowtie_results&#x2F;bwt2&#x2F;sample1&#x2F;XB_merged_canu_asm.fasta.bwt2pairs.bam<br>[E::idx_find_and_load] Could not retrieve index file for ‘bowtie_results&#x2F;bwt2&#x2F;sample1&#x2F;XB_R1_merged_canu_asm.fasta.bwt2merged.bam’<br>[E::idx_find_and_load] Could not retrieve index file for ‘bowtie_results&#x2F;bwt2&#x2F;sample1&#x2F;XB_R2_merged_canu_asm.fasta.bwt2merged.bam’</p><p>mapping_combine.log:<br>[bam_sort_core] merging from 6120 files and 36 in-memory blocks…<br>[E::hts_open_format] Failed to open file “tmp&#x2F;XB_R1_merged_canu_asm.fasta.1018.bam” : Too many open files<br>samtools sort: fail to open “tmp&#x2F;XB_R1_merged_canu_asm.fasta.1018.bam”: Too many open files</p><p>yes well done ! So the samtools sort failed.<br>If you look at your command, -@ 36 -m 21M, means that it only has 21Mo to sort the file which is too few.<br>So it has to swap a lot, and generate too many tmp files.<br>This memory parameter is in your configuration file SORT_RAM. By default, it is set to 768M</p><p>Actually, the SORT_RAM parameter is divided by the number of CPUs<br>For instance, using 1000M with 4 CPUs means that samtools sort is run with 250M of RAM.<br>So it makes sense … you have 1000M &#x2F; 36 CPU &#x3D; 27M of RAM.<br>I would suggest to decrease the number of CPU to 8 for instance … this is enough ! or to increase again the SORT_RAM parameter.</p><hr><p>ref</p><p><a href="https://www.plob.org/article/24873.html">https://www.plob.org/article/24873.html</a></p><p><a href="https://lxz9.com/2021/08/05/ALLHIC/">https://lxz9.com/2021/08/05/ALLHIC/</a> ALLHiC</p>]]></content>
    
    
    <categories>
      
      <category>Software</category>
      
    </categories>
    
    
    <tags>
      
      <tag>assembly</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【Linux集群任务调度系统】【LSF/SGE/Slurm/PBS】【grid】</title>
    <link href="/GeekFocus/2022/03/06/2022-03-06-Linux-grid/"/>
    <url>/GeekFocus/2022/03/06/2022-03-06-Linux-grid/</url>
    
    <content type="html"><![CDATA[<p>调度器主要是基于<strong>HPC场景</strong>的<strong>集群任务调度系统</strong>，英文<strong>Cluster Scheduler</strong>、<strong>Job Scheduler</strong>等。</p><p>市面主流调度器有四大流派：<font color="red"><strong>LSF   SGE   Slurm   PBS</strong></font></p><span id="more"></span><h1 id="从Cluster-集群-、Grid-网格-到-Cloud-（云）"><a href="#从Cluster-集群-、Grid-网格-到-Cloud-（云）" class="headerlink" title="从Cluster (集群)、Grid (网格) 到 Cloud （云）"></a>从Cluster (集群)、Grid (网格) 到 Cloud （云）</h1><p>为解决复杂的<strong>计算密集型</strong>和<strong>数据密集型</strong>问题，需要<strong>高网络性能</strong>、<strong>快速存储</strong>、<strong>大量内存</strong>、<strong>超高计算能力</strong>。</p><h2 id="Cluster"><a href="#Cluster" class="headerlink" title="Cluster"></a><strong>Cluster</strong></h2><p>一组松散集成的计算机<strong>软件</strong>或<strong>硬件</strong>连接起来<strong>高度紧密地协作</strong>完成计算工作。在某种意义上，可以被看作是一台计算机。集群系统中的<font color="blue"><strong>单个计算机</strong></font>通常称为<font color="blue"><strong>节点node</strong></font>，通常通过<strong>局域网(LAN)连接</strong>,性价比比<font color="blue"><strong>大型机（mainframe）</strong></font>等<strong>高</strong>。</p><h2 id="Grid"><a href="#Grid" class="headerlink" title="Grid"></a><strong>Grid</strong></h2><p>通过<strong>利用</strong>大量<strong>异构计算机</strong>的<strong>未用资源</strong>，如<strong>CPU</strong>、<strong>磁盘存储</strong>等，将其作为嵌入在分布式的一个<strong>虚拟的计算机集群</strong>，为解决<strong>大规模计算问题</strong>提供一个<strong>模型</strong>。目标是<font color="blue">解决</font>对单一超级计算机都<font color="blue">困难的大问题</font>，并同时保持解决多个<font color="blue">较小</font>问题的灵活性。网格天生就是在本地网、城域网或广域网上进行分布的。网格<font color="blue">可以分布在任何地方</font>。而<font color="blue">集群</font>物理上都在<font color="blue">一处</font>，通常是<font color="blue">局域网互连</font>。</p><h2 id="Cloud"><a href="#Cloud" class="headerlink" title="Cloud"></a><strong>Cloud</strong></h2><p>集群技术发展而来，区别在于<font color="blue">集群虽然把多台机器联起来</font>，但其<font color="blue">某项<strong>具体任务</strong>执行的时候还是会被转发到<strong>某台服务器</strong>上</font>，而<font color="blue">云</font>可以简单认为是<font color="blue">任务被<strong>分割成多个进程</strong>在<strong>多台服务器</strong>上<strong>并行计算</strong></font>，优势是大数据量的操作性能非常好。云可以使用廉价的PC服务器 ，可以<font color="blue"><strong>管理</strong>大数据量与大集群</font>，<font color="blue">关键技术在于能够对云内的基础设施进行动态按需分配与管理</font>。云计算与并行计算、分布式计算的区别，<font color="red">对于计算机用户，<strong>并行计算</strong>由<strong>单个用户完成</strong>，<strong>分布式计算</strong>由<strong>多个用户合作</strong>完成，<strong>云计算</strong>是<strong>没有用户参与</strong>，而是交给<strong>网络另一端的服务器完成</strong>。</font></p><p><img src="/GeekFocus/./1.png" alt="img"></p><p><img src="/GeekFocus/./2.png" alt="img"></p><p><strong>研究发现</strong>：<strong>商务计算机</strong>只用到其<strong>功能</strong>的 <strong>10％ —20％</strong>。24 小时内，一般的 <strong>UNIX 服务器</strong>只<strong>利用 10％</strong> 的时间，大型机大约 40％，<strong>台式机少于 5％</strong>。同样时间间隔内，利用<strong>网格计算</strong>，<strong>资源利用</strong>可以达到 <strong>90％</strong> 。</p><h2 id="从服务角度看网格分类"><a href="#从服务角度看网格分类" class="headerlink" title="从服务角度看网格分类"></a><strong>从服务角度看网格分类</strong></h2><ul><li><p><strong>专用网格</strong></p><p>由用于网格的<strong>专用硬件</strong>和<strong>计算资源</strong>组成, 提供了<strong>最大</strong>的<strong>控制</strong>和<strong>灵活性</strong></p></li><li><p><strong>非专用网格</strong></p><p>更多地<strong>依赖</strong>于<strong>现有网络</strong>和<strong>基础设施</strong>，对<strong>网络决策</strong>的<strong>控制很少</strong>甚至不能控制。</p></li><li><p><strong>分布式网格</strong></p><p>分布式网格 由在 WAN 或 <font color="blue"><strong>Internet 上分布的</strong>、<strong>位于任何位置</strong></font>（内部或外部）的<strong>计算机资源组成</strong>。</p></li></ul><h2 id="从应用角度网格分类"><a href="#从应用角度网格分类" class="headerlink" title="从应用角度网格分类"></a><strong>从应用角度网格分类</strong></h2><ul><li><p><strong>计算网格</strong></p><p>侧重于<font color="blue">计算密集型</font>操作的网格</p></li><li><p><strong>数据网格</strong></p><p>处理数据的数据计算系统——<font color="blue">控制大量的分布式数据的共享和管理</font></p></li><li><p><strong>设备网格</strong></p><p><font color="blue">用于<strong>远程控制</strong>设备和分析产生的数据</font></p></li></ul><h1 id="SGE-Sun-Grid-Engine"><a href="#SGE-Sun-Grid-Engine" class="headerlink" title="SGE [Sun Grid Engine]"></a>SGE [Sun Grid Engine]</h1><p><font color="red">从<strong>登陆节点</strong>上<strong>向计算节点</strong>进行<strong>任务投递</strong></font>。SGE或者其他集群管理工作做的事情就是<font color="blue">将用户投递的<strong>任务排队</strong></font>，然后将任务交给<font color="blue"><strong>能够运行</strong>的<strong>计算节点执行</strong></font>，工作流程分四步:</p><ol><li><strong>接受</strong>用户投放的<strong>任务</strong></li><li>在任务运行以前，将任务<strong>放到</strong>一个<strong>存储区域</strong></li><li><strong>发送任务</strong>到一个<strong>执行设备</strong>，并<strong>监控</strong>任务的运行</li><li>运行<strong>结束</strong>写回结果并记录运行<strong>日志</strong></li></ol><h2 id="SGE的常用命令"><a href="#SGE的常用命令" class="headerlink" title="SGE的常用命令"></a>SGE的常用命令</h2><h3 id="任务投递"><a href="#任务投递" class="headerlink" title="任务投递"></a>任务投递</h3><p>SGE中投递任务所用到的命令是<code>qsub</code>. 最简单的用法，即将要执行的命令通过标准输入的方式传递给<code>qsub</code></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;ls -l &quot;</span> | qsub<br></code></pre></td></tr></table></figure><p>投递之后可以用<code>qstat</code>查看任务运行情况，如下图</p><p><img src="/GeekFocus/./3.png" alt="img"></p><p>任务投递情况</p><p>第一列是任务编号, 第二列是优先级，第三列是任务名字，在参数里没有特别说明的情况下，SGE会用任务的来源进行命令，STDIN表示来自于标准输入，第四列是用户名，第五列是运行状态(“r”表示运行中), 第六列表示任务投递和开始时间，第七列是任务投递的节点，第8列则是要申请的线程数。在执行完成后会在家目录下生成”STDIN.e7883”和”STDIN.o7883”, 其中7883是任务编号, 前者存放标准错误输出, 后者存放标准输出， 因此”cat STDIN.o7883”的内容就是<code>ls -l</code>的内容。</p><p>另一种方法是先写脚本后投递，比如先编辑文件”ls.sh”, 然后用”qsub ls.sh”投递任务。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">ls</span> -l<br></code></pre></td></tr></table></figure><p>跟之前一样，最后在home目录产生了”ls.sh.exxxx”和”ls.sh.exxxx”两个文件</p><p>实际肯定没有那么简单，需要增加各种参数来调整<code>qsub</code>的行为，用<code>qsub -help</code>可以看完整参数，但是常用的为如下几个 </p><ul><li>-q xxx : 指定要投递到的队列，如果不指定的话，SGE会在用户可使用的队列中选择一个满足要求的队列</li><li>-V： <font color="red">将当前的环境变量传递到执行命令的节点【在使用PBS时，直接运行可以执行，投递PBS则失败，是任务到了计算节点不识别环境变量？】</font></li><li>cwd: 在当前目录下执行任务, sge的日志会输出到当前路径。 不增加该指令，所有投递的任务都会在home目录下执行</li><li>-l resource&#x3D;value: 请求资源数, 例如 <code>-l vf=25G -l h=node1</code> 任务的预估内存要25G(内存估计的值应稍微大于真实内存，内存预估偏小可能会导致节点跑挂), 申请在node1上运行</li><li>-S &#x2F;bin&#x2F;bash: 表示在bash环境下执行命令。默认tcsh.</li><li>-pe openmpi 4: 表示使用openmpi进行并行运算，且申请的线程是4，</li><li>-N 任务名: 手动执行任务的名字</li><li>-j y|n ：是否将标准输入和标准输入合并成一个文件</li><li>-sync y|n: 是否等待任务结束，返回退出码</li><li>-o path: 指定标准输出的文件夹</li></ul><p>接下来就可以添加这些参数运行一些命令，例如在命令行里投递一个比对任务</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;bowtie2 -p 8 -x index/ref -1 data/A_1.fq -2 data/A_2.fq | samtools sort &gt; A.bam&quot;</span> | qsub -V -cwd -l vf=25G -S /bin/bash -pe openmpi 8 -N A.bt2<br></code></pre></td></tr></table></figure><p>这些参数除了在<strong>外部设置</strong>外，还可以在shell脚本<strong>内部设置</strong>，如下</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-meta">#!/bin/bash</span><br><span class="hljs-comment">#$ -S /bin/bash</span><br><span class="hljs-comment">#$ -V</span><br><span class="hljs-comment">#$ -cwd</span><br><span class="hljs-comment">#$ -l vf=25G</span><br><span class="hljs-comment">#$ -pe openmpi 8</span><br><span class="hljs-comment">#$ -N a.bt2</span><br>bowtie2 -p 8 -x index/ref -1 data/A_1.fq -2 data/A_2.fq | samtools <span class="hljs-built_in">sort</span> &gt; A.bam<br></code></pre></td></tr></table></figure><h3 id="查询任务"><a href="#查询任务" class="headerlink" title="查询任务"></a>查询任务</h3><p>除任务投递外，查询任务也是常用命令，除直接用<code>qstat</code>查看，还有如下参数比较好用</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs bash">qstat -f        <span class="hljs-comment"># 查看用户任务</span><br>qstat -j jobId  <span class="hljs-comment"># 按任务id查看</span><br>qstat -explain a|c|A|E -j jobID <span class="hljs-comment"># 查看任务任务并给出解释</span><br>qstat -u user   <span class="hljs-comment"># 按用户查看</span><br></code></pre></td></tr></table></figure><p>任务状态：</p><ul><li>qw: 表示等待状态</li><li>hqw: 任务挂起等待中，待依赖的任务完成后执行</li><li>Eqw: 投递任务出错</li><li>r: 表示任务正在运行</li><li>s: 暂时挂起</li><li>dr: 节点挂了之后，删除任务就会出现这个状态，只有节点重启后，任务才会消失</li></ul><h3 id="删除任务"><a href="#删除任务" class="headerlink" title="删除任务"></a>删除任务</h3><p>任务删除也比较重要，偶尔会出现任务投递出错的情况</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">qdel -j 1111   删除任务号为1111的任务<br></code></pre></td></tr></table></figure><h3 id="其他命令"><a href="#其他命令" class="headerlink" title="其他命令"></a>其他命令</h3><ul><li><p>qrsh：与qsub相比，是交互式的投递任务，注意参数:</p><figure class="highlight coffeescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs coffeescript">-now <span class="hljs-literal">yes</span>|<span class="hljs-literal">no</span><br></code></pre></td></tr></table></figure><p>默认设置为yes</p><ul><li>若设置为yes，<font color="blue">立即调度作业</font>，如果没有可用资源，则拒绝作业，任务投递失败，任务状态为Eqw。</li><li>若设置为no，调度时如果没有可用资源，则将作业<font color="blue">排入队列</font>，等待调度。</li><li>例子： qrsh -l vf&#x3D;*G -q all.q -now no -w n *sh</li></ul></li><li><p>qacct 从集群日志中抽取任意账户信息</p></li><li><p>qalter 更改已提交但正处于暂挂状态的作业的属性</p></li><li><p>qconf 为集群和队列配置提供用户界面</p><ul><li><code>qconf -spl</code>查看可用并行环境</li></ul></li><li><p>qhold 阻止已提交作业的执行</p></li><li><p>qhost 显示<font color="blue">SGE执行主机</font>（即<font color="blue">各个计算节点</font>）的<font color="blue">状态信息</font></p><ul><li><code>qhost -j</code>按照节点显示任务</li><li><code>qhost -F</code>展示每个节点的资源</li></ul></li><li><p>qlogin 启动telnet或类似的登录会话。</p></li></ul><h2 id="案例：一个投递比对任务的简单脚本"><a href="#案例：一个投递比对任务的简单脚本" class="headerlink" title="案例：一个投递比对任务的简单脚本"></a>案例：一个投递比对任务的简单脚本</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-meta">#!/bin/bash</span><br><br><span class="hljs-built_in">set</span> -e<br><span class="hljs-built_in">set</span> -u<br><span class="hljs-built_in">set</span> -o pipefail<br><br>threads=8<br>index=index/hg19<br><br>FQ_DIR=<span class="hljs-string">&quot;analysis/0-raw-data&quot;</span><br>ALIGN_DIR=<span class="hljs-string">&quot;analysis/2-read-align&quot;</span><br>LOG_DIR=<span class="hljs-string">&quot;analysis/log&quot;</span><br>TMP_DIR=<span class="hljs-string">&quot;analysis/tmp&quot;</span><br><br><span class="hljs-built_in">mkdir</span> -p <span class="hljs-variable">$&#123;ALIGN_DIR&#125;</span><br><span class="hljs-built_in">mkdir</span> -p <span class="hljs-variable">$&#123;LOG_DIR&#125;</span><br><span class="hljs-built_in">mkdir</span> -p <span class="hljs-variable">$&#123;TMP_DIR&#125;</span><br><br><span class="hljs-built_in">tail</span> -n+2 download_table.txt | <span class="hljs-built_in">cut</span> -f 6 | <span class="hljs-keyword">while</span> <span class="hljs-built_in">read</span> <span class="hljs-built_in">id</span>;<br><span class="hljs-keyword">do</span><br>    <span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;</span><br><span class="hljs-string">    bowtie2 --very-sensitive-local --mm -p <span class="hljs-variable">$threads</span> -x <span class="hljs-variable">$index</span> -U <span class="hljs-variable">$&#123;FQ_DIR&#125;</span>/<span class="hljs-variable">$id</span>.fastq.gz 2&gt; <span class="hljs-variable">$&#123;LOG_DIR&#125;</span>/<span class="hljs-variable">$id</span>.bt2.log | \</span><br><span class="hljs-string">    samtools sort -@ 2 -m 1G -T <span class="hljs-variable">$&#123;TMP_DIR&#125;</span>/<span class="hljs-variable">$&#123;id&#125;</span> -o <span class="hljs-variable">$&#123;ALIGN_DIR&#125;</span>/<span class="hljs-variable">$&#123;id&#125;</span>.sort.bam&quot;</span> | qsub -V -cwd -pe openmpi <span class="hljs-variable">$threads</span> -N <span class="hljs-variable">$&#123;id&#125;</span>_bt2 -q all.q -S /bin/bash<br><span class="hljs-keyword">done</span><br></code></pre></td></tr></table></figure><h1 id="PBS-Protable-Batch-System"><a href="#PBS-Protable-Batch-System" class="headerlink" title="PBS [Protable Batch System]"></a>PBS [Protable Batch System]</h1><h2 id="1-服务器集群"><a href="#1-服务器集群" class="headerlink" title="1. 服务器集群"></a>1. 服务器集群</h2><ul><li>服务器集群指将很多服务器集中一起进行同种服务，在<font color="blue">客户端看来就像只有一个服务器</font>，集群可以利用多个计算机进行<font color="blue">并行计算</font>从而获得很高的计算速度，也可以用多个计算机做<font color="blue">备份</font>，从而使得任何一个机器坏了整个系统还是正常运行。</li><li>集群是一组独立的计算机（节点）的集合体，节点间通过高性能的互连网络连接；<strong>各节点</strong>除作为<strong>单一计算资源</strong>供交互式用户使用外，还可以<strong>协同工作</strong>并表现为一个单一的、集中的计算资源供并行计算任务使用。</li></ul><p><strong>1.1. 集群系统基本信息</strong></p><ul><li>集群配制的<a href="https://baike.baidu.com/item/%E5%88%80%E7%89%87%E6%9C%8D%E5%8A%A1%E5%99%A8/1375424">刀片计算节点</a>的CPU，GPU配制情况。<a href="https://www.dt-stor.com/yingpanbaike/407.html#:~:text=%E5%88%80%E7%89%87%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%B8%8E%E4%BC%A0%E7%BB%9F%E6%9C%BA%E6%9E%B6%E5%BC%8F%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%9B%B8%E6%AF%94%EF%BC%8C%E5%88%80%E7%89%87%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%9B%A0%E5%85%B1%E4%BA%AB%E5%86%B7%E5%8D%B4%E3%80%81%E7%94%B5%E6%BA%90%E7%B3%BB%E7%BB%9F%E8%80%8C%E6%88%90%E4%B8%BA%E5%8F%97%E6%AC%A2%E8%BF%8E%E7%9A%84%E8%8A%82%E8%83%BD%E7%8E%AF%E4%BF%9D%E4%BA%A7%E5%93%81%EF%BC%8C%E4%B8%8E%E5%90%8C%E7%AD%89%E7%9A%841U%E6%9C%BA%E6%9E%B6%E5%BC%8F%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%9B%B8%E6%AF%94%EF%BC%8C%E8%83%BD%E8%80%97%E9%99%8D%E4%BD%8E%E8%BE%BE,40%25%EF%BC%8C%E7%A9%BA%E9%97%B4%E5%8D%A0%E7%94%A8%E5%87%8F%E5%B0%9140%25%20%E3%80%82">刀片机优缺点</a>; <a href="https://www.intel.cn/content/www/cn/zh/products/docs/processors/cpu-vs-gpu.html">GPU与CPU</a>。</li><li>系统配备的<strong>并行文件系统</strong>，各组<strong>刀片机</strong>之间的<strong>网络连接</strong></li><li>系统配制的<font color="blue">登陆管理节点</font>，部署的集群管理系统。用户可根据<font color="blue">登录节点IP，登录集群，提交作业</font>，编译程序。</li></ul><p><strong>1.2. 集群计算资源列表</strong></p><p><img src="/GeekFocus/./4.png" alt="集群计算资源列表示例"></p><ul><li>一般搭建好集群后，都会给出集群计算资源列表，类似于上图的几个部分。<ul><li>首先，会将整个<font color="blue">集群划分为若干个队列（Queue）</font>，并根据<font color="blue">队列资源配置</font>情况进行<font color="blue">相应命名</font>；</li><li>其次，<font color="blue">每个<strong>队列</strong>下若干个<strong>计算节点</strong>（<strong>nodes</strong>），每个计算节点配制<strong>若干个CPU</strong>（<strong>ppn</strong>）</font>；</li><li>最后，对集群的一些其他<strong>信息说明</strong>和<strong>限制情况说明</strong>，如CPU型号和核数，用户<strong>可提交的作业数</strong>，每个作业的<strong>最大运行时间</strong>等。</li></ul></li><li>在往集群上投递任务之前，首先要了解该<strong>任务所需的计算资源是否能被集群所满足</strong>。</li></ul><h2 id="2-PBS任务管理系统"><a href="#2-PBS任务管理系统" class="headerlink" title="2. PBS任务管理系统"></a>2. PBS任务管理系统</h2><h3 id="2-1-PBS-简介"><a href="#2-1-PBS-简介" class="headerlink" title="2.1 PBS 简介"></a><strong>2.1 PBS 简介</strong></h3><ul><li>PBS （Protable Batch System） 是一种常用作业管理系统，其他类似的还有 LSF 和 SLURM。</li></ul><ul><li><p>PBS会根据一个集群上的<strong>可用计算节点</strong>的<strong>计算资源</strong><font color="blue">管理和调度</font>所有计算作业（无论批处理作业还是交互式作业）。</p></li><li><p>目前有两个版本：<font color="blue">OpenPBS（开源）</font>和<font color="blue">PBSPro（商业）</font>。TORQUE：基于PBS项目的开源软件，是开源的OpenPBS改进版。主要包括：</p></li><li><p><strong>PBS Server</strong>：运行于集群的<font color="red"><strong>管理节点</strong></font>。<font color="red"><strong>创建并接受作业、修改作业、激活调度器（PBS Scheduler）以及通知PBS执行器（PBS Moms）执行作业</strong></font></p></li><li><p><strong>PBS Scheduler激活调度器</strong>：根据资源管理器获知<strong>各个节点的资源状况</strong>和<strong>系统的作业信息</strong>生成相应<font color="red">作业优先级列表</font></p></li><li><p><strong>PBS MomsPBS执行器</strong>：<font color="blue">每个节点均有一个<strong>后台进程</strong>，该进程真正<strong>启动</strong>和<strong>停止</strong>提交到该节点的作业</font></p></li></ul><h3 id="2-2-常用PBS命令"><a href="#2-2-常用PBS命令" class="headerlink" title="2.2 常用PBS命令"></a><strong>2.2 常用PBS命令</strong></h3><ul><li>查看节点状态<br><font color="red"><strong>pbsnodes （查看所有节点）</strong></font><br><font color="red"><strong>pbsnodes -l free （查看空闲节点）</strong></font><br>pbsnodes 某节点 （查看某节点状态）</li><li>节点切换<br><font color="red"><strong>ssh 某节点 （转到某节点）</strong></font></li><li>退出节点<br><strong>exit （离开节点）</strong></li><li>查看任务运行状态<br><font color="red"><strong>【qstat （列出所有作业运行状态）】</strong></font></li></ul><blockquote><p>【主要包括以下几个方面信息】</p><ul><li><p>Job ID 任务ID号</p></li><li><p>Name 任务脚本名称</p></li><li><p>User 用户名</p></li><li><p>Time Use 任务运行时间</p></li><li><p>S State 任务状态<br>* B 只用于任务向量，表示任务向量已经开始执行<br>* E 任务在运行后退出<br>* H 任务被服务器或用户或者管理员阻塞<br>* Q 任务正在排队中，等待被调度运行<br>* R 任务正在运行<br>* S 任务被服务器挂起，由于一个更高优先级的任务需要当前任务的资源<br>* T 任务被转移到其它执行节点了<br>* U 由于服务器繁忙，任务被挂起<br>* W 任务在等待它所请求的执行时间的到来(qsub -a)<br>* X 只用于子任务，表示子任务完成<br>* C 表示程序正在被关闭，一般是程序运行错误，报错</p></li><li><p>Queue 任务执行所在队列</p></li></ul><p><strong>qstat -q （列出队列使用信息）</strong><br><strong>qstat -n （列出队列中使用的节点）</strong><br><strong>qstat -f jobid （查看jobid任务的详细信息）</strong></p></blockquote><ul><li><strong>提交</strong>任务到集群<br>qsub 文件名.pbs&#x2F;.sh （提交任务）<br>echo “script.py” | qsub -l q batch1 -l nodes&#x3D;1:ppn&#x3D;2 (直接在终端设置PBS资源命令，并在此资源下提交可执行脚本)</li><li><strong>任务挂起，释放，重新加载</strong><br>qhold：挂起作业<br>qrls：释放挂起的作业<br>qrerun：重新运行作业</li><li><strong>任务更改</strong><br>qmove：将作业移动到另一个队列<br>qalter： 更改作业资源属性</li><li>删除任务<br><strong>qdel jobid</strong> （取消任务）</li></ul><h3 id="2-3-qsub-提交任务"><a href="#2-3-qsub-提交任务" class="headerlink" title="2.3 qsub 提交任务"></a><strong>2.3 qsub 提交任务</strong></h3><p><strong>2.3.1 通过终端提交任务</strong></p><ul><li>通过命令行参数传递给 qsub 命令</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">echo &quot;python script.py -i inputdir -o outdir &quot; | qsub -q Batch1 -l nodes=1:ppn=1 -l mem=40gb -N jobname<br></code></pre></td></tr></table></figure><p><strong>执行script.py 脚本， 通过pbs投递任务, 任务提交到Batch1队列，所需资源为，1个节点，节点使用1个cpu, 40GB物理内存，该任务命名jobname</strong></p><ul><li>-N 任务名称</li><li>-q 指定Queue</li><li><font color="red">-l</font> resource_list 指定<font color="red">任务所需资源</font><br>一般包括：<br>* cput&#x3D;N， 请求N秒CPU时间，N也可以写成hh:mm::ss，单位分别是 时：分：秒<br>* mem&#x3D;N[K|M|G|][B|W], 请求N大小的<font color="red">内存</font><br>* nodes&#x3D;N, N个<font color="red">节点</font><br>* ppn&#x3D;M, 每个节点需要M个<font color="red">cpu</font></li><li>-e path 将标准错误重定向到path</li><li>-o path 标准输出重定向到path</li><li>-j join 将标准输出信息与标准错误信息合并到同一个文件join中去</li><li>-p priority 任务优先级，整数，无定义默认0</li><li>-m mail_options mail_option &#x3D;a：左右abort时给用户发信；&#x3D;b：作业开始时发信；&#x3D;e：作业结束时发信. 默认&#x3D;a</li></ul><p><strong>2.3.2 <font color="red">PBS通过sh脚本执行命令</font></strong></p><ul><li><font color="red">在 PBS 脚本中以 #PBS 方式指定</font><br>在PBS系统中，用户使用qsub命令提交用户程序。用户运行程序的命令 以及 PBS环境变量设置 共同组成了PBS作业脚本。</li><li>注释为 “#” 开头</li><li>PBS指令为 “#PBS” 开头</li><li>shell命令 （运行脚本的命令）</li></ul><p>例如 run.sh</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_">#</span><span class="language-bash">参数解析</span><br><span class="hljs-meta prompt_">#</span><span class="language-bash">指定节点数目 ppn指每个节点运行的cpu数量（4个小节点，每个48个CPU）</span><br><span class="hljs-meta prompt_">#</span><span class="language-bash">PBS -l nodes=1:ppn=16</span><br><span class="hljs-meta prompt_">#</span><span class="language-bash">指定合并到标准输出文件中</span><br><span class="hljs-meta prompt_">#</span><span class="language-bash">PBS -j oe</span><br><span class="hljs-meta prompt_">#</span><span class="language-bash">设置程序运行的最大时间192小时</span><br><span class="hljs-meta prompt_">#</span><span class="language-bash">PBS -l walltime=192:00:00</span><br><span class="hljs-meta prompt_">#</span><span class="language-bash">指定qsub的所有环境变量都传递到批处理作业中</span><br><span class="hljs-meta prompt_">#</span><span class="language-bash">PBS -V</span><br><span class="hljs-meta prompt_">#</span><span class="language-bash">输出文件</span><br><span class="hljs-meta prompt_">#</span><span class="language-bash">PBS -o /public/home/tang/chaim/back_info/<span class="hljs-variable">$jobname</span>.out</span><br><span class="hljs-meta prompt_">#</span><span class="language-bash">错误输出文件</span><br><span class="hljs-meta prompt_">#</span><span class="language-bash">PBS -e /public/home/tang/chaim/back_info/<span class="hljs-variable">$jobname</span>.err</span><br>cd PBS_O_OUTDIR<br><span class="hljs-meta prompt_"># </span><span class="language-bash">程序执行命令</span><br>python script.py -i inputdir -o outdir <br></code></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_"># </span><span class="language-bash">执行脚本</span><br>qsub run.sh<br><span class="hljs-meta prompt_"># </span><span class="language-bash">制定命令开始运行的时间</span>  <br>qusb -a 070000 run.s  #7天后运行程序，此时是处于W状态(等待状态)<br>qsub -a 2400 run.s #24h后运行程序<br></code></pre></td></tr></table></figure><p><strong>2.3.3 通过交互式的方式执行任务</strong></p><ul><li><strong>qsub -I</strong></li><li>qsub -I -q Batch1 -l nodes&#x3D;1:ppn&#x3D;1 -l mem&#x3D;80gb -N jobname</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_">[#</span><span class="language-bash">11<span class="hljs-comment">#Rd01@login ~]$</span></span><br><span class="hljs-meta prompt_">$</span><span class="language-bash">qsub -I -q Batch1 -l nodes=1:ppn=1 -l mem=80gb -N jobname</span><br>qsub: waiting for job 1230615.admin to start<br>qsub: job 1230615.admin ready<br><span class="hljs-meta prompt_"></span><br><span class="hljs-meta prompt_">[#</span><span class="language-bash">1<span class="hljs-comment">#Rd01@comput4 ~]$</span></span><br><span class="hljs-meta prompt_">$</span><br></code></pre></td></tr></table></figure><h3 id="2-4-PBS常用环境变量"><a href="#2-4-PBS常用环境变量" class="headerlink" title="2.4 PBS常用环境变量"></a><strong>2.4 PBS常用环境变量</strong></h3><ul><li>PBS_ENVIRONMENT：批处理作业为 PBS_BATCH，交互式作业为 PBS_INTERACTIVE</li><li>PBS_JOBID：PBS 系统给作业分配的标识号</li><li>PBS_JOBNAME：用户指定的作业名称</li><li>PBS_NODEFILE：包含作业所用计算节点的文件名</li><li>PBS_QUEUE：作业所执行的队列名称</li><li>PBS_O_HOME：执行 qsub 命令的 HOME 环境变量值</li><li>PBS_O_PATH：执行 qsub 命令的 PATH 环境变量值</li><li>PBS_O_SHELL：执行 qsub 命令的 SHELL 环境变量值</li><li>PBS_O_HOST：执行 qsub 命令节点名称</li><li>PBS_O_QUEUE：提交作业的最初队列名称</li><li>PBS_O_WORKDIR：执行 qsub 命令所在的绝对路径</li></ul><h1 id="调度器"><a href="#调度器" class="headerlink" title="调度器"></a>调度器</h1><p><strong>如果有一天，你有16万个CPU，你要怎么用？</strong> <strong>调度器</strong>最大程度压榨现有<strong>资源或时间的最大价值</strong>。</p><p>不同行业因使用习惯和不同调度器对应用的支持力度不同，往往有不同偏好：<strong>比如高校和超算经常用Slurm，半导体公司最常用的是LSF和SGE，工业制造业可能用PBS更多一些。</strong></p><p>1篇 <a href="https://fastonetech.com/blog/biotech-fastone-help-hms-on-molecules-selection-20200709/">15小时虚拟筛选10亿分子，《Nature》+HMS验证云端新药研发未来</a> 文章里哈佛大学医学院用<strong>云端16万个CPU来筛选10亿种化合物</strong>，只用了15小时。<br><strong>超大规模计算集群上的工作流程图</strong>：</p><p><img src="/GeekFocus/./5.png" alt="调度器-生信分析-高性能计算集群-化合物筛选"></p><p>蓝色框表示计算节点，其中包含CPU核数（蓝色框内的黑色正方形），紫色小圆圈代表待处理的配体。整张图代表整个计算集群，并行运行1.1到X.1个任务，任务1.1完成后会自动运行任务1.2，以此类推直到任务完成。<br>每个任务（包含多个子任务）使用3个计算节点，每个节点有8个CPU核。</p><p><strong>假设有10亿化合物需要筛选，面对16万CPU，把流程图里缺乏的时间维度考虑进来，我们可以多思考几个问题：</strong></p><ol><li><strong>16万CPU，怎么顺利一一配置，启动，关闭？</strong></li><li><strong>怎么能让集群整体资源利用率最高？跑更多任务？</strong></li><li><strong>能不能指定特定任务在某种类型计算节点上运行？</strong></li><li><strong>任务之间存在先后顺序，能否确保特定任务一定先运行？</strong></li><li><strong>怎么统计和限制不同用户的用量？</strong></li><li><strong>怎么监控每个节点的状态和使用情况？</strong></li><li><strong>怎么降低集群的整体运行成本？避免浪费？</strong></li><li><strong>计算节点间网络&#x2F;数据传输怎么考虑？</strong></li><li><strong>如何应对云上集群资源高度动态的特性？空闲资源不足时怎么办？</strong></li></ol><p>如果还不是特别明白，再打个比方。认真想像一下你是老板，手里有且只有100个打工人，你想想要怎么管理才能让他们更好地为你工作？？</p><p><strong>基于这几家主流调度器：LSF&#x2F;SGE&#x2F;Slurm&#x2F;PBS以及它们的不同演化版本进行了梳理和盘点，尤其是对云的支持方面划了重点。</strong></p><h2 id="LSF"><a href="#LSF" class="headerlink" title="LSF"></a>LSF</h2><p><strong>基于LSF（Load Sharing Facility）的调度器主要有Spectrum LSF、PlatformLSF、OpenLava三家。</strong></p><p>早期LSF由Toronto大学开发的Utopia系统发展而来。<br>2007年，<strong>Platform Computing</strong>基于早期老版本的LSF开源了一个简化版Platform Lava。</p><p>这个开源项目2011年中止了，被<strong>OpenLava</strong>接手。<br>2011年，Platform员工David Bigagli基于Platform Lava的派生代码创建了OpenLava 1.0。2014年，一些Platform的员工成立了Teraproc公司，为OpenLava提供开发和商业支持。<strong>2016年IBM就LSF版权对Teraproc公司发起诉讼，2018年IBM胜诉，OpenLava被禁用。</strong></p><p>2011年，Platform Lava开源项目中止后。<strong>2012年1月，IBM收购了Platform Computing。Spectrum LSF</strong>就是IBM收购后推出的商用版本，目前更新到10.1.0，同时支持Linux和Windows，<font color="red">最大节点数超过6000，在国内提供商业支持。</font><br><strong>Platform LSF</strong>是LSF的早期版本，与Spectrum LSF一样属于IBM，目前版本是9.1.3，目测已经停止更新以维护为主。</p><h2 id="SGE"><a href="#SGE" class="headerlink" title="SGE"></a>SGE</h2><p><strong>基于SGE（Sun Grid Engine）的调度器包括UGE（Univa Grid Engine）和SGE（Son of Grid Engine）。</strong></p><p>1993年，<strong>Grid Engine</strong>作为商业软件发布，先后使用了<strong>CODINE</strong>（Computing in Distributed Networked Environments）、<strong>GRD</strong>（Global Resource Director）作为名称。1999年，第一次由Genias Software推出市场，然后被Gridware公司收购。直到2000年被SUN收购之后正式改名<strong>Sun Grid Engine</strong>，2001年发布开源版。</p><p>2010年被Oracle收购后改名<strong>Oracle Grid Engine</strong>，改成闭源版，不提供源代码。原来开源项目的资料库禁止用户修改。<br>于是，Grid Engine社区开始开源版本的<strong>SGE</strong>（<strong>Son of Grid Engine</strong>）项目。该调度器最后一次更新为2016年的8.1.9，由于存在版权风险，SGE已长期无维护和更新。</p><p>2013年Univa收购了Oracle Grid Engine，成为唯一商业软件<strong>UGE（Univa Grid Engine）</strong>提供商。UGE最新版本为8.6.15，同时支持Linux和Windows，国内暂无商业支持的相关信息。<br>2020年9月，Altair收购了Univa。</p><h2 id="Slurm-四大流派里唯一纯开源派"><a href="#Slurm-四大流派里唯一纯开源派" class="headerlink" title="Slurm 四大流派里唯一纯开源派"></a>Slurm <strong>四大流派里唯一纯开源派</strong></h2><p><font color="red"><strong>Slurm全称为Simple Linux Utility for Resource Management</strong></font>，前期主要由劳伦斯利弗莫尔国家实验室、SchedMD、Linux NetworX、Hewlett-Packard 和 Groupe Bull 负责开发，受到闭源软件Quadrics RMS的启发。</p><p>Slurm最新版本为20.02，目前由社区和SchedMD公司共同维护，<strong>保持开源和免费</strong>，由SchedMD公司提供商业支持，仅支持Linux系统，<font color="red">最大节点数量超过12万</font>。<br>Slurm拥有<font color="red">容错率高、支持异构资源、高度可扩展等优点，每秒可提交超过1000个任务，且由于是开放框架，高度可配置，拥有超过100种插件，因此适用性相当强。</font></p><p><strong>全球60%的TOP500超算中心和超大规模集群（包括我国的天河二号等）都采用Slurm作为调度系统。我们的TOP500就是用Slurm调度云上资源跑的。</strong><a href="https://fastonetech.com/blog/top500/">上榜啦～花费4小时5500美元，速石科技跻身全球超算TOP500</a></p><p>支持在Slurm上的集群自动伸缩和云端费用监控，并支持AWS、阿里云、Azure、腾讯云、华为云、Google Cloud等云厂商。</p><p><strong><a href="https://fastonetech.com/blog/case-vina-20201021/">生信云实证Vol.3</a>：提速2920倍！用AutoDockVina对接2800万个分子  这篇主要基于用户不同的策略，跨区、跨类型自动为用户调度云资源，如何以最快速度or最低成本完成计算任务。</strong></p><h2 id="PBS"><a href="#PBS" class="headerlink" title="PBS"></a>PBS</h2><p><strong>基于PBS（Portable Batch System）的调度器包括OpenPBS、PBS PRO、Moab&#x2F;TORQUE。</strong></p><p>PBS最初是由MRJ Technology Solutions于 1991 年 6 月开始为 <font color="red">NASA 所研发的作业调度系统</font>，MRJ于 20 世纪90 年代末被 Veridian 收购。2003年，Altair收购了Veridian，获得了PBS的技术和知识产权。<br><font color="red"><strong>PBS Pro</strong></font>是Altair旗下PBS WORKS提供的<font color="red">商业版本，支持可视化界面，节点数超过50000个。</font></p><p>2016年Altair基于<strong>PBS Pro</strong>提供了开源许可版本，其与MRJ于1998年发布的原始开源版本两者合二为一大致就是现在的<font color="red"><strong>OpenPBS</strong></font>。<font color="red">与Pro版本比，多了很多限制，但都支持Linux和Windows。</font></p><p><strong>Moab&#x2F;TORQUE合在一起是一个完整调度器的功能，现在属于同一家公司Adaptive Computing。</strong>90年代中期由MHPCC的David Jackson开发的Maui，他后来创立了Adaptive Computing。</p><p><strong>Moab</strong>是Adaptive Computing 公司（前身为 Cluster Resources 公司开发的Maui Cluster Scheduler）维护的 OpenPBS 分支，2003年发布。该项目最初是开源免费的，后来变成了商用软件Moab后不再免费。</p><p><strong>TORQUE</strong>（Terascale Open-source Resource and QUEue Manager）早期的 Torque 也是开源免费软件，不过 2018 年 6 月开始 TORQUE 不再开源。<br><font color="red">两者均只支持Linux系统，提供可视化界面，拥有约数千个节点。</font></p><p>云服务方面，PBS Pro能通过<strong>Altair Control产品</strong>从本地溢出到多云和Auto-Scale集群自动伸缩，支持的云厂商包括AWS、Azure和Google Cloud。</p><p>Moab&#x2F;TORQUE 则可通过 <strong>NODUSCloud OS 产品</strong>实现本地扩展到云，支持TORQUE 或 Slurm集群和自动伸缩，可支持的云厂商包括AWS、Azure、GoogleCloud 和华为云，并通过 Account Manager 产品实现云端费用监控。</p><hr><p>ref</p><p> <a href="https://fastonetech.com/blog/cluster-scheduler-20201105/">https://fastonetech.com/blog/cluster-scheduler-20201105/</a></p><p><a href="https://www.jianshu.com/p/45e3f88086f3">https://www.jianshu.com/p/45e3f88086f3</a></p><p><a href="https://www.jianshu.com/p/b7b540a3c015">https://www.jianshu.com/p/b7b540a3c015</a></p>]]></content>
    
    
    <categories>
      
      <category>Linux</category>
      
    </categories>
    
    
    <tags>
      
      <tag>grid</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>HiFi-4-QC-BUSCO</title>
    <link href="/GeekFocus/2022/03/05/2022-03-02-HiFi-4-BUSCO/"/>
    <url>/GeekFocus/2022/03/05/2022-03-02-HiFi-4-BUSCO/</url>
    
    <content type="html"><![CDATA[<p>BUSCO - <strong>B</strong>enchmarking <strong>U</strong>niversal <strong>S</strong>ingle-<strong>C</strong>opy <strong>O</strong>rthologs</p><p>普遍通用的单拷贝直系同源测试?</p><span id="more"></span><p>official：<a href="https://busco.ezlab.org/busco_userguide.html">https://busco.ezlab.org/busco_userguide.html</a></p><p>Ref:<a href="https://www.jianshu.com/p/5041460f7a5d">https://www.jianshu.com/p/5041460f7a5d</a></p><p>BUSCO是使用python语言编写的<font color="blue">对<strong>转录组</strong>和<strong>基因组组装质量</strong>进行<strong>评估</strong></font>的软件。相近物种间总有一些保守序列，BUSCO<font color="blue">使用这些<strong>保守序列</strong>与<strong>组装结果</strong>进行<strong>比对</strong></font>，鉴定组装结果是否包含这些序列，包含单条、多条还是部分或者不包含等情况给出结果</p><blockquote><p>BUSCO 软件根据<strong>OrthoDB 数据库</strong>，构建了<strong>几个大的进化分支</strong>的<strong>单拷贝基因集</strong>。将转录本拼接结果<strong>与该基因集比较</strong>，根据比对上的比例、完整性，来评价拼接结果的<strong>准确性和完整性</strong></p></blockquote><p>基于大量物种的<font color="blue">单拷贝基因构建数据集</font>，用于评估<font color="blue"><strong>基因组组装，转录组组装，基因注释，蛋白集的完整性</strong></font>。core-genes 构建方式，90%物种共享的基因即为核心基因。使用的是直系同源基因家族的概念，基于100个物种基因组，某一个基因家族存在于&gt;90个基因组中，即将该基因家族认定为核心基因</p><p>BUSCO使用其他工具搭建流程</p><figure class="highlight xl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs xl"><span class="hljs-function"><span class="hljs-title">genoem</span> assemble : tBLASTn --&gt;</span> A<span class="hljs-function"><span class="hljs-title">ugustus</span> --&gt;</span> HMMER3 √<br>T<span class="hljs-function"><span class="hljs-title">ranscriptome</span>   :             Find ORF --&gt;</span> HMMER3<br>Gene set        :                          HMMER3<br></code></pre></td></tr></table></figure><h1 id="下载"><a href="#下载" class="headerlink" title="下载"></a>下载</h1><h2 id="conda"><a href="#conda" class="headerlink" title="conda"></a>conda</h2><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs routeros"><span class="hljs-comment"># 没有镜像的话，添加镜像</span><br>conda<span class="hljs-built_in"> config </span>--show <br>conda<span class="hljs-built_in"> config </span>--<span class="hljs-built_in">add</span> channels conda-forge<br><br><span class="hljs-comment"># 构建conda的python3环境</span><br>【conda create --name python36 <span class="hljs-attribute">python</span>=3.6】<br><span class="hljs-comment">#  然后激活</span><br>【conda activate python36】<br><span class="hljs-comment"># 执行安装</span><br>【conda install -c conda-forge -c bioconda <span class="hljs-attribute">busco</span>=5.3.0】<br><span class="hljs-comment"># 在使用完busco之后可以退出python36环境</span><br>【conda deactivate】<br><br></code></pre></td></tr></table></figure><h2 id="独立安装？"><a href="#独立安装？" class="headerlink" title="独立安装？"></a>独立安装？</h2><p>busco，依赖Augustus，HMMER，Blast+</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment">#  ============ 下载BUSCO  ============ </span><br><span class="hljs-built_in">cd</span> ~/Applications/download<br>wget -c https://gitlab.com/ezlab/busco/-/archive/master/busco-master.zip -O busco.zip<br><br><span class="hljs-comment"># ============ 下载依赖的工具 ============</span><br><span class="hljs-comment"># 下载Augustus</span><br>wget -c http://bioinf.uni-greifswald.de/augustus/binaries/augustus.current.tar.gz<br><span class="hljs-comment"># 下载HMMER</span><br>wget -c http://eddylab.org/software/hmmer/hmmer.tar.gz -O hmmer.tar.gz<br><span class="hljs-comment"># 下载Blast+</span><br>wget -c ftp://ftp.ncbi.nlm.nih.gov/blast/executables/LATEST/ncbi-blast-2.7.1+-x64-linux.tar.gz<br><span class="hljs-comment">#-------------------------------------------------------------------------------------</span><br><span class="hljs-built_in">cd</span> ~/Applications/download<br><br><span class="hljs-comment"># === 安装busco ===</span><br>unzip busco.zip<br><span class="hljs-comment"># 改名</span><br><span class="hljs-built_in">mv</span> busco-master busco <br><span class="hljs-comment"># 移动到外部</span><br><span class="hljs-built_in">mv</span> busco ../<br><span class="hljs-built_in">cd</span> ../busco<br><span class="hljs-comment"># 安装</span><br>python setup.py install<br><br><span class="hljs-built_in">cd</span> ~/Applications/download<br><span class="hljs-comment"># === 安装Augustus ===</span><br>tar -xzvf augustus.current.tar.gz<br><span class="hljs-built_in">cd</span> augustus-3.3.1<br><span class="hljs-built_in">cd</span> ../<br><span class="hljs-built_in">mv</span> augustus-3.3.1 ../<br><span class="hljs-built_in">cd</span> ../augustus-3.3.1<br><span class="hljs-comment"># 打开common.mk文件，将ZIPINPUT = true注释掉（即在最前面加一#号）</span><br>vim common.mk<br><span class="hljs-comment"># 安装</span><br>make<br><br><span class="hljs-built_in">cd</span> ~/Applications/download<br><span class="hljs-comment"># === 安装HMMER ===</span><br>tar -xzvf hmmer.tar.gz<br><span class="hljs-built_in">cd</span> hmmer-3.2.1<br>./configure<br>make<br><br><span class="hljs-comment"># === 安装blast+ ===</span><br>tar -xzvf ncbi-blast-2.7.1+-x64-linux.tar.gz<br><span class="hljs-comment"># 改名</span><br><span class="hljs-built_in">mv</span> ncbi-blast-2.7.1+ ../blast+-2.7.1-linux<br><br><span class="hljs-comment"># 删除安装包</span><br><span class="hljs-built_in">cd</span> ~/Applications/download<br><span class="hljs-built_in">rm</span> busco.zip<br><span class="hljs-built_in">rm</span> augustus.current.tar.gz<br><span class="hljs-built_in">rm</span> hmmer.tar.gz<br><span class="hljs-built_in">rm</span> ncbi-blast-2.7.1+-x64-linux.tar.gz<br></code></pre></td></tr></table></figure><h2 id="下载数据库文件"><a href="#下载数据库文件" class="headerlink" title="下载数据库文件"></a>下载数据库文件</h2><p><a href="https://busco-data.ezlab.org/v5/data/lineages/">https://busco-data.ezlab.org/v5/data/lineages/</a></p><figure class="highlight asciidoc"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs asciidoc">大类五类<br><span class="hljs-bullet">- </span>Bacteria 细菌<br><span class="hljs-bullet">- </span>Protists 原生生物<br><span class="hljs-bullet">- </span>Metazoa 后生动物<br><span class="hljs-bullet">- </span>Fungi 真菌<br><span class="hljs-bullet">- </span>Plant 植物<br>下载的是植物相关 embryophyta<span class="hljs-emphasis">_odb10.2020-09-10.tar.gz</span><br><span class="hljs-emphasis"># 解压文件</span><br><span class="hljs-emphasis">tar -xzvf embryophyta_</span>odb9.tar.gz<br></code></pre></td></tr></table></figure><p>执行时需要对应的数据库文件路径 &#x2F;&#x2F;&#x2F;embryophyta_odb9</p><h1 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h1><p>配置是必须的，<strong>这一步需要仔细一些，路径出错的话是无法通过busco的检测的</strong>，在安装好软件之后 <code>~/Applications/busco/config/</code>之中并没有<code>config.ini</code>文件，只有一个<code>config.ini_default</code>文件，可以把里面的内容复制下来，</p><ul><li>方法1</li></ul><p>新建<code>config.ini</code>文件或者直接复制</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">cp</span> config.ini_default config.ini<br></code></pre></td></tr></table></figure><ul><li>方法2</li></ul><p>也可新建</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 增加配置文件</span><br>vim ~/Applications/busco/config/config.ini<br></code></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># BUSCO specific configuration</span><br><span class="hljs-comment">#It 【overrides default values】 in code and dataset cfg, and is 【overridden by arguments in command line】</span><br><span class="hljs-comment"># Uncomment lines when appropriate</span><br>[busco]<br><span class="hljs-comment"># Input file</span><br>;<span class="hljs-keyword">in</span> = ./sample_data/target.fa<br><span class="hljs-comment"># Run name, used in output files and folder</span><br>;out = SAMPLE<br><span class="hljs-comment"># Where to store the output directory</span><br><span class="hljs-comment">#【？】 out_path = /workdir</span><br><span class="hljs-comment"># Path to the BUSCO dataset</span><br>;lineage_path = ./sample_data/example<br><span class="hljs-comment"># Which mode to run (【genome / protein / transcriptome】)</span><br>;mode = genome<br><span class="hljs-comment"># How many threads to use for 【multithreaded】 steps</span><br>;cpu = 1<br><span class="hljs-comment"># Domain for augustus retraining, eukaryota or prokaryota</span><br><span class="hljs-comment"># 【Do not change】 this unless you know exactly why !!!</span><br>;domain = eukaryota<br><span class="hljs-comment"># Force rewrite if files already exist (True/False)</span><br>;force = False<br><span class="hljs-comment"># Restart mode (True/False)</span><br>;restart = False<br><span class="hljs-comment"># Blast e-value</span><br>;evalue = 1e-3<br><span class="hljs-comment"># Species to use with augustus, for old datasets only</span><br>;species = fly<br><span class="hljs-comment"># Augustus extra parameters</span><br><span class="hljs-comment"># Use single quotes, like this: &#x27;--param1=1 --param2=2&#x27;</span><br>;augustus_parameters = <span class="hljs-string">&#x27;&#x27;</span><br><span class="hljs-comment"># Tmp folder</span><br>;tmp_path = ./tmp/<br><span class="hljs-comment"># How many candidate regions (contigs, scaffolds) to consider for each BUSCO</span><br>;<span class="hljs-built_in">limit</span> = 3<br><span class="hljs-comment"># Augustus long mode for retraining (True/False)</span><br>;long = False<br><span class="hljs-comment"># Quiet mode (True/False)</span><br>;quiet = False<br><span class="hljs-comment"># Debug logs (True/False), it needs Quiet to be False</span><br>debug = True<br><span class="hljs-comment"># tar gzip output files (True/False)</span><br>;gzip = False<br><span class="hljs-comment"># Force single core for the tblastn step</span><br>;blast_single_core = True<br><br>【[tblastn]】<br><span class="hljs-comment"># path to tblastn</span><br>path = ~/Applications/blast+-2.7.1-linux/bin<br><br>【[makeblastdb]】<br><span class="hljs-comment"># path to makeblastdb</span><br>path = ~/Applications/blast+-2.7.1-linux/bin<br><br>【[augustus]】<br><span class="hljs-comment"># path to augustus</span><br>path = ~/Applications/augustus-3.3.1/bin<br><br>【[etraining]】<br><span class="hljs-comment"># path to augustus etraining</span><br>path = ~/Applications/augustus-3.3.1/bin<br><br><span class="hljs-comment"># path to augustus perl scripts, redeclare it for each new script        </span><br>【[gff2gbSmallDNA.pl]】                                                      <br>path = ~/Applications/augustus-3.3.1/scripts                         <br>【[new_species.pl]】                                                         <br>path = ~/Applications/augustus-3.3.1/scripts                         <br>【[optimize_augustus.pl]】                                                   <br>path = ~/Applications/augustus-3.3.1/scripts                         <br>                                                                         <br>【[hmmsearch]】                                                              <br><span class="hljs-comment"># path to HMMsearch executable                                           </span><br>path = ~/Applications/hmmer-3.2.1/src                                <br>                                                                         <br>【[Rscript]】                                                                <br><span class="hljs-comment"># path to Rscript, if you wish to use the plot tool                      </span><br>path = /usr/bin/<br></code></pre></td></tr></table></figure><p>新建config.ini&#96;文件之后，</p><ol><li>将<code>config.ini</code>文件中的<code>out_path = /workdir</code>前面加上<code>#</code><br>因为输出路径有时候会出错，所以注释掉，之后运行busco，<font color="blue">输出的路径就是cd的路径</font></li><li>之后需要改这几项对应的路径（<strong>里面的路径需要更改为自己的工具的路径</strong>）</li></ol><table><thead><tr><th>选项</th><th>相关</th></tr></thead><tbody><tr><td>[tblastn]</td><td>blast+</td></tr><tr><td>[makeblastdb]</td><td>blast+</td></tr><tr><td>[augustus]</td><td>Augustus</td></tr><tr><td>[hmmsearch]</td><td>HMMER</td></tr><tr><td>[gff2gbSmallDNA.pl]</td><td>Augustus</td></tr><tr><td>[new_species.pl]</td><td>Augustus</td></tr><tr><td>[optimize_augustus.pl]</td><td>Augustus</td></tr><tr><td>[hmmsearch]</td><td>HMMER</td></tr></tbody></table><h1 id="环境变量"><a href="#环境变量" class="headerlink" title="环境变量"></a>环境变量</h1><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># augustus工具的执行文件所在文件夹</span><br><span class="hljs-built_in">export</span> PATH=<span class="hljs-string">&quot;/home/ssd/Applications/augustus-3.3.1/bin:<span class="hljs-variable">$PATH</span>&quot;</span><br><span class="hljs-comment"># augustus工具附加脚本所在文件夹</span><br><span class="hljs-built_in">export</span> PATH=<span class="hljs-string">&quot;/home/ssd/Applications/augustus-3.3.1/scripts:<span class="hljs-variable">$PATH</span>&quot;</span><br><span class="hljs-comment"># augustus工具配置文件的所在位置 。AUGUSTUS_CONFIG_PATH 需要使用绝对路径</span><br><span class="hljs-built_in">export</span> AUGUSTUS_CONFIG_PATH=<span class="hljs-string">&quot;/home/ssd/Applications/augustus-3.3.1/config&quot;</span><br><span class="hljs-comment"># hmmer工具的执行文件所在文件夹</span><br><span class="hljs-built_in">export</span> PATH=<span class="hljs-string">&quot;/home/ssd/Applications/hmmer-3.2.1/src:<span class="hljs-variable">$PATH</span>&quot;</span><br><span class="hljs-comment"># blast+工具的执行文件所在文件夹</span><br><span class="hljs-built_in">export</span> PATH=<span class="hljs-string">&quot;/home/ssd/Applications/blast+-2.7.1-linux/bin:<span class="hljs-variable">$PATH</span>&quot;</span><br></code></pre></td></tr></table></figure><h1 id="运行"><a href="#运行" class="headerlink" title="运行"></a>运行</h1><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sh">run_BUSCO.py -i [组装的文件.fasta]  -l  [数据库文件夹] -o [输出文件名] -m [评估模式] [其他一些选项]<br></code></pre></td></tr></table></figure><p>实例，如果用<code>conda</code>安装BUSCO。执行只需写<code>busco</code>。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 首先cd到对应的组装文件的文件夹</span><br><span class="hljs-comment"># 确保canu全路径，conda安装，which busco</span><br><span class="hljs-comment"># -i 输入文件</span><br><span class="hljs-comment"># -l BUSCO的数据库文件</span><br><span class="hljs-comment"># -o 输出的文件名的后缀以及文件夹的名称</span><br><span class="hljs-comment"># -m 分析类型（genome、transcriptome、proteins）</span><br><span class="hljs-comment"># --cpu 线程数</span><br>busco \<br>    -i contigs.fasta \<br>    -l ~/database/BUSCO/embryophyta_odb9 \<br>    -o suffix\<br>    -m genome \<br>    --cpu 8<br></code></pre></td></tr></table></figure><h2 id="参数"><a href="#参数" class="headerlink" title="参数"></a><font color="red">参数</font></h2><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><code class="hljs sh">usage: busco -i [SEQUENCE_FILE] -l [LINEAGE] -o [OUTPUT_NAME] -m [MODE] [OTHER OPTIONS]<br><br>Welcome to BUSCO 5.3.0: the Benchmarking Universal Single-Copy Ortholog assessment tool.<br>For more detailed usage information, please review the README file provided with this distribution and the BUSCO user guide. Visit this page https://gitlab.com/ezlab/busco<span class="hljs-comment">#how-to-cite-busco to see how to cite BUSCO</span><br><br>optional arguments:<br>  <span class="hljs-string">&#x27;-i&#x27;</span> SEQUENCE_FILE, --<span class="hljs-keyword">in</span> SEQUENCE_FILE<br>                        Input sequence file <span class="hljs-keyword">in</span> <span class="hljs-string">&#x27;FASTA format&#x27;</span>. Can be an assembled genome or transcriptome (DNA), or protein sequences from an annotated gene <span class="hljs-built_in">set</span>. Also possible to use a path to a directory containing multiple input files.<br>  <span class="hljs-string">&#x27;-o&#x27;</span> OUTPUT, --out OUTPUT<br>                        Give your analysis run a recognisable short name. <span class="hljs-string">&#x27;Output folders and files will be labelled with this name&#x27;</span>. The path to the output folder is <span class="hljs-built_in">set</span> with --out_path.<br>  <span class="hljs-string">&#x27;-m&#x27;</span> MODE, --mode MODE  Specify <span class="hljs-built_in">which</span> BUSCO analysis mode to run.<br>                        There are three valid modes:<br>                        - geno or <span class="hljs-string">&#x27;genome&#x27;</span>, <span class="hljs-keyword">for</span> genome assemblies (DNA)<br>                        - tran or transcriptome, <span class="hljs-keyword">for</span> transcriptome assemblies (DNA)<br>                        - prot or proteins, <span class="hljs-keyword">for</span> annotated gene sets (protein)<br>  <span class="hljs-string">&#x27;-l&#x27;</span> LINEAGE, --lineage_dataset LINEAGE<br>                        Specify the name of the BUSCO lineage to be used<span class="hljs-string">&#x27;database?&#x27;</span><br>  --augustus            Use augustus gene predictor <span class="hljs-keyword">for</span> eukaryote runs<br>  --augustus_parameters --PARAM1=VALUE1,--PARAM2=VALUE2<br>                        Pass additional arguments to Augustus. All arguments should be contained within a single string with no white space, with each argument separated by a comma.<br>  --augustus_species AUGUSTUS_SPECIES<br>                        Specify a species <span class="hljs-keyword">for</span> Augustus training.<br>  --auto-lineage        Run auto-lineage to find optimum lineage path<br>  --auto-lineage-euk    Run auto-placement just on eukaryote tree to find optimum lineage path<br>  --auto-lineage-prok   Run auto-lineage just on non-eukaryote trees to find optimum lineage path<br>  <span class="hljs-string">&#x27;-c&#x27;</span> N, --cpu N         Specify the number (N=<span class="hljs-built_in">integer</span>) of threads/cores to use.<br>  <span class="hljs-string">&#x27;--config&#x27;</span> CONFIG_FILE  Provide a config file<br>  --datasets_version DATASETS_VERSION<br>                        Specify the version of BUSCO datasets, e.g. odb10<br>  <span class="hljs-string">&#x27;--download&#x27;</span> [dataset [dataset ...]]<br>                        Download dataset. Possible values are a specific dataset name, <span class="hljs-string">&quot;all&quot;</span>, <span class="hljs-string">&quot;prokaryota&quot;</span>, <span class="hljs-string">&quot;eukaryota&quot;</span>, or <span class="hljs-string">&quot;virus&quot;</span>. If used together with other <span class="hljs-built_in">command</span> line arguments, make sure to place this last.<br>  --download_base_url DOWNLOAD_BASE_URL<br>                        Set the url to the remote BUSCO dataset location<br>  --download_path DOWNLOAD_PATH<br>                        Specify <span class="hljs-built_in">local</span> filepath <span class="hljs-keyword">for</span> storing BUSCO dataset downloads<br>  <span class="hljs-string">&#x27;-e&#x27;</span> N, --evalue N      <span class="hljs-string">&#x27;E-value cutoff for BLAST searches&#x27;</span>. Allowed formats, 0.001 or 1e-03 (Default: 1e-03)<br>  -f, --force           Force rewriting of existing files. Must be used when output files with the provided name already exist.<br>  -h, --<span class="hljs-built_in">help</span>            Show this <span class="hljs-built_in">help</span> message and <span class="hljs-built_in">exit</span><br>  --<span class="hljs-built_in">limit</span> N             How many candidate regions (contig or transcript) to consider per BUSCO (default: 3)<br>  --list-datasets       Print the list of available BUSCO datasets<br>  --long                Optimization Augustus self-training mode (Default: Off); adds considerably to the run time, but can improve results <span class="hljs-keyword">for</span> some non-model organisms<br>  --metaeuk_parameters <span class="hljs-string">&quot;--PARAM1=VALUE1,--PARAM2=VALUE2&quot;</span><br>                        Pass additional arguments to Metaeuk <span class="hljs-keyword">for</span> the first run. All arguments should be contained within a single string with no white space, with each argument separated by a comma.<br>  --metaeuk_rerun_parameters <span class="hljs-string">&quot;--PARAM1=VALUE1,--PARAM2=VALUE2&quot;</span><br>                        Pass additional arguments to Metaeuk <span class="hljs-keyword">for</span> the second run. All arguments should be contained within a single string with no white space, with each argument separated by a comma.<br>  <span class="hljs-string">&#x27;--offline&#x27;</span>            <span class="hljs-string">&#x27;To indicate that BUSCO cannot attempt to download files&#x27;</span><br>  --out_path OUTPUT_PATH<br>                        Optional location <span class="hljs-keyword">for</span> results folder, excluding results folder name. <span class="hljs-string">&#x27;Default is current working directory&#x27;</span>.<br>  -q, --quiet           Disable the info logs, <span class="hljs-string">&#x27;displays only errors&#x27;</span><br>  -r, --restart         <span class="hljs-string">&#x27;Continue a run that had already partially completed&#x27;</span>.<br>  --tar                 <span class="hljs-string">&#x27;Compress some subdirectories with many files to save space&#x27;</span><br>  --update-data         Download and replace with last versions all lineages datasets and files necessary to their automated selection<br>  -v, --version         Show this version and <span class="hljs-built_in">exit</span><br><br></code></pre></td></tr></table></figure><p>fasta文件中，一些组装工具生成的<code>contig</code>的名字是形如<code>&gt;contig/1/12345</code>之类的，这种fasta文件运行时BUSCO会报错，解决办法是改名，perl单行。</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-built_in">cat</span> contig.fasta | perl -p -e <span class="hljs-string">&#x27;s&#123;/&#125;&#123;&#125;g&#x27;</span> &gt; contig.new.fasta<br></code></pre></td></tr></table></figure><h1 id="结果解读"><a href="#结果解读" class="headerlink" title="结果解读"></a>结果解读</h1><p>在运行文件夹下会有</p><ul><li><code>run_suffix</code> 文件夹：因为上面<code>-o</code>选项设置了<code>suffix</code>，所以文件夹名称加了后缀。文件夹里，有一个文件最为重要。是<code>short_summary_suffix.txt</code></li></ul><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs text"># Summarized benchmarking in BUSCO notation for file assembly/spades/contigs.fasta<br># BUSCO was run in mode: genome<br>    C:98.6%[S:98.6%,D:0.0%],F:0.0%,M:1.4%,n:148<br><br>    146 Complete BUSCOs (C)<br>    146 Complete and single-copy BUSCOs (S)<br>    0   Complete and duplicated BUSCOs (D)<br>    0   Fragmented BUSCOs (F)<br>    2   Missing BUSCOs (M)<br>    148 Total BUSCO groups searched<br></code></pre></td></tr></table></figure><table><thead><tr><th align="left">缩写</th><th>全称</th><th>说明</th><th>关系</th></tr></thead><tbody><tr><td align="left">C</td><td>Complete</td><td>多少个BUSCO测试基因被覆盖。</td><td>C &#x3D; S + D</td></tr><tr><td align="left">S</td><td>single-copy</td><td>多少个基因经过比对发现是单拷贝。</td><td>-</td></tr><tr><td align="left">D</td><td>duplicated</td><td>多少个基因经过比对发现包含多拷贝。</td><td>-</td></tr><tr><td align="left">F</td><td>Fragment</td><td>多少个基因经过比对覆盖不完全，只是部分比对上。</td><td>-</td></tr><tr><td align="left">M</td><td>Miss</td><td>没有得到比对结果的基因数</td><td>-</td></tr><tr><td align="left">Total</td><td>Total</td><td>总共测试的基因条目数</td><td>Total &#x3D; C + F + M</td></tr></tbody></table><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs css">一般情况下对于完整度较好的基因组组装结果来讲，Complete and single-copy越多越好，而Complete and duplicated和Missing越少越好，对于Fragmented也尽可能地少一些。<br>真实项目中，Complete BUSCOs (C) 的比例通常都能达到 <span class="hljs-number">80%</span> 以上。<br>C值表示和BUSCO集相比的完整度，M值表示可能缺少的基因数，D则是重复数。<br></code></pre></td></tr></table></figure><p>三种比对</p><ul><li>情况1 - 完全覆盖</li></ul><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs sh">说明: +表示组装得到基因序列 -表示用于测试的基因序列<br><br>组装 : ================+++++++==============<br>测试                   -------<br>                       或者<br>组装 : ==============+++++++++++============<br>测试                   -------               <br></code></pre></td></tr></table></figure><ul><li>情况2 - 部分覆盖</li></ul><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs text">组装 : ================+++++++==============<br>测试                   -----<br>                     /      \<br>                       或者<br>组装 : ================+++++++==============<br>测试                   -------<br>                     /        \<br></code></pre></td></tr></table></figure><ul><li>情况3 - 没有比对</li></ul><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs text">组装 : ================+++++++==============<br>测试 <br></code></pre></td></tr></table></figure><p>一般<code>S</code> + <code>D</code>的数值也就是<code>C</code>的值越大越好，但是在文献中作者说如果<code>D</code>的数值太多的话可能意味着组装错误的可能性较大。因为一个基因（BUSCO数据库中该基因一般为单拷贝）被覆盖多次，那么可能就是说该基因所在的片段组装可能出现问题。<br>因为理论上</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs text">理论上：--------------------------------------------<br>实际上：--------   ----------    ----------    -----<br>错误的：--------                 -------------<br>           \\\\                    ///<br>          -----------     --------------<br></code></pre></td></tr></table></figure><p>理论上组装之后各个片段之间应该前后有序，之间除了重复区域或者其他特殊片段之外不应该有可以重叠的地方。<br>例如</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs text">sequence1 : ..TAGTCGTGA                         GTGCATGCTGTAGC..<br>                       \                       /<br>                        AAAATTGG......CGATGAAAA<br>                       /                       \<br>sequence2 : ..GGGTAGCGG                         TTGACTAGCTAGCT..<br></code></pre></td></tr></table></figure><p>也就是说中间一段序列是两个序列的共同部分，除非这个序列存在多个拷贝，否则就很可能是拼接错误。通常一般这种拼接错误的序列的两端会出现重复序列。另外如果是多倍体组装的话，<code>D</code>值也可能大。</p><p>一般来看，<code>S</code>似乎越大越好，<code>M</code>越小越好，说明组装的越完整，因为检测的单拷贝同源基因出现得多。但是<code>D</code>与<code>F</code>这两个数值越大不见得就是好的，因为组装的错误可能会带来这两个值的增大。不能仅仅只是通过这一个软件来判定。比如还可以借助<code>QUAST</code>和常规指标<code>N50</code>、<code>总的核酸量</code>、<code>点阵图</code>等等多个辅助标准来进行综合的评估。</p><h1 id="画图"><a href="#画图" class="headerlink" title="画图"></a>画图</h1><p>执行完毕后，可使用<code>generate_plot.py</code>画图，条形图。</p><ul><li>首先把所有经过BUSCO检测的结果聚集到一个文件夹之内</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">mkdir</span> my_summaries<br><span class="hljs-built_in">cp</span> run_SPEC1/short_summary_SPEC1.txt my_summaries/.<br><span class="hljs-built_in">cp</span> run_SPEC2/short_summary_SPEC2.txt my_summaries/.<br><span class="hljs-built_in">cp</span> run_SPEC3/short_summary_SPEC3.txt my_summaries/.<br><span class="hljs-built_in">cp</span> run_SPEC4/short_summary_SPEC4.txt my_summaries/.<br><span class="hljs-built_in">cp</span> run_SPEC5/short_summary_SPEC5.txt my_summaries/.<br></code></pre></td></tr></table></figure><ul><li>运行</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs undefined">python scripts/generate_plot.py –wd my_summaries<br></code></pre></td></tr></table></figure><p>五个数值变成条形图显示，对比更加明显.</p>]]></content>
    
    
    <categories>
      
      <category>Software</category>
      
    </categories>
    
    
    <tags>
      
      <tag>busco</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【paper】Insight into the evolution of the Solanaceae from the parental genomes of Petunia hybrida</title>
    <link href="/GeekFocus/2022/03/02/2022-03-02-paper-Petunia/"/>
    <url>/GeekFocus/2022/03/02/2022-03-02-paper-Petunia/</url>
    
    <content type="html"><![CDATA[<p>Solanaceae 茄科</p><span id="more"></span><h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><p>The assemblies include 91.3% and 90.2% coverage of their diploid genomes (1.4 Gb; 2n &#x3D; 14) containing 32,928 and 36,697 protein-coding genes, respectively. The genomes reveal that the Petunia lineage has experienced at least two rounds of hexaploidization: the older gamma event, which is shared with most Eudicots, and a more recent Solanaceae event that is shared with tomato and other solanaceous species. Transcription factors involved in the shift from bee to moth pollination reside in particularly dynamic regions of the genome, which may have been key to the remarkable diversity of floral colour patterns and pollination systems. The high-quality genome sequences will enhance the value of Petunia as a model system for research on unique biological phenomena such as small RNAs, symbiosis, self-incompatibility and circadian rhythms.</p><p>矮牵牛是一种流行的花坛植物，作为一种遗传学模式系统有着悠久的历史。我们报道了其两个野生亲本腋毛假单胞菌(P. axillaris N)和膨胀假单胞菌(P. inflata S6)近交系衍生物的全基因组测序和组装。该组合的二倍体基因组覆盖率为91.3%和90.2% (1.4 Gb;2n &#x3D; 14)，分别含有32,928个和36,697个蛋白编码基因。基因组显示矮矮花至少经历了两轮六倍化:更古老的伽玛事件，与大多数双子叶植物共享，以及更近的茄科事件，与番茄和其他茄科植物共享。转录因子参与了从蜜蜂到飞蛾的传粉过程，它们位于基因组中特别活跃的区域，这可能是花的颜色模式和传粉系统显著多样性的关键。高质量的基因组序列将提高矮种矮花作为研究小rna、共生、自交不亲和性和昼夜节律等独特生物现象的模型系统的价值。</p><p>矮牵牛（<em>Petunia hybrida</em>）属于茄科（Solanaceae），是一种流行的花坛植物，长期作为一个遗传模式系统。本论文报道了矮牵牛的两个野生亲本的基因组，<em>P. axillaris</em> N 和 <em>P. inflata</em> S6。The assemblies include 91.3% and 90.2% coverage of their diploid genomes (1.4 Gb; 2n &#x3D; 14) containing 32,928 and 36,697 protein-coding genes, respectively. 组装的基因组矮牵牛的基因组大小大约是1.4Gb，14对染色体。报道的两个基因组分别注释到32928和36697个编码蛋白基因。</p><p><em>P. axillaris</em> N 基因组的组装利用了137 X的二代测序（Illumina）数据和 21 X三代测序（PacBio）技术数据，<em>P. inflata</em> S6 基因组的组装利用了 135 X 的二代测序数据，测序深度都不低。相信矮牵牛基因组的发布会推动自交不亲和、花色等方面的研究。</p>]]></content>
    
    
    <categories>
      
      <category>Biology</category>
      
    </categories>
    
    
    <tags>
      
      <tag>paper</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>HiFi-3-assemble-software</title>
    <link href="/GeekFocus/2022/03/02/2022-03-02-HiFi-3-software/"/>
    <url>/GeekFocus/2022/03/02/2022-03-02-HiFi-3-software/</url>
    
    <content type="html"><![CDATA[<p>Hifiasm is a <font color="blue"><strong>fast haplotype-resolved de novo assembler</strong></font> for <font color="blue"><strong>PacBio HiFi reads(High Fidelity,high accuracy consensus reads)</strong></font>. HiCanu, Hifiasm, BUSCO, Peregrine, minimap2</p><span id="more"></span><h1 id="HiFi-快-准-狠"><a href="#HiFi-快-准-狠" class="headerlink" title="HiFi 快 准 狠"></a><a href="https://zhuanlan.zhihu.com/p/138395531">HiFi 快 准 狠</a></h1><h2 id="组装快"><a href="#组装快" class="headerlink" title="组装快"></a>组装快</h2><p>CLR或Nanopore长Reads测序准确性较低，进行组装时需要利用高准确性Illumina短Reads纠错。而HiFi Reads本身即高准确性长Reads，可直接拼接，因此大大节省运算资源和时间。第一篇利用HiFi进行人基因组组装的报道表明，<font color="red"><strong>HiFi Reads组装速度比CLR Reads快10–100倍</strong></font> <a href="https://pubmed.ncbi.nlm.nih.gov/31406327/">[1]</a>。另一项同时利用HiFi 和CLR 对人基因组组装的比较中，HiFi 组装仅花费约2,800个CPU时，而CLR 组装花费超过50,000个CPU时，利用Nanopore Reads进行组装更是花费约151,000个CPU时 <a href="https://pubmed.ncbi.nlm.nih.gov/31711268/">[2]</a>。27 Gb六倍体加州红杉超大基因组，利用HiFi Reads两周就完成组装。</p><h2 id="组装准"><a href="#组装准" class="headerlink" title="组装准"></a>组装准</h2><h3 id="1-连续性与CLR和Nanopore相当"><a href="#1-连续性与CLR和Nanopore相当" class="headerlink" title="1 连续性与CLR和Nanopore相当"></a>1 连续性与CLR和Nanopore相当</h3><p>虽HiFi Reads在<font color="red"><strong>读长打折扣</strong></font>，但在<font color="red"><strong>连续性方面毫不逊色</strong></font>于PacBio CLR和Nanopore Reads。同时利用HiFi 和CLR 对人基因组组装的比较中，<font color="red"><strong>HiFi 和CLR 组装的Contigs N50相当</strong></font>（25.52 Mb和29.26 Mb）。一般认为<font color="red">Nanopore ultra-long</font>在基因组组装<font color="red"><strong>连续性更具优势</strong></font>，但同时利用HiFi 和Nanopore 进行水稻组装的报道中，三个组装软件中两个的组装结果都显示<font color="red"><strong>HiFi 组装Contigs N50高于Nanopore Reads</strong></font> <a href="https://pubmed.ncbi.nlm.nih.gov/33319909/">[3]</a>。</p><h3 id="2-组装质量显著提升"><a href="#2-组装质量显著提升" class="headerlink" title="2 组装质量显著提升"></a>2 组装质量显著提升</h3><p>由于HiFi 与Illunima短Reads具有相当的碱基准确性，因此在组装上具有CLR和Nanopore无法比拟的优势。利用HiFi 对人基因组组装结果表明，<font color="red"><strong>HiFi 组装质量比CLR高6倍，比经Illumina校正的Nanopore高77倍</strong></font> <a href="https://pubmed.ncbi.nlm.nih.gov/31406327/">[1]</a>。</p><p>值得一提，利用HiFi 和Nanopore 进行水稻组装文章表明，<font color="red"><strong>对于高重复区域利用高质量Illumina对Nanopore长Reads纠错效果一般</strong></font>。原因在于Illumina<font color="blue">短Reads在重复区域很难准确比对</font>，导致<strong>覆盖深度有限</strong>，因而<strong>无法起到准确纠错的作用</strong>。而HiFi 兼具长读长和高准确性双重优势，对<font color="red"><strong>重复区域</strong>仍然能够获得<strong>较高</strong>的组装<strong>质量</strong></font>。</p><h3 id="3-对重复区域和着丝粒区域具有较高的分辨率"><a href="#3-对重复区域和着丝粒区域具有较高的分辨率" class="headerlink" title="3 对重复区域和着丝粒区域具有较高的分辨率"></a>3 对重复区域和着丝粒区域具有较高的分辨率</h3><p>除了整个基因组的连续性和准确性，HiFi 在<font color="red"><strong>重复区域</strong>和<strong>着丝粒区域</strong></font>的组装也表现不俗。对人基因组的组装表现上，HiFi 组装对<font color="red"><strong>散在重复</strong>的<strong>分辨率为43%</strong></font>，<font color="red"><strong>高于</strong> CLR和已有的Nanopore版本</font>。对于<font color="red"><strong>数百拷贝的串联重复</strong></font>，HiFi 组装<font color="red">比CLR具有<strong>更高</strong>的<strong>分辨率</strong>和<strong>准确性</strong></font>。而专门针对HiFi Reads组装优化的<font color="blue"><strong>HiCanu</strong></font>在<font color="blue"><strong>重复序列和着丝粒组装</strong></font>方面更有良好表现。</p><p><img src="/GeekFocus/./9.png" alt="img"></p><p>HiFi和CLR对<strong>串联重复区域组装</strong>结果的比较 <a href="https://pubmed.ncbi.nlm.nih.gov/31711268/">[2]</a></p><p><strong>variable number of tandem repeats (VNTRs)</strong></p><blockquote><p>b) Dot plot of a <strong>6.7 kbp VNTR</strong> in the <strong>intron</strong> of <em>RTEL1</em> (chr20:63693361–63693833) (top panel), <strong>which was resolved in the HiFi assembly only</strong>. The <strong>CLR assembly</strong> contained a <strong>gap</strong> over this region. The overall structure and length of this VNTR was <strong>supported by the ONT reads</strong> mapping to this location, which averaged 5,956 +&#x2F;− 1799 bp (n &#x3D; 5 ultra-long ONT reads), placing the HiFi sequence length at &lt;1 standard deviation away from the average ONT read. The motif homology plot (bottom panel) indicates that the content of the <em>RTEL1</em> VNTR is relatively pure, with an average sequence identity to the 15-mer repeat unit of 94.49% across the 439 copies.</p></blockquote><blockquote><p>c)Dot plot of the <strong>zinc finger protein gene <em>ZNF717</em></strong> (GRCh38 coordinates: chr3:75777127–75780446) (top panel), which was <strong>collapsed in the CLR</strong> assembly but <strong>fully represented in the HiFi assembly</strong>. The number of copies of this <strong>35 bp repeat unit</strong> increased from <strong>15 in the CLR</strong> assembly to <strong>89 in the HiFi</strong> assembly. The large amount of variation between individual copies of this VNTR is shown in the region between the <strong>red lines</strong> in the motif homology plots (bottom panels). The <strong>level of purity within the VNTR increased</strong> from 80.38% sequence identity in the CLR assembly to 90.75% sequence identity in the HiFi assembly. The red vertical lines indicate the start and end position of the VNTR.</p></blockquote><h2 id="狠"><a href="#狠" class="headerlink" title="狠"></a>狠</h2><h3 id="1-简单复杂基因组通吃"><a href="#1-简单复杂基因组通吃" class="headerlink" title="1 简单复杂基因组通吃"></a><strong>1 简单复杂基因组通吃</strong></h3><p>PacBio官方，除了已报道的<strong>人、水稻、果蝇和跗库蚊</strong>，目前HiFi 组装已经在<strong>人、大麻、燕麦、四倍体月季和六倍体加州红杉</strong>等物种中应用。即便是<strong>大麻、燕麦、月季、加州红杉</strong>这些<strong>复杂</strong>基因组，HiFi 组装不俗。11 Gb燕麦的Contig N50高达<strong>20 Mb</strong>！高重复高杂合的多倍体裸子植物的加州红杉超大基因组，HiFi 的Contig N50也达到1.92 Mb，远高于已报道其他裸子植物基因组。</p><h3 id="2-高质量单倍型基因组组装"><a href="#2-高质量单倍型基因组组装" class="headerlink" title="2 高质量单倍型基因组组装"></a><strong>2 高质量单倍型基因组组装</strong></h3><p>组装<strong>多倍体</strong>时，组装软件必须能<strong>区分不同的等位基因</strong>，并<strong>保存为不同的序列</strong>。用HiCanu对人基因组的HiFi Reads组装结果包含<strong>超过2 Gb的替代Contig</strong>，而<strong>其它软件</strong>只能产生<strong>不到400 Mb</strong>的<strong>替代Contig</strong>。说明HiCanu结合HiFi Reads具有更强的<strong>区分单倍型的能力</strong>。并且，HiCanu组装的<font color="blue">主要Contig</font>和<font color="blue">替代Contig</font>都具有较高的<font color="red">BUSCO完整性</font>（&gt; <strong>94％</strong>和&gt; 75％），远<strong>高</strong>于<strong>Nanopore ultra-long Reads</strong>组装的BUSCO完整性（分别只有**63%<strong>和</strong>0.3%**）。</p><h1 id="hifiasm-Official-doc"><a href="#hifiasm-Official-doc" class="headerlink" title="hifiasm Official doc"></a><a href="https://github.com/chhylp123/hifiasm">hifiasm Official doc</a></h1><p><strong>install</strong></p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-comment"># Install hifiasm (requiring g++ and zlib)</span><br>git <span class="hljs-built_in">clone</span> https://github.com/chhylp123/hifiasm<br><span class="hljs-comment">#download zipfile unzip</span><br><span class="hljs-built_in">cd</span> hifiasm &amp;&amp; make<br></code></pre></td></tr></table></figure><p><strong>simple use</strong></p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-comment"># Run on test data (use -f0 for small datasets)?</span><br>wget https://github.com/chhylp123/hifiasm/releases/download/v0.7/chr11-2M.fa.gz<br>./hifiasm -o <span class="hljs-built_in">test</span> -t4 -f0 chr11-2M.fa.gz 2&gt; test.log<br>【awk <span class="hljs-string">&#x27;/^S/&#123;print &quot;&gt;&quot;$2;print $3&#125;&#x27;</span> test.bp.p_ctg.gfa &gt; test.p_ctg.fa】  <span class="hljs-comment"># get primary contigs in FASTA</span><br><br><span class="hljs-comment"># Assemble inbred/homozygous genomes (-l0 disables duplication purging)</span><br><span class="hljs-comment">#?</span><br>hifiasm -o CHM13.asm -t32 -l0 CHM13-HiFi.fa.gz 2&gt; CHM13.asm.log<br><span class="hljs-comment"># Assemble heterozygous genomes with built-in duplication purging</span><br><span class="hljs-comment">#?</span><br>hifiasm -o HG002.asm -t32 HG002-file1.fq.gz HG002-file2.fq.gz<br><br><span class="hljs-comment"># Hi-C phasing with paired-end short reads in two FASTQ files</span><br><span class="hljs-comment">#add Hi-C data</span><br>hifiasm -o HG002.asm --h1 read1.fq.gz --h2 read2.fq.gz HG002-HiFi.fq.gz<br><br><span class="hljs-comment"># Trio binning assembly (requiring https://github.com/lh3/yak)</span><br><span class="hljs-comment">#combine parent sequencing data</span><br>yak count -b37 -t16 -o pat.yak &lt;(<span class="hljs-built_in">cat</span> pat_1.fq.gz pat_2.fq.gz) &lt;(<span class="hljs-built_in">cat</span> pat_1.fq.gz pat_2.fq.gz)<br>yak count -b37 -t16 -o mat.yak &lt;(<span class="hljs-built_in">cat</span> mat_1.fq.gz mat_2.fq.gz) &lt;(<span class="hljs-built_in">cat</span> mat_1.fq.gz mat_2.fq.gz)<br>hifiasm -o HG002.asm -t32 -1 pat.yak -2 mat.yak HG002-HiFi.fa.gz<br></code></pre></td></tr></table></figure><h2 id="introduction"><a href="#introduction" class="headerlink" title="introduction"></a>introduction</h2><p>Hifiasm is a <font color="blue"><strong>fast haplotype-resolved de novo assembler</strong></font> for <font color="blue"><strong>PacBio HiFi reads</strong></font>. It can <strong>assemble a human genome in several hours</strong> and assemble a <strong>~30Gb</strong> California redwood genome in <strong>a few days</strong>. Hifiasm emits <font color="red"><strong>partially phased assemblies</strong></font> of quality competitive with the best assemblers. Given <font color="green"><strong>parental short reads</strong></font> or <font color="green"><strong>Hi-C data</strong></font>, it produces arguably <font color="red"><strong>the best haplotype-resolved assemblies</strong></font> so far.</p><h2 id="Why-Hifiasm"><a href="#Why-Hifiasm" class="headerlink" title="Why Hifiasm?"></a>Why Hifiasm?</h2><ul><li>Hifiasm delivers high-quality assemblies. It tends to generate <font color="blue">longer contigs</font> and resolve <font color="blue">more segmental duplications</font> than other assemblers.</li><li>Given <font color="blue">Hi-C reads</font> or <font color="blue">short reads from the parents</font>, hifiasm can produce overall <font color="blue"><strong>the best haplotype-resolved assembly</strong></font> so far. It is the assembler of choice by the <a href="https://humanpangenome.org/">Human Pangenome Project</a> for the first batch of samples.</li><li>Hifiasm can <font color="blue">purge duplications?</font> between haplotigs without relying on third-party tools such as purge_dups. Hifiasm does <font color="blue">not need polishing tools?</font> like pilon or racon, either. This simplifies the assembly pipeline and saves running time.</li><li>Hifiasm is <font color="blue">fast</font>. It can assemble a human genome in half a day and assemble a ~30Gb redwood genome in three days. <font color="blue">No genome is too large for hifiasm</font>.</li><li>Hifiasm is trivial to install and easy to use. It does not required Python, R or C++11 compilers, and can be compiled into a single executable. The default setting works well with a variety of genomes.</li></ul><h1 id="hifiasm-paper"><a href="#hifiasm-paper" class="headerlink" title="hifiasm paper"></a>hifiasm paper</h1><p>ref：<a href="https://www.jianshu.com/p/6d79690dce5d">https://www.jianshu.com/p/6d79690dce5d</a></p><p><a href="https://hifiasm.readthedocs.io/en/latest/index.html">https://hifiasm.readthedocs.io/en/latest/index.html</a></p><p><a href="https://links.jianshu.com/go?to=https://github.com/chhylp123/hifiasm">https://github.com/chhylp123/hifiasm</a></p><p><a href="https://links.jianshu.com/go?to=https://www.nature.com/articles/s41592-020-01056-5">https://www.nature.com/articles/s41592-020-01056-5</a></p><h2 id="原理介绍1"><a href="#原理介绍1" class="headerlink" title="原理介绍1"></a>原理介绍1</h2><p>hifiasm有效利用PacBio HiFi测序技术，在<font color="red"><strong>分型组装图(pahsed assembly gprah)</strong></font>中可靠的表示单倍体信息。</p><p><strong>第一阶段</strong>：通过所有序列相互比对，对潜在测序错误纠正。如果<font color="red">一个位置只存在两种碱基类型</font>，且每个碱基类型<font color="red">至少有3条read支持</font>，那么这个位置会被当作<font color="red">杂合位点</font>，否则视作测序错误纠正。</p><p><strong>第二阶段</strong>：根据<font color="red">序列之间重叠关系</font>，构建<font color="red">分型的字符串图(phased string graph)</font>。其中调整朝向的序列作为<font color="red">顶点(vertex)</font>，一致重叠作为<font color="red">边(edge)</font>。字符串图中的<font color="red">气泡(bubble)</font>则是<font color="red">杂合位点</font>。</p><p><strong>第三阶段</strong>：如果没有额外的信息，hifiasm会<font color="red">随机选择气泡一边</font>构建primary assembly，另一边则是alternate assembly. 该策略和HiCanu，Falcon-Unzip一样。对于杂合基因组而言，由于存在一个以上的纯合haplotype，因此<font color="red">primary assembly可能还会包含haplotigs</font>。HiCanu依赖第三方的purge_dups, 而hifiasm内部实现purge_dups算法的变种，简化了流程。如果有<font color="red">额外信息</font>，hifiasm可正确的对<font color="red">haplotype进行分型</font>。</p><p><img src="/GeekFocus/./1.png" alt="img"></p><h2 id="hifiasm-原理介绍2"><a href="#hifiasm-原理介绍2" class="headerlink" title="hifiasm 原理介绍2"></a>hifiasm 原理介绍2</h2><p><strong>可识别单倍型的纠错</strong></p><p>Hifiasm将所有hifi reads读取到内存中进行<font color="red"><strong>all-vs-all比对并纠错</strong></font>。基于reads间overlap信息，如果read上有一个碱基与其他碱基不同，并有<font color="red"><strong>至少3条reads支持</strong></font>，则认为它是<font color="red"><strong>SNP</strong></font>并保留，<strong>否则</strong>认为是错误并<strong>纠正</strong>。</p><p><strong>组装图的构建</strong></p><p>在校正之后，大多数错误被去除，同时<font color="red"><strong>杂合变异信息被保留</strong></font>。基于这些信息，Hifiasm构建了<font color="red"><strong>以reads为顶点、重叠区为边的定相string-graph</strong></font>。</p><p><strong>组装序列的生成</strong></p><ul><li><p>如果<font color="red">没有其他数据</font>，Hifiasm在输出序列时会<font color="red"><strong>任意选择</strong>每个气泡<strong>bubble</strong>的<strong>一侧输出</strong>类似<strong>Falcon unzip</strong>和<strong>HiCanu</strong>的主要组装结果</font>（primary contigs）。</p></li><li><p>如果同时有<font color="red">父母本的测序数据</font>，Hifiasm可以通过<font color="red">亲本特有的kmer</font>在图上<font color="red">识别来自父母本的序列</font>，得到<font color="red"><strong>两套单倍体</strong>基因组</font>。</p></li><li><p>当然HiFiasm文章中也提到：</p><p>与其他基于图形的汇编程序不同，HiFiasm致力于<strong>保持所有单倍型的连续性。</strong><br><font color="red"><strong>HiCanu</strong>只试图<strong>保持一个亲本单倍型</strong>的<strong>连续性</strong></font>，并且经常<font color="red">破坏另一个单倍型的连续性</font>，当分离亲本单倍型时，这些突变点将导致单倍型分解的碎片—HiCanu<font color="red">没有充分利用HiFi Reads</font><br>Hifiasm针对HiFi特点开发，在hifi数据的组装表现上较同类软件更为突出，在多个基因组上表现出了更高的<strong>准确性</strong>和组装的<strong>连续性</strong>。</p></li></ul><h2 id="仅HiFi数据模式"><a href="#仅HiFi数据模式" class="headerlink" title="仅HiFi数据模式"></a>仅HiFi数据模式</h2><p>最基本的用法，会得到两个部分分型的组装</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs sh">wget https://github.com/chhylp123/hifiasm/releases/download/v0.7/chr11-2M.fa.gz<br>hifiasm -o <span class="hljs-built_in">test</span> -t 32 chr11-2M.fa.gz 2&gt; test.log<br><span class="hljs-comment">#-o输出文件前缀 -t线程</span><br></code></pre></td></tr></table></figure><p>结果文件关注如下几项 (prefix为前缀）</p><ul><li><code>prefix.bp.r_utg.gfa</code>: haplotype-resolved raw unitig graph，记录所有的单倍型信息</li><li><code>prefix.bp.p_utg.gfa</code>: 在raw unitig graph基础上过滤小的bubble，</li><li><code>prefix.bp.p_ctg.gfa</code>: 主要contig的assembly graph</li><li><code>prefix.bp.hap1.p_ctg.gfa</code>: haplotype1的部分分型的contig graph</li><li><code>prefix.bp.hap2.p_ctg.gfa</code>: haplotype2的部分分型的contig graph</li></ul><p>如果并不需要部分分型的组装，只要primary和alternate的组装结果，可以在之前命令的基础上，加上 <code>--primary</code>参数。</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sh">hifiasm --primary -o <span class="hljs-built_in">test</span> -t 32 chr11-2M.fa.gz 2&gt; test.log2<br></code></pre></td></tr></table></figure><p>由于hifiasm运行时会将步骤中纠错和相互比对的结果保存成 bin 文件，因此rerun速度很快(前缀名差异)。</p><p>primay模式下输出的文件和之前的类似，唯一的不同在于没有 <strong>bp</strong></p><p>prefix<code>.r_utg.gfa</code>: haplotype-resolved raw unitig graph: 保留了组装生成的所有单体型信息，包括体细胞突变和重复的测序错误。</p><p>prefix<code>.p_utg.gfa</code>: haplotype-resolved processed unitig graph without small bubbles：无小气泡的单倍型解析；去掉由于体细胞突变和数据背景噪音引起的small bubbles（这个并不是真正的单体型信息），对于高度杂合基因组物种优先选择这个结果。</p><p>prefix<code>.p_ctg.gfa</code>: assembly graph of primary contigs：对于低杂合度物种来说，优先选择该文件；对于高杂合度物种，该结果代表其中一个单倍型。</p><p>prefix<code>.a_ctg.gfa</code>: assembly graph of alternate contigs：组装出来的另一套单体型基因组结果。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment">#contig，通过awk提取</span><br>awk <span class="hljs-string">&#x27;/^S/&#123;print &quot;&gt;&quot;$2;print $3&#125;&#x27;</span> test.p_ctg.gfa &gt; test.p_ctg.fa<br></code></pre></td></tr></table></figure><h2 id="双亲二代测序Trio-binning模式"><a href="#双亲二代测序Trio-binning模式" class="headerlink" title="双亲二代测序Trio-binning模式"></a>双亲二代测序Trio-binning模式</h2><p>如果有双亲数据，则可使用trio-binning方法进行更可靠的分型。分为两步，<font color="red"><strong>先用yak统计k-mers， 然后用hifiasm进行组装</strong></font></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">yak count -k31 -b37 -t16 -o pat.yak paternal.fq.gz<br>yak count -k31 -b37 -t16 -o mat.yak maternal.fq.gz<br>hifiasm -o NA12878.asm -t 32 -1 pat.yak -2 mat.yak NA12878.fq.gz<br></code></pre></td></tr></table></figure><p>输出和之前类似，主要关注文件名<font color="red">带 dip 的输出gfa文件</font></p><ul><li><strong>prefix.r_utg.gfa</strong>(Haplotype-resolved raw unitig graph in GFA format):保存了所有的单倍型信息。</li></ul><ul><li><code>prefix.dip.hap1.p_ctg.gfa</code>: 完成分型的<font color="red"><strong>父源单倍体 contig图</strong></font>。(Phased paternal&#x2F;haplotype1 contig graph):保留了阶段性父系&#x2F;单倍型1组装。</li><li><code>prefix.dip.hap2.p_ctg.gfa</code>: 完全分型的<font color="red"><strong>母源单倍体contig图</strong></font>。(Phased maternal&#x2F;haplotype2 contig graph):保留了阶段性母系&#x2F;单倍型2组装。</li></ul><h2 id="附加Hi-C模式"><a href="#附加Hi-C模式" class="headerlink" title="附加Hi-C模式"></a>附加Hi-C模式</h2><p>由于Hi-C数据能够提供<strong>远距信息</strong>，因此也能<strong>用于单倍体分型</strong>。需要加两个参数， h1为Hi-C的read1, h2 为Hi-C的read2</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">hifiasm -o NA12878.asm -t 32 --h1 read1.fq.gz --h2 read2.fq.gz HiFi-reads.fq.gz<br></code></pre></td></tr></table></figure><p>在该模式下，每个contig要么是来自于父亲，要么是来自于母亲。hifiasm将<font color="red">同一来源的contig放在同一个组装中</font>。需要注意的是，hifiasm未必能够处理好<font color="red">着丝粒附近区域</font>，另外<font color="red">hifiasm中Hi-C也不会用于进行scaffold</font>。</p><p>输出结果重点关注带hic的文件</p><ul><li><code>prefix.hic.p_ctg.gfa</code>: 主要contig的组装图</li><li><code>prefix.hic.hap1.p_ctg.gfa</code>: 完全分型的haplotype1的contig图</li><li><code>prefix.hic.hap2.p_ctg.gfa</code>: 完全分型的haplotype2的contig图</li><li><code>prefix.hic.a_ctg.gfa</code> : 如果设置了 <code>--primary</code>参数，还会输出该次要contig的组装图</li></ul><h2 id="日志和参数调整"><a href="#日志和参数调整" class="headerlink" title="日志和参数调整"></a>日志和参数调整</h2><p>绝大部分的时候，只需要使用默认参数即可得到相对比较好的结果。但是当默认参数无法达到目的，就需要检查日志信息，阅读相关参数从而优化结果。</p><p>日志信息主要分三项</p><ul><li><font color="red">k-mer图</font>: 纯合样本一个peak，杂合样本2个peak。</li><li><font color="red">纯合峰的覆盖度</font>: <code>[M::purge_dups] homozygous read coverage threshold: X</code> , 一般会由hifiasm自动推断。</li><li><font color="red">杂合&#x2F;纯合碱基数目（Hi-C模式）</font>: Hi-C模式下，如果纯合的碱基数超过杂合碱基数，那么hifiasm就不容易找对纯合read的所在峰。</li></ul><p>对于日志信息，最主要关注<font color="red">k-mer图</font>，从而判断hifiasm是否能够正确的找到纯合峰，杂合峰所在位置。如果hifiasm没有找对纯合峰所在的位置，就需要<font color="red">根据k-mer图手动指定?</font> <code>--hom-cov</code>。</p><p>对于一个组装结果，最直接的<strong>评估标准</strong>就是<font color="red">基因组大小是否符合预期</font>，分型的<font color="red">两套基因组是否相差不大</font>，序列<strong>是否足够长</strong>，<strong>是否存在错误组装</strong>的情况。</p><p>如果基因组<font color="red"><strong>大小不符合预期</strong></font>，一般都是hifiasm<strong>找错纯合峰的位置</strong>，需要手动指定 <code>--hom-cov</code>；</p><p>如果分型的两套基因组<font color="red"><strong>差别过大</strong></font>，则通过降低 <code>-s</code> 调整。</p><p>如果<font color="red"><strong>序列不够长，片段化明显</strong></font>，则可尝试<font color="red">增加</font>  <code>-D</code> 和  <code>-N</code>, 虽增加运行时间，但会<font color="red">提高重复区域的分辨率</font>。</p><p>如果后续的Hi-C，或者BioNano发现hifiasm组装结果<font color="red"><strong>有比较多错误组装</strong></font>，则可以适当降低 <code>--purge-max</code>, <code>-s</code>和 <code>-O</code>。或者设置 <code>-u</code> 关闭post-join 步骤，hifiasm通过该步骤提高组装的连续性。</p><h2 id="输入格式-fq还是fa"><a href="#输入格式-fq还是fa" class="headerlink" title="输入格式 fq还是fa"></a>输入格式 fq还是fa</h2><figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs nginx"><span class="hljs-comment"># bam --&gt; fasta</span><br><span class="hljs-attribute">samtools</span> view <span class="hljs-regexp">*.bam</span> | awk <span class="hljs-string">&#x27;&#123;print &quot;&gt;&quot;<span class="hljs-variable">$1</span>&quot;\n&quot;<span class="hljs-variable">$10</span>&#125;&#x27;</span> &gt; fasta<br><span class="hljs-comment"># bam2fastq</span><br></code></pre></td></tr></table></figure><hr><h1 id="HiCanu-https-canu-readthedocs-io-en-latest-index-html"><a href="#HiCanu-https-canu-readthedocs-io-en-latest-index-html" class="headerlink" title="HiCanu[https://canu.readthedocs.io/en/latest/index.html]"></a>HiCanu[<a href="https://canu.readthedocs.io/en/latest/index.html]">https://canu.readthedocs.io/en/latest/index.html]</a></h1><hr><p>ref <a href="https://www.jianshu.com/p/c1aeeae77cb5">https://www.jianshu.com/p/c1aeeae77cb5</a></p><p>Canu分三个步骤，<font color="red"><strong>纠错</strong></font>，<font color="red"><strong>修整</strong></font>和<font color="red"><strong>组装</strong></font>，每一步<font color="red">步骤<strong>相似</strong></font>：</p><ul><li>加载read到read数据库，gkpStore</li><li>对k-mer进行记数，用于计算序列间的overlap</li><li>计算overlap</li><li>加载overlap到overlap数据库，OvlStore</li><li>根据read和overlap完成特定分析目标<ul><li>read<font color="blue"><strong>纠错</strong></font>时会从overlap中挑选一致性序列替换原始的噪声read</li><li>read<font color="blue"><strong>修整</strong></font>时会使用overlap确定read哪些区域是高质量区域，哪些区域质量较低需要修整。最后保留单个最高质量的序列块</li><li>序列<font color="blue"><strong>组装</strong></font>时根据一致的overlap对序列进行编排(layout), 最后得到contig</li></ul></li></ul><p>三步<font color="blue">可分开</font>运行，既可用<font color="blue">Canu纠错后结果</font>作为<font color="blue">其他组装软件输入</font>，也可将其他软件的纠错结果作为Canu的输入。</p><p><font color="red">几个<strong>全局参数</strong></font>：</p><ul><li><font color="red"><strong>genomeSize</strong></font>设置预估基因组大小，用于Canu<font color="blue">估计测序<strong>深度</strong></font>, The genome size should be your best guess of the haploid genome size of what is being assembled, It is used primarily to estimate coverage in reads, NOT as the desired assembly size.</li><li><font color="red">maxThreads</font>设置最大<font color="blue">线程</font></li><li><font color="red">rawErrorRate</font>设置<font color="blue">两个<strong>未纠错read之间</strong>最大<strong>期望差异碱基数</strong></font></li><li><font color="red">correctedErrorRate</font>设置<font color="blue"><strong>纠错后</strong>read之间最大<strong>期望差异碱基数</strong>，<strong>组装</strong>步骤<strong>多次调整</strong></font></li><li><font color="red">minReadLength</font>表示<font color="blue">只使用大于阈值的序列</font></li><li><font color="red">minOverlapLength</font>表示<font color="blue">Overlap最小长度</font></li><li>提高minReadLength可<strong>提</strong>高运行<strong>速</strong>度，增加minOverlapLength可<strong>降</strong>低<strong>假阳性overlap</strong></li></ul><p><font color="blue">测试数据</font> “<a href="https://links.jianshu.com/go?to=https://www.nature.com/articles/s41467-018-03016-2">High contiguity Arabidopsis thaliana genome assembly with a single nanopore flow cell</a>“。 提供 <em>Arabidopsis thaliana</em> KBS-Mac-74 的30X短片段文库二代测序、PacBio和Nanopore的三代测序以及Bionano测序数据, 拟南芥基因组被认为是植物金标准，数据适合练习。项目编号”PRJEB21270”, 在European Nucleotide Archive上找到下载地址。</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs awk"><span class="hljs-comment">## PacBio Sequal</span><br>wget -c -q ftp:<span class="hljs-regexp">//</span>ftp.sra.ebi.ac.uk<span class="hljs-regexp">/vol1/</span>ERA111<span class="hljs-regexp">/ERA1116568/</span>bam/pb.bam<br><span class="hljs-comment">## MinION</span><br>wget -c -q ftp:<span class="hljs-regexp">//</span>ftp.sra.ebi.ac.uk<span class="hljs-regexp">/vol1/</span>ERA111<span class="hljs-regexp">/ERA1116595/</span>fastq/ont.fq.gz<br><span class="hljs-comment"># Illuminia MiSeq</span><br>wget -c -q ftp:<span class="hljs-regexp">//</span>ftp.sra.ebi.ac.uk<span class="hljs-regexp">/vol1/</span>ERA111<span class="hljs-regexp">/ERA1116569/</span>fastq/il_1.fq.gz<br>wget -c -q ftp:<span class="hljs-regexp">//</span>ftp.sra.ebi.ac.uk<span class="hljs-regexp">/vol1/</span>ERA111<span class="hljs-regexp">/ERA1116569/</span>fastq/il_2.fq.gz<br></code></pre></td></tr></table></figure><p><font color="blue">PacBio数据以BAM格式存储</font>，通过安装PacBio的smrtlink工具套装，使用其中<font color="blue">bam2fasta</font>转换</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-string">&#x27;build index for convert&#x27;</span><br>~/opt/biosoft/smrtlink/smrtcmds/bin/pbindex pb.bam &amp;<br><span class="hljs-comment"># convert bam to fasta</span><br>~/opt/biosoft/smrtlink/smrtcmds/bin/bam2fasta -o pb pb.bam &amp;<br></code></pre></td></tr></table></figure><p>PacBio的smrtlink工具套装大小1.4G，下载速度慢，安装手动确认各种选项, 好处是工具全。</p><h2 id="Install"><a href="#Install" class="headerlink" title="Install"></a>Install</h2><p>latest: <a href="https://github.com/marbl/canu/releases/tag/v2.2">https://github.com/marbl/canu/releases/tag/v2.2</a></p><h2 id="Run-Canu"><a href="#Run-Canu" class="headerlink" title="Run Canu"></a>Run Canu</h2><p><strong>第一步</strong>：<font color="red"><strong>纠错</strong></font>。三代测序错误率高，原始数据充满噪音。通过<strong>序列</strong>间<strong>相互比较纠错得到高可信度的碱基</strong>。<font color="blue">主要<strong>调整两个参数</strong></font></p><ul><li><font color="blue">corOutCoverage</font>: 控制<strong>多少数据</strong>用于纠错。如拟南芥120M基因组，100X测序12G数据，如果只用最长6G数据纠错，参数设置为50(120m x 50)。<strong>设置大于测序深度的值</strong>如120表示<strong>使用所有数据</strong>。<font color="green"><strong>-pacbio-raw</strong></font></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs bash">canu -correct \<br>    -p ath -d pb_ath \<br>    Threads=10 gnuplotTested=<span class="hljs-literal">true</span>\<br>    genomeSize=120m minReadLength=2000 minOverlapLength=500\<br>    corOutCoverage=120 corMinCoverage=2 \<br>    -pacbio-raw pb.fasta.gz<br></code></pre></td></tr></table></figure><p>注: 有些服务器<strong>没有安装gnuplot</strong>, <strong>gnuplotTested&#x3D;true</strong> 跳过检查。</p><p><strong>第二步</strong>：<font color="red"><strong>修整</strong></font>。为获取更高质量的序列，<font color="blue">移除可疑区域</font>（如残留的SMRTbell接头)。<font color="green"><strong>-pacbio-corrected</strong></font></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs bash">canu -trim \<br>        -p ath -d pb_ath<br>        maxThreads=20 gnuplotTested=<span class="hljs-literal">true</span>\<br>        genomeSize=120m minReadLength=2000 minOverlapLength=500\<br>        -pacbio-corrected ath/pb_ath.correctedReads.fasta.gz<br></code></pre></td></tr></table></figure><p><strong>第三步</strong>: <font color="red"><strong>组装</strong></font>。前两步获得高质量序列后正式组装。 主要调整参数是<font color="red">纠错后的<strong>序列错误率 correctedErrorRate</strong></font>，它会影响utgOvlErrorRate。可尝试多个参数，因为速度较块。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># error rate 0.035</span><br>canu -assemble \<br>    -p ath -d ath-erate-0.035 \<br>    maxThreads=20 gnuplotTested=<span class="hljs-literal">true</span> \<br>    genomeSize=120m\<br>    correctedErrorRate=0.035 \<br>    -pacbio-corrected atg/pb_ath.trimmedReads.fasta.gz<br><span class="hljs-comment"># error rate 0.050</span><br>canu -assemble \<br>    -p ath -d ath-erate-0.050 \<br>    maxThreads=20 gnuplotTested=<span class="hljs-literal">true</span> \<br>    genomeSize=120m\<br>    correctedErrorRate=0.050 \<br>    -pacbio-corrected atg/pb_ath.trimmedReads.fasta.gz<br></code></pre></td></tr></table></figure><p>输出文件<font color="red"><strong>ath.contigs.fasta</strong></font>结果文件。</p><h2 id="Debug"><a href="#Debug" class="headerlink" title="Debug"></a>Debug</h2><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-comment">#qsub: submit error (No default queue specified MSG=requested queue not found)</span><br><span class="hljs-comment">#invalid useGrid (1) and gridEngine (PBS); found no execution hosts - is grid available from this host?.</span><br></code></pre></td></tr></table></figure><p>issue: <a href="https://github.com/marbl/canu/issues/1040">https://github.com/marbl/canu/issues/1040</a></p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs sh">advice : Canu uses the <span class="hljs-string">&quot;PBS command pbsnodes&quot;</span> to poll your available resources. On your compute nodes this is not working. See the FAQ: http://canu.readthedocs.io/en/latest/faq.html<span class="hljs-comment">#my-run-stopped-with-the-error-failed-to-submit-batch-jobs</span><br>If your nodes <span class="hljs-string">&#x27;cannot access/submit&#x27;</span> to the <span class="hljs-string">&#x27;grid&#x27;</span> <span class="hljs-keyword">then</span> Canu <span class="hljs-string">&#x27;wont work with your grid system&#x27;</span>. These are grid configuration issues so youll have to check with your sysadmin <span class="hljs-keyword">if</span> it can be changed. If not, youll have to run Canu on a single node or use useGrid=remote from the <span class="hljs-built_in">head</span> node <span class="hljs-built_in">which</span> will <span class="hljs-built_in">print</span> the commands <span class="hljs-keyword">for</span> you to manually run (see issue <span class="hljs-comment">#822).</span><br></code></pre></td></tr></table></figure><p><a href="https://canu.readthedocs.io/en/latest/faq.html#my-run-stopped-with-the-error-failed-to-submit-batch-jobs">canu FAQ</a></p><p><strong>How do I run Canu on my SLURM &#x2F; SGE &#x2F; PBS &#x2F; LSF &#x2F; Torque system?</strong></p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs sh">Canu will <span class="hljs-string">&#x27;detect and configure&#x27;</span> itself to use on most <span class="hljs-string">&#x27;grids&#x27;</span>. You <span class="hljs-keyword">do</span> not need to submit Canu to the grid <span class="hljs-keyword">in</span> this <span class="hljs-keyword">case</span>. Canu will query the system <span class="hljs-keyword">for</span> <span class="hljs-string">&#x27;grid support&#x27;</span>, configure itself <span class="hljs-keyword">for</span> the machines <span class="hljs-string">&#x27;available in the grid&#x27;</span>, <span class="hljs-keyword">then</span> submit itself to the grid <span class="hljs-keyword">for</span> execution. You can <span class="hljs-keyword">then</span> monitor the run <span class="hljs-string">&#x27;using your grid&#x27;</span>.<br><br>Canu will <span class="hljs-string">&#x27;NOT request explicit time limits or queues/partitions&#x27;</span>. You can supply your own grid options, such as a partition on SLURM, an account code on SGE, and/or time limits with gridOptions=<span class="hljs-string">&quot;&lt;your options list&gt;&quot;</span> <span class="hljs-built_in">which</span> will passed to every job submitted by Canu. Similar options exist <span class="hljs-keyword">for</span> every stage of Canu, <span class="hljs-built_in">which</span> could be used to, <span class="hljs-keyword">for</span> example, restrict overlapping to a specific partition or queue.<br><br>【【【<span class="hljs-string">&#x27;To disable grid support and run only on the local machine, specify useGrid=false&#x27;</span>】】】<br><br>It is possible to <span class="hljs-built_in">limit</span> the number of grid <span class="hljs-built_in">jobs</span> running at the same time, but this isn’t directly supported by Canu. The various gridOptions parameters can pass grid-specific parameters to the submit commands used; see Issue <span class="hljs-comment">#756 for Slurm and SGE examples.</span><br></code></pre></td></tr></table></figure><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-comment">#common options:</span><br>useGrid=string<br>      - Run under grid control (<span class="hljs-literal">true</span>), <span class="hljs-string">&#x27;locally (false)&#x27;</span>, or <span class="hljs-built_in">set</span> up <span class="hljs-keyword">for</span> grid control<br>        but dont submit any <span class="hljs-built_in">jobs</span> (remote)<br></code></pre></td></tr></table></figure><h2 id="Advice"><a href="#Advice" class="headerlink" title="Advice"></a>Advice</h2><h3 id="后续分析要去冗余"><a href="#后续分析要去冗余" class="headerlink" title="后续分析要去冗余"></a>后续分析要去冗余</h3><p>Canu2.0之前的contig尽管运行日志说没有bubble，其实是没有检测到。Canu2.0才加上该信息。但作者强烈推荐先用purge_dups去冗余，避免软件难以检测到的冗余序列存在影响后续分析。</p><p>作者：旧版Canu没有真正检测到bubble，因此contig包含着buble，建议后续分析用purge_dups 处理这些冗余序列</p><p>Canu改动基本上是增加新功能，提高组装准确性，提高组装速度，常规bug修复。</p><p>1.8版本更改了Nanopore的错误率，提高10倍左右组装速度，同时完整支持了trio-binning</p><p>1.9版开始增加PacBio的HiFi数据，极大提高相互比对速度</p><p>这些修改，可以直接将组装得到的contig用于后续分析</p><p>而2.0做了许多优化用来保证contig组装更长更准确，其中一个是在contig构建期间会检测bubbles, 防止他们打断杂合基因组</p><p>例如组装发现染色体明显偏大，用新Canu组装该物种时候发现，前后两次组装结果在bubbles一栏有明显差别。1.8版本是0，2.0版本是136，约6M基因组大小。</p><p>查看之前所有组装物种的日志，发现bubble一栏都是0（即便是杂合基因组）。</p><p>意味着，2.0版本装的基因组不能直接用于下游的HiC，而需要先把bubble这部分序列给过滤掉，不然基因组偏离实际值。</p><h3 id="高杂合物种组装"><a href="#高杂合物种组装" class="headerlink" title="高杂合物种组装"></a>高杂合物种组装</h3><p>高杂合物种组装，Canu建议是用 <code>batOptions=-dg 3 -db 3 -dr 1 -ca 500 -cp 50</code>参数尽量分出两套单倍型，然后对基因组去冗余。</p><p><code>batOptions</code>表示传递后续的参数给组装软件<code>bogart</code>, <code>-dg 3 -db3</code>降低自动确定阈值时的错误率离差(deviation)，从而更好分开单倍型。<code>-dr 1 -ca 500 -cp 50</code>会影响错误组装的拆分，对于一个模棱两可的contig，如果另一条可选路径的overlap长度至少是500bp，或另一条可选路径时在长度上和当前最佳路径存在50%的差异，那么将contig拆分。</p><p>关于杂合物种组装的讨论，参考<a href="https://links.jianshu.com/go?to=https://github.com/marbl/canu/issues/201%23issuecomment-233750764">https://github.com/marbl/canu/issues/201#issuecomment-233750764</a></p><h3 id="购买SSD避免服务器IO瓶颈"><a href="#购买SSD避免服务器IO瓶颈" class="headerlink" title="购买SSD避免服务器IO瓶颈"></a>购买SSD避免服务器IO瓶颈</h3><p>如果服务器线程数很多，在普通机械硬盘上组装，而且系统还是CentOS，那么需要调整一个参数，避免其中一步的IO严重影响服务器性能。</p><p>Canu通过两个策略进行并行，bucketizing (‘ovb’ 任务) 和 sorting (‘ovs’ 任务)。 bucketizing会从1-overlap读取输出的overlap，将他们<strong>复制</strong>一份作为中间文件。sorting一步将这些文件加载到内存中进行排序然后<strong>写出</strong>到硬盘上。 如果你的overlap输出特别多，那么该步骤将会瞬间挤爆的你的IO.</p><p>为了避免悲剧发生，请增加如下参数: <code>ovsMemory=16G ovbConcurrency=15 ovsConcurrency=15</code>， 也就是降低这两步同时投递的任务数，缓解IO压力。</p><hr><h1 id="HiFI组装实例"><a href="#HiFI组装实例" class="headerlink" title="HiFI组装实例"></a>HiFI组装实例</h1><p>Contiguity, Completeness, and Correctness</p><h2 id="2018-10"><a href="#2018-10" class="headerlink" title="2018.10"></a>2018.10</h2><p>PacBio公司 高保真 单分子 长读长 测序【HiFi】模式</p><h2 id="2019-01"><a href="#2019-01" class="headerlink" title="2019.01"></a>2019.01</h2><p>首篇利用HiFi数据进行人基因组 结构变异检测 和 基因组组装 文章发布</p><h2 id="2020-01"><a href="#2020-01" class="headerlink" title="2020.01"></a>2020.01</h2><p>HiFi在 四倍体玫瑰 燕麦 大麻 白蛉 等多个物种基因组组装</p><h2 id="2020-03-27Gb六倍体加州红杉"><a href="#2020-03-27Gb六倍体加州红杉" class="headerlink" title="2020.03 27Gb六倍体加州红杉"></a>2020.03 27Gb六倍体加州红杉</h2><p><a href="https://mp.weixin.qq.com/s?__biz=MzkxMjIzNzY3Mw==&mid=2247489444&idx=2&sn=e6e9e4eebac756a0d518ee4a0fa09956&source=41#wechat_redirect">PacBio科学家利用HiFi测序两周内完成基因组高达27Gb的六倍体加州红杉基因组组装</a></p><h3 id="初衷"><a href="#初衷" class="headerlink" title="初衷"></a>初衷</h3><p><font color="blue">15Gb六倍体小麦</font>基因组，选择<font color="blue">HiFi还是CLR？</font><font color="blue">11Gb燕麦</font>基因组组装说明<font color="blue">HiFi组装<strong>超大基因组</strong>的能力</font>，<strong>Contig N50</strong>高达<strong>20Mb</strong>！HiFi Reads <font color="blue"><strong>读取长度</strong></font> 和 <font color="blue"><strong>准确性</strong></font> 之间的 <font color="blue"><strong>平衡</strong></font> 是否能克服最艰巨的基因组（大且复杂）挑战？</p><h3 id="测序过程"><a href="#测序过程" class="headerlink" title="测序过程"></a>测序过程</h3><p>斯坦福大学校园内采样，DNA提取文库构建。</p><p>使用<font color="blue">BluePippin[高分子量DNA核酸片段分离和回收]</font>将DNA片段选择大小设为<strong>15 kb</strong>，更长的插入片段允许HiFi读长达到<strong>50 kb</strong>。 HiFi reads 的准确率分布可以发现所有reads准确率<strong>都在Q20以上</strong>，HiFi reads<strong>最密集</strong>的插入片段在<strong>20k-30k区间</strong>，最长的插入片段达到<strong>50k精度都高于Q20</strong>(99％)，大约有<strong>超过一半的reads</strong>准确率接近或超过<strong>Q30</strong>(99.9%)。</p><p><strong>7天连续测序</strong>共获得<strong>606Gb</strong> HiFi数据，相当于<strong>22X</strong>。在之前很多使用HiFi进行组装的项目中发现，只需<strong>20倍</strong>左右的覆盖度就能够产生<strong>出色</strong>的组装结果，且<strong>不需要NGS纠错</strong>。</p><h3 id="组装结果"><a href="#组装结果" class="headerlink" title="组装结果"></a>组装结果</h3><p>在获得HiFi数据之后，PacBio负责<strong>超大基因组组装</strong>的资深生信科学家<strong>Greg Concepcion</strong>开始了加州红杉基因组的组装工作。Greg选择的工具是<font color="red">Hifiasm</font>，因为这是目前<font color="blue"><strong>最快</strong>的且<strong>专注于解析单倍型</strong>的组装软件</font>。</p><p>Hifiasm软件运行<font color="red">6天</font>后，组装工作顺利完成。具体消耗计算资源如下；</p><p>服务器配置：64核512Gb RAM</p><p>生成HiFi数据：46,000 CPU hours</p><p>基因组组装：7,200 CPU hours，总共分析时间6天</p><p>对比2019年Oxford Nanopore + NGS同样组装加州红杉，使用2Tb内存,最终花费5-6个月才完成组装。</p><p>Sequencing and assembling mega-genomes of mega-trees: the giant sequoia and coast redwood genomes，<strong>Nanopore Community Meeting 2019</strong>【最大内存使用：2T；error correction：330，000CPU hours；Assembly post-error-correction：700，000CPU hours；wall clock time：5-6month】</p><p>获得的结果惊人，结果几乎是<font color="blue">预期基因大小<strong>两倍</strong></font>，而<font color="blue">Contig N50</font>达到<font color="blue"><strong>1.92Mb</strong></font> ！相对2019年Oxford Nanopore + NGS组装<font color="blue"><strong>提升18倍</strong></font>。大于预期基因组大小的组装中，大部分可是<font color="blue"><strong>两个类似的单倍型</strong></font>，而<font color="red"><strong>并非完全不同的六倍体</strong></font>，这与最近Scott发表的红杉相关研究类似，印证了加州红杉的多倍体化是<font color="red"><strong>自多倍体事件</strong></font>。</p><p><img src="/GeekFocus/./640.jpeg" alt="图片"></p><p><font color="blue">加州红杉组装结果中<strong>BUSCO评分只有59%??</strong> </font>不是一般<strong>较好</strong>的组装结果BUSCO值都要高达<font color="blue"><strong>90%以上吗？</strong></font>因为<font color="blue">裸子植物（加州红杉属于裸子植物）的BUSCO基因集与被子植物的<strong>BUSCO基因集相差很</strong>多</font>。意味着针对加州红杉使用<font color="red"><strong>通用BUSCO基因集</strong></font>来<font color="red"><strong>评估</strong>基因组完整性<strong>不准确</strong></font>，只是<strong>目前没有</strong>其它<strong>更好</strong>评估方法。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>从加州红杉基因组研究中得到什么呢？</p><p>首先，对PacBio SMRT测序充满信心，建议使用HiFi数据从任何生物体生成高质量的基因组数据。 </p><p>其次，它将彻底改变对<strong>大型，复杂</strong>的基因组装配的认知。之前经验是<strong>超大型复杂基因组</strong>组装需要花费<strong>大量时间</strong>和生信<strong>计算资源</strong>，还不包括测序时间。而加州红杉庞大基因组在短短17天内就可完成（包括4天样品准备和建库，7天测序和6天组装）。 </p><p><strong>通过PacBio HiFi数据，可以对<font color="blue">任何生物</font>进行<font color="blue">高质量</font>的基因组测序。</strong></p><h2 id="2020-05"><a href="#2020-05" class="headerlink" title="2020.05"></a>2020.05</h2><p>HiFi助力同源四倍体紫花苜蓿基因组组装，NC发表</p><p>Allele-aware chromosome-level genome assembly and efficient transgene-free genome editing for the autotetraploid cultivated alfalfa</p><p>（1）使用Canu默认参数，利用CCS clean reads组装contigs。组装得到的Contig N50值为459kb，总长度为3.15GB。</p><p>（2）使用HiC-Pro将Hi-C reads与contigs 进行比对，产生比对BAM文件。</p><p>（3）使用注释的蒺藜苜蓿蛋白作为参考，完全基于同源的策略注释contigs。对138,729个同源基因进行了结构注释。用MCscan用于鉴定contigs和参考基因组之间的共线性。显示紫花苜蓿和蒺藜苜蓿之间的高共线性。【下载父母本petunia ref】</p><p>（4）使用内部脚本处理BAM文件，去除等位基因contigs之间的links。使用ALLHiC软件，提取、聚类和重排Contigs (Contigs syntenic与蒺藜苜蓿染色体一致)，得到原始的scaffolds。</p><p>（5）Juicebox用于以图形和交互方式微调组装的scaffolds。剪裁了40个总长度达1800Mb的scaffolds 。</p><p>（6） 基于组装的scaffold，通过Hi-C数据，每个unplaced contig被分配到互作最强的那些contig cluster里。</p><p>（7）使用ALLHiC对那些contig clusters再次进行重排和构建scaffold。</p><p>（8）使用Juicebox对scaffolds进行微调，并从scaffolds上去除不一致的contigs，产生最终的染色体基因组，其包含32条染色体(8个同源组，每个组中有4个等位基因染色体)，总长度为2738Mb，和419Mb未挂载到染色体水平的序列。</p><h2 id="2020-07"><a href="#2020-07" class="headerlink" title="2020.07"></a>2020.07</h2><p>加州大学HiFi组装人完整X染色体，Nature</p><p>Miga Karen H,Koren Sergey,Rhie Arang et al. Telomere-to-telomere assembly of a complete human X chromosome.[J] .Nature, 2020.</p><h1 id="HiFi与不同类型基因组组装"><a href="#HiFi与不同类型基因组组装" class="headerlink" title="HiFi与不同类型基因组组装"></a><a href="https://www.jianshu.com/p/4d42719d8b01">HiFi与不同类型基因组组装</a></h1><h2 id="高重复基因组—玉米"><a href="#高重复基因组—玉米" class="headerlink" title="高重复基因组—玉米"></a><strong>高重复基因组—玉米</strong></h2><p>玉米（<em>Z.mays</em>）是世界上产量最高种植最广的作物，也是遗传学和基因组学的基础model。玉米基因组经历<font color="blue"><strong>全基因组复制事件</strong></font>和<font color="blue"><strong>长末端重复转座子扩增</strong></font>导致基因组<strong>急剧扩大</strong>（<font color="red">2.3Gb</font>）。最终导致玉米基因组中<font color="red"><strong>转座子占比高达85%</strong></font>。</p><p>利用<strong>HiFi</strong>组装的<font color="blue"><strong>玉米B73</strong></font>基因组大小为<font color="blue"><strong>2.164 Gb</strong></font>，<strong>略大于</strong>2017年发表的利用PacBio <font color="blue">CLR</font>的组装版本（<font color="blue">2.104 Gb</font>）。在连续性方面，HiFi组装<font color="blue"><strong>Contig N50则达到28.2 Mb</strong></font>，提升近<font color="red"><strong>23倍</strong></font>，甚至<strong>超过</strong>最近发表的<strong>NC358</strong>基因组。<font color="red"><strong>BUSCO评估表明</strong></font>，HiFi组装版本的组装质量也<font color="red"><strong>高于所有</strong></font>已发表的<strong>玉米基因组版本</strong>。在时间和资源消耗上，最近发表的<strong>75× CLR数据</strong>组装NC358基因组花费了<strong>11,520 CPU hours</strong>，而HiFi数据组装仅在6小时完成，仅花费360 CPU hours，<font color="red"><strong>资源消耗节省了31倍</strong></font>。体现了HiFi在<font color="blue">高重复基因组组装</font>的明显<font color="blue">优势</font>。</p><p><img src="/GeekFocus/./10.png" alt="img"></p><p>HiFi 组装 <strong>玉米B73</strong> 基因组结果</p><h2 id="大型复杂基因组—黄腿山蛙"><a href="#大型复杂基因组—黄腿山蛙" class="headerlink" title="大型复杂基因组—黄腿山蛙"></a><strong>大型复杂基因组—黄腿山蛙</strong></h2><p>黄腿山蛙（<em>R. muscosa</em>）是一种两栖动物。<font color="blue"><strong>两栖动物</strong>是<strong>脊椎动物</strong>中<strong>基因组大小变化最大</strong>的一类</font>，已完成基因组测序的<strong>美西钝口螈</strong>高达<strong>32 Gb</strong>。蛙科物种中，最大基因组达10 Gb以上，黄腿山蛙的基因组<strong>预计9 Gb</strong>左右。</p><p>利用HiFi数据组装的黄腿山蛙基因组获得<font color="blue">两套单倍型基因组</font>，单倍型基因组大小分别为<font color="blue">9.03G和5.23 Gb</font>，<font color="red"><strong>主要单倍型基因组</strong></font>大小<strong>接近预估</strong>基因组大小。<font color="red"><strong>主要单倍型基因组</strong>Contig <strong>N50达2.8 M</strong>，<strong>远高于</strong>已发表的蛙科物种基因组</font>。HiFi 组装的<font color="blue"><strong>黄腿山蛙</strong>基因组的<strong>BUSCO评估结果</strong>也<strong>明显高于</strong>另外两个物种的基因组</font>。此外，虽然黄腿山蛙的基因组高达9 Gb，利用HiFi 组装也仅花费<strong>12小时</strong>。上述表明，HiFi快速组装<font color="blue">高质量大型基因组</font>出色。</p><p><img src="/GeekFocus/./11.png" alt="img"></p><p>HiFi组装 <strong>黄腿山蛙</strong> 基因组结果</p><h2 id="异源多倍体基因组—草莓"><a href="#异源多倍体基因组—草莓" class="headerlink" title="异源多倍体基因组—草莓"></a><strong>异源多倍体基因组—草莓</strong></h2><p>栽培草莓（<em>F. x ananassa</em>）是一个<font color="blue"><strong>异源</strong>八倍体物种（2n&#x3D;8x&#x3D;56）</font>，由两种<font color="blue">野生八倍体物种天然杂交</font>产生，这<font color="blue"><strong>两种野生八倍体</strong>都是<strong>100多万年</strong>前<strong>四种二倍体祖先物种合并</strong>的产物</font>。</p><p>利用HiFi数据组装的八倍体草莓基因组获得了<font color="blue">两套单倍型基因组</font>，大小分别为<font color="blue">776M和304 M</font>，<font color="red"><strong>主要单倍型基因组</strong></font>的大小与<strong>2019年</strong>最新<strong>发表</strong>的<strong>栽培草莓基因组相当</strong>，但<font color="blue">Contig N50达<strong>15.5 Mb</strong>，提升<strong>193倍</strong></font>。此外，整个基因组组装仅花费<strong>3小时</strong>。上述结果体现HiFi测序在<font color="blue">多倍体基因组组装中的良好表现</font>。</p><p><img src="/GeekFocus/./12.png" alt="img"></p><p>HiFi 数据组装 <strong>八倍体草莓</strong> 基因组结果</p><h2 id="同源多倍体基因组—苜蓿-√"><a href="#同源多倍体基因组—苜蓿-√" class="headerlink" title="同源多倍体基因组—苜蓿 √"></a><strong>同源多倍体基因组—苜</strong>蓿 √</h2><p>栽培紫花苜蓿（<em>M. sativa</em>）是一种<font color="blue">自交不亲和的<strong>同源</strong>四倍体（2n&#x3D;4×&#x3D;32）</font>植物。5月昆明动物研究所等单位利用HiFi测序（约23×）实现栽培紫花苜蓿的基因组组装 <a href="https://pubmed.ncbi.nlm.nih.gov/32427850/">paper</a>。</p><p>利用专门针对HiFi数据开发的组装软件<font color="red"><strong>HiCanu和Hifiasm</strong></font>重新对该基因组进行组装。<font color="blue">HiCanu组装版本</font>基因组大小为<font color="blue">2.66 G</font>，<strong>略低</strong>于<font color="blue">Canu版本</font>；<font color="blue"><strong>Hifiasm组装版本</strong></font>的基因组大小（<font color="blue">3.22 G</font>）则略高于Canu版本。<font color="red"><strong>HiCanu</strong>和<strong>Hifiasm</strong>的组装的<strong>Contig N50</strong>分别为<strong>1.67</strong>和<strong>1.73</strong> Mb，<strong>明显高于Canu</strong>版本</font>。测试结果及已发表的苜蓿基因组均表明，HiFi能够实现<font color="blue">同源多倍体基因组的高质量组装</font>。</p><p><img src="/GeekFocus/./14.png" alt="同源四倍体苜蓿基因组组装结果比较"></p><h2 id="单倍型基因组-人"><a href="#单倍型基因组-人" class="headerlink" title="单倍型基因组   人"></a><strong>单倍型基因组   人</strong></h2><p>目前已发表多个高质量人基因组序列，且已有多个利用HiFi组装人基因组的案例，利用HiFi组装出<strong>人两套单倍型基因组</strong>也已经被报道。</p><p>利用HiFi 对人基因组组装，获得两套单倍型基因组。<font color="blue"><strong>两套单倍型基因组</strong>大小分别为<strong>3.14G</strong>和<strong>2.50 G</strong>，<strong>Contig N50</strong>分别为<strong>42.2M</strong>和<strong>1.6 M</strong></font>。这一结果与<strong>已发表的利用HiFi数据组装的HG002和HG00733基因组相当。整个组装过程仅花费2小时。</strong>上述结果体现HiFi在<font color="blue">单倍型基因组组装中的优势</font>。</p><p><img src="/GeekFocus/./13.png" alt="img"></p><p>HiFi 组装 人 基因组结果</p><hr><h1 id="？Pacbio序列结构变异germline-SV-calling"><a href="#？Pacbio序列结构变异germline-SV-calling" class="headerlink" title="？Pacbio序列结构变异germline SV calling"></a>？Pacbio序列结构变异germline SV calling</h1><p><a href="https://blog.csdn.net/weixin_36416921/article/details/112277318">https://blog.csdn.net/weixin_36416921/article/details/112277318</a> ？？</p><p><img src="/GeekFocus/./2.png" alt="img"></p><ul><li><p>获取bam文件（Pacbio下机数据）。</p></li><li><p>subreads.bam文件 到ccs.bam文件</p></li><li><p>bam到fastq文件</p></li><li><p>数据分析，变异检测</p><ul><li><strong>mapping &amp; calling 【</strong>nextSV2流程】</li><li>常用的长序列比对软件有<strong>ngmlr</strong> 和 <strong>minimap2</strong>，不同的mapping软件得到结果略有差别，minimap2比对得到的结果较多？</li><li><strong>sniffles calling</strong></li></ul></li></ul><hr><p>一般认为只有CLR的subreads需要用NGS校正，ccs或hifi reads已经自身校正了，不用额外校正。当ccs的阈值设定为3时，得到的序列就是HIFI reads了。</p><h1 id="HiFi-HiCanu"><a href="#HiFi-HiCanu" class="headerlink" title="HiFi+HiCanu"></a>HiFi+HiCanu</h1><p>ref: <a href="http://www.genome.cn/News/Industry/1099.html">http://www.genome.cn/News/Industry/1099.html</a></p><p><a href="https://pubmed.ncbi.nlm.nih.gov/32801147/">HiCanu: accurate assembly of segmental duplications, satellites, and allelic variants from high-fidelity long reads</a> <strong>2020.09 Genom Res</strong></p><p><strong>PacBio HiFi+HiCanu</strong>完成准确度超99.999%，<strong>Contig N50</strong>达到<strong>77Mb</strong>的<strong>人类</strong>基因组组装结果！</p><p>NIH科学家使用PacBio HiFi Reads组装基因组文章 <strong>HiCanu</strong>。使用HiCanu组装工具（专门针对 HiFi Reads优化组装流程），对<font color="red"><strong>果蝇</strong></font>和<font color="red"><strong>人类</strong></font><strong>标准基因组</strong>组装，重点探索HiFi Reads对<font color="blue"><strong>基因组单倍型的区分</strong></font>，主要<font color="blue"><strong>组织相容性复合体（MHC）变异</strong></font>，染色体<font color="blue"><strong>卫星区域</strong></font>和<font color="blue"><strong>片段重复</strong></font>的检测能力。</p><h2 id="基因组连续性和准确性提升"><a href="#基因组连续性和准确性提升" class="headerlink" title="基因组连续性和准确性提升"></a><strong>基因组连续性和准确性提升</strong></h2><p>30X HiFi Reads通过HiCanu将人CHM13细胞系的基因组组装的<strong>Contig N50</strong> 提升至<strong>77M</strong>，单碱基准确性超过99.999%（Q50）！在组装的准确性连续性两个方面，HiFi Reads的组装结果都超过了最新 高覆盖度 超长 牛津 纳米孔测序 的结果。</p><p><img src="/GeekFocus/./3.png" alt="3.png"></p><p>使用PacBio HiFi和Ultra-Long (Oxford Nanoproe) 组装人CHM13基因组结果对比，都<strong>未经短读长测序数据polish</strong>。Peregrine, Canu和HiCanu是不同的组装工具。</p><h2 id="基因组单倍型检测的提升-做此图类似评估"><a href="#基因组单倍型检测的提升-做此图类似评估" class="headerlink" title="基因组单倍型检测的提升[做此图类似评估]"></a><strong>基因组单倍型检测的提升</strong>[做此图类似评估]</h2><p>组装多倍体时，组装软件要能区分<font color="blue"><strong>不同等位基因</strong></font>，并将它们<font color="blue"><strong>保存为不同的序列</strong></font>，以<font color="blue"><strong>主要Contig</strong>和<strong>替代Contig</strong>模式</font>表示。对于<font color="blue">双倍体人</font>基因组组装，HiCanu组装结果<font color="blue">包含<strong>超过2 Gbp</strong>的<strong>替代Contig</strong></font>，而<font color="blue">其它组装软件</font>只能产生<font color="blue">不到400 Mbp的替代Contig [hifiasm如何?]</font>。说明<font color="blue">HiCanu</font>结合HiFi Reads具有<font color="blue">更强的<strong>区分单倍型能力</strong></font>。如下图，HiCanu组装的<font color="red">主要Contig和替代Contig<strong>都</strong></font>具有<font color="red">较高的<strong>BUSCO完整性</strong></font>（分别**&gt; 94％<strong>和</strong>&gt; 75％<strong>），而采用 <strong>超长 牛津纳米孔测序</strong>的BUSCO完整性分别只有</strong>63%<strong>和</strong>0.3%**。并且HiCanu + HiFi Reads的<font color="red"><strong>Phase Block NG50?</strong></font>是高覆盖度超长牛津纳米孔测序的2.5倍！</p><p><img src="/GeekFocus/./4.png" alt="4"></p><p>HiCanu与其它组装软件 <strong>组装 双倍体基因组 结果对比</strong>，其中HG00733的Haplotype asm hap1(hap2)a和HG002的Haplotype asm hap1(hap2)b 的数据是<font color="red"><strong>HiFi结合Hi-C的组装结果</strong></font>。</p><p>为了<font color="red">评估</font>不同组装工具对<strong>难以检测</strong>的<font color="red"><strong>复杂临床相关等位基因分型结果</strong></font>，通过HiCanu+ HiFi 得到的六个经典的<font color="blue">人类白细胞抗原（HLA）基因</font>的<font color="blue">装配分型结果</font>与之前通过<strong>多种检测方法</strong>获得的<strong>已知HG002和HG00733等位基因</strong>进行比较。<font color="red">只有HiCanu和TrioCanu能够<strong>恢复</strong>具有<strong>100％序列同一性</strong>的<strong>所有等位基因</strong></font>。这也体现HiCanu+ HiFi对于潜在的复杂临床相关基因的精确检测能力。</p><h2 id="应对复杂片段重复序列"><a href="#应对复杂片段重复序列" class="headerlink" title="应对复杂片段重复序列"></a><strong>应对复杂片段重复序列</strong></h2><p>为了评估对<font color="red"><strong>片段重复（SD，segmental duplications）</strong>序列的组装能力</font>，使用了BAC文库挑战。被<strong>选择</strong>的<strong>BAC文库序列包含大量片段重复序列</strong>，而片段重复区域是基因组<font color="blue"><strong>最难组装区域之一</strong></font>。经过初步比对，HiCanu+ HiFi在所有组装方案中<font color="red">解析最多的BAC</font>，并且实现<font color="red">最高的BAC对比质量</font>。</p><p><img src="/GeekFocus/./5.png" alt="不同测序数据与组装工具在BAC文库挑战中的结果"></p><p>不同测序数据与组装工具在BAC文库挑战中的结果</p><p>针对<font color="blue">CHM13中<strong>未能</strong>成功解析的BAC深入研究</font>，发现其中【11个BAC本身可能包含组装错误或克隆伪像?】。手动检查11个BAC的HiFi组装结果，并没有发现明显组装错误（如下图）。这表明HiCanu+ HiFi 实际上成功解析CHM13 341个BAC中的<strong>337个</strong>。</p><p><img src="/GeekFocus/./6.png" alt="1585618676593848.png"></p><p>人工检查可能本身存在错误的BAC</p><h2 id="人类染色体着丝粒的组装-how"><a href="#人类染色体着丝粒的组装-how" class="headerlink" title="人类染色体着丝粒的组装 [how?]"></a>人类染色体着丝粒的组装 [how?]</h2><p>使用HiCanu+HiFi 成功生成包括CHM13 <font color="blue"><strong>19号染色体着丝粒在内</strong></font>的<font color="blue"><strong>共9个人类染色体着丝粒装配图</strong></font>。CHM13 <font color="red"><strong>19号染色体着丝粒区域被认为是最难组装的着丝粒之一</strong></font>，因为它<font color="red"><strong>由多个HOR（Higher Order Repeat）区域组成</strong></font>并<font color="red"><strong>与1号和5号染色体的着丝粒区域共享α卫星序列</strong></font>。</p><p>HiCanu+HiFi 不仅能<font color="red">组装<strong>覆盖整个着丝粒</strong>的contig<strong>群</strong></font>，而且可以<font color="red">准确<strong>区分</strong>三个<strong>不同的HOR区域???</strong></font>：<strong>D19Z1，D19Z2和D19Z3</strong>。在之前的<font color="red"><strong>X染色体T2T研究</strong>中</font>，为了达到如此完整的人类染色体<strong>着丝粒组装</strong>结果，需要<font color="blue">使用包括<strong>高深度超长纳米孔测序</strong>，<strong>60X PacBio CLR</strong>测序和<strong>illumina短读长</strong>测序的数据<strong>共同</strong>组装</font>才能达到这样的效果。而现在<font color="blue">仅使用<strong>一种</strong>测序技术</font>，即<strong>HiFi 结合HiCanu</strong>就能<strong>解析</strong>人类染色体<strong>着丝粒</strong>结构。</p><p><img src="/GeekFocus/./7.png" alt="1585618881806532.png"></p><p>CHM13 19号染色体<font color="blue"><strong>着丝粒的HiCanu装配</strong></font>。tig00006497的<font color="red"><strong>RepeatMasker</strong>揭示了位于<strong>19号着丝粒</strong>（D19Z1，D19Z2α和D19Z3；标有黑条）中的<strong>三个α卫星HOR区域</strong></font>。这些<strong>HOR序列长度</strong>分别为<strong>606 kbp，289 kbp和3.96 Mbp</strong>，分别由<strong>13-mer</strong>，复杂的<strong>高阶HOR</strong>和<strong>二聚体HOR单元</strong>组成?</p><h2 id="总结与展望"><a href="#总结与展望" class="headerlink" title="总结与展望"></a><strong>总结与展望</strong></h2><p>通过本研究，证明<font color="blue">HiFi 结合HiCanu</font>能够生成迄今为止<font color="blue">最准确，最完整</font>的人类基因组<font color="blue">装配体</font>。其他应用，例如同样需要高精度Reads的<strong>宏基因组组装</strong>。<font color="red">HiFi擅长解决<strong>大型高度相似</strong>（但<strong>不完全相同</strong>）的<strong>重复序列</strong></font>。HiCanu+HiFi 对人类<strong>1号，7号，9号和16号</strong>染色体的重建<strong>显著改善</strong>先前<strong>超长纳米孔测序的组装连续性</strong>。这些染色体包含<font color="blue">多个长度超过<strong>200 kbp的片段重复</strong></font>，需要 <font color="blue">HiFi 才能<strong>识别</strong>变异并<strong>分离</strong>出<strong>单个拷贝</strong></font>。使用 <strong>HiFi <font color="red">独立完成</font><strong>人类染色体</strong>九个着丝粒区域</strong>的装配草图，这也是T2T项目的最难挑战之一。</p><p><font color="blue">HiFi 的长度</font>对组装结果有很大影响，目前最新HiFi Reads已经达到25k。HiCanu在亚马逊<strong>云平台</strong>上组装一个<strong>人</strong>类基因组只需要<strong>22小时</strong>，这还<strong>不是目前最快</strong>的针对 HiFi数据的组装软件，最快的软件只需要<strong>2小时</strong>。相信未来随着HiFi Reads的长度不断提高，以及更多针对PacBio HiFi Reads优化的组装软件出现，基因组的从头组装会<strong>更快更准</strong>。</p><h1 id=""><a href="#" class="headerlink" title=""></a></h1>]]></content>
    
    
    <categories>
      
      <category>Biology</category>
      
    </categories>
    
    
    <tags>
      
      <tag>assembly</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Sequencing data and fastq.gz</title>
    <link href="/GeekFocus/2022/03/01/2022-03-01-sequencing-data/"/>
    <url>/GeekFocus/2022/03/01/2022-03-01-sequencing-data/</url>
    
    <content type="html"><![CDATA[<h1 id="fastq压缩之gzip文件大小与样本数据量关系"><a href="#fastq压缩之gzip文件大小与样本数据量关系" class="headerlink" title="fastq压缩之gzip文件大小与样本数据量关系"></a>fastq压缩之gzip文件大小与样本数据量关系</h1><span id="more"></span><p>ref : <a href="https://www.zxzyl.com/archives/1011">https://www.zxzyl.com/archives/1011</a></p><p>测序时，先拿到的是样本fastq压缩后的gz文件，若关心数据量够不够，则需计算fastq.gz文件大小和测序数据量的关系。</p><p>用Miseq测序数据（gz文件200M），Hiseq panel（gz文件50M）和WES测序数据（gz文件4G）进行简单分析。发现，<font color="green"><strong>虽然R1和R2数据量是一样，解压出来的文件大小一样，但R2的gzip文件总比R1大</strong></font>。不管是Miseq还是Hiseq的panel测序，压缩后的R2均大于R1文件，且文件越小，差异越大。</p><p>因R1和R2数据量相同，只看R1的真实文件和gz文件大小与数据量之间的关系。<br><font color="green"><strong>数据量</strong></font>&#x3D;FASTQ文件行数&#x2F;4x<font color="green"><strong>151</strong></font>&#x2F;1000&#x2F;<font color="green"><strong>1000</strong></font> 单位为<strong>M</strong><br><font color="green"><strong>真实文件大小估计</strong></font>&#x3D;FASTQ文件行数&#x2F;4x<font color="green"><strong>357</strong></font>&#x2F;1024&#x2F;<font color="green"><strong>1024</strong></font> 单位为<strong>M</strong>，预测值，差别不大，<strong>因为FASTQ文件中每四行357个字符</strong>（和平台和设置有关系），每个字符1byte。</p><p>GZ文件大小通过ll -h查看</p><p>因为FASTQ文件是<strong>规范</strong>的，<strong>每四行字符基本一致</strong>，所以<font color="green"><strong>FASTQ真实文件大小和数据量成正比</strong></font>。<strong>前面提到每四行有357个字符，其中序列只占151个字符，FASTQ文件大小大概是测序量的357&#x2F;151≈2.3倍多</strong>。但因FASTQ文件为文本文件，占用空间较大，所以一般将FASTQ文件压缩成gz。</p><p>用gz文件大小除以估计的真实文件大小，得到压缩比，发现压缩比和测序平台有关系，<font color="green"><strong>Miseq</strong>的压缩比在<strong>0.35</strong>左右，<strong>Hiseq</strong>平台中的panel测序在<strong>0.24</strong>左右，<strong>WES</strong>在<strong>0.2</strong>左右</font>。可以发现WES的数据的压缩效率最高，猜测不同平台在压缩过程中设置的压缩比例不同。Hiseq测序平台的gz文件压缩性能大于Miseq平台。</p><ul><li><p>以Miseq的gzip文件大小和数据量<strong>作图</strong>，可以很直观的发现gz文件大小和数据量之间的线性关系。斜率是1.245，截距可以忽略不计，因为纵坐标很大。也就是说R1文件的数据量约等于gzip文件的1.245倍。</p></li><li><p><strong>从另外一个角度计算</strong>，<font color="green"><strong>R1文件数据量&#x3D;gzip文件大小&#x2F;压缩效率&#x2F;2.3</strong></font>，则因为Miseq的压缩效率在0.35，Hiseq在0.23左右，所以Miseq R1文件的数据量大概是gzip文件的<font color="green">1.242倍（1&#x2F;0.35&#x2F;2.3）</font>，和上图拟合的结果很相近，<strong>Hiseq约在1.89(1&#x2F;0.23&#x2F;2.3)倍</strong>。真实的数据量其实是R1文件数据量的2倍（R2文件中的数据量和R1文件相同）。</p></li></ul><p><strong>结论：</strong>不同平台和不同测序方法之间的<font color="green">fastq文件压缩比例并不一致</font>，但同一种方法和平台内的压缩比例是相近的，因而可以根据gzip文件的大小推测出测序的数据量。</p><p><strong>Miseq的测序量约是R1 gzip文件大小的2.49倍(R1+R2)，Hiseq的测序量约是R1 gzip文件大小的3.78倍。</strong>不同平台和方法之间，这个值是不固定的，可以根据手头的数据计算一下这个比例，就能迅速的估算出样本的数据量。</p>]]></content>
    
    
    <categories>
      
      <category>Biology</category>
      
    </categories>
    
    
    <tags>
      
      <tag>note</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Genome assemble pipeline</title>
    <link href="/GeekFocus/2022/02/28/2022-02-28-genome-assemble/"/>
    <url>/GeekFocus/2022/02/28/2022-02-28-genome-assemble/</url>
    
    <content type="html"><![CDATA[<p>Genome assemble pipeline</p><span id="more"></span><blockquote><p>内容均来自菲沙基因（<a href="https://links.jianshu.com/go?to=http://www.frasergen.com/">Frasergen</a>）暑期生信培训班课堂笔记</p><p><a href="https://www.jianshu.com/p/c7663d2cf337">https://www.jianshu.com/p/c7663d2cf337</a></p></blockquote><h2 id="Genome-de-nove-基础知识"><a href="#Genome-de-nove-基础知识" class="headerlink" title="Genome de nove 基础知识"></a>Genome <em>de nove</em> 基础知识</h2><ul><li>基因组是物种所含有的一套遗传物质(单倍体细胞核、细胞器所含的全部DNA分子) , 包括全套基因和间隔序列</li><li>基因组&#x3D;物种所拥有的一套完整单倍体序列</li><li>利用测序技术对物种体内所有DNA分子进行测序,获取碱基组成,明确基因结构信息,外显子及内含子区域、启动子位置,以及基因的排列顺序及功能</li><li>基因组<em>de nove</em>,又称基因组从头测序,是指对基因组序列未知(或仅有基因组草图)的物种进行全基因组测序,然后进行拼装,从而得到该物种的全基因组序列,为后续功能基因挖掘、调控代谢网络构建、物种进化分析等奠定基础。</li></ul><h2 id="构建参考基因组pipeline"><a href="#构建参考基因组pipeline" class="headerlink" title="构建参考基因组pipeline"></a>构建参考基因组pipeline</h2><p><img src="/GeekFocus/./1.png" alt="1"></p><h3 id="基因组Survey分析"><a href="#基因组Survey分析" class="headerlink" title="基因组Survey分析"></a>基因组Survey分析</h3><ul><li><p>基因组Survey基于小片段文库的低深度测序数据( 50X-100X ) ;</p></li><li><p>通过K-mer分析 ,有效的<strong>评估基因组大小、GC含量、杂合度以及重复序列的含量等信息</strong>;</p></li><li><p>是全面了解某一物种基因组特征的有效方法;</p></li><li><p>为后续的全基因组 <em>de novo</em> 测序的组装策略的制定提供理论依据。</p></li></ul><p><img src="/GeekFocus/./2.png" alt="2"></p><h4 id="补充知识1：基因组复杂度评估"><a href="#补充知识1：基因组复杂度评估" class="headerlink" title="补充知识1：基因组复杂度评估"></a>补充知识1：基因组复杂度评估</h4><p><img src="/GeekFocus/./3.png" alt="3"></p><h4 id="补充知识2：根据kmer-图确认物种倍型"><a href="#补充知识2：根据kmer-图确认物种倍型" class="headerlink" title="补充知识2：根据kmer-图确认物种倍型"></a>补充知识2：根据kmer-图确认物种倍型</h4><blockquote><p>二倍体：杂合峰：主峰：重复峰&#x3D;1：2：4（x）</p></blockquote><p><img src="/GeekFocus/./4.png" alt="4"></p><blockquote><p>三倍体：正常情况下杂合峰：主峰：重复峰 &#x3D; 1:2:3（左图）。主峰和重复峰深度低则可能重叠在一起：杂合峰：主峰：重复峰 &#x3D; 1:2（右图）</p></blockquote><p><img src="/GeekFocus/./5.png" alt="5"></p><blockquote><p><strong>异源四倍体</strong>：2个峰，呈现1:2的关系</p></blockquote><p><img src="/GeekFocus/./6.png" alt="6"></p><blockquote><p><strong>同源四倍体</strong>：同源四倍体的峰就是1 : 2 : 3 : 4 ,其中3和4经常重叠在一起</p></blockquote><p><img src="/GeekFocus/./7.png" alt="7"></p><h4 id="补充知识3：Survey优势"><a href="#补充知识3：Survey优势" class="headerlink" title="补充知识3：Survey优势"></a>补充知识3：Survey优势</h4><p><img src="/GeekFocus/./8.png" alt="8"></p><h3 id="基因组组装与注释"><a href="#基因组组装与注释" class="headerlink" title="基因组组装与注释"></a>基因组组装与注释</h3><ul><li><strong>Contig</strong>：使用短reads之间的overlap关系拼接所得的无GAP序列片段</li><li><strong>Scaffold</strong>：通过大片段文库将Contig进-步连接所得的长序列片段，各个Contig之间用”N”填补</li></ul><p><img src="/GeekFocus/./9.png" alt="9"></p><ul><li><p>组装质量评价基本指标：<strong>ContigN50</strong>与<strong>ScaffoldN50</strong></p></li><li><p>将组装所得序列<strong>从大到小</strong>排列，并依次相加，当<strong>累加长度达到总长度一半时，最后一条序列的长度</strong>即为N50;N50越大，组装结果连续性越好</p></li></ul><h4 id="组装流程"><a href="#组装流程" class="headerlink" title="组装流程"></a>组装流程</h4><p><img src="/GeekFocus/./10.png" alt="10"></p><h4 id="组装"><a href="#组装" class="headerlink" title="组装"></a>组装</h4><p>常用软件有**<a href="https://links.jianshu.com/go?to=https://canu.readthedocs.io/en/latest/">Canu</a>, <a href="https://links.jianshu.com/go?to=https://github.com/xiaochuanle/MECAT">MECAT</a>, <a href="https://links.jianshu.com/go?to=https://github.com/PacificBiosciences/pb-assembly">FALCON</a><strong>。从项目周期、组装结果、资源消耗等方面综合来看,菲沙基因（<a href="https://links.jianshu.com/go?to=http://www.frasergen.com/">Frasergen</a>）首选</strong>Mecat 2**进行基因组组装。</p><p>####Hi-C辅助组装</p><p>Hi-C数据的一般规律:<br>➢ 染色体内的互作高于染色体间的互作<br>➢ 染色体内互作强度随线性距离增加而减弱</p><p><img src="/GeekFocus/./11.png" alt="11"></p><h4 id="组装结果评估"><a href="#组装结果评估" class="headerlink" title="组装结果评估"></a>组装结果评估</h4><p>数据回比：为了评估组装的完整性和测序覆盖的均匀性,选择CLR (Continuous Long Reads) subreads ,使用比对工具Minimap2 ( v2.5默认参数)比对回组装好的基因组,统计reads的比对率、覆盖基因组的程度以及深度的分布情况,由此评估组装的完整性和测序覆盖的均匀性,结果如下表所示。</p><p>BUSCO评估：基于OrthoDB中的单拷贝同源基因集,使用BUSCO ( V3.0.2 )预测这些基因并统计其完整度,碎片化程度及可能的丢失率。由此评估整个组装结果中基因区的完整性(大于90%较好)。BUSCO评估结果如下表所示。</p><p><img src="/GeekFocus/./12.png" alt="12"></p><h4 id="基因结构注释"><a href="#基因结构注释" class="headerlink" title="基因结构注释"></a>基因结构注释</h4><p>基因结构预测包括预测基因组中的基因位点、开放性阅读框架（ORF）、翻译起始位点和终止位点、内含子和外显子区域、启动子和终止子、可变剪切位点以及蛋白编码序列（CDS）等</p><p><img src="/GeekFocus/./13.png" alt="13"></p><h4 id="基因功能注释"><a href="#基因功能注释" class="headerlink" title="基因功能注释"></a>基因功能注释</h4><p>全基因组测序将产生大量数据，此前普遍采用比对方法对对预测出来的<strong>编码基因</strong>进行功能注释，通过与各种功能数据库（NR、Swiss-Prot 、GO、KOG、KEGG）进行蛋白质比对，获取该基因的功能信息。其中GO和KEGG数据库分别在基因功能和代谢通路研究中占据重要地位。</p><p><img src="/GeekFocus/./14.png" alt="14"></p><h4 id="非编码RNA注释"><a href="#非编码RNA注释" class="headerlink" title="非编码RNA注释"></a>非编码RNA注释</h4><p>非编码RNA（ncRNA），指不翻译成蛋白质的RNA，如<br> miRNA(MicroRNA),<br> tRNA(转运RNA)，<br> rRNA(核糖体RNA),<br> snRNA（小核RNA）等。<br> 利用tRNAscan-SE对全基因组进行tRNA预测；利用RNAmmer预测全基因的rRNA；利用Rfam数据库通过cmscan鉴定全基因组非编码RNA</p><p><img src="/GeekFocus/./15.png" alt="15"></p><h4 id="重复序列分析"><a href="#重复序列分析" class="headerlink" title="重复序列分析"></a>重复序列分析</h4><p>重复序列广泛存在于真核生物基因组中，这些重复序列或集中成簇，或分散在基因之间，根据分布把重复序列分为分散重复序列（Interpersed repeat）和串联重复序列（Tendam repeat）</p><p><img src="/GeekFocus/./16.png" alt="16"></p><h4 id="基因组圈图结果展示"><a href="#基因组圈图结果展示" class="headerlink" title="基因组圈图结果展示"></a>基因组圈图结果展示</h4><p><img src="/GeekFocus/./18.png" alt="18"></p><h3 id="比较基因组学"><a href="#比较基因组学" class="headerlink" title="比较基因组学"></a>比较基因组学</h3><ul><li><p>比较基因组学是从基因组中解析生物学意义</p><p><img src="/GeekFocus/./19.png" alt="19"></p></li></ul><h4 id="基因家族聚类"><a href="#基因家族聚类" class="headerlink" title="基因家族聚类"></a>基因家族聚类</h4><p><img src="/GeekFocus/./20.png" alt="20"></p><h4 id="系统进化树"><a href="#系统进化树" class="headerlink" title="系统进化树"></a>系统进化树</h4><p><img src="/GeekFocus/./21.png" alt="21"></p><h4 id="物种分歧时间计算"><a href="#物种分歧时间计算" class="headerlink" title="物种分歧时间计算"></a>物种分歧时间计算</h4><p><img src="/GeekFocus/./22.png" alt="22"></p><h4 id="基因家族扩展收缩分析"><a href="#基因家族扩展收缩分析" class="headerlink" title="基因家族扩展收缩分析"></a>基因家族扩展收缩分析</h4><p><img src="/GeekFocus/./23.png" alt="23"></p><h4 id="正选择分析"><a href="#正选择分析" class="headerlink" title="正选择分析"></a>正选择分析</h4><p><img src="/GeekFocus/./24.png" alt="24"></p><h4 id="共线性分析-需到染色体水平"><a href="#共线性分析-需到染色体水平" class="headerlink" title="共线性分析(需到染色体水平)"></a>共线性分析(需到染色体水平)</h4><p><img src="/GeekFocus/./25.png" alt="25"></p><h4 id="全基因组复制分析-WGD"><a href="#全基因组复制分析-WGD" class="headerlink" title="全基因组复制分析(WGD)"></a>全基因组复制分析(WGD)</h4><p><img src="/GeekFocus/./26.png" alt="26"></p><h4 id="泛基因组分析（需要多份基因组de-nove测序数据）"><a href="#泛基因组分析（需要多份基因组de-nove测序数据）" class="headerlink" title="泛基因组分析（需要多份基因组de nove测序数据）"></a>泛基因组分析（需要多份基因组<em>de nove</em>测序数据）</h4><p><img src="/GeekFocus/./27.png" alt="27"></p><h2 id="文章"><a href="#文章" class="headerlink" title="文章"></a>文章</h2><p><img src="/GeekFocus/./28.png" alt="28"></p><p><a href="https://links.jianshu.com/go?to=https://pan.baidu.com/s/1t_xbRf4Bj3DoHTQV-y6xAQ">https://pan.baidu.com/s/1t_xbRf4Bj3DoHTQV-y6xAQ</a></p><p>yyds</p>]]></content>
    
    
    <categories>
      
      <category>Biology</category>
      
    </categories>
    
    
    <tags>
      
      <tag>assembly</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Soapdenovo2</title>
    <link href="/GeekFocus/2022/02/24/2022-02-25-soapdenovo2/"/>
    <url>/GeekFocus/2022/02/24/2022-02-25-soapdenovo2/</url>
    
    <content type="html"><![CDATA[<h1 id="soapdenovo2"><a href="#soapdenovo2" class="headerlink" title="soapdenovo2:"></a>soapdenovo2:</h1><span id="more"></span><p>SOAPdenovo使用说明，内容包括程序<font color="green"><strong>使用</strong></font>、<font color="green"><strong>参数说明</strong></font>、<font color="green"><strong>参数调整</strong></font>、主要<font color="green"><strong>输出文件</strong></font>的格式说明等。</p><p><img src="/GeekFocus/./1.png" alt="img"></p><h1 id="contiging"><a href="#contiging" class="headerlink" title="contiging"></a>contiging</h1><p><em><strong>a.</strong></em>  基因组DNA随机打断，使用paired-end测序。长度在150-500bp的short clones扩增直接测序。在2-10kb的长paired-end libraries 通过DNA环化、fragmentation破碎，然后净化400-600bp的碎片为了cluster 结构。</p><p><em><strong>b.</strong></em>  raw reads 或预修正reads被存储，de Bruijn graph data structure 被用于表示reads间overlap。</p><p>Kmer-graph构建：所有reads被切割成某一固定Kmer长度的序列（21bp&#x3D;&lt;kmer&lt;&#x3D;127bp），形成等长的Kmers。将Kmers连成图。<font color="green"><strong>相邻的kmers是通过K-1 overlaping连接</strong></font>，所以它不需要成对序列比对（The neighboring kmers are K-1 overlaping which generated from read sequences, so it doesn’t need pair-wise reads alignment.）。重复序列在图中被压缩。</p><p><img src="/GeekFocus/./2.png" alt="img"></p><p><em><strong>c.</strong></em>  产生<font color="red"><strong>tips翼尖、bubbles气泡、low coverage links低覆盖率链接、tiny repeat微小重复</strong></font>等问题。</p><p><font color="blue"><strong>tips翼尖（a）</strong></font>和<font color="blue"><strong>bubbles气泡（c）</strong></font>：由于<strong>测序错误</strong>或<strong>杂合</strong>或<strong>高重复序列</strong>相似性，将会导致翼尖和气泡出现。</p><p><font color="blue"><strong>low coverage links低覆盖率链接：（b）（d）</strong></font>。</p><p><font color="blue"><strong>tiny repeat微小重复(e)</strong></font>：重复在graph中被压缩，并作为不同路径的共享边缘，但是能够通过reads 穿过来解决。</p><p><img src="/GeekFocus/./3.png" alt="img"></p><p><img src="/GeekFocus/./4.png" alt="img"></p><p><img src="/GeekFocus/./5.png" alt="img"></p><p>移除错误链接和graph simplification图形简化，得到contigs or contig  graphs：tips翼尖移除；删除低覆盖链接；bubbles合并气泡；解决微小重复；</p><p><img src="/GeekFocus/./6.png" alt="img"></p><p><img src="/GeekFocus/./7.png" alt="img"></p><p><img src="/GeekFocus/./8.png" alt="img"></p><p><img src="/GeekFocus/./9.png" alt="img"></p><p> <em><strong>d.</strong></em>  contig  graphs,在重复的节点处剪断?，输出contigs</p><h1 id="scaffolding"><a href="#scaffolding" class="headerlink" title="scaffolding"></a>scaffolding</h1><p><em><strong>e.</strong></em>  重新用reads和contigs进行比对，使用<font color="red"><strong>paired-end信息</strong></font>把单一的contigs连接成scaffolds。reads 比对到contigs上，临近的contig建立连接；repeat将会引来冲突矛盾信息；<font color="red"><strong>在组装成scaffold时，repeat contigs将会被屏蔽</strong></font>；paired-end信息的不同插入片段被用来一步步从短到长的建立scaffold graph(Scaffolding iteratively from short to long insert PEs.&#x2F;Various insert size of paired-end information is used to build contig graph step by step from short to long)。</p><p><img src="/GeekFocus/./10.png" alt="img"></p><p><img src="/GeekFocus/./11.png" alt="img"></p><p><img src="/GeekFocus/./12.png" alt="img"></p><h1 id="Gap-Filling"><a href="#Gap-Filling" class="headerlink" title="Gap Filling:"></a>Gap Filling:</h1><p><em><strong>f.</strong></em>  使用paired-end reads来填补scaffolds内部可能是由重复序列所造成的Gap。contig N50 通常比较小（&lt;3KB）,但是，gap filling之后能够显著提高N50值（i.e.,&gt;20KB）;Most of the gaps are repeat relative sequences.;Reads locate at gaps can collected by their paired-end which uniquely map to the contig.</p><p><img src="/GeekFocus/./13.png" alt="img"></p><h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>SOAPdenovo（目前最新版是SOAPdenovo2）是利用一种新的组装短read的方法，它以kerm为节点单位，利用<font color="green"><strong>de Bruijn图</strong></font>的方法实现全基因组的组装，和其他短序列组装软件相比，它可以进行大型基因组比如人类基因组的组装，组装结果更加准确可靠，可以通过组装的结果非常准确地鉴别出基因组上的序列结构性变异，为构建全基因组参考序列和以低测序成本对未知基因组实施精确分析创造了可能。</p><p>SOAPdenovo aims for large plant and animal genomes, although it also works well on bacteria and fungi genomes. It runs on 64-bit Linux system with a minimum of 5G physical memory. For <strong>big genomes</strong> like human, about <strong>150 GB memory</strong> would be required.</p><p>程序的下载及安装：<br>下载地址：<a href="http://soap.genomics.org.cn/soapdenovo.html">http://soap.genomics.org.cn/soapdenovo.html</a><br>安装：<br>(a) 下载SOAPdenovo的压缩包   </p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs sh">git <span class="hljs-built_in">clone</span> https://github.com/aquaskyline/SOAPdenovo2.git<br><span class="hljs-built_in">cd</span> SOAPdenovo2<br>make<br></code></pre></td></tr></table></figure><p>(b) 解压缩<br>(c)将得到可执行文件SOAPdenovo和一个配置文件的模板example.contig</p><p><strong>3个可执行文件</strong></p><ol><li><font color="green"><strong>SOAPdenovo-63mer</strong></font></li><li><font color="green"><strong>SOAPdenovo-127mer</strong></font></li><li><font color="green"><strong>SOAPdenovo-fusion</strong></font></li></ol><p>第一个支持最大k-mer为63，第二个最大kmer为127，第三个文件用于单细胞测序和宏基因组测序数据。</p><h1 id="使用程序及参数"><a href="#使用程序及参数" class="headerlink" title="使用程序及参数"></a>使用程序及参数</h1><p>SOAPdenovo可以一步跑完，也可以分成四步单独跑<br><font color="green"><strong>一步跑完脚本:</strong></font><br>.&#x2F; SOAPdenovo <font color="red"><strong>all</strong></font> <strong>-s</strong> lib.cfg <strong>-K</strong> 29 <strong>-D</strong> 1 <strong>-o</strong> ant &gt;&gt;ass.log<br><font color="green"><strong>四步单独跑的脚本</strong></font><br>.&#x2F; SOAPdenovo <font color="red"><strong>pregraph</strong></font> <strong>-s</strong> lib.cfg <strong>-d</strong> 1  <strong>-K</strong> 29 <strong>-o</strong> ant &gt;pregraph.log<br>.&#x2F; SOAPdenovo <font color="red"><strong>contig</strong></font> <strong>-g</strong> ant <strong>-D</strong> 1 <strong>-M</strong> 3 &gt;contig.log<br>.&#x2F; SOAPdenovo <font color="red"><strong>map</strong></font> <strong>-s</strong> lib23.cfg <strong>-g</strong> ant &gt;map.log<br>.&#x2F; SOAPdenovo <font color="red"><strong>scaff</strong></font> <strong>-g</strong> ant <strong>-F</strong> &gt;scaff.log</p><h1 id="参数说明"><a href="#参数说明" class="headerlink" title="参数说明"></a>参数说明</h1><p>用法：&#x2F;PathToProgram&#x2F;SOAPdenovo all -s configFile [-K kmer -d KmerFreqCutOff -D EdgeCovCutoff -M mergeLevel -R -u -G gapLenDiff -L minContigLen -p n_cpu] -o Output</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs sh">-s    STR     配置文件√<br>-o    STR     图形输出的文件名前缀 √<br>-g    STR     输入文件的文件名前缀<br>-K    INT     输入的K-mer值大小，默认值23，取值范围 13-63 √<br>-p    INT     程序运行时设定的cpu线程数，默认值8<br>-R            <span class="hljs-string">&quot;利用read鉴别短的重复序列，默认值不进行此操作&quot;</span> √<br>-d    INT     去除频数不大于该值的k-mer，默认值为0;<span class="hljs-string">&quot;最小化错误测序带来的影响&quot;</span> √<br>-D    INT     去除频数不大于该值的由k-mer连接的边，默认值为1，即该边上每个点的频数都小于等于1时才去除,最小化错误测序带来的影响 ?<br>-M    INT     连接contig时合并相似序列的等级(强度)，默认值为1，最大值3。<br>-F            利用<span class="hljs-built_in">read</span>对scaffold中的gap进行填补，默认不执行<br>-u            构建scaffold前不屏蔽高覆盖度的contig，这里高频率覆盖度指平均contig覆盖深度的2倍。默认屏蔽<br>-G    INT     估计gap的大小和实际补gap的大小的差异，默认值为50bp。<br>-L            用于构建scaffold的contig的最短长度，默认为：Kmer参数值 ×2<br></code></pre></td></tr></table></figure><p><font color="blue"><strong>全局配置</strong></font></p><p><code>max_rd_len</code></p><p><font color="blue"><strong>文库配置</strong></font></p><p>每个文库的配置以<code>[LIB]</code>开头，主要指定输入文件的路径，支持多种格式的输入文件，用不同的前缀表示， <code>q</code>代表输入序列为fastq格式；<code>f</code>代笔输入序列为fasta格式，<code>b</code>代表输入文件为bam格式，对于双端数据，分别用后缀<code>1</code>和<code>2</code>表示R1端和R2端的reads。</p><p><font color="blue"><strong>主要参数</strong></font></p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs sh">-avg_ins    This value indicates the average insert size of this library or the peak value position <span class="hljs-keyword">in</span> the <span class="hljs-string">&quot;insert size distribution figure?&quot;</span>. <span class="hljs-comment">#文库平均插入长度(或取插入大小分布图中的峰值位置)，根据建库情况设置。 </span><br><br>-reverse_seq    This option takes value 0 or 1. It tells the assembler <span class="hljs-keyword">if</span> the <span class="hljs-built_in">read</span> sequences need to be complementarily reversed. Illumima GA produces two types of paired-end libraries: a) <span class="hljs-string">&quot;forward-reverse&quot;</span>, generated from fragmented DNA ends with typical <span class="hljs-string">&quot;insert size less than 500 bp&quot;</span>; b) <span class="hljs-string">&quot;reverse-forward&quot;</span>, generated from <span class="hljs-string">&quot;circularizing libraries&quot;</span> with typical <span class="hljs-string">&quot;insert size greater than 2 Kb&quot;</span>. The parameter <span class="hljs-string">&quot;reverse_seq&quot;</span> should be <span class="hljs-built_in">set</span> to indicate this: 0, forward-reverse; 1, reverse-forward. <br><br>-asm_flags    This indicator decides <span class="hljs-keyword">in</span> <span class="hljs-built_in">which</span> part(s) the reads are used. It takes value 1(only contig assembly), 2 (only scaffold assembly), <span class="hljs-string">&quot;3(both contig and scaffold assembly)&quot;</span><span class="hljs-string">&quot;, or 4 (only gap closure). </span><br><span class="hljs-string"></span><br><span class="hljs-string">-rd_len_cutof    The assembler will &quot;</span><span class="hljs-built_in">cut</span> the reads from the current library to this length<span class="hljs-string">&quot;.</span><br><span class="hljs-string"></span><br><span class="hljs-string">-rank    It takes integer values and decides in which &quot;</span>order the reads are used <span class="hljs-keyword">for</span> scaffold assembly<span class="hljs-string">&quot;. Libraries with the same &quot;</span>rank<span class="hljs-string">&quot; are used at the same time during scaffold assembly.</span><br><span class="hljs-string"></span><br><span class="hljs-string">-pair_num_cutoff    This parameter is the cutoff value of pair number for a &quot;</span>reliable connection<span class="hljs-string">&quot; between two contigs or pre-scaffolds. The minimum number for &quot;</span>paired-end reads and mate-pair reads is 3 and 5 respectively<span class="hljs-string">&quot;. </span><br><span class="hljs-string"></span><br><span class="hljs-string">-map_len    This takes effect in the &quot;</span>map<span class="hljs-string">&quot; step and is the minimun alignment length between a read and a contig required for a reliable read location. The minimum length for &quot;</span>paired-end reads and mate-pair reads is 32 and 35 respectively<span class="hljs-string">&quot;.</span><br></code></pre></td></tr></table></figure><p><font color="blue"><strong>实例</strong></font></p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs sh">max_rd_len=100<br>[LIB]<br><span class="hljs-comment">#avg_ins 文库插入片段的平均长度，在实际设置时，可以参考文库size分布图，取峰值即可???</span><br>avg_ins=200<br><span class="hljs-comment">#reverse_seq 是否需要将序列反向互补，pair-end数据，不需反向互补，设置为0；mate-pair需要设置为1</span><br>reverse_seq=0<br><span class="hljs-comment">#asm_flags 1只组装contig. 2只组装scaffold,3同时组装contig和scaffold,4只补gap</span><br>asm_flags=3<br><span class="hljs-comment">#序列长度阈值，作用和max_rd_len相同，大于该长度的序列会被切除到该长度</span><br>rd_len_cutoff=100<br><span class="hljs-comment">#设置不同文库数据的优先级顺序，取值范围为整数，rank值相同的多个文库，在组装scaffold时，会同时使用。</span><br>rank=1<br>q1=fastq1_read_1.fq<br>q2=fastq1_read_2.fq<br>-pair_num_cutoff<br><span class="hljs-comment">#contig或者scaffold之前的最小overlap个数，pair-end数据默认为3；mate-paird数据默认为5</span><br>-map_len<br><span class="hljs-comment">#比对长度的最小阈值，pair-end数据默认为32；mate-pair数据默认为35</span><br></code></pre></td></tr></table></figure><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sh">SOAPdenovo-63mer all -s config_file -K 63 -R -o graph_prefix<br></code></pre></td></tr></table></figure><h1 id="使用方法及示例"><a href="#使用方法及示例" class="headerlink" title="使用方法及示例"></a>使用方法及示例</h1><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-comment">#（1）示例</span><br>SOAPdenovo all -s HCB.lib -K 25 -d -o <span class="hljs-built_in">test</span><br><span class="hljs-comment">#（2）配置文件 configFile</span><br><span class="hljs-comment">#maximal read length （read的最大长度），该值【一般设置的比实际read读长稍微短一些？】，截去测序最后的部分，具体长度看测序质量</span><br>max_rd_len=50    <br><br><span class="hljs-comment">#[LIB]文库信息以此开头</span><br><br>avg_ins=200<span class="hljs-comment">#?</span><br><br>reverse_seq=0<br><span class="hljs-comment">#序列是否需反转，目前测序技术，插入片段大于等于2k的采用了环化，对于插入长度大于等于2k文库，序列需要反转，reverse_seq＝1，小片段设为0</span><br><br>asm_flags=3<br><span class="hljs-comment">#该文库中的read序列在组装的哪些过程（contig/scaff/fill）中用到</span><br><span class="hljs-comment">#短插入片段(&lt;2K)的设为3，同时构建contig和scaffold，长插入片段(&gt;=2k)设为2，不构建contig，只构建scaffold，454single 长reads只用于补洞。</span><br><br>rank=1<br><span class="hljs-comment">#该值取整数，决定了reads用于构建scaffold的次序，值越低数据越优先用于构建scaffold。【相同rank的文库数据会同时用于组装scaffold】。一般将短插入片段设为1；2k设为2；5k设为3；10k设为4；当【某个档的数据量较大】时可以将其分为多个档，同样当【某档数据量不足够】时，可以将多个档的数据合在一起构建scaffold?。这里说的数据量够与不够是从该档的测序覆盖度和物理覆盖度两个方面考虑。</span><br><br>pair_num_cutoff=3<br><span class="hljs-comment">#【可选参数】，该参数规定连接两个contig 或者是pre-scaffold 的可信连接的阈值，当连接数大于该值，连接才算有效。短插入片段(&lt;2k)默认值为3，长插入长度序列默认值为5</span><br><br>map_len=32<br><span class="hljs-comment">#map_len该参数规定在map过程中 reads和contig的比对长度必须达到该值（比对不容mismacth和gap），该比对才能作为一个可信的比对。可选参数，短插入片段(&lt;2k)一般设置为32，长插入片段设置为35，默认值是K＋2。</span><br><br>q1=/path/LIBNAMEA/fastq_read_1.fq<span class="hljs-comment">#read 1的fastq</span><br>q2=/path/LIBNAMEA/fastq_read_2.fq<span class="hljs-comment">#read 2的fastq【注意顺序】</span><br>f1=/path/LIBNAMEA/fasta_read_1.fa<span class="hljs-comment">#read 1的fa</span><br>f2=/path/LIBNAMEA/fasta_read_2.fa<br>q=/path/LIBNAMEA/fastq_read_single.fq<span class="hljs-comment">#单向测序fastq</span><br>f=/path/LIBNAMEA/fasta_read_single.fa<span class="hljs-comment">#单向测序fa</span><br>p=/path/LIBNAMEA/pairs_in_one_file.fa<span class="hljs-comment">#双向测序一个fasta</span><br></code></pre></td></tr></table></figure><h1 id="输出文件及说明"><a href="#输出文件及说明" class="headerlink" title="输出文件及说明"></a>输出文件及说明</h1><p>SOAPdenovo 分四部分别对应的输出文件：<br>  ● pregraph  生成7个文件 *.kmerFreq  *.edge  *.preArc  *.markOnEdge  *.path  *.vertex  *.preGraphBasic<br>  ● contig       生成4个文件 <font color="red"> ***.contig**</font>  *.ContigIndex  *.updated.edge  *.Arc<br>  ● map          生成3个文件 *.readOnContig  *.peGrads  *.readInGap<br>  ● scaff          生成6个文件 *.newContigIndex  *.links  *.scaf  *.scaf_gap  <font color="red"> ***.scafSeq**</font>  *.gapSeq</p><p>*.kmerFreq             #每行显示一个数，这个数是kmer值出现的频率等于行号的kmer个数。</p><p><font color="red"><em><strong>.contig</strong></font>：没有使用mate pair 信息的contig sequences<br><font color="red"></em><strong>.scafSeq</strong></font>：fasta格式scaffold序列文件，contig之间的gap用N填充；<br><strong>对于得到的.scafSeq文件还需要用<font color="red">GapCloser</font>去合并其中的gap，最后的contig文件则是对补洞之后的scaffold文件通过打断N区的方法得到?</strong><br>以上两个文件是组装结果中最主要的输出。</p><p><font color="red"><em><strong>.scaf</strong></font>：包括scaffold中contig的详细信息；<br>在</em>*scaffold行<strong>中包括scaffold名字、contig长度和该scaffold长度。<br>在</strong>contig行**包括contig名字、contig在scaffold上的起始位置、正反链、长度和contig间的链接信息<br><font color="red"> *.links</font>：contig间的pair-end连接信息<br><font color="red"> *.readOnContig</font>：reads在contig上的位置<br><font color="red"> *.peGrads</font>： 通过调整本文件中参数来显示构建scaffold所用到的插入片段库的个数，总共用到的read数，最长read，每个库对应的哪些reads，rank设置，pair_num_cutoff设置。例如：</p><blockquote><p>grads&amp;num: 10   522083934       70<br>323     104577616       1       3<br>334     180770522       1       3<br>345     226070520       1       3<br>486     361955834       2       3<br>2200    392088076       3       5<br>2290    422272580       3       5<br>2400    445522690       3       5<br>4870    475666064       4       5<br>9000    511030930       5       8<br>9110    522083934       5       5</p><p>该文件中共分成4列。<strong>组装的配置文件中有n个文库，该文件则有n+1行，且按照文库大小顺序排列。</strong><br><strong>第1行</strong>，二三四列分别是所用文库数目，reads总数和<font color="red">组装中用到的最长的reads长度？</font>。<br><strong>第2行</strong>，四列分别是文库大小，文库reads数目，文库reads的rank等级和pair_num_cutoff。<br><strong>第3～n+1行</strong>，四列分别是文库大小，文库reads数目加上前面文库中的reads总数，文库reads的rank等级pair_num_cutoff。#contig或者scaffold之前的最小overlap个数，pair-end数据默认为3；mate-paird数据默认为5,若配置文件没设置pair_num_cutoff，即使用默认参数0。</p></blockquote><p><strong>对于SOAPdenovo的每个步骤都有日志文件输出，要保存好日志文件，日志文件中包含有很多有用的信息。</strong></p><p>SOAPdenovo日志输出说明：</p><p>1）<font color="red">pregraph.log</font>:  其中有很多的统计信息，包括构建debruijn-graph所用reads数目，构图产生多少uniq的kmer以及设置-d参数后去除了多少kmer。</p><blockquote><p>-R            利用read鉴别短的重复序列，默认值不进行此操作</p><p>-d    INT     去除频数不大于该值的k-mer，默认值为0</p></blockquote><p>在pregraph中，可选参数有 –R –K –d  结果如：<br>5467781332 <strong>nodes</strong> allocated, 70662750348 <strong>kmer</strong> <strong>in reads</strong>, 70662750348 <strong>kmer processed</strong><br>3283081670 <strong>kmer removed</strong><br>其中Kmer 数取决于k值和数据量，nodes数即特异性kmer数，当nodes数目过高<strong>（一般和基因组大小差不多大小），可能是数据的错误率比较高，也可能是存在杂合</strong>。若nodes数目偏小，且kmer数目多，则基因组重复度较高。</p><p>k值的选取，当数据量充足（&gt;&#x3D;40X），<strong>植物基因组一般采用大kmer效果较好</strong>，而<strong>动物基因组k值一般取27和29足够</strong>。kmer removed表示的 <strong>–d 参数所去除的低频的kmer</strong>。</p><p>2）<font color="red">contig.log</font>: contig 中，可选参数 –R –D –M，注，-R 参数的选定，必须pregraph和contig中同时选择才有效。</p><blockquote><p>-R            利用read鉴别短的重复序列，默认值不进行此操作</p></blockquote><p>结果例子：<br>16430183 pairs found, 2334584 pairs of paths compared, 1674493 pairs merged<br><strong>merged的数量可作为估计杂合以及测序错误的程度</strong>。<br>sum up 1932549703bp, with average length 1170<br>the longest is 36165bp, contig N50 is 2871 bp,contig N90 is 553 bp<br>相关统计信息，通常<strong>植物基因组的contig N90在200bp左右</strong>，若<strong>N90高于200bp则该基因组scaffold构建不会有太大问题</strong>。动物基因组scaffold构建很少有出问题的。</p><p>3）<font color="red">map.log</font>:<br>Output 415219610 out of 1956217742 (21.2)% reads in gaps<br><strong>1661094582 out of 1956217742 (84.9)% reads mapped to contigs</strong><br>一般情况下，reads in gap比例和map to contig 比例<strong>总和大于1（21.2%+84.9%）</strong>。因为reads map到多个地方都被统计。当map to contig的比例很高（80%左右时），但组装效果不好可能是重复序列较多。reads in gap比例较高（大于40%）是因为基因组组装的较碎gap区域较多。<br>map_len 默认值&#x3D;K+5，短插入片段(&lt;2k)一般设置为32，长插入片段为35。取值为max{K+5,map_len}</p><p>4）<font color="red">scaff.log</font>:<br>average contig coverage is 23, 5832270 contig masked<br>构建scaffold是对高频覆盖的contig进行屏蔽（即<strong>频率高于average contig coverage的两倍的contig不用于构建scaffold(average-dep 2倍以上repeat sequences)?<strong>），从这里可以看出组装的基因组一定的重复情况。<br><strong>estimated PE size 162</strong>, by 40034765 pairs<br>on contigs longer than 173, 38257479 pairs found,SD&#x3D;8, insert_size estimated: 163<br><font color="green"><strong>173 是配置文件文库insertsize</strong></font>，<font color="green"><strong>163 是reads  map到contig上的距离的估计值</strong></font>，8是分布标准偏差。一般考虑比对上去的pair数目和SD值。若pair对数很多且SD值很小？（小片段文库数据不超过三位数，大片段文库数据不超过500），<font color="green">一般可将配置文件中</strong>文库插入片段值修改</strong>为对短插入片段文库（&lt;1k）的大小<strong>估计值<strong>，下次</strong>组装<strong>以及</strong>补洞<strong>时应根据估计值对原配置文件中的</strong>insertsize修正**</font>。对于大片段文库（&gt;&#x3D;2K），因为是把reads map到contig上，若最长contig较短，可能找不到成pair比对上去的reads，无法估计文库大小，需要自己将大片段一级一级的map到前一级的组装结果上，然后再分析大片段文库的插入片段大小。注，</strong>需要调整insertsize时，只需修改* .peGrads文件中第一列，后删除*.links文件，重跑scaff即可*<em>。即构建scaffold时，主要是根据</em>.links文件的信息进行连接。<br>Cutoff for number of pairs to make a reliable connection: 3<br>1124104 weak connects removed (there were 4773564 active cnnects))<br>Cutoff for number是在配置文件中设的pair_num_cutoff值，weak connects是低于这个值被认定为无效的连接数，active connects是满足cutoff的连接数，根据这个数值可对pair_num_cutoff做调整<br>Picked  25241 subgraphs,4 have conflicting connections<br>conflicting connections 是表示构建scaffold时的矛盾数，矛盾数比较高（&gt;100）时，可根据前面的有效连接数，适当提高pair_num_cutoff值，即提高scaffold连接要求的最少关系数<br>182483 scaffolds&amp;singleton sum up 1990259817bp, with average length 10906<br>the longest is 6561520bp,scaffold N50 is 836795 bp, scaffold N90 is 157667 bp<br>scaffold 统计信息，将是根据rank分梯度的统计<br>Done with 13301 scaffolds, 2161915 gaps finished, 2527441 gaps overall<br><strong>-F 参数补洞的统计信息。</strong></p><blockquote><p>发现scafstatistics 文件中的sca N50是整个scafSeq文件中的N50（包括不存在于scaf内的contig）。log文件中的sca N50只包括scaf 中的N50.</p><p>sacf.seq中可能有N，也可能无N。大部分有</p><p>gap finish？</p></blockquote><h1 id="参数调整"><a href="#参数调整" class="headerlink" title="参数调整"></a>参数调整</h1><p>组装时需调整的参数，主要分两种：</p><p>一种是脚本中参数改动：如调整  -K  -R  -d  -D  -M<br>-K 值一般与基因组的特性和数据量相关，目前用到的SOAPdenovo软件主要有两个版本，SOAPdenovo-63mer是可使用大kmer组装，K值范围13-63。<br>【<strong>经验</strong>】：植物基因组组装采用大kmer效果会比较好（要求短片段reads长度75bp），动物基因组很少有用到大kmer后有明显改进效果的，且<strong>动物基因组组装K值一般设置为27和29较多</strong>。</p><p><font color="red"><strong>组装杂合子基因组的K-mer值应该小一点；组装含有高repeats基因组且要求其有高的测序深度和长的reads,的K-mer应该大一点。</strong></font></p><p>-R参数，对于<font color="green">动物基因组R参数一般不设置</font>，<font color="red"><strong>植物基因组</strong>由于<strong>较多的repeat区</strong>则<strong>设置R参数</strong>后效果更好</font>。注意<strong>设置-R时，一般使用-M 的默认值</strong>。（熊猫基因组组装时得出的结论）</p><p>-M 参数，0-3,<strong>默认值1</strong>。一般杂合率为千分之几就设为几。熊猫基因组组装时-M 2 。</p><p>-d 参数，对于没有纠错，没有处理的质量又较差的原始数据，kmer频数为1数据较多的组装，<font color="red"><strong>设置为-d 1 足够</strong></font>。对于处理过或是测序质量较好数据可不设置。数据量较多时，也可设置-d 去除部分质量稍差数据。</p><p>-D 参数，默认为1，一般不用另行设置。</p><p>第二种，从<strong>map</strong>过程去调节参数。可以<font color="red"> 调整配置文件map_len的值和调整文件 * .peGrads  </font>。<br>当<strong>文库插入片段分布图</strong>中文库大小与<strong>实验给出的文库大小</strong><font color="red">差异很大</font>，<font color="red"><em><em>调整</em>.peGrad</em>*s</font>文件中的插入片段大小。</p><p>根据每一档数据的数据量去调整文库的<strong>rank等级</strong>。</p><p>当该文库的数据量很多或者是在构建scaffold的过程中的冲突数很多时，可是适当的调大第四列的<strong>pair_num_cutoff</strong>，把条件设置的更严。</p><h1 id="内存估计"><a href="#内存估计" class="headerlink" title="内存估计"></a>内存估计</h1><p>SOAPdenovo四个步骤消耗的内存不一样</p><p>第一步消耗内存最多，使用没有纠错的的reads，(<font color="blue"> <strong>K&lt;&#x3D;31**</font>)第一步消耗的内存在<font color="blue"><strong>基因组大小80－100倍</strong>左右</font>，<font color="blue">纠过错在</strong>40－50倍**左右</font></p><p>第二步相对消耗内存会少很多</p><p>第三步消耗内存仅次于第一步，在第一步的一半左右</p><p>第四步消耗的内存也会比较少</p><p>对于CPU的使用，默认是8个，如果申请内存时申请一个计算节点的所有内存, CPU就设置为该计算节点的CPU个数充分利用计算资源，如果仅申请一个节点的部分内存则根据实际情况考虑。</p><p>对于<font color="blue"><strong>大kemr(K&gt;31)</strong></font>其内存使用是<font color="blue">**(k&lt;&#x3D;31)**</font>的<font color="blue"><strong>1.5倍</strong></font>左右，有时甚至更多，要充分估计内存使用，在第一次运行时考虑不能太保守。</p><h1 id="常见错误"><a href="#常见错误" class="headerlink" title="常见错误"></a>常见错误</h1><p>1）配置文件reads存储路径错误<br>只输出日志文件。<br>pregraph.log中的错误信息：“Cannot open &#x2F;path&#x2F;LIBNAMEA&#x2F;fastq_read_1.fq. Now exit to system…”<br>2）-g 后所跟参数与pregraph（第一步） -o  后所跟参数名不一致【**-o对应后面的-g**】<br>contig  map  scaff 这三个步骤都只是输出日志文件。<br><font color="green">contig.log</font>错误信息：“Cannot open *.preGraphBasic. Now exit to system…”<br><font color="green">map.log</font>错误信息：“Cannot open *.contig. Now exit to system…”<br><font color="green">scaff.log</font>错误信息：“Cannot open *.preGraphBasic. Now exit to system…”<br>3）<font color="blue">从map开始重新跑时，需要删除 *.links文件</font>，否则会生成core文件，程序退出。</p><hr><h1 id="Github-Readme-md"><a href="#Github-Readme-md" class="headerlink" title="Github-Readme.md"></a>Github-Readme.md</h1><h2 id="Configuration-file"><a href="#Configuration-file" class="headerlink" title="Configuration file"></a>Configuration file</h2><p>For big genome projects with deep sequencing, <font color="red">the data is usually organized as <strong>multiple read sequence files</strong> generated from <strong>multiple libraries</strong></font>. The configuration file: where? information? example.config</p><p>The configuration file has a section for <font color="red"><strong>global information</strong></font>, and then <font color="red"><strong>multiple library sections</strong></font>. Right now only “max_rd_len” is included in the global information section. Any read longer than max_rd_len will be cut to this length.</p><p>The library information and the information of sequencing data generated from the library should be organized in the corresponding library section. <font color="red"><strong>Each library section starts with tag [LIB]</strong></font> and includes the following items:</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs sh">-avg_ins<br>-reverse_seq<br>-asm_flags<br>-rd_len_cutof<br>-rank<br>-pair_num_cutoff<br>-map_len<br></code></pre></td></tr></table></figure><p>The assembler accepts read file in three kinds of formats: <font color="green">FASTA, FASTQ and BAM</font>. Mate-pair relationship could be indicated in two ways: two sequence files with reads in the same order belonging to a pair, or two adjacent reads in a single file (FASTA only) belonging to a pair. If a read in <strong>bam</strong> file <strong>fails</strong> platform&#x2F;vendor <strong>quality checks</strong>(the flag field 0x0200 is set), itself and it’s <strong>paired read</strong> would be <strong>ignored</strong>.</p><p>All the above items in each library section are optional. The assembler assigns default values for most of them. <strong>If you are not sure how to set a parameter, you can remove it from your configuration file</strong>.</p><h2 id="Get-started"><a href="#Get-started" class="headerlink" title="Get started"></a>Get started</h2><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-string">&quot;one step&quot;</span><br>SOAPdenvo all -s config_file -K 63 -R -o graph_prefix 1&gt;ass.log 2&gt;ass.err<br><span class="hljs-comment">#-R            利用read鉴别短的重复序列，默认值不进行此操作</span><br><br><span class="hljs-comment">#step by step </span><br><span class="hljs-string">&quot;step1:&quot;</span><br>SOAPdenvo pregraph -s config_file -K 63 -R -o graph_prefix 1&gt;pregraph.log 2&gt;pregraph.err<br><span class="hljs-string">&quot;OR&quot;</span><br>SOAPdenvo sparse_pregraph -s config_file -K 63 -z 5000000000 -R -o graph_prefix 1&gt;pregraph.log 2&gt;pregraph.err<br><span class="hljs-comment">#-z genomize(required):estimated genome size</span><br><br><span class="hljs-string">&quot;step2:&quot;</span><br>SOAPdenvo contig -g graph_prefix -R 1&gt;contig.log 2&gt;contig.err<br><span class="hljs-comment">#-g    STR     输入文件的文件名前缀</span><br><br><span class="hljs-string">&quot;step3:&quot;</span><br>SOAPdenvo map -s config_file -g graph_prefix 1&gt;map.log 2&gt;map.err<br><br><span class="hljs-string">&quot;step4:&quot;</span><br>SOAPdenvo scaff -g graph_prefix -F 1&gt;scaff.log 2&gt;scaff.err<br><span class="hljs-comment">#-F            利用read对scaffold中的gap进行填补，默认不执行       </span><br></code></pre></td></tr></table></figure><h2 id="Options"><a href="#Options" class="headerlink" title="Options"></a>Options</h2><h3 id="Options-for-all-pregraph-contig-map-scaff"><a href="#Options-for-all-pregraph-contig-map-scaff" class="headerlink" title="Options for all (pregraph-contig-map-scaff)"></a>Options for all (<font color="red">pregraph-contig-map-scaff</font>)</h3><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-string">&quot;-s&quot;</span>    configFile: the config file of solexa reads<br><span class="hljs-string">&quot;-o&quot;</span>     outputGraph: prefix of <span class="hljs-string">&quot;output graph file name&quot;</span><br><span class="hljs-string">&quot;-K&quot;</span>        kmer(min 13, max 63/127): kmer size, [23]<br><span class="hljs-string">&quot;-p&quot;</span>        n_cpu: number of cpu <span class="hljs-keyword">for</span> use, [8]<br><span class="hljs-string">&quot;-a?&quot;</span>        initMemoryAssumption: memory assumption initialized to avoid further reallocation, unit G, [0]<br><span class="hljs-string">&quot;-d&quot;</span>        KmerFreqCutoff: kmers with frequency no larger than KmerFreqCutoff will be deleted, [0]INT     去除频数不大于该值的k-mer，默认值为0<br><span class="hljs-string">&quot;-R&quot;</span> (optional)  resolve repeats by reads, [NO]<br><span class="hljs-string">&quot;-D&quot;</span>        EdgeCovCutoff: edges with coverage no larger than EdgeCovCutoff will be deleted, [1]INT     去除频数不大于该值的由k-mer连接的边，默认值为1，即该边上每个点的频数都小于等于1时才去除<br><span class="hljs-string">&quot;-M&quot;</span>        mergeLevel(min 0, max 3): the strength of merging similar sequences during contiging, [1]INT     连接contig时合并相似序列的等级，默认值为1，最大值3。<br>-m        max k when using multi kmer<br>-e        weight to filter arc when linearize two edges(default 0)<br>-r (optional)  keep available <span class="hljs-built_in">read</span>(*.<span class="hljs-built_in">read</span>)<br>-E (optional)  merge clean bubble before iterate<br>-f (optional)  output gap related reads <span class="hljs-keyword">in</span> map step <span class="hljs-keyword">for</span> using SRkgf to fill gap, [NO]<br>-k        kmer_R2C(min 13, max 63): kmer size used <span class="hljs-keyword">for</span> mapping <span class="hljs-built_in">read</span> to contig, [K]<br>-F (optional)  fill gaps <span class="hljs-keyword">in</span> scaffold, [NO]利用<span class="hljs-built_in">read</span>对scaffold中的gap进行填补，默认不执行<br>-u (optional)  un-mask contigs with high/low coverage before scaffolding, [mask]构建scaffold前不屏蔽高覆盖度的contig，这里高频率覆盖度指平均contig覆盖深度的2倍。默认屏蔽<br>-w (optional)  keep contigs weakly connected to other contigs <span class="hljs-keyword">in</span> scaffold, [NO]<br>-G        gapLenDiff: allowed length difference between estimated and filled gap, [50]INT     估计gap的大小和实际补gap的大小的差异，默认值为50bp。<br>-L        minContigLen: shortest contig <span class="hljs-keyword">for</span> scaffolding, [K+2]用于构建scaffold的contig的最短长度，默认为：Kmer参数值 ×2<br>-c      minContigCvg: <span class="hljs-string">&quot;minimum contig coverage&quot;</span> (c*avgCvg), contigs shorter than 100bp with coverage smaller than c*avgCvg will be masked before scaffolding unless -u is <span class="hljs-built_in">set</span>, [0.1]<br>-C      maxContigCvg: <span class="hljs-string">&quot;maximum contig coverage&quot;</span> (C*avgCvg), contigs with coverage larger than C*avgCvg or contigs shorter than 100bp with coverage larger than 0.8*C*avgCvg will be masked before scaffolding unless -u is <span class="hljs-built_in">set</span>, [2]<br>-b      insertSizeUpperBound: (b*avg_ins) will be used as upper bound of insert size <span class="hljs-keyword">for</span> large insert size ( &gt; 1000) when handling pair-end connections between contigs <span class="hljs-keyword">if</span> b is <span class="hljs-built_in">set</span> to larger than 1, [1.5]<br>-B      bubbleCoverage: remove contig with lower cvoerage <span class="hljs-keyword">in</span> bubble structure <span class="hljs-keyword">if</span> both contigs<span class="hljs-string">&#x27; coverage are smaller than bubbleCoverage*avgCvg, [0.6]</span><br><span class="hljs-string">-N        genomeSize: genome size for statistics, [0]</span><br><span class="hljs-string">-V (optional)  output visualization information of assembly, [NO]</span><br></code></pre></td></tr></table></figure><h3 id="Options-for-sparse-pregraph"><a href="#Options-for-sparse-pregraph" class="headerlink" title="Options for sparse_pregraph"></a>Options for sparse_pregraph</h3><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs sh">Usage: ./SOAPdenovo2 sparse_pregraph -s configFile -K kmer -z genomeSize -o outputGraph [-g maxKmerEdgeLength -d kmerFreqCutoff -e kmerEdgeFreqCutoff -R -r runMode -p n_cpu]<br>  -s      configFile: the config file of solexa reads<br>  -K         kmer(min 13, max 63/127): kmer size, [23]<br>  -g         maxKmerEdgeLength(min 1, max 25): number of skipped intermediate kmers, [15]<br>  <span class="hljs-string">&quot;-z&quot;</span>         genomeSize(mandatory): estimated genome size<br>  <span class="hljs-string">&quot;-d&quot;</span>         kmerFreqCutoff: delete kmers with frequency no larger than,[1]<br>  -e         kmerEdgeFreqCutoff: delete kmers<span class="hljs-string">&#x27; related edge with frequency no larger than [1]</span><br><span class="hljs-string">  -R (optional)   output extra information for resolving repeats in contig step, [NO]</span><br><span class="hljs-string">  -r         runMode: 0 build graph &amp; build edge and preArc, 1 load graph by prefix &amp; build edge and preArc, 2 build graph only, 3 build edges only, 4 build preArcs only [0]</span><br><span class="hljs-string">  &quot;-p&quot;         n_cpu: number of cpu for use,[8]</span><br><span class="hljs-string">  -o         outputGraph: prefix of output graph file name</span><br></code></pre></td></tr></table></figure><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs sh">contigs：<br>      -g  &lt;string&gt;      输入graph file文件名前缀 <br>    -R  (optional)    移除repeats，使用pregraph步骤中产生的结果，如果参数-R在pregraph步骤中被设置的话，默认[NO]<br>    -D  &lt;int&gt;         去除频数不大于该值（edgeCovCutoff）的由k-mer连接的边，默认值[1]，即该边上每个点的频数都小于等于1时才去除。edges with coverage no larger than EdgeCovCutoff will be deleted, [1] <span class="hljs-comment">#最小化错误测序带来的影响</span><br>    -M  &lt;int&gt;         在contiging操作时，合并相似序列的强度，默认值为[1]，最小值0，最大值3。<span class="hljs-comment">#deal with heterozygosis</span><br>    -e  &lt;int&gt;         两边缘之间的弧的权重大于该值（arcWeight），将被线性化，默认值[0]<br>    -m  &lt;int&gt;         最大的kmer size（max 127）用于multi-kmer，默认[NO]<br>    -E  (optional)    在iterate迭代之前，合并clean bubble功能，仅在当使用multi-kmer时且设置-M参数，默认[NO]<br> <br>map：<br>    -g  &lt;string&gt;      输入graph file文件名前缀 <br>    -k  &lt;int&gt;         该值（kmer_R2C）是kmer size用于mapping reads到contigs上时的值，默认值[K]<br>    -f  (optional)    在map那一步中，对于使用SRkgf去填充gap，输出与gap相关的reads,默认[NO]<br> <br>scaffold：<br>      -F  (optional)    利用<span class="hljs-built_in">read</span>对scaffold中的gap进行填补，默认[NO]<br>    -u  (optional)    构建scaffolding前不屏蔽高/低覆盖度的contigs，这里高频率覆盖度指平均contig覆盖深度的2倍。默认[mask]屏蔽<br>    -w  (optional)    在scaffold中，保持contigs弱连接于其他contigs，默认[NO]<br>    -G  &lt;int&gt;         估计gap的大小和实际补gap的大小的差异值，默认值[50]bp。<br>    -L  &lt;int&gt;         用于构建scaffold的contig的最短长度(minContigLen)，默认为：[Kmer参数值+2]<br>    -c  &lt;<span class="hljs-built_in">float</span>&gt;       在scaffolding之前，contigs小于100bp，且覆盖率小于该最小contig覆盖率（c*avgCvg），将被屏蔽，除非参数-u已设定，默认值[0.1]<br>    -C  &lt;<span class="hljs-built_in">float</span>&gt;       在scaffolding之前，contigs覆盖率大于该最大contigs覆盖率（C*avgCvg），或者contigs小于100bp且覆盖率大于0.8*（C*avgCvg），将被屏蔽，除非参数-u已设定，默认值[2]<br>    -b  &lt;<span class="hljs-built_in">float</span>&gt;       当处理contigs间的pair-end连接时，如果参数-b&gt;1，该插入片段的上限值（b*avg_ins）将被用来作为大的插入片段（&gt;1000）的上限，默认值[1.5]<br>    -B  &lt;<span class="hljs-built_in">float</span>&gt;       如果两个contigs的覆盖率都小于bubble覆盖率（bubbleCoverage）乘以contigs平均覆盖率（bubbleCoverage*avgCvg），则去除在bubble结构中的低覆盖率contig，默认值[0.6]<br>    -N  &lt;int&gt;         统计基因组大小，默认值[0]<br>    -V  (optional)    输出相关信息为了可视化组装，默认[NO]<br></code></pre></td></tr></table></figure><h2 id="Output-files"><a href="#Output-files" class="headerlink" title="Output files"></a>Output files</h2><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs sh">a. <span class="hljs-string">&quot;*.contig&quot;</span><br>  contig sequences without using mate pair information.<br>b. <span class="hljs-string">&quot;*.scafSeq&quot;</span><br>  scaffold sequences (final contig sequences can be extracted by breaking down scaffold sequences at gap regions).<br></code></pre></td></tr></table></figure><h2 id="FAQ"><a href="#FAQ" class="headerlink" title="FAQ"></a>FAQ</h2><h3 id="How-to-set-K-mer-size"><a href="#How-to-set-K-mer-size" class="headerlink" title="How to set K-mer size?"></a>How to set K-mer size?</h3><p>The program accepts odd numbers between 13 and 31? <strong>Larger K-mers would have higher rate of uniqueness in the genome and would make the graph simpler, but it requires deep sequencing depth and longer read length to guarantee the overlap at any genomic location.</strong> <font color="red"><strong>Balance?</strong></font></p><p>The <strong>sparse_pregraph</strong> module usually needs <strong>2-10bp smaller kmer</strong> length to achieve the same performance as the original <strong>pregraph</strong> module. <font color="red"><strong>Difference?</strong></font></p><h3 id="How-to-set-genome-size-z-for-sparse-pregraph-module"><a href="#How-to-set-genome-size-z-for-sparse-pregraph-module" class="headerlink" title="How to set genome size(-z) for sparse_pregraph module?"></a>How to set genome size(-z) for sparse_pregraph module?</h3><p>The -z parameter for sparse pregraph should be set <font color="red"><strong>a litter larger than the real genome size</strong></font>, it is used to allocate memory.</p><h3 id="How-to-set-library-rank"><a href="#How-to-set-library-rank" class="headerlink" title="How to set library rank?"></a>How to set library rank?</h3><p>SOAPdenovo will <font color="red">use the <strong>pair-end libraries</strong> with <strong>insert size</strong> from <strong>smaller to larger</strong> to <strong>construct</strong> scaffolds</font>. Libraries with the same rank would be used at the same time. For example, in a dataset of a human genome, we set <strong><font color="red">five ranks</font> for five libraries with insert size 200-bp, 500-bp, 2-Kb, 5-Kb and 10-Kb</strong>, separately. It is desired that the pairs in each rank provide adequate physical coverage of the genome.</p><h2 id="APPENDIX-A-an-example-config"><a href="#APPENDIX-A-an-example-config" class="headerlink" title="APPENDIX A: an example.config"></a>APPENDIX A: an example.config</h2><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-comment">#maximal read length</span><br>max_rd_len=100<br><span class="hljs-string">&quot;[LIB]&quot;</span><br><span class="hljs-comment">#average insert size</span><br>avg_ins=200<br><span class="hljs-comment">#if sequence needs to be reversed</span><br>reverse_seq=0<br><span class="hljs-comment">#in which part(s) the reads are used</span><br>asm_flags=3<br><span class="hljs-comment">#use only first 100 bps of each read</span><br>rd_len_cutoff=100<br><span class="hljs-comment">#in which order the reads are used while scaffolding</span><br>rank=1<br><span class="hljs-comment"># cutoff of pair number for a reliable connection (at least 3 for short insert size)</span><br>pair_num_cutoff=3<br><span class="hljs-comment">#minimum aligned length to contigs for a reliable read location (at least 32 for short insert size)</span><br>map_len=32<br><span class="hljs-comment">#a pair of fastq file, read 1 file should always be followed by read 2 file</span><br>q1=/path/**LIBNAMEA**/fastq1_read_1.fq<br>q2=/path/**LIBNAMEA**/fastq1_read_2.fq<br><span class="hljs-comment">#another pair of fastq file, read 1 file should always be followed by read 2 file</span><br>q1=/path/**LIBNAMEA**/fastq2_read_1.fq<br>q2=/path/**LIBNAMEA**/fastq2_read_2.fq<br><span class="hljs-comment">#a pair of fasta file, read 1 file should always be followed by read 2 file</span><br>f1=/path/**LIBNAMEA**/fasta1_read_1.fa<br>f2=/path/**LIBNAMEA**/fasta1_read_2.fa<br><span class="hljs-comment">#another pair of fasta file, read 1 file should always be followed by read 2 file</span><br>f1=/path/**LIBNAMEA**/fasta2_read_1.fa<br>f2=/path/**LIBNAMEA**/fasta2_read_2.fa<br><span class="hljs-comment">#fastq file for single reads</span><br>q=/path/**LIBNAMEA**/fastq1_read_single.fq<br><span class="hljs-comment">#another fastq file for single reads</span><br>q=/path/**LIBNAMEA**/fastq2_read_single.fq<br><span class="hljs-comment">#fasta file for single reads</span><br>f=/path/**LIBNAMEA**/fasta1_read_single.fa<br><span class="hljs-comment">#another fasta file for single reads</span><br>f=/path/**LIBNAMEA**/fasta2_read_single.fa<br><span class="hljs-comment">#a single fasta file for paired reads</span><br>p=/path/**LIBNAMEA**/pairs1_in_one_file.fa<br><span class="hljs-comment">#another single fasta file for paired reads</span><br>p=/path/**LIBNAMEA**/pairs2_in_one_file.fa<br><span class="hljs-comment">#bam file for single or paired reads, reads 1 in paired reads file should always be followed by reads 2</span><br><span class="hljs-comment">#<span class="hljs-doctag">NOTE:</span> If a read in bam file fails platform/vendor quality checks(the flag field 0x0200 is set), itself and it&#x27;s paired read would be ignored.</span><br>b=/path/**LIBNAMEA**/reads1_in_file.bam<br><span class="hljs-comment">#another bam file for single or paired reads</span><br>b=/path/**LIBNAMEA**/reads2_in_file.bam<br><span class="hljs-string">&quot;[LIB]&quot;</span><br>avg_ins=2000<br>reverse_seq=1<br>asm_flags=2<br>rank=2<br><span class="hljs-comment"># cutoff of pair number for a reliable connection (at least 5 for large insert size)</span><br>pair_num_cutoff=5<br><span class="hljs-comment">#minimum aligned length to contigs for a reliable read location (at least 35 for large insert size)</span><br>map_len=35<br>q1=/path/**LIBNAMEB**/fastq_read_1.fq<br>q2=/path/**LIBNAMEB**/fastq_read_2.fq<br>f1=/path/**LIBNAMEA**/fasta_read_1.fa<br>f2=/path/**LIBNAMEA**/fasta_read_2.fa<br>p=/path/**LIBNAMEA**/pairs_in_one_file.fa<br>b=/path/**LIBNAMEA**/reads_in_file.bam<br></code></pre></td></tr></table></figure><h2 id="Appendix-B-output-files"><a href="#Appendix-B-output-files" class="headerlink" title="Appendix B: output files"></a>Appendix B: output files</h2><h3 id="1-Output-files-from-the-command-“pregraph”"><a href="#1-Output-files-from-the-command-“pregraph”" class="headerlink" title="1. Output files from the command “pregraph”"></a>1. Output files from the command “pregraph”</h3><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs sh">a. *.kmerFreq<br>   Each row shows the number of Kmers with a frequency equals the row number. Note that those peaks of frequencies <span class="hljs-built_in">which</span> are the integral multiple of 63 are due to the data structure.<br>b. *.edge<br>   Each record gives the information of an edge <span class="hljs-keyword">in</span> the pre-graph: length, Kmers on both ends, average kmer coverage, whether it<span class="hljs-string">&#x27;s reverse-complementarily identical and the sequence.</span><br><span class="hljs-string">c. *.markOnEdge &amp; *.path</span><br><span class="hljs-string">   These two files are for using reads to solve small repeats.</span><br><span class="hljs-string">e. *.preArc</span><br><span class="hljs-string">   Connections between edges which are established by the read paths.</span><br><span class="hljs-string">f. *.vertex</span><br><span class="hljs-string">   Kmers at the ends of edges.</span><br><span class="hljs-string">g. *.preGraphBasic</span><br><span class="hljs-string">   Some basic information about the pre-graph: number of vertex, K value, number of edges, maximum read length etc.</span><br></code></pre></td></tr></table></figure><h3 id="2-Output-files-from-the-command-“contig”"><a href="#2-Output-files-from-the-command-“contig”" class="headerlink" title="2. Output files from the command “contig”"></a>2. Output files from the command “contig”</h3><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs sh">a. *.contig<br>      Contig information: corresponding edge index, length, kmer coverage, whether it<span class="hljs-string">&#x27;s tip and the sequence. Either a contig or its reverse complementry counterpart is included. Each reverse complementary contig index is indicated in the *.ContigIndex file.</span><br><span class="hljs-string">   b. *.Arc</span><br><span class="hljs-string">      Arcs coming out of each edge and their corresponding coverage by reads</span><br><span class="hljs-string">   c. *.updated.edge</span><br><span class="hljs-string">      Some information for each edge in graph: length, Kmers at both ends, index difference between the reverse-complementary edge and this one.</span><br><span class="hljs-string">   d. *.ContigIndex</span><br><span class="hljs-string">      Each record gives information about each contig in the *.contig: it&#x27;</span>s edge index, length, the index difference between its reverse-complementary counterpart and itself.<br></code></pre></td></tr></table></figure><h3 id="3-Output-files-from-the-command-“map”"><a href="#3-Output-files-from-the-command-“map”" class="headerlink" title="3. Output files from the command “map”"></a>3. Output files from the command “map”</h3><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs sh">a. *.peGrads<br>      Information <span class="hljs-keyword">for</span> each <span class="hljs-built_in">clone</span> library: insert-size, <span class="hljs-built_in">read</span> index upper bound, rank and pair number cutoff <span class="hljs-keyword">for</span> a reliable <span class="hljs-built_in">link</span>. This file can be revised manually <span class="hljs-keyword">for</span> scaffolding tuning.<br>   b. *.readOnContig<br>      Reads<span class="hljs-string">&#x27; locations on contigs. Here contigs are referred by their edge index. Howerver about half of them are not listed in the *.contig file for their reverse-complementary counterparts are included already.</span><br><span class="hljs-string">   c. *.readInGap</span><br><span class="hljs-string">      This file includes reads that could be located in gaps between contigs. This information will be used to close gaps in scaffolds if &quot;-F&quot; is set.</span><br></code></pre></td></tr></table></figure><h3 id="4-Output-files-from-the-command-“scaff”"><a href="#4-Output-files-from-the-command-“scaff”" class="headerlink" title="4. Output files from the command “scaff”"></a>4. Output files from the command “scaff”</h3><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs sh">a. *.newContigIndex<br>      Contigs are sorted according their length before scaffolding. Their new index are listed <span class="hljs-keyword">in</span> this file.  This is useful <span class="hljs-keyword">if</span> one wants to corresponds contigs <span class="hljs-keyword">in</span> *.contig with those <span class="hljs-keyword">in</span> *.links.<br>   b. *.links<br>      Links between contigs <span class="hljs-built_in">which</span> are established by <span class="hljs-built_in">read</span> pairs. New index are used.<br>   c. *.scaf_gap<br>      Contigs <span class="hljs-keyword">in</span> gaps found by contig graph outputted by the contiging procedure. Here new index are used.<br>   d. *.scaf<br>      Contigs <span class="hljs-keyword">for</span> each scaffold: contig index (concordant to index <span class="hljs-keyword">in</span> *.contig),  approximate start position on scaffold, orientation, contig length, and its links to others contigs.<br>   e. *.gapSeq<br>      Gap sequences between contigs.<br>   f. *.scafSeq<br>      Sequences of each scaffolds.<br>   g. *.contigPosInscaff<br>      Contigs<span class="hljs-string">&#x27; positions in each scaffold.</span><br><span class="hljs-string">   h. *.bubbleInScaff</span><br><span class="hljs-string">      Contigs that form bubble structures in scaffolds. Every two contigs form a bubble and the contig with higher coverage will be kept in scaffold.</span><br><span class="hljs-string">   i. *.scafStatistics</span><br><span class="hljs-string">      Statistic information of final scaffold and contig.</span><br></code></pre></td></tr></table></figure><hr><h1 id="小记1"><a href="#小记1" class="headerlink" title="小记1"></a>小记1</h1><p> ref：<a href="https://www.cnblogs.com/Formulate0303/p/6879841.html">https://www.cnblogs.com/Formulate0303/p/6879841.html</a></p><h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>确定基因组缺失什么；确定难以生化研究的基因和pathways；研究感兴趣pathway通路中每一个基因；研究基因组非编码区（introns、promoters、telomeres端粒等）的调控机理和结构特征；基因组提供可进行各种统计的大型数据库（provide large databases that are amenable to statistical methods）;识别不同可能有细微表型的序列；研究物种和基因组的进化过程。一般都是用不同梯度的插入片段来测序，小片段（200,500,800）和大片段（1k, 2kb 5kb 10kb 20kb 40kb）。</p><h2 id="测序前准备"><a href="#测序前准备" class="headerlink" title="测序前准备"></a>测序前准备</h2><p>搜集物种相关信息（染色体的倍型、基因组大小、杂合度、重复序列比例、是否有可用的遗传图谱、GC含量 和 GC分布）。提供已经发表的近源物种。根据近源物种分析以上信息，尤其是GC含量以及对应的GC分布，重复程度。</p><h3 id="1-获取基因组大小"><a href="#1-获取基因组大小" class="headerlink" title="1 获取基因组大小"></a>1 获取基因组大小</h3><ul><li><p>基因组太大（&gt;10Gb）超出了目前denovo组装基因组软件对机器内存的要求，则无法实现组装；对组装结果的大小的进行正确性与否判断。</p></li><li><p>动物基因组大小数据库（ANIMAL GENOME SIZE DATABASE）: <a href="http://www.genomesize.com/%EF%BC%9B%E5%AF%B9%E4%BA%8E%E6%9F%A5%E4%B8%8D%E5%88%B0%E7%9A%84%E7%89%A9%E7%A7%8D%E5%9F%BA%E5%9B%A0%E7%BB%84%E5%A4%A7%E5%B0%8F%E7%9A%84%EF%BC%8C%E5%8F%AF%E4%BB%A5%E9%80%9A%E8%BF%87%E4%B8%80%E4%BA%9B%E6%96%B9%E6%B3%95%E5%8E%BB%E4%BC%B0%E8%AE%A1%E3%80%82">http://www.genomesize.com/；对于查不到的物种基因组大小的，可以通过一些方法去估计。</a></p></li><li><p>实验（流式细胞仪）估计基因组大小的例子： “A full-length enriched cDNA library and expressed sequence tag analysis of the parasitic weed, Striga hermonthica.” BMC Plant Biol (2010)</p></li><li><p>基于福尔摩根染色估计基因组大小：书The evolution of the genome《基因组进化》, Gregory, T. (2005).</p></li><li><p>定量PCR估计基因组大小: “Real-time PCR-based method for the estimation of genome sizes.” Nucleic Acids Res (2003); “The nuclear genome of the phytoseiid Metaseiulus occidentalis (Acari: Phytoseiidae) is among the smallest known in arthropods.” Exp Appl Acarol (2009)</p></li><li><p>通过Kmer估计基因组大小：Kim, E. B., X. Fang, et al. (2011). “<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3319411/"><strong>Genome sequencing reveals insights into physiology and longevity of the naked mole rat</strong></a>.” Nature 479(7372): 223-227. [Obtained 2.5 G contig sequences with N50 19.3 kbp and N90 4.7 kbp, and 2.7 G scaffold sequences with N50 1.6 Mbp and N90 0.3 Mbp.]</p></li></ul><h3 id="2-杂合度评估"><a href="#2-杂合度评估" class="headerlink" title="2 杂合度评估"></a>2 杂合度评估</h3><ul><li><p>主要体现在<font color="green">不能合并姊妹染色体</font>，杂合度高的区域，会把两条姊妹染色单体都组装出来，造成组装的基因组<font color="green">偏大</font>。</p></li><li><p><font color="red"><strong>杂合度&gt;0.5%则组装有一定难度</strong></font>。杂合度&gt;1%则很难组装出来。</p></li><li><p>杂合度高则组装的序列不适合用于后续生物学分析（eg:拷贝数、基因完整结构等）。</p></li></ul><h3 id="3-是否有遗传图谱可用"><a href="#3-是否有遗传图谱可用" class="headerlink" title="3 是否有遗传图谱可用"></a>3 是否有遗传图谱可用</h3><p>随着测序对质量提高和相关技术成熟，<font color="red"><strong>遗传图谱？</strong></font>也快成了denovo基因组的必须组成。</p><p><a href="https://cdmd.cnki.com.cn/Article/CDMD-10504-1019065822.htm">矮牵牛遗传图谱构建及重瓣分子标记筛选</a></p><p>遗传图谱是某一物种的染色体图，显示所知的基因和&#x2F;或遗传标记的相对位置，而不是在每条染色体上特殊的物理位置。由<a href="https://baike.baidu.com/item/%E9%81%97%E4%BC%A0%E9%87%8D%E7%BB%84/6391485">遗传重组</a>测验结果推算出来的、在一条染色体上可以发生的突变座位的直线排列（<a href="https://baike.baidu.com/item/%E5%9F%BA%E5%9B%A0%E4%BD%8D%E7%82%B9/3613206">基因位点</a>的排列）图。</p><p>Genetic map，<a href="https://baike.baidu.com/item/%E9%81%97%E4%BC%A0%E5%9B%BE/2951032">遗传图</a>或遗传<a href="https://baike.baidu.com/item/%E8%BF%9E%E9%94%81%E5%9B%BE/1586423">连锁图</a>是以<a href="https://baike.baidu.com/item/%E5%9F%BA%E5%9B%A0%E8%BF%9E%E9%94%81/7740242">基因连锁</a>、重组<a href="https://baike.baidu.com/item/%E4%BA%A4%E6%8D%A2%E5%80%BC/5106108">交换值</a>构建的图谱，图距为cM（<a href="https://baike.baidu.com/item/%E5%8E%98%E6%91%A9/1586351">厘摩</a>），1%交换值为1cM，约相当于1000kb。人基因组全长约3300cM，如两个标记之间相距1cM，则需3300个标记，如相距2～5cM，则需660～l650个标记。标记可以是体质性状，也可以是可检出的DNA序列，例如基因、<a href="https://baike.baidu.com/item/%E9%99%90%E5%88%B6%E7%89%87%E6%AE%B5%E9%95%BF%E5%BA%A6%E5%A4%9A%E6%80%81%E6%80%A7/3841692">限制片段长度多态性</a>（<a href="https://baike.baidu.com/item/RFLP/5060944">RFLP</a>）和特定的<a href="https://baike.baidu.com/item/%E5%8D%95%E4%B8%80%E5%BA%8F%E5%88%97/1851974">单一序列</a>等。每一个标记都要用专一序列位点（STS）作鉴定。STS是指其位置及核苷酸序列均已知的、人基因组中只有一份拷贝的DNA短片段（一般长200～500碱基对），它很容易用多聚酶链反应（PCR）加以验证。当各个实验室报道定位和测序的数据时，可用STS来确定这些DNA片段的定位与取向。人类基因组计划的研究目标是，完成一个完全连接的人类遗传图，标记之间平均相距2～5cM。</p><p>遗传图谱构建相关概念推荐参考书：<strong>The handbook of plant genome mapping: genetic and physical mapping</strong> </p><h3 id="4-生物学问题的调研"><a href="#4-生物学问题的调研" class="headerlink" title="4 生物学问题的调研"></a>4 生物学问题的调研</h3><h2 id="组装"><a href="#组装" class="headerlink" title="组装"></a>组装</h2><ul><li><p>BAC-by-BAC:测序和组装每一个BAC, 合并BAC和移除BAC冗余部分，获得参考基因组序列。</p></li><li><p>whole genome shotgun：全基因组鸟枪法，染色体DNA被随机打断成片段，依次测序和组装。</p></li></ul><h3 id="算法"><a href="#算法" class="headerlink" title="算法"></a>算法</h3><p>二代测序数据从头组装的解决overlap的三种算法</p><ul><li><p>overlap-layout-consensus：重叠布局一致OLC法，【软件：PHRAP.NEWBLER.CABOG.CELERA.SHORTY.EDENA,popular for long reads】，1. Overlap discovery involves all-against-all, pair-wise read comparison. 2. Construction an approximate read layout according to the pair-wise alignment 3. Multiple sequence alignment determines the precise layout and the consensus.</p></li><li><p>De bruijn graph:DBG法，【软件：SOAPdenovo2.Velvet.EULER,popular for illumina ，for short reads】,1.所有的测序reads都被切割成某一固定Kmer长度的序列（21bp&#x3D;&lt;kmer&lt;&#x3D;127bp）.2.相邻kmers链接是来自read序列，所以它不需要成对序列比对(The links between neighboring Kmers are derived from read sequences,so it doesn’t need pair-wise reads alignment.）3.冗余的数据自动被压缩。</p></li><li><p>greedy method：贪婪法(use OLC or DBG)，【软件：SSAKE.SHARCGS.VCAKE】，从给定的reads和contigs开始，使用下一个得分最高的overlap去做下一个连接，这样一直做下去，直到不能进行下去为止。</p></li></ul><h3 id="评估"><a href="#评估" class="headerlink" title="评估"></a>评估</h3><p>组装short reads的挑战</p><p>1.基因组的复杂性，<strong>重复序列</strong>、<strong>杂合</strong>的<strong>二倍体</strong>基因组heterozygous diploid genome、<strong>多倍性</strong>polyploidy.</p><p>2.illumina reads 的数据特征，<strong>测序错误</strong>率<del>1%、short read 长度</del>100bp、<del>100X的高测序深度、不同级别的文库插入片段（200bp</del>40Kbp）。</p><p>3.Complexity of computation</p><h2 id=""><a href="#" class="headerlink" title=""></a></h2><hr><h1 id="小记2"><a href="#小记2" class="headerlink" title="小记2"></a>小记2</h1><p>ref <a href="https://www.jianshu.com/p/e02ecd537c83">https://www.jianshu.com/p/e02ecd537c83</a></p><h2 id="reads质量控制"><a href="#reads质量控制" class="headerlink" title="reads质量控制"></a>reads质量控制</h2><ul><li>认识数据。(read类型，read数量，其GC含量，可能的污染和其他问题)</li><li>数据清理。(组装前清理原始数据可以使组装结果更好,因为移除了低质量和污染的reads)</li><li>为组装软件提供一些组装的参数</li></ul><h2 id="检查原始read数据的质量"><a href="#检查原始read数据的质量" class="headerlink" title="检查原始read数据的质量"></a>检查原始read数据的质量</h2><p>(1)read长度:在设置组装的最大k-mer值时将很重要。</p><p>(2)质量编码类型:对于quality trimming软件很重要。(Phred33、64)</p><p>(3)GC含量:<strong>高GC的生物体往往组装得不好，并且read覆盖率分布可能不均匀</strong></p><p>(4)总的reads数:<strong>了解coverage范围</strong></p><p>(4)在read的开始、中间或结尾附近质量下降:确定可能的修整&#x2F;清除方法和参数。</p><p>(5)出现<strong>高度重复的k-mers</strong>:说明序列可能存在污染。</p><p>(6)reads中存在<strong>大量N</strong>:可能表明测序质量较差。你需要修剪这些read，以删除N.</p><h2 id="genome-survey"><a href="#genome-survey" class="headerlink" title="genome survey"></a>genome survey</h2><p>正式组装前进行kmer分析，以了解以下信息。</p><p>(1)基因组杂合度。</p><p>(2)重复序列比例。</p><p>(3)预估基因组大小。</p><p>(4)测序深度。</p><p>所用软件为kmergenie，<a href="https://links.jianshu.com/go?to=http://kmergenie.bx.psu.edu/">http://kmergenie.bx.psu.edu/</a> </p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-comment">#安装(使用时，确保服务器装有Pthon与R)</span><br>tar -xzvf kmergenie-1.7051.tar.gz &amp;&amp; <span class="hljs-built_in">cd</span> kmergenie-1.7051<br>python setup.py install<br> <br><span class="hljs-comment">#添加可执行权限</span><br><span class="hljs-built_in">chmod</span> -R 755 *<br></code></pre></td></tr></table></figure><p>接下来介绍怎么用，参考：<a href="https://links.jianshu.com/go?to=http://wap.sciencenet.cn/blog-3406804-1159967.html">http://wap.sciencenet.cn/blog-3406804-1159967.html</a></p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-built_in">touch</span> fq_501.txt                                 <span class="hljs-comment">#存储fastq文件的路径。</span><br>vim fq_501.txt                                   <span class="hljs-comment">#编辑fq.txt，输入fastq文件路径。</span><br><span class="hljs-built_in">mkdir</span> kmergenie_result     <br>./tools/kmergenie-1.7051/kmergenie fq_501.list -o ./kmergenie_result/PB_501 -k 105 -<br>l 15 -s 10 -t 12                               <br><span class="hljs-comment">#-o:输出文件存放的地址。</span><br><span class="hljs-comment">#-k:最大的k值</span><br><span class="hljs-comment">#-l:最小的k值</span><br><span class="hljs-comment">#-s:从最小的k----最大的k，每次增加的k。</span><br><span class="hljs-comment">#-t:线程数。</span><br><span class="hljs-comment">#注:刚开始s可以设大点，可以根据判断出的最佳k值，缩小s再进行判断((第一次:I:15,k:105,s:10 第二次I:85,k:140,s:6)。</span><br></code></pre></td></tr></table></figure><figure class="highlight livecodeserver"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><code class="hljs livecodeserver">usage:<br><br>    ./kmergenie reads_file<br><br>reads_file is either <span class="hljs-keyword">a</span> single FASTA, FASTQ, FASTA.gz, FASTQ.gz <span class="hljs-built_in">file</span> <span class="hljs-keyword">or</span> <span class="hljs-keyword">a</span> list <span class="hljs-keyword">of</span> <span class="hljs-built_in">file</span> names, <span class="hljs-literal">one</span> per <span class="hljs-built_in">line</span>. For example:<br>    <br>    ls <span class="hljs-number">-1</span> *.fastq.gz &gt; list_files<br>    ./kmergenie list_files<br><br>    type ./kmergenie <span class="hljs-built_in">to</span> see extra options<br><br>input:<br><br>    Input reads should be exactly those <span class="hljs-keyword">the</span> de novo assembler will use <span class="hljs-built_in">to</span> <span class="hljs-built_in">create</span> contigs, i.e. <span class="hljs-keyword">the</span> list <span class="hljs-keyword">of</span> all single <span class="hljs-keyword">and</span> paired-<span class="hljs-function"><span class="hljs-keyword">end</span> <span class="hljs-title">reads</span>.</span><br><br>    The order does <span class="hljs-keyword">not</span> matter, KmerGenie treats <span class="hljs-keyword">the</span> reads <span class="hljs-keyword">as</span> <span class="hljs-keyword">an</span> unordered <span class="hljs-built_in">set</span> <span class="hljs-keyword">of</span> k-mers. Orientation <span class="hljs-keyword">of</span> <span class="hljs-keyword">the</span> reads also does <span class="hljs-keyword">not</span> matter.<br>    With Velvet, <span class="hljs-keyword">if</span> you have mate-pairs, Velvet uses them <span class="hljs-built_in">to</span> <span class="hljs-built_in">create</span> contigs, so <span class="hljs-built_in">do</span> <span class="hljs-built_in">include</span> them <span class="hljs-keyword">in</span> KmerGenie.<br>    Otherwise, <span class="hljs-keyword">if</span> <span class="hljs-keyword">the</span> mate-pairs are used only <span class="hljs-keyword">for</span> scaffolding (i.e. asm_flag=<span class="hljs-number">2</span> <span class="hljs-keyword">in</span> SOAPdenovo), <span class="hljs-built_in">do</span> <span class="hljs-keyword">not</span> <span class="hljs-built_in">include</span> them.<br><br>tips:<br><br>    * Take <span class="hljs-keyword">a</span> look <span class="hljs-keyword">at</span> <span class="hljs-keyword">the</span> generated HTML report. It provides <span class="hljs-keyword">a</span> summary <span class="hljs-keyword">of</span> <span class="hljs-keyword">the</span> results, <span class="hljs-keyword">and</span> <span class="hljs-keyword">contains</span> <span class="hljs-keyword">an</span> Advanced Help section <span class="hljs-built_in">to</span> help analysis.<br><br>    * There is no need <span class="hljs-built_in">to</span> use Kmergenie <span class="hljs-keyword">for</span> <span class="hljs-keyword">a</span> multi-k assembler, like SPAdes. Default parameters <span class="hljs-keyword">of</span> multi-k assemblers are generally better than <span class="hljs-keyword">a</span> single best k.<br><br>    * By default, KmerGenie will perform another pass <span class="hljs-built_in">to</span> estimate k more precisely. You may skip <span class="hljs-keyword">it</span> <span class="hljs-keyword">by</span> <span class="hljs-keyword">using</span> <span class="hljs-keyword">the</span> <span class="hljs-string">&quot;--one-pass&quot;</span> option (roughly <span class="hljs-number">2</span>x faster).<br><br>    * To run multiple instances <span class="hljs-keyword">of</span> KmerGenie <span class="hljs-keyword">on</span> <span class="hljs-title">the</span> <span class="hljs-title">same</span> <span class="hljs-title">folder</span>, <span class="hljs-title">specify</span> <span class="hljs-title">the</span> <span class="hljs-string">&quot;-o&quot;</span> <span class="hljs-title">and</span> <span class="hljs-string">&quot;-t&quot;</span> <span class="hljs-title">parameters</span> (<span class="hljs-title">output</span> <span class="hljs-title">prefix</span>, <span class="hljs-title">number</span> <span class="hljs-title">of</span> <span class="hljs-title">threads</span> <span class="hljs-title">per</span> <span class="hljs-title">instance</span>).<br><br>    * The sampling <span class="hljs-built_in">value</span> e (<span class="hljs-string">&quot;-e&quot;</span> parameter) makes sure that roughly n/e k-mers are sampled out <span class="hljs-keyword">of</span> <span class="hljs-keyword">the</span> n distinct kmers <span class="hljs-keyword">in</span> <span class="hljs-keyword">the</span> dataset. The datasets are fully analyzed, though. Kmergenie samples <span class="hljs-built_in">from</span> <span class="hljs-keyword">the</span> <span class="hljs-built_in">set</span> <span class="hljs-keyword">of</span> distinct kmers, <span class="hljs-keyword">not</span> <span class="hljs-built_in">from</span> <span class="hljs-keyword">the</span> <span class="hljs-built_in">set</span> <span class="hljs-keyword">of</span> reads.<br><br>    * The diploid model should only be used <span class="hljs-keyword">for</span> moderate-high heterozygosity rates. The haploid model works better when only <span class="hljs-literal">one</span> peak is visible <span class="hljs-keyword">in</span> <span class="hljs-keyword">the</span> histograms (indicating low heterozygosity).<br><br>outputs:<br><br>    histograms_report.html<br>        html report <span class="hljs-keyword">of</span> all <span class="hljs-keyword">the</span> results<br>    histograms.dat<br>        <span class="hljs-built_in">file</span> containing <span class="hljs-keyword">the</span> raw data <span class="hljs-keyword">for</span> <span class="hljs-keyword">the</span> <span class="hljs-built_in">number</span> <span class="hljs-keyword">of</span> genomic kmers <span class="hljs-keyword">for</span> <span class="hljs-keyword">each</span> k <span class="hljs-built_in">value</span><br>    histograms-k*.histo<br>        <span class="hljs-built_in">files</span> containing raw sampled histograms <span class="hljs-keyword">for</span> <span class="hljs-keyword">each</span> k <span class="hljs-built_in">value</span><br>    histograms-k*.histo.pdf<br>        plots <span class="hljs-keyword">of</span> <span class="hljs-keyword">the</span> histograms <span class="hljs-keyword">and</span> <span class="hljs-keyword">the</span> fits. Colors: red is <span class="hljs-keyword">the</span> fit <span class="hljs-keyword">of</span> <span class="hljs-keyword">the</span> complete statistical model <span class="hljs-keyword">of</span> <span class="hljs-keyword">the</span> histogram (erroneous k-mers + genomic k-mers). With <span class="hljs-keyword">the</span> diploid model, green are only <span class="hljs-keyword">the</span> heterozygous k-mers, blue are only <span class="hljs-keyword">the</span> homozygous k-mers.<br>    &lt;<span class="hljs-keyword">stdout</span>&gt;<br>        <span class="hljs-keyword">last</span> <span class="hljs-built_in">line</span> is <span class="hljs-keyword">the</span> best k <span class="hljs-built_in">value</span><br>    &lt;<span class="hljs-literal">return</span> code / error code&gt;<br>        <span class="hljs-number">0</span> <span class="hljs-keyword">if</span> <span class="hljs-keyword">and</span> only <span class="hljs-keyword">if</span> <span class="hljs-keyword">a</span> best k was found (note: no longer returns <span class="hljs-keyword">the</span> best k <span class="hljs-keyword">as</span> error code)<br></code></pre></td></tr></table></figure><p>结果文件生成report。报告以折线图形式给出每种长度的kmer下，估计的基因组大小，同时给出了最佳的kmer(评估基因组总大小最高)</p><p><img src="/GeekFocus/./14.png" alt="img"></p><p>理想条件该图应该为一条平滑的曲线，有明确最大值。然而在一些情况下有多个局部最大值。</p><p>这些情况表明，对于某些k值，Kmergenie中的统计模型并不总是正确地拟合输入数据。因此由Kmergenie预测的最佳k值可能不是最佳的。在随后的分析中，还尝试使用比Kmergenie预测的k大的k(其他峰值)</p><p>若基因组k-mers的数量不会随着k值的升高而下降，则是一个高覆盖率(high coverage)数据集的迹象？<br>什么是覆盖率呢？<br>覆盖率(coverage)：指的是测序过程中读取单个碱基的平均次数。如果覆盖度为100×，说明平均每个碱基测序了100次。对碱基测序的频率越高，数据的质量越高。</p><p><img src="/GeekFocus/./15.png" alt="img"></p><h2 id="soapdevovo2"><a href="#soapdevovo2" class="headerlink" title="soapdevovo2"></a>soapdevovo2</h2><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-comment">#正式组装(kmer选103,113,123,127分别跑)</span><br><span class="hljs-comment">#SOAPdenovo2既可以一步组装也可以分四步，如果基因组大且复杂建议分四步。</span><br> <span class="hljs-built_in">nohup</span> ./tools/SOAPdenovo2-master/SOAPdenovo-127mer all -s config_file -d 1 -R -F -K 113 -p 60 -o PB_501_113 &gt; PB_501_113.<span class="hljs-built_in">log</span> &amp;  <span class="hljs-comment">#注:加nohup和&amp;是为了让它在后台运行(防止远程连接断开程序停止)</span><br></code></pre></td></tr></table></figure><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-comment">#分四步(在k=103、113、123、及127(支持的最大kmer)跑了后发现127在同样参数下contig N50最大)，下面是为了优化结果跑的。</span><br><span class="hljs-comment">#pregraph(d=1,2,3,4)</span><br><span class="hljs-built_in">nohup</span> ./tools/SOAPdenovo2-master/SOAPdenovo-127mer pregraph -s config_file -o PB_501_127_d_3 -R -K 127 -p 60 -d 2 &gt;PB_501_127_d_3_pre.<span class="hljs-built_in">log</span> &amp;<br><span class="hljs-built_in">nohup</span> ./tools/SOAPdenovo2-master/SOAPdenovo-127mer contig -g PB_501_127_d_3 -R -p 60 &gt;PB_501_127_d_3_con.<span class="hljs-built_in">log</span> &amp;<br><span class="hljs-built_in">nohup</span> ./tools/SOAPdenovo2-master/SOAPdenovo-127mer map -s config_file -g PB_501_127_d_3 -p 60 -k 127 &gt;PB_501_127_d_3_map.<span class="hljs-built_in">log</span> &amp;  <br><span class="hljs-built_in">nohup</span> ./tools/SOAPdenovo2-master/SOAPdenovo-127mer scaff -g PB_501_127_d_3 -F -p 60 &gt;PB_501_127_d_3_scaf.<span class="hljs-built_in">log</span> &amp;<br></code></pre></td></tr></table></figure><h2 id="统计"><a href="#统计" class="headerlink" title="统计"></a>统计</h2><p><img src="/GeekFocus/./16.png" alt="img"></p><h2 id="组装评估"><a href="#组装评估" class="headerlink" title="组装评估"></a>组装评估</h2><p>QUAST软件下载:<a href="https://links.jianshu.com/go?to=https://sourceforge.net/projects/quast/files/quast-5.0.2.tar.gz/download">https://sourceforge.net/projects/quast/files/quast-5.0.2.tar.gz/download</a></p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-comment">#解压安装</span><br>tar -zxvf quast-5.0.2.tar.gz &amp;&amp; <span class="hljs-built_in">cd</span> quast-5.0.2<br>python  setup.py install_full<br></code></pre></td></tr></table></figure><h3 id="参考基因组下载"><a href="#参考基因组下载" class="headerlink" title="参考基因组下载"></a>参考基因组下载</h3><h3 id="QUAST使用"><a href="#QUAST使用" class="headerlink" title="QUAST使用"></a>QUAST使用</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs bash">./tools/quast-5.0.2/quast.py -o ./quast_results -R ./reference/IRGSP-1.0_genome.fasta.gz -t 70 ./PB_501_results/PB_501_127_d_1/PB_501_127_d_1.scafSeq ./PB_501_results/PB_501_127_d_2/PB_501_127_d_2.scafSeq ./PB_501_results/PB_501_127_d_3/PB_501_127_d_3.scafSeq ./PB_501_results/PB_501_127_d_6/PB_501_127_d_6.scafSeq<br><span class="hljs-comment">#-o输出目录</span><br><span class="hljs-comment">#-R参考基因组序列</span><br><span class="hljs-comment">#-t线程数</span><br><span class="hljs-comment">#后面为要比较的contig/scaffold所在目录。</span><br></code></pre></td></tr></table></figure><h2 id="结果"><a href="#结果" class="headerlink" title="结果"></a>结果</h2><h3 id="统计结果"><a href="#统计结果" class="headerlink" title="统计结果"></a>统计结果</h3><p>将contig&#x2F;scaffold比对到参考基因组上，下面是比对得到的结果。</p><p><img src="/GeekFocus/./17.png" alt="img"></p><p><img src="/GeekFocus/./18.png" alt="img"></p><p>累计长度:若与灰色线重合越好，组装结果越好。</p><p><img src="/GeekFocus/./19.png" alt="img"></p><p>错误组装情况：</p><p><img src="/GeekFocus/./20.png" alt="img"></p><p>GC含量:</p><p><img src="/GeekFocus/./21.png" alt="img"></p><h3 id="contig-x2F-scaffold大小可视化"><a href="#contig-x2F-scaffold大小可视化" class="headerlink" title="contig&#x2F;scaffold大小可视化"></a>contig&#x2F;scaffold大小可视化</h3><p><img src="/GeekFocus/./22.png" alt="img"></p><h3 id="比对到每条染色体情况"><a href="#比对到每条染色体情况" class="headerlink" title="比对到每条染色体情况"></a>比对到每条染色体情况</h3><p><img src="/GeekFocus/./23.png" alt="img"></p><p>比对到每条染色体可视化情况:</p><p><img src="/GeekFocus/./24.png" alt="img"></p>]]></content>
    
    
    <categories>
      
      <category>Software</category>
      
    </categories>
    
    
    <tags>
      
      <tag>assembly</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>seqkit</title>
    <link href="/GeekFocus/2022/02/24/2022-02-24-Seqkit/"/>
    <url>/GeekFocus/2022/02/24/2022-02-24-Seqkit/</url>
    
    <content type="html"><![CDATA[<h1 id="SeqKit-a-cross-platform-and-ultrafast-toolkit-for-FASTA-x2F-Q-file-manipulation"><a href="#SeqKit-a-cross-platform-and-ultrafast-toolkit-for-FASTA-x2F-Q-file-manipulation" class="headerlink" title="SeqKit - a cross-platform and ultrafast toolkit for FASTA&#x2F;Q file manipulation"></a>SeqKit - a cross-platform and ultrafast toolkit for FASTA&#x2F;Q file manipulation</h1><span id="more"></span><p><a href="https://bioinf.shenwei.me/seqkit/usage/#fx2tab-tab2fx">Official doc</a></p><h1 id="Quick-Guide"><a href="#Quick-Guide" class="headerlink" title="Quick Guide"></a>Quick Guide</h1><ul><li>Basic: <a href="https://bioinf.shenwei.me/seqkit/usage/#seq">seq</a>, <a href="https://bioinf.shenwei.me/seqkit/usage/#stats">stats</a>, <a href="https://bioinf.shenwei.me/seqkit/usage/#subseq">subseq</a>, <a href="https://bioinf.shenwei.me/seqkit/usage/#sliding">sliding</a>, <a href="https://bioinf.shenwei.me/seqkit/usage/#faidx">faidx</a>, <a href="https://bioinf.shenwei.me/seqkit/usage/#watch">watch</a>, <a href="https://bioinf.shenwei.me/seqkit/usage/#sana">sana</a>, <a href="https://bioinf.shenwei.me/seqkit/usage/#scat">scat</a></li><li>Format conversion: <a href="https://bioinf.shenwei.me/seqkit/usage/#fq2fa">fq2fa</a>, <a href="https://bioinf.shenwei.me/seqkit/usage/#fx2tab-tab2fx">fx2tab</a>, <a href="https://bioinf.shenwei.me/seqkit/usage/#fx2tab-tab2fx">tab2fx</a>, <a href="https://bioinf.shenwei.me/seqkit/usage/#convert">convert</a>, <a href="https://bioinf.shenwei.me/seqkit/usage/#translate">translate</a></li><li>Searching: <a href="https://bioinf.shenwei.me/seqkit/usage/#grep">grep</a>, <a href="https://bioinf.shenwei.me/seqkit/usage/#locate">locate</a>, <a href="https://bioinf.shenwei.me/seqkit/usage/#amplicon">amplicon</a>, <a href="https://bioinf.shenwei.me/seqkit/usage/#fish">fish</a></li><li>Set operation: <a href="https://bioinf.shenwei.me/seqkit/usage/#sample">sample</a>, <a href="https://bioinf.shenwei.me/seqkit/usage/#rmdup">rmdup</a>, <a href="https://bioinf.shenwei.me/seqkit/usage/#common">common</a>, <a href="https://bioinf.shenwei.me/seqkit/usage/#duplicate">duplicate</a>, <a href="https://bioinf.shenwei.me/seqkit/usage/#split">split</a>, <a href="https://bioinf.shenwei.me/seqkit/usage/#split2">split2</a>, <a href="https://bioinf.shenwei.me/seqkit/usage/#head">head</a>, <a href="https://bioinf.shenwei.me/seqkit/usage/#head-genome">head-genome</a>, <a href="https://bioinf.shenwei.me/seqkit/usage/#range">range</a>, <a href="https://bioinf.shenwei.me/seqkit/usage/#pair">pair</a></li><li>Edit: <a href="https://bioinf.shenwei.me/seqkit/usage/#concat">concat</a>, <a href="https://bioinf.shenwei.me/seqkit/usage/#replace">replace</a>, <a href="https://bioinf.shenwei.me/seqkit/usage/#restart">restart</a>, <a href="https://bioinf.shenwei.me/seqkit/usage/#mutate">mutate</a>, <a href="https://bioinf.shenwei.me/seqkit/usage/#rename">rename</a></li><li>Ordering: <a href="https://bioinf.shenwei.me/seqkit/usage/#sort">sort</a>, <a href="https://bioinf.shenwei.me/seqkit/usage/#shuffle">shuffle</a></li><li>BAM processing: <a href="https://bioinf.shenwei.me/seqkit/usage/#bam">bam</a></li></ul><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sh">conda install -c bioconda seqkit<br></code></pre></td></tr></table></figure><h1 id="command"><a href="#command" class="headerlink" title="command"></a>command</h1><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><code class="hljs sh">amplicon        通过引物检索扩增子(或其周围的特定区域)<br>bam             检查和在线绘制BAM记录文件的直方图<br>common          通过<span class="hljs-built_in">id</span>/名称/序列查找多个文件的公共序列<br>concat          连接多个文件中具有相同ID的序列<br>convert         转换FASTQ质量编码格式：支持格式包括：桑格，Solexa和Illumina<br>duplicate       重复序列N次<br>faidx           创建FASTA索引文件并提取子序列<br>fish            使用局部比对在较大的序列中寻找短序列<br>fq2fa           转换FASTQ到FASTA<br>fx2tab          将FASTA/Q转换为表格格式(包含长度/GC含量/GC偏好)<br>genautocomplete 生成shell自动完成脚本<br>grep            通过ID/name/sequence/sequence motif搜索序列，允许错配<br><span class="hljs-built_in">head</span>            打印第一条序列<br><span class="hljs-built_in">help</span>            打印帮助信息<br>locate          定位序列，或者motifs，允许错配<br>mutate          编辑序列(点突变、插入、删除)<br>pair            匹配双端序列文件<br>range           打印一个范围内的序列<br>rename          重命名重复序列ID<br>replace         使用正则表达式修改名称或者序列<br>restart         重置环状基因组的起始位置<br>rmdup           通过<span class="hljs-built_in">id</span>/名称/序列删除重复的序列<br>sample          按数量或比例对序列进行抽样<br>sana            清理损坏的单行fastq文件<br>scat            real time recursive concatenation and streaming of fastx files<br><span class="hljs-built_in">seq</span>             转换序列(反向，补充，提取ID…)<br>shuffle         随机序列<br>sliding         序列滑窗提取，支持环形基因组<br><span class="hljs-built_in">sort</span>            按<span class="hljs-built_in">id</span>/名称/序列/长度排序序列<br><span class="hljs-built_in">split</span>           按<span class="hljs-built_in">id</span>/seq区域/大小/部件将序列拆分为文件(主要用于FASTA)<br>split2          按序列数量/文件数将序列拆分为多个文件(FASTA, PE/SE FASTQ)<br>stats           FASTA/Q文件的简单统计<br>subseq          通过region/gtf/bed得到子序列，包括侧翼序列<br>tab2fx          转换表格格式为FASTA/Q格式<br>translate       翻译DNA/RNA到蛋白质序列(支持歧义碱基)<br>version         打印版本信息并检查是否更新<br>watch           序列特征的监测和在线直方图<br><br><br></code></pre></td></tr></table></figure><h1 id="Parameter"><a href="#Parameter" class="headerlink" title="Parameter:"></a>Parameter:</h1><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs sh">Flags:<br>      --alphabet-guess-seq-length int   seqkit根据第一个FASTA记录猜测序列类型的序列前缀的长度(0表示整个序列)(默认10000)<br>  -h, --<span class="hljs-built_in">help</span>                            显示帮助<br>      --id-ncbi                         FASTA头是ncbi风格的，例如&gt;gi|110645304|ref|NC_002516.2 <br>      --id-regexp string                用于解析ID的正则表达式(default <span class="hljs-string">&quot;^(\\S+)\\s?&quot;</span>)，匹配空格前的部分为序列名<br>      --infile-list string              输入文件列表中的文件 (one file per line), <span class="hljs-keyword">if</span> given, they are appended to files from cli arguments<br>  -w, --line-width int                  输出FASTA格式时的行宽 (0 <span class="hljs-keyword">for</span> no wrap) (default 60)<br>  -o, --out-file string                 输出 (<span class="hljs-string">&quot;-&quot;</span> <span class="hljs-keyword">for</span> stdout, suffix .gz <span class="hljs-keyword">for</span> gzipped out) (default <span class="hljs-string">&quot;-&quot;</span>) -代表标准输出，加.gz可输出压缩文件<br>      --quiet                           保持安静，不要显示额外的信息<br>  -t, --seq-type string                 序列类型 (dna|rna|protein|<span class="hljs-built_in">unlimit</span>|auto) (auto, 按第一个序列自动检测) (default <span class="hljs-string">&quot;auto&quot;</span>)<br>  -j, --threads int                     CPU数量 (默认单核为1，多核为2) (default 2)<br><br><br></code></pre></td></tr></table></figure><h1 id="stats-FASTA-x2F-Q文件的简单统计"><a href="#stats-FASTA-x2F-Q文件的简单统计" class="headerlink" title="stats FASTA&#x2F;Q文件的简单统计"></a>stats FASTA&#x2F;Q文件的简单统计</h1><p>统计序列格式fa&#x2F;fq、内容类型DNA&#x2F;RNA&#x2F;Protein，<font color="red">序列数量、总长度，最小、平均和最大长度</font></p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-comment"># FASTA DNA</span><br><span class="hljs-built_in">echo</span> -e <span class="hljs-string">&quot;&gt;seq\nacgtryswkmbdhvACGTRYSWKMBDHV&quot;</span> | seqkit stats<br>file  format  <span class="hljs-built_in">type</span>  num_seqs  sum_len  min_len  avg_len  max_len<br>-     FASTA   DNA          1       28       28       28       28<br><br><span class="hljs-comment"># RNA </span><br><span class="hljs-built_in">echo</span> -e <span class="hljs-string">&quot;&gt;seq\nACGUN\nACGUN&quot;</span> | seqkit stats<br>file  format  <span class="hljs-built_in">type</span>  num_seqs  sum_len  min_len  avg_len  max_len<br>-     FASTA   RNA          1       10       10       10       10<br><br><span class="hljs-comment"># Protein</span><br><span class="hljs-built_in">echo</span> -e <span class="hljs-string">&quot;&gt;seq\nabcdefghijklmnpqrstvwyz&quot;</span> | seqkit stats<br>file  format  <span class="hljs-built_in">type</span>     num_seqs  sum_len  min_len  avg_len  max_len<br>-     FASTA   Protein         1       23       23       23       23<br><br><span class="hljs-comment"># FASTQ DNA</span><br><span class="hljs-built_in">echo</span> -e <span class="hljs-string">&quot;@read\nACTGCN\n+\n@IICCG&quot;</span> | seqkit stats<br>file  format  <span class="hljs-built_in">type</span>  num_seqs  sum_len  min_len  avg_len  max_len<br>-     FASTQ   DNA          1        6        6        6        6<br><br>file                             format  <span class="hljs-built_in">type</span>     num_seqs         sum_len  min_len  avg_len  max_len<br>R1.fastq.gz  FASTQ   DNA   254,677,261  34,439,769,981       50    135.2      138<br><br></code></pre></td></tr></table></figure><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs r"><span class="hljs-comment"># 一般模式</span><br>seqkit stats C1_1.fq.gz<br><span class="hljs-comment">#--输出结果tab分隔</span><br>seqkit stats C1_1.fq.gz <span class="hljs-operator">-</span><span class="hljs-built_in">T</span><br><span class="hljs-comment">#--输出文件转化其他格式</span><br>seqkit stats C1_1.fq.gz <span class="hljs-operator">-</span><span class="hljs-built_in">T</span><span class="hljs-operator">|</span> csvtk pretty <span class="hljs-operator">-</span>t<br>seqkit stats C1_1.fq.gz <span class="hljs-operator">-</span><span class="hljs-built_in">T</span><span class="hljs-operator">|</span> csvtk csv2md <span class="hljs-operator">-</span>t<br><span class="hljs-comment"># 统计更多信息 -a</span><br>seqkit stats C1_1.fq.gz <span class="hljs-operator">-</span>a<br><span class="hljs-comment"># j多线程加速，尤其是对于具有多个序列文件会加速</span><br><span class="hljs-comment"># seqkit stats -j 2 *.fq.gz</span><br><br><br></code></pre></td></tr></table></figure><h1 id="seq-转换序列-（反向、互补-x2F-提取ID）"><a href="#seq-转换序列-（反向、互补-x2F-提取ID）" class="headerlink" title="seq 转换序列 （反向、互补&#x2F;提取ID）"></a>seq 转换序列 （反向、互补&#x2F;提取ID）</h1><p>“-n”: 提取序列ID，包括“&gt;”后面的全部内容</p><p>“-n -i”: 仅提取第一个空格前的ID</p><h1 id="按长度过滤-常用"><a href="#按长度过滤-常用" class="headerlink" title="按长度过滤(常用)"></a>按长度过滤(常用)</h1><p>扩增子分析时要筛选扩增长度相近的片段，过长或过短一般都要删除。宏基因组中比如组装的结果，经常要过滤&lt;200&#x2F;300bp的短片段，分箱时要筛选&gt;1000&#x2F;2000的长片段使用。本条命令非常多的应用场景。筛选后结果可用 &gt; 写入文件</p><p>-m 按照序列长度过滤，表示保留的最小长度，-M 此为保留的最大长度</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-comment">#--提取序列长度大于60的并统计长度信息</span><br>zcat hairpin.fa.gz | seqkit <span class="hljs-built_in">seq</span> -m 60 | seqkit stats<br><span class="hljs-comment"># 设置最小序列长度和最大序列长度，用于过滤序列，并统计</span><br>zcat hairpin.fa.gz | seqkit <span class="hljs-built_in">seq</span> -m 100 -M 1000 | seqkit stats<br><span class="hljs-comment"># 保存&gt;100且&lt;1000长度的序列</span><br>seqkit <span class="hljs-built_in">seq</span> -m 100 -M 1000 hairpin.fa.gz &gt; hairpin100-1000.fa<br>seqkit <span class="hljs-built_in">stat</span> hairpin100-1000.fa<br><br></code></pre></td></tr></table></figure><h1 id="提取ID"><a href="#提取ID" class="headerlink" title="提取ID"></a>提取ID</h1><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-built_in">head</span> gene.fa<br><span class="hljs-comment">## 名称全行</span><br>seqkit <span class="hljs-built_in">seq</span> gene.fa -n | <span class="hljs-built_in">head</span><br><span class="hljs-comment"># 仅仅打印ID</span><br>seqkit <span class="hljs-built_in">seq</span> gene.fa -n -i | <span class="hljs-built_in">head</span><br> <br><span class="hljs-comment"># 使用正则表达式提取名字中的信息</span><br>zcat hairpin.fa.gz | <span class="hljs-built_in">head</span><br><span class="hljs-comment"># 提取ID中第二个字段作为ID</span><br>seqkit <span class="hljs-built_in">seq</span> hairpin.fa.gz -n -i --id-regexp <span class="hljs-string">&quot;^[^\s]+\s([^\s]+)\s&quot;</span> | <span class="hljs-built_in">head</span><br><br><br></code></pre></td></tr></table></figure><h1 id="单行-x2F-多行转换"><a href="#单行-x2F-多行转换" class="headerlink" title="单行&#x2F;多行转换"></a>单行&#x2F;多行转换</h1><ul><li>-s提取并展示序列</li><li>-w 代表每行的碱基数量，0代表不换行</li></ul><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-comment">#仅仅提取序列 -s</span><br>seqkit <span class="hljs-built_in">seq</span> gene.fa -s -w 0|<span class="hljs-built_in">head</span><br><span class="hljs-comment">#--将多行序列转化为标准4行FASTQ</span><br>seqkit <span class="hljs-built_in">seq</span> C1_1.fq.gz -w 0|<span class="hljs-built_in">head</span><br></code></pre></td></tr></table></figure><h1 id="反向-x2F-互补"><a href="#反向-x2F-互补" class="headerlink" title="反向&#x2F;互补"></a>反向&#x2F;互补</h1><ul><li>-r 序列反向</li><li>-p序列互补</li></ul><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-comment"># 序列反向互补,-r反向，-p互补</span><br>seqkit <span class="hljs-built_in">seq</span> hairpin.fa.gz -r -p|<span class="hljs-built_in">head</span><br></code></pre></td></tr></table></figure><h1 id="删除gap-x2F-大小写转换"><a href="#删除gap-x2F-大小写转换" class="headerlink" title="删除gap&#x2F;大小写转换"></a>删除gap&#x2F;大小写转换</h1><ul><li>-g 去除序列中的间隔,将中间的横杠去掉</li><li>-u转化序列为大写字母展示</li></ul><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-built_in">echo</span> -e <span class="hljs-string">&quot;&gt;seq\nACGT-ACTGC-acc&quot;</span> | seqkit <span class="hljs-built_in">seq</span> -g -u<br></code></pre></td></tr></table></figure><h1 id="RNA转为DNA"><a href="#RNA转为DNA" class="headerlink" title="RNA转为DNA"></a>RNA转为DNA</h1><ul><li>—rna2dna 将RNA序列转化为DNA序列</li></ul><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-built_in">echo</span> -e <span class="hljs-string">&quot;&gt;seq\nUCAUAUGCUUGUCUCAAAGAUUA&quot;</span> | seqkit <span class="hljs-built_in">seq</span> --rna2dna<br></code></pre></td></tr></table></figure><h1 id="subseq通过指定区域"><a href="#subseq通过指定区域" class="headerlink" title="subseq通过指定区域"></a>subseq通过指定区域</h1><ul><li>-r 通过区域来截取序列</li></ul><p>如1:12提取前12个碱基，-12:-1提取序列结尾12个碱基；<br>for last 12 bases, 13:-1 for cutting first 12 bases. type “seqkit subseq -h” for more examples</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-comment">#-提取序列前1：12个碱基</span><br><span class="hljs-attribute">zcat</span> C1_1.fq.gz | seqkit subseq -r <span class="hljs-number">1</span>:<span class="hljs-number">12</span> |head<br><span class="hljs-comment">#-提取序列最后1：12个碱基</span><br><span class="hljs-attribute">zcat</span> C1_1.fq.gz | seqkit subseq -r -<span class="hljs-number">12</span>:-<span class="hljs-number">1</span> |head<br> <br><span class="hljs-comment">#取第12至倒数第12个碱基，即前11和后11个碱基去掉</span><br><span class="hljs-attribute">zcat</span> C1_1.fq.gz | seqkit subseq -r <span class="hljs-number">12</span>:-<span class="hljs-number">12</span>| head<br></code></pre></td></tr></table></figure><p>基于gtf&#x2F;bed信息挑选子序列。</p><p>—gtf  根据gtf文件挑选基因，这部分功能用于根据基因注释快速提取基因序列，在宏基因组、转录组、重测序中常用。—chr 选择染色体，—feature cds选择序列类型</p><p>以拟南芥基因组的序列和注释数据演示：提取第一条染色体上的CDS基因信息，并统计基本信息</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs stylus">seqkit subseq <span class="hljs-attr">--gtf</span> Arabidopsis_thaliana<span class="hljs-selector-class">.TAIR10</span>.<span class="hljs-number">49</span><span class="hljs-selector-class">.gtf</span><span class="hljs-selector-class">.gz</span> <span class="hljs-attr">--chr</span> <span class="hljs-number">1</span> <span class="hljs-attr">--feature</span> cds  Arabidopsis_thaliana<span class="hljs-selector-class">.TAIR10</span><span class="hljs-selector-class">.dna</span><span class="hljs-selector-class">.toplevel</span><span class="hljs-selector-class">.fa</span><span class="hljs-selector-class">.gz</span>  &gt; chr1<span class="hljs-selector-class">.gtf</span><span class="hljs-selector-class">.cds</span><span class="hljs-selector-class">.fa</span><br>seqkit stats chr1<span class="hljs-selector-class">.gtf</span><span class="hljs-selector-class">.cds</span><span class="hljs-selector-class">.fa</span><br><br><br></code></pre></td></tr></table></figure><ul><li>-u 可以提取目标基因上游的序列</li><li>-f 目标区域不展示</li></ul><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-comment">#--挑选序列并多加上上游的3个碱基</span><br><span class="hljs-attribute">seqkit</span> subseq --gtf Arabidopsis_thaliana.TAIR10.<span class="hljs-number">49</span>.gtf.gz Arabidopsis_thaliana.TAIR10.dna.toplevel.fa.gz -u <span class="hljs-number">3</span> |head<br> <br><span class="hljs-comment"># 仅提取上游序列，如提取启动子区2k：-f仅定位不输出位置序列，-u输出上游序列，此处示例3bp</span><br><span class="hljs-attribute">seqkit</span> subseq --gtf Arabidopsis_thaliana.TAIR10.<span class="hljs-number">49</span>.gtf.gz Arabidopsis_thaliana.TAIR10.dna.toplevel.fa.gz -u <span class="hljs-number">3</span> -f |head<br><br><br></code></pre></td></tr></table></figure><h1 id="sliding-滑窗提取序列，支持环状基因组"><a href="#sliding-滑窗提取序列，支持环状基因组" class="headerlink" title="sliding 滑窗提取序列，支持环状基因组"></a>sliding 滑窗提取序列，支持环状基因组</h1><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-comment">#-s 步长为3，-W 序列长度为6个碱基</span><br><span class="hljs-attribute">echo</span> -e <span class="hljs-string">&quot;&gt;seq\nACGTacgtNN&quot;</span> | seqkit sliding -s <span class="hljs-number">3</span> -W <span class="hljs-number">6</span><br><span class="hljs-comment"># -g 贪婪模式，后面不足6个那也取</span><br><span class="hljs-attribute">echo</span> -e <span class="hljs-string">&quot;&gt;seq\nACGTacgtNN&quot;</span> | seqkit sliding -s <span class="hljs-number">3</span> -W <span class="hljs-number">6</span> -g<br><span class="hljs-comment"># 环状DNA模式-C，首尾不算中断，环状</span><br><span class="hljs-attribute">echo</span> -e <span class="hljs-string">&quot;&gt;seq\nACGTacgtNN&quot;</span> | seqkit sliding -s <span class="hljs-number">3</span> -W <span class="hljs-number">6</span> -C<br><br><br></code></pre></td></tr></table></figure><ul><li>步长为5，取30个碱基序列，然后统计GC含量</li></ul><ul><li>fx2tab：统计fasta&#x2F;fastq序列的信息为表格</li><li>-n仅输出ID，不输出序列</li><li>-g为GC含量</li></ul><figure class="highlight coq"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs coq">zcat hairpin.fa.gz | <span class="hljs-type">seqkit</span> sliding -s <span class="hljs-number">5</span> -W <span class="hljs-number">30</span> | <span class="hljs-type">seqkit</span> fx2tab -n -g |<span class="hljs-type">head</span><br></code></pre></td></tr></table></figure><h1 id="faidx-创建FASTA索引文件并提取子序列"><a href="#faidx-创建FASTA索引文件并提取子序列" class="headerlink" title="faidx 创建FASTA索引文件并提取子序列"></a>faidx 创建FASTA索引文件并提取子序列</h1><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-comment"># 解压</span><br><span class="hljs-attribute">zcat</span> hairpin.fa.gz &gt; hairpin.fa<br> <br><span class="hljs-comment"># 建索引*.fai文件</span><br><span class="hljs-attribute">seqkit</span> faidx hairpin.fa<br> <br><span class="hljs-comment"># ID信息：hsa-let-7a-1 hsa-let-7a-2</span><br><span class="hljs-attribute">seqkit</span> faidx hairpin.fa hsa-let-<span class="hljs-number">7</span>a-<span class="hljs-number">1</span> hsa-let-<span class="hljs-number">7</span>a-<span class="hljs-number">2</span><br><span class="hljs-comment"># -f 标题行全部显示</span><br><span class="hljs-attribute">seqkit</span> faidx hairpin.fa hsa-let-<span class="hljs-number">7</span>a-<span class="hljs-number">1</span> hsa-let-<span class="hljs-number">7</span>a-<span class="hljs-number">2</span> -f<br><span class="hljs-comment"># 提取序列并选择区域显示</span><br><span class="hljs-attribute">seqkit</span> faidx hairpin.fa hsa-let-<span class="hljs-number">7</span>a-<span class="hljs-number">1</span>:<span class="hljs-number">1</span>-<span class="hljs-number">10</span><br><span class="hljs-attribute">seqkit</span> faidx hairpin.fa hsa-let-<span class="hljs-number">7</span>a-<span class="hljs-number">1</span>:-<span class="hljs-number">10</span>--<span class="hljs-number">1</span><br><span class="hljs-attribute">seqkit</span> faidx hairpin.fa hsa-let-<span class="hljs-number">7</span>a-<span class="hljs-number">1</span>:<span class="hljs-number">1</span><br><span class="hljs-comment"># 检查hsa开头的序列并统计</span><br><span class="hljs-attribute">seqkit</span> faidx hairpin.fa hsa -r | seqkit stats<br><br><br></code></pre></td></tr></table></figure><h1 id="watch-序列质量的监测和在线直方图"><a href="#watch-序列质量的监测和在线直方图" class="headerlink" title="watch 序列质量的监测和在线直方图"></a>watch 序列质量的监测和在线直方图</h1><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs powershell"><span class="hljs-comment">#-取对数展示直方图</span><br>seqkit watch <span class="hljs-literal">-L</span> <span class="hljs-operator">-f</span> ReadLen hairpin.fa<br> <br><span class="hljs-comment"># 每五千个做一个图保存在pdf文件中</span><br>seqkit watch <span class="hljs-literal">-p</span> <span class="hljs-number">500000</span> <span class="hljs-literal">-O</span> qhist.pdf <span class="hljs-operator">-f</span> MeanQual C1_1.fq.gz<br></code></pre></td></tr></table></figure><p>从有错误记录的fastq文件中挽救可用的读取</p><h1 id="sana：清理损坏fastq文件"><a href="#sana：清理损坏fastq文件" class="headerlink" title="sana：清理损坏fastq文件"></a>sana：清理损坏fastq文件</h1><p>这里我专门将C1_1.fq的第一个序列进行了错位，进行测试。这个操作往往在进行数据整合的时候可以有很大作用。</p><figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs nginx"><span class="hljs-attribute">zcat</span> C1_1.fq.gz|sed <span class="hljs-string">&#x27;2 s/^/A/&#x27;</span> &gt; C1_1_bad.fq<br>seqkit sana C1_1_bad.fq -o rescued.fq.gz<br></code></pre></td></tr></table></figure><h1 id="fq2fa-将fq转为fa格式"><a href="#fq2fa-将fq转为fa格式" class="headerlink" title="fq2fa 将fq转为fa格式"></a>fq2fa 将fq转为fa格式</h1><figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs reasonml">seqkit fq2fa <span class="hljs-module-access"><span class="hljs-module"><span class="hljs-identifier">C1_1</span>.</span></span>fq.gz -o <span class="hljs-module-access"><span class="hljs-module"><span class="hljs-identifier">C1_1</span>.</span></span>fa<br></code></pre></td></tr></table></figure><h1 id="fx2tab-amp-tab2fx-序列转化表格格式"><a href="#fx2tab-amp-tab2fx-序列转化表格格式" class="headerlink" title="fx2tab &amp; tab2fx 序列转化表格格式"></a>fx2tab &amp; tab2fx 序列转化表格格式</h1><figure class="highlight ldif"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs ldif">这一转化很有用，往往用于表格/矩阵处理的时候。<br>seqkit fx2tab hairpin.fa.gz | head -n 2<br>通过矩阵格式的序列文件统计序列长度和质量值<br><br><span class="hljs-literal">-</span>l 统计序列长度<br><br><span class="hljs-literal">-</span>g 统计平均GC含量<br><br><span class="hljs-literal">-</span>i 只打印名称(不打印序列)<br><br><span class="hljs-literal">-</span>H 打印标题行<br><span class="hljs-comment"># 打印序列长度、GC含量</span><br>seqkit fx2tab hairpin.fa.gz -l -g -n -i -H | head<br><br><br></code></pre></td></tr></table></figure><p>tab2fx 和表格格式转化为序列格式</p><figure class="highlight 1c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs 1c"><span class="hljs-meta"># seqkit tab2fx 表格形式转化为序列形式</span><br>zcat hairpin.fa.gz <span class="hljs-string">| seqkit fx2tab | seqkit tab2fx | head</span><br> <br><span class="hljs-meta"># 转化为表格，然后排序，然后转化回去</span><br>zcat hairpin.fa.gz \<br>    <span class="hljs-string">| seqkit fx2tab -l \</span><br>    <span class="hljs-string">| sort -t &quot;</span>`echo -e &#x27;\t&#x27;`<span class="hljs-string">&quot; -n -k4,4 \</span><br>    <span class="hljs-string">| seqkit tab2fx | head</span><br><span class="hljs-meta"># 等同于下面的命令</span><br>seqkit sort -l hairpin.fa.gz <span class="hljs-string">| head</span><br> <br><span class="hljs-meta"># 通过这个转化可以将很多在表格中实现的数据处理方法用于序列</span><br>例如下面的提取<span class="hljs-number">1000</span>个序列：seqkit fx2tab hairpin.fa.gz <span class="hljs-string">| head -n 1000 | seqkit tab2fx | head</span><br></code></pre></td></tr></table></figure><h1 id="translate-翻译DNA-x2F-RNA为蛋白质序列"><a href="#translate-翻译DNA-x2F-RNA为蛋白质序列" class="headerlink" title="translate 翻译DNA&#x2F;RNA为蛋白质序列"></a>translate 翻译DNA&#x2F;RNA为蛋白质序列</h1><figure class="highlight processing"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs processing">#--转化为蛋白序列<br>seqkit <span class="hljs-built_in">translate</span> gene.<span class="hljs-property">fa</span>|head<br> <br># 去除<span class="hljs-string">&#x27;X&#x27;</span> 和 <span class="hljs-string">&#x27;*&#x27;</span><br>seqkit <span class="hljs-built_in">translate</span> hairpin.<span class="hljs-property">fa</span> <br>seqkit <span class="hljs-built_in">translate</span> hairpin.<span class="hljs-property">fa</span> --<span class="hljs-built_in">trim</span> | head<br></code></pre></td></tr></table></figure><h1 id="grep-序列匹配"><a href="#grep-序列匹配" class="headerlink" title="grep  序列匹配"></a>grep  序列匹配</h1><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 生成一个ID列表</span><br>grep <span class="hljs-string">&#x27;&gt;&#x27;</span> C1_1.fa|<span class="hljs-built_in">cut</span> -c2-|<span class="hljs-built_in">head</span> -n 10 &gt; id.txt<br> <br><span class="hljs-comment"># 使用序列id列表进行搜索(不包含空格)</span><br>seqkit grep -f id.txt C1_1.fq.gz -o result.fq.gz<br><span class="hljs-comment"># 使用序列名称列表进行搜索(它们可能包含空格)</span><br>seqkit grep -n -f id.txt C1_1.fq.gz -o result.fa.gz<br>zcat  result.fa.gz<br><span class="hljs-comment"># 提取hsa开头的序列</span><br>zcat hairpin.fa.gz | seqkit grep -r -p ^hsa |<span class="hljs-built_in">head</span><br> <br><span class="hljs-comment"># -v参数v用于移除序列</span><br>zcat hairpin.fa.gz | seqkit grep -r -p ^hsa -p ^mmu -v | <span class="hljs-built_in">head</span><br> <br><span class="hljs-comment"># 提取ID</span><br>zcat miRNA.diff.gz | grep ^<span class="hljs-comment"># -v | grep NEW | cut -f 2 &gt; list</span><br><span class="hljs-built_in">head</span> list<br><span class="hljs-comment"># 根据ID提取文件</span><br>zcat hairpin.fa.gz | seqkit grep -f list &gt; new.fa<br><span class="hljs-built_in">head</span> new.fa<br> <br><span class="hljs-comment"># 提取包含特定碱基组合的序列</span><br><span class="hljs-built_in">cat</span> hairpin.fa.gz | seqkit grep -s -i -p aggcg |<span class="hljs-built_in">head</span><br><span class="hljs-comment"># 统计</span><br><span class="hljs-built_in">cat</span> hairpin.fa.gz | seqkit grep -s -i -p aggcg | seqkit stats<br> <br><span class="hljs-comment">#  去除 包含特定组合碱基的序列</span><br>zcat hairpin.fa.gz | seqkit grep -s -r -i -p ^aggcg |<span class="hljs-built_in">head</span><br><br><br></code></pre></td></tr></table></figure><h1 id="locate-输出匹配位置"><a href="#locate-输出匹配位置" class="headerlink" title="locate 输出匹配位置"></a>locate 输出匹配位置</h1><figure class="highlight 1c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs 1c">＃　其他两种输出格式<br>zcat hairpin.fa.gz <span class="hljs-string">| seqkit locate -i -d -p AUGGACUN --bed</span><br>zcat hairpin.fa.gz <span class="hljs-string">| seqkit locate -i -d -p AUGGACUN --gtf</span><br><br><br></code></pre></td></tr></table></figure><h1 id="fish-使用局部比对在较大的序列中寻找短序列"><a href="#fish-使用局部比对在较大的序列中寻找短序列" class="headerlink" title="fish 使用局部比对在较大的序列中寻找短序列"></a>fish 使用局部比对在较大的序列中寻找短序列</h1><figure class="highlight 1c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs 1c">echo -e &#x27;&gt;seq\nACGACGACGA&#x27; \<br>    <span class="hljs-string">| seqkit locate -p ACGA -G | csvtk -t pretty</span><br> <br>echo -e &#x27;&gt;seq\nACGACGACGA&#x27; \<br>    <span class="hljs-string">| seqkit fish -F ACGA -a 2&gt;&amp;1 | csvtk -t pretty</span><br><br><br></code></pre></td></tr></table></figure><h1 id="amplicon-通过引物检索扩增子-或其周围的特定区域"><a href="#amplicon-通过引物检索扩增子-或其周围的特定区域" class="headerlink" title="amplicon 通过引物检索扩增子(或其周围的特定区域)"></a>amplicon 通过引物检索扩增子(或其周围的特定区域)</h1><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs powershell"><span class="hljs-built_in">echo</span> <span class="hljs-operator">-ne</span> <span class="hljs-string">&quot;&gt;seq\nacgcccactgaaatga\n&quot;</span> \<br>    | seqkit amplicon <span class="hljs-operator">-F</span> ccc <span class="hljs-literal">-R</span> ttt<br> <br><span class="hljs-comment"># 设置输出格式为bed，匹配的位点等信息</span><br><span class="hljs-built_in">echo</span> <span class="hljs-operator">-ne</span> <span class="hljs-string">&quot;&gt;seq\nacgcccactgaaatga\n&quot;</span> \<br>    | seqkit amplicon <span class="hljs-operator">-F</span> ccc <span class="hljs-literal">-R</span> ttt <span class="hljs-literal">--bed</span><br> <br><span class="hljs-comment">#- 使用引物文件，这用于刘老师组的高通量分菌的序列拆分速度应该很客观</span><br><span class="hljs-comment"># cat seqs4amplicon.fa | seqkit amplicon -p primers.tsv --bed</span><br><br><br></code></pre></td></tr></table></figure><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs powershell"><span class="hljs-comment"># 输出除去引物之外的部分，-r输出几个碱基</span><br><span class="hljs-built_in">echo</span> <span class="hljs-operator">-ne</span> <span class="hljs-string">&quot;&gt;seq\nacgcccactgaaatga\n&quot;</span> \<br>    | seqkit amplicon <span class="hljs-operator">-F</span> ccc <span class="hljs-literal">-R</span> ttt <span class="hljs-literal">-r</span> <span class="hljs-number">4</span>:<span class="hljs-number">7</span><br><span class="hljs-comment"># 输出格式为bed</span><br><span class="hljs-built_in">echo</span> <span class="hljs-operator">-ne</span> <span class="hljs-string">&quot;&gt;seq\nacgcccactgaaatga\n&quot;</span> \<br>    | seqkit amplicon <span class="hljs-operator">-F</span> ccc <span class="hljs-literal">-R</span> ttt <span class="hljs-literal">-r</span> <span class="hljs-number">4</span>:<span class="hljs-number">7</span> <span class="hljs-literal">--bed</span><br><br><br></code></pre></td></tr></table></figure><h1 id="duplicate-对序列重复N次"><a href="#duplicate-对序列重复N次" class="headerlink" title="duplicate 对序列重复N次"></a>duplicate 对序列重复N次</h1><figure class="highlight 1c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs 1c"><span class="hljs-meta"># 重复序列1次，但是名字没有修改</span><br>cat hairpin.fa <span class="hljs-string">| seqkit head -n 1 \</span><br>    <span class="hljs-string">| seqkit duplicate -n 2</span><br><span class="hljs-meta"># 对重复序列改名，使其独一无二</span><br>cat hairpin.fa <span class="hljs-string">| seqkit head -n 1 \</span><br>    <span class="hljs-string">| seqkit duplicate -n 2 | seqkit rename</span><br><br><br></code></pre></td></tr></table></figure><h1 id="rmdup-通过id-x2F-名称-x2F-序列删除重复的序列"><a href="#rmdup-通过id-x2F-名称-x2F-序列删除重复的序列" class="headerlink" title="rmdup 通过id&#x2F;名称&#x2F;序列删除重复的序列"></a>rmdup 通过id&#x2F;名称&#x2F;序列删除重复的序列</h1><figure class="highlight 1c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs 1c"><span class="hljs-meta"># 去除重复的序列</span><br>zcat hairpin.fa.gz <span class="hljs-string">| seqkit rmdup -s -o clean.fa.gz</span><br> <br><span class="hljs-meta"># 保存重复序列得到文件 -D duplicated.detail.txt</span><br>zcat hairpin.fa.gz \<br>    <span class="hljs-string">| seqkit rmdup -s -i -o clean.fa.gz -d duplicated.fa.gz -D duplicated.detail.txt</span><br><br><br></code></pre></td></tr></table></figure><h1 id="common-：通过id-x2F-名称-x2F-序列查找多个文件的公共序列"><a href="#common-：通过id-x2F-名称-x2F-序列查找多个文件的公共序列" class="headerlink" title="common ：通过id&#x2F;名称&#x2F;序列查找多个文件的公共序列"></a>common ：通过id&#x2F;名称&#x2F;序列查找多个文件的公共序列</h1><figure class="highlight axapta"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs axapta"><span class="hljs-meta"># 通过ID匹配，文件夹下全部的fa序列公共部分输出来</span><br>seqkit <span class="hljs-keyword">common</span> *.fq.gz<br> <br><span class="hljs-meta"># 通过-n实现全部名字匹配，-o输出结果</span><br>seqkit <span class="hljs-keyword">common</span> *.fq.gz -n -o <span class="hljs-keyword">common</span>.fq <br><span class="hljs-meta"># 通过-s序列匹配</span><br>seqkit <span class="hljs-keyword">common</span> *.fq.gz -s -i -o <span class="hljs-keyword">common</span>.fq<br><br><br></code></pre></td></tr></table></figure><h1 id="split-拆分序列为子文件"><a href="#split-拆分序列为子文件" class="headerlink" title="split 拆分序列为子文件"></a>split 拆分序列为子文件</h1><figure class="highlight tcl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs tcl">按名称ID、给定区域的子序列、文件大小或序列数量将序列拆分为文件<br><br>可用于将大文件拆分后，并行处理，加速分析。如从contig中预测基因。<br><span class="hljs-comment">#按照10000个序列为一个文件拆分，结果为hairpin.fa.gz.split/目录 ，文件名为hairpin.part_00x.fasta，-s</span><br>seqkit <span class="hljs-keyword">split</span> hairpin.fa.gz -s <span class="hljs-number">10000</span> <span class="hljs-number">-2</span><br> <br><span class="hljs-comment"># 将序列拆分为四个部分(常用，等分然后并行)</span><br>seqkit <span class="hljs-keyword">split</span> hairpin.fa.gz -p <span class="hljs-number">5</span> <span class="hljs-number">-2</span><br> <br><span class="hljs-comment"># 复杂一点的就是按照ID区分</span><br>seqkit <span class="hljs-keyword">split</span> hairpin.fa.gz -i --id-<span class="hljs-keyword">regexp</span> <span class="hljs-string">&quot;^([\w]+)\-&quot;</span> <span class="hljs-number">-2</span><br> <br><span class="hljs-comment"># 按照前三个序列碱基来区分</span><br>seqkit <span class="hljs-keyword">split</span> hairpin.fa.gz -r <span class="hljs-number">1</span>:<span class="hljs-number">3</span> <span class="hljs-number">-2</span><br></code></pre></td></tr></table></figure><h1 id="split2-拆分文件-升级版本"><a href="#split2-拆分文件-升级版本" class="headerlink" title="split2 拆分文件 升级版本"></a>split2 拆分文件 升级版本</h1><figure class="highlight csharp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs csharp">Flags:<br>  -l, --<span class="hljs-keyword">by</span>-length <span class="hljs-built_in">string</span>   split sequences <span class="hljs-keyword">into</span> chunks of &gt;=N bases, supports K/M/G suffix<br>  -p, --<span class="hljs-keyword">by</span>-part <span class="hljs-built_in">int</span>        按照拆分出来的数量，比如：拆分成两个子文件<span class="hljs-number">2</span>。-s, --<span class="hljs-keyword">by</span>-size <span class="hljs-built_in">int</span>        按照序列数量拆分<br>  -f, --force              强制覆盖文件<br>  -h, --help               查看帮助文件<br>  -O, --<span class="hljs-keyword">out</span>-dir <span class="hljs-built_in">string</span>     输出文件夹 (<span class="hljs-literal">default</span> <span class="hljs-keyword">value</span> <span class="hljs-keyword">is</span> $infile.split)<br>  <span class="hljs-number">-1</span>, --<span class="hljs-function">read1 <span class="hljs-title">string</span>       (<span class="hljs-params">gzipped</span>) 双端序列第一个</span><br><span class="hljs-function">  -2, --read2 <span class="hljs-title">string</span>       (<span class="hljs-params">gzipped</span>) 双端序列第二个</span><br><span class="hljs-function"></span><br><span class="hljs-function"></span><br></code></pre></td></tr></table></figure><p>同时支持fa和fq文件。单端和双端序列拆分实例</p><p>-f强制覆盖结果，适合重复计算时使用</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">seqkit</span> split2 hairpin.fa.gz -s <span class="hljs-number">10000</span> -f<br> <br><span class="hljs-comment"># 双端序列拆分(重点)，p指定拆分数量，-O指定输出目录，-f覆盖结果，默认为压缩</span><br><span class="hljs-attribute">seqkit</span> split2 -<span class="hljs-number">1</span> C1_1.fq.gz -<span class="hljs-number">2</span> C1_2.fq.gz -p <span class="hljs-number">2</span> -O out -f<br><br><br></code></pre></td></tr></table></figure><h1 id="pair-拼接两个fastq文件"><a href="#pair-拼接两个fastq文件" class="headerlink" title="pair 拼接两个fastq文件"></a>pair 拼接两个fastq文件</h1><p>留下匹配的，去除不匹配的，这里我们使用扩增子的双端序列做一个演示：</p><p>注意：双端序列在两个文件中的顺序最好是一样的，否则会消耗大量内存去匹配。</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">seqkit</span> pair -<span class="hljs-number">1</span> C1_1.fq.gz -<span class="hljs-number">2</span> C1_2.fq.gz -O result<br><span class="hljs-comment"># -u 输出未匹配上的文件</span><br><span class="hljs-attribute">seqkit</span> pair -<span class="hljs-number">1</span> C1_1.fq.gz -<span class="hljs-number">2</span> C1_2.fq.gz -O result -u -f<br><br></code></pre></td></tr></table></figure><h1 id="sample-按数量或比例对序列进行抽样。"><a href="#sample-按数量或比例对序列进行抽样。" class="headerlink" title="sample 按数量或比例对序列进行抽样。"></a>sample 按数量或比例对序列进行抽样。</h1><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs awk">按照百分比例和序列数量进行抽样<br><span class="hljs-comment"># 抽样百分之十</span><br>zcat C1_1.fq.gz | seqkit sample -p <span class="hljs-number">0.1</span> -o sample.fq.gz<br><span class="hljs-comment"># 抽样1000条</span><br>zcat C1_1.fq.gz | seqkit sample -n <span class="hljs-number">1000</span> -o sample.fq.gz<br><br>注意：<span class="hljs-number">1000</span>条并不是很准确，可能是<span class="hljs-number">900</span>多条，为什么呢？看这里了解问题。https:<span class="hljs-regexp">//</span>bioinf.shenwei.me<span class="hljs-regexp">/seqkit/</span>note/<span class="hljs-comment">#effect-of-random-seed-on-results-of-seqkit-sample</span><br></code></pre></td></tr></table></figure><p>这里为大家展示一下减少内存的序列抽样方法</p><figure class="highlight 1c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs 1c"><span class="hljs-meta"># 抽样 seqkit sample </span><br>zcat hairpin.fa.gz \<br>    <span class="hljs-string">| seqkit sample -p 0.1 \</span><br>    <span class="hljs-string">| seqkit head -n 1000 -o sample.fa.gz</span><br> <br><span class="hljs-meta"># 设置随机种子，方便重复结果: -s 11</span><br>zcat hairpin.fa.gz \<br>    <span class="hljs-string">| seqkit sample -p 0.1 -s 11 |head</span><br> <br><span class="hljs-meta"># 抽样后打乱序列 :seqkit shuffle</span><br>zcat hairpin.fa.gz \<br>    <span class="hljs-string">| seqkit sample -p 0.1 \</span><br>    <span class="hljs-string">| seqkit shuffle -o sample.fa.gz</span><br><br><br></code></pre></td></tr></table></figure><h1 id="range-打印序列-按照一个范围"><a href="#range-打印序列-按照一个范围" class="headerlink" title="range 打印序列 按照一个范围"></a>range 打印序列 按照一个范围</h1><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-comment"># 打印一个范围内的序列</span><br><span class="hljs-attribute">cat</span> hairpin.fa | seqkit range -r <span class="hljs-number">1</span>:<span class="hljs-number">10</span><br><span class="hljs-comment"># 打印最后几行的序列</span><br><span class="hljs-attribute">cat</span> hairpin.fa | seqkit range -r -<span class="hljs-number">100</span>:-<span class="hljs-number">1</span> | seqkit stats<br><span class="hljs-comment"># 打印中间范围的序列</span><br><span class="hljs-attribute">cat</span> hairpin.fa | seqkit range -r <span class="hljs-number">101</span>:<span class="hljs-number">150</span> | seqkit stats<br><br><br></code></pre></td></tr></table></figure><h1 id="repeat-使用正则表达式替换名称-x2F-序列。"><a href="#repeat-使用正则表达式替换名称-x2F-序列。" class="headerlink" title="repeat 使用正则表达式替换名称&#x2F;序列。"></a>repeat 使用正则表达式替换名称&#x2F;序列。</h1><figure class="highlight livecodeserver"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs livecodeserver"><span class="hljs-comment"># 修改序列名称：删除空格后内存</span><br>echo -e <span class="hljs-string">&quot;&gt;seq1 abc-123\nACGT-ACGT&quot;</span> \<br>    | seqkit <span class="hljs-built_in">replace</span> -p <span class="hljs-string">&quot;\s.+&quot;</span><br> <br><span class="hljs-comment"># 修改序列名：替换</span><br>echo -e <span class="hljs-string">&quot;&gt;seq1 abc-123\nACGT-ACGT&quot;</span> \<br>    | seqkit <span class="hljs-built_in">replace</span> -p <span class="hljs-string">&quot;\-&quot;</span> -r <span class="hljs-string">&#x27;=&#x27;</span><br> <br><span class="hljs-comment"># 修改序列：去除序列间隔</span><br>echo -e <span class="hljs-string">&quot;&gt;seq1 abc-123\nACGT-ACGT&quot;</span> \<br>    | seqkit <span class="hljs-built_in">replace</span> -p <span class="hljs-string">&quot; |-&quot;</span> -s<br> <br><span class="hljs-comment"># 修改序列：给每一个碱基加上空格</span><br>echo -e <span class="hljs-string">&quot;&gt;seq1 abc-123\nACGT-ACGT&quot;</span> \<br>    | seqkit <span class="hljs-built_in">replace</span> -p <span class="hljs-string">&quot;(.)&quot;</span> -r <span class="hljs-string">&#x27;$1 &#x27;</span> -s<br> <br><span class="hljs-comment"># 使用字符加数据重命名序列-用于扩增子代表序列改名非常优秀</span><br>echo -e <span class="hljs-string">&quot;&gt;abc\nACTG\n&gt;123\nATTT&quot;</span> \<br>    |  seqkit <span class="hljs-built_in">replace</span> -p .+ -r <span class="hljs-string">&quot;ASV_&#123;nr&#125;&quot;</span><br> <br>echo -e <span class="hljs-string">&quot;&gt;abc\nACTG\n&gt;123\nATTT&quot;</span> \<br>    |  seqkit <span class="hljs-built_in">replace</span> -p .+ -r <span class="hljs-string">&quot;SAV_&#123;nr&#125;&quot;</span> <span class="hljs-comment">--nr-width 5</span><br><br><br></code></pre></td></tr></table></figure><h1 id="rename-重命名重复的ID"><a href="#rename-重命名重复的ID" class="headerlink" title="rename 重命名重复的ID"></a>rename 重命名重复的ID</h1><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs lsl"># 重命名：相同序列会在后面加上_2 来处理<br>echo -e <span class="hljs-string">&quot;&gt;a comment<span class="hljs-subst">\n</span>acgt<span class="hljs-subst">\n</span>&gt;b comment of b<span class="hljs-subst">\n</span>ACTG<span class="hljs-subst">\n</span>&gt;a comment<span class="hljs-subst">\n</span>aaaa&quot;</span> \<br>    | seqkit rename<br><br><br></code></pre></td></tr></table></figure><h1 id="concat-连接多个文件中具有相同ID的序列"><a href="#concat-连接多个文件中具有相同ID的序列" class="headerlink" title="concat 连接多个文件中具有相同ID的序列"></a>concat 连接多个文件中具有相同ID的序列</h1><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-comment">#这里演示组合前面两个碱基和最后两个碱基的用法</span><br><span class="hljs-attribute">seqkit</span> concat &lt;(seqkit subseq -r <span class="hljs-number">1</span>:<span class="hljs-number">2</span> C1_1.fq.gz) &lt;(seqkit subseq -r -<span class="hljs-number">2</span>:-<span class="hljs-number">1</span> C1_2.fq.gz)|head<br><br></code></pre></td></tr></table></figure><h1 id="shuffle-随机打乱序列-默认全部读入内存"><a href="#shuffle-随机打乱序列-默认全部读入内存" class="headerlink" title="shuffle 随机打乱序列 默认全部读入内存"></a>shuffle 随机打乱序列 默认全部读入内存</h1><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs stylus">seqkit shuffle hairpin<span class="hljs-selector-class">.fa</span><span class="hljs-selector-class">.gz</span> -<span class="hljs-number">2</span>  &gt; shuffled.fa<br></code></pre></td></tr></table></figure><h1 id="sort-按id-x2F-名称-x2F-序列-x2F-长度排序序列"><a href="#sort-按id-x2F-名称-x2F-序列-x2F-长度排序序列" class="headerlink" title="sort 按id&#x2F;名称&#x2F;序列&#x2F;长度排序序列"></a>sort 按id&#x2F;名称&#x2F;序列&#x2F;长度排序序列</h1><p>—quiet 屏幕不输出过程</p><p>-i 排序忽略大小写</p><p>-l 按照序列长度排序</p><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs lsl"># ID排序<br>echo -e <span class="hljs-string">&quot;&gt;seq1<span class="hljs-subst">\n</span>ACGTNcccc<span class="hljs-subst">\n</span>&gt;SEQ2<span class="hljs-subst">\n</span>acgtnAAAA&quot;</span> \<br>    | seqkit sort --quiet<br> <br># 按照ID排序，忽略大小写<br>echo -e <span class="hljs-string">&quot;&gt;seq1<span class="hljs-subst">\n</span>ACGTNcccc<span class="hljs-subst">\n</span>&gt;SEQ2<span class="hljs-subst">\n</span>acgtnAAAA&quot;</span> \<br>    | seqkit sort --quiet -i<br> <br># 按照序列长度排序，由小到大<br>echo -e <span class="hljs-string">&quot;&gt;seq1<span class="hljs-subst">\n</span>ACGTNcccc<span class="hljs-subst">\n</span>&gt;SEQ2<span class="hljs-subst">\n</span>acgtnAAAAnnn<span class="hljs-subst">\n</span>&gt;seq3<span class="hljs-subst">\n</span>acgt&quot;</span> \<br>    | seqkit sort --quiet -l<br><br><br></code></pre></td></tr></table></figure><h1 id="mutate-编辑序列-点突变、插入、删除"><a href="#mutate-编辑序列-点突变、插入、删除" class="headerlink" title="mutate 编辑序列(点突变、插入、删除)"></a>mutate 编辑序列(点突变、插入、删除)</h1><figure class="highlight swift"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs swift">echo <span class="hljs-operator">-</span>ne <span class="hljs-string">&quot;&gt;1<span class="hljs-subst">\n</span>ACTGNactgn<span class="hljs-subst">\n</span>&gt;2<span class="hljs-subst">\n</span>actgnACTGN<span class="hljs-subst">\n</span>&quot;</span><br> <br># 修改第一个碱基<br>echo <span class="hljs-operator">-</span>ne <span class="hljs-string">&quot;&gt;1<span class="hljs-subst">\n</span>ACTGNactgn<span class="hljs-subst">\n</span>&gt;2<span class="hljs-subst">\n</span>actgnACTGN<span class="hljs-subst">\n</span>&quot;</span> \<br>    <span class="hljs-operator">|</span> seqkit mutate <span class="hljs-operator">-</span>p <span class="hljs-number">1</span>:x<br> <br># 修改第五个位置的碱基，输出信息隐藏    <br>echo <span class="hljs-operator">-</span>ne <span class="hljs-string">&quot;&gt;1<span class="hljs-subst">\n</span>ACTGNactgn<span class="hljs-subst">\n</span>&gt;2<span class="hljs-subst">\n</span>actgnACTGN<span class="hljs-subst">\n</span>&quot;</span> \<br>    <span class="hljs-operator">|</span> seqkit mutate <span class="hljs-operator">-</span>p <span class="hljs-number">5</span>:x <span class="hljs-operator">--</span>quiet<br> <br># 可以同时修改多个碱基<br>echo <span class="hljs-operator">-</span>ne <span class="hljs-string">&quot;&gt;1<span class="hljs-subst">\n</span>ACTGNactgn<span class="hljs-subst">\n</span>&gt;2<span class="hljs-subst">\n</span>actgnACTGN<span class="hljs-subst">\n</span>&quot;</span> \<br>    <span class="hljs-operator">|</span> seqkit mutate <span class="hljs-operator">-</span>p <span class="hljs-number">1</span>:x <span class="hljs-operator">-</span>p <span class="hljs-operator">-</span><span class="hljs-number">1</span>:x <span class="hljs-operator">--</span>quiet<br> <br># 删除碱基<br>echo <span class="hljs-operator">-</span>ne <span class="hljs-string">&quot;&gt;1<span class="hljs-subst">\n</span>ACTGNactgn<span class="hljs-subst">\n</span>&gt;2<span class="hljs-subst">\n</span>actgnACTGN<span class="hljs-subst">\n</span>&quot;</span> \<br>    <span class="hljs-operator">|</span> seqkit mutate <span class="hljs-operator">-</span>d <span class="hljs-number">1</span>:<span class="hljs-number">1</span> <span class="hljs-operator">--</span>quiet<br> <br># 删除倒数三个碱基<br>echo <span class="hljs-operator">-</span>ne <span class="hljs-string">&quot;&gt;1<span class="hljs-subst">\n</span>ACTGNactgn<span class="hljs-subst">\n</span>&gt;2<span class="hljs-subst">\n</span>actgnACTGN<span class="hljs-subst">\n</span>&quot;</span> \<br>    <span class="hljs-operator">|</span> seqkit mutate <span class="hljs-operator">-</span>d <span class="hljs-operator">-</span><span class="hljs-number">3</span>:<span class="hljs-operator">-</span><span class="hljs-number">1</span> <span class="hljs-operator">--</span>quiet<br> <br># 插入碱基<br>echo <span class="hljs-operator">-</span>ne <span class="hljs-string">&quot;&gt;1<span class="hljs-subst">\n</span>ACTGNactgn<span class="hljs-subst">\n</span>&gt;2<span class="hljs-subst">\n</span>actgnACTGN<span class="hljs-subst">\n</span>&quot;</span> \<br>    <span class="hljs-operator">|</span> seqkit mutate <span class="hljs-operator">-</span>i <span class="hljs-number">0</span>:xx <span class="hljs-operator">--</span>quiet<br><br><br></code></pre></td></tr></table></figure><h1 id="head-展示开头N行的序列"><a href="#head-展示开头N行的序列" class="headerlink" title="head 展示开头N行的序列"></a>head 展示开头N行的序列</h1><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs stylus">seqkit head -n <span class="hljs-number">1</span> hairpin<span class="hljs-selector-class">.fa</span><span class="hljs-selector-class">.gz</span><br><br><br></code></pre></td></tr></table></figure><h1 id="locate-定位子序列或者保守序列位置"><a href="#locate-定位子序列或者保守序列位置" class="headerlink" title="locate 定位子序列或者保守序列位置"></a>locate 定位子序列或者保守序列位置</h1><figure class="highlight 1c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs 1c">cat gene.fa <span class="hljs-string">| seqkit locate -p ACT | csvtk pretty -t</span><br><span class="hljs-meta"># 调整错配 最大错配为1</span><br>cat gene.fa \<br>  <span class="hljs-string">| seqkit locate -p ACTG -m 1 \</span><br>  <span class="hljs-string">| csvtk pretty -t</span><br> <br><span class="hljs-meta"># 简并碱基</span><br>zcat hairpin.fa.gz \<br>    <span class="hljs-string">| seqkit locate -i -d -p AUGGACUN \</span><br>    <span class="hljs-string">| head -n 4</span><br><br><br></code></pre></td></tr></table></figure><h1 id="restart-重置循环基因组的起始位置"><a href="#restart-重置循环基因组的起始位置" class="headerlink" title="restart 重置循环基因组的起始位置"></a>restart 重置循环基因组的起始位置</h1><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">echo</span> -e <span class="hljs-string">&quot;&gt;seq\nacgtnACGTN&quot;</span><br> <br><span class="hljs-built_in">echo</span> -e <span class="hljs-string">&quot;&gt;seq\nacgtnACGTN&quot;</span> | seqkit restart -i 2<br><span class="hljs-built_in">echo</span> -e <span class="hljs-string">&quot;&gt;seq\nacgtnACGTN&quot;</span> | seqkit restart -i -2<br><br><br></code></pre></td></tr></table></figure><h1 id="convet-二代测序质量值的转化为-Sanger"><a href="#convet-二代测序质量值的转化为-Sanger" class="headerlink" title="convet 二代测序质量值的转化为 Sanger"></a>convet 二代测序质量值的转化为 Sanger</h1><figure class="highlight clean"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs clean"># Illumina<span class="hljs-number">-1.8</span>+ -&gt; Sanger<br># seqkit convert tests/Illimina1<span class="hljs-number">.8</span>.fq.gz  | seqkit head -n <span class="hljs-number">1</span><br># <span class="hljs-number">40</span>分以上的都认为<span class="hljs-number">40</span> Illumina<span class="hljs-number">-1.8</span>+ -&gt; Sanger<br># seqkit convert tests/Illimina1<span class="hljs-number">.8</span>.fq.gz -f | seqkit head -n <span class="hljs-number">1</span><br> <br>#Illumina<span class="hljs-number">-1.8</span>+ -&gt; Illumina<span class="hljs-number">-1.5</span>+<br># seqkit convert tests/Illimina1<span class="hljs-number">.8</span>.fq.gz --to Illumina<span class="hljs-number">-1.5</span>+ | seqkit head -n <span class="hljs-number">1</span><br> <br># Illumina<span class="hljs-number">-1.8</span>+ -&gt; Illumina<span class="hljs-number">-1.5</span>+ -&gt;  Sanger.<br># seqkit convert tests/Illimina1<span class="hljs-number">.8</span>.fq.gz --to Illumina<span class="hljs-number">-1.5</span>+ | seqkit convert | seqkit head -n <span class="hljs-number">1</span><br> <br># Solexa -&gt; Sanger<br># seqkit convert tests/Illimina1<span class="hljs-number">.8</span>.fq.gz --<span class="hljs-keyword">from</span> Solexa<br> <br># Illumina<span class="hljs-number">-1.5</span>+ -&gt; Sanger<br># seqkit convert tests/Illimina1<span class="hljs-number">.5</span>.fq | seqkit head -n <span class="hljs-number">1</span><br><br><br></code></pre></td></tr></table></figure><h1 id="技术细节和使用"><a href="#技术细节和使用" class="headerlink" title="技术细节和使用"></a>技术细节和使用</h1><p>seqkit处理压缩文件</p><p>pigz 或者 gzip 在部分操作中不能加速，所以在v.0.8.1版本以便关注了，然而还是可以使用命令：</p><p>pigz -d -c seqs.fq.gz | seqkit xxx<br>因为seqkit使用了pgzip去写gzip。这比gzip和pigz更快。（10X of gzip, 4X of pigz），而且gzip压缩文件比较大。</p><p>从数据处理格式来讲</p><p>seqkit无缝支持fa和fq格式数据，并且可以自动识别。除了 faidx之外，全部命令都可以处理这两种格式的数据。</p><p>只有fa格式支持命令(subseq, split, sort和shuffle)利用FASTA索引(by flag -two-pass)下提高大文件的性能。</p><p>序列类型的检测DNA&#x2F;RNA&#x2F;Protein，会使用子序列进行，默认检测第一条子序列，通过—alphabet-guess-seq-length参数默认为10000，如果长度小于10000，则检查整条序列。</p><p>序列名字</p><p>所有的软件，包括seqkit，使用第一个空格之前的字符作为序列的名字：<br>需要注意的NCBI等一些序列的格式并不是如此，例如：</p><blockquote><p>gi|110645304|ref|NC_002516.2| Pseudomona<br>想要在seqkit中识别出来的序列ID为：NC_002516.2。</p></blockquote><p>此时使用参数–id-regexp “|([^|]+)| “，或者添加参数–id-ncbi，但如果是只要前面的gi数字作为ID的话，添加参数：–id-regexp “^gi|([^|]+)|“。</p><p>注意：.seqkit.fai不同于samtools产生的.fai格式文件，seqkit使用整个序列开头而不是ID作为索引。</p><p>并行运算</p><p>单核CPU默认线程：—threads 1，多个CPU，线程默认2.</p><p>内存占用</p><p>seqkit许多的命令都不需要将整个序列读入到内存中。包括：stat, fq2fa, fx2tab, tab2fx, grep, locate, replace, seq, sliding, subseq。</p><p>注意：如果使用subseq —gtf | —bed时，如果GTF或者BED文件太大，内存使用量会暴增，可以通过指定染色体：—chr，或者—feature去限制特征。</p><p>有一些命令需要将文件读入内存，但是可以用过rmdup 和 common减少内存使用。</p><p>随机—抽样</p><p>抽样命令sample和shuffle使用了随机功能，为了保证重现性，可以使用-s设置随机种子。这可以保证在不同的环境中可以有相同的抽样结果。</p><h1 id="序列长度分布"><a href="#序列长度分布" class="headerlink" title="序列长度分布"></a>序列长度分布</h1><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-comment"># -j 是线程数</span><br>seqkit fx2tab -j 30 -l  -n -i -H file.fastq.gz | <span class="hljs-built_in">cut</span> -f 4 &gt; Length.txt<br><span class="hljs-comment"># 查看Length.txt</span><br></code></pre></td></tr></table></figure><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs r">library<span class="hljs-punctuation">(</span>tidyverse<span class="hljs-punctuation">)</span><br><br><span class="hljs-built_in">length</span> <span class="hljs-operator">&lt;-</span> read_tsv<span class="hljs-punctuation">(</span><span class="hljs-string">&quot;Length.txt&quot;</span><span class="hljs-punctuation">)</span> <span class="hljs-operator">%&gt;%</span> group_by<span class="hljs-punctuation">(</span><span class="hljs-built_in">length</span><span class="hljs-punctuation">)</span> <span class="hljs-operator">%&gt;%</span><br>  summarise<span class="hljs-punctuation">(</span>Count <span class="hljs-operator">=</span> n<span class="hljs-punctuation">(</span><span class="hljs-punctuation">)</span><span class="hljs-punctuation">)</span><br><span class="hljs-built_in">length</span><span class="hljs-operator">$</span><span class="hljs-built_in">length</span> <span class="hljs-operator">&lt;-</span> <span class="hljs-built_in">as.character</span><span class="hljs-punctuation">(</span><span class="hljs-built_in">length</span><span class="hljs-operator">$</span><span class="hljs-built_in">length</span><span class="hljs-punctuation">)</span><br><span class="hljs-built_in">sum</span> <span class="hljs-operator">&lt;-</span> <span class="hljs-built_in">sum</span><span class="hljs-punctuation">(</span><span class="hljs-built_in">length</span><span class="hljs-operator">$</span>Count<span class="hljs-punctuation">)</span><br>ggplot<span class="hljs-punctuation">(</span><span class="hljs-built_in">length</span><span class="hljs-punctuation">)</span> <span class="hljs-operator">+</span> geom_col<span class="hljs-punctuation">(</span>aes<span class="hljs-punctuation">(</span><span class="hljs-built_in">length</span><span class="hljs-punctuation">,</span> Count<span class="hljs-punctuation">)</span><span class="hljs-punctuation">,</span> width <span class="hljs-operator">=</span> <span class="hljs-number">0.8</span><span class="hljs-punctuation">)</span> <span class="hljs-operator">+</span> <br>  geom_line<span class="hljs-punctuation">(</span>aes<span class="hljs-punctuation">(</span><span class="hljs-built_in">length</span><span class="hljs-punctuation">,</span> Count<span class="hljs-punctuation">)</span><span class="hljs-punctuation">,</span> group <span class="hljs-operator">=</span> <span class="hljs-number">1</span><span class="hljs-punctuation">)</span> <span class="hljs-operator">+</span> geom_point<span class="hljs-punctuation">(</span>aes<span class="hljs-punctuation">(</span><span class="hljs-built_in">length</span><span class="hljs-punctuation">,</span> Count<span class="hljs-punctuation">)</span><span class="hljs-punctuation">)</span> <span class="hljs-operator">+</span> <br>  scale_y_continuous<span class="hljs-punctuation">(</span>sec.axis <span class="hljs-operator">=</span> sec_axis<span class="hljs-punctuation">(</span><span class="hljs-operator">~</span>.<span class="hljs-operator">*</span><span class="hljs-number">100</span><span class="hljs-operator">/</span><span class="hljs-built_in">sum</span><span class="hljs-punctuation">,</span> name <span class="hljs-operator">=</span> <span class="hljs-string">&quot;% Relative Abundance&quot;</span><span class="hljs-punctuation">)</span><span class="hljs-punctuation">)</span> <span class="hljs-operator">+</span> xlab<span class="hljs-punctuation">(</span><span class="hljs-string">&quot;Length&quot;</span><span class="hljs-punctuation">)</span> <span class="hljs-operator">+</span><br>  theme_bw<span class="hljs-punctuation">(</span><span class="hljs-punctuation">)</span> <span class="hljs-operator">+</span> theme<span class="hljs-punctuation">(</span>panel.grid <span class="hljs-operator">=</span> element_blank<span class="hljs-punctuation">(</span><span class="hljs-punctuation">)</span><span class="hljs-punctuation">,</span> <br>                     axis.title <span class="hljs-operator">=</span> element_text<span class="hljs-punctuation">(</span>size <span class="hljs-operator">=</span> <span class="hljs-number">15</span><span class="hljs-punctuation">)</span><span class="hljs-punctuation">)</span><br><br>ggsave<span class="hljs-punctuation">(</span><span class="hljs-string">&quot;Length.png&quot;</span><span class="hljs-punctuation">,</span> height <span class="hljs-operator">=</span> <span class="hljs-number">5</span><span class="hljs-punctuation">,</span> width <span class="hljs-operator">=</span> <span class="hljs-number">8</span><span class="hljs-punctuation">)</span><br>ggsave<span class="hljs-punctuation">(</span><span class="hljs-string">&quot;Length.pdf&quot;</span><span class="hljs-punctuation">,</span> height <span class="hljs-operator">=</span> <span class="hljs-number">5</span><span class="hljs-punctuation">,</span> width <span class="hljs-operator">=</span> <span class="hljs-number">8</span><span class="hljs-punctuation">)</span><br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>Software</category>
      
    </categories>
    
    
    <tags>
      
      <tag>fastq-tool</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Linux 内存 存储</title>
    <link href="/GeekFocus/2022/02/24/2022-02-24-memory/"/>
    <url>/GeekFocus/2022/02/24/2022-02-24-memory/</url>
    
    <content type="html"><![CDATA[<h1 id=""><a href="#" class="headerlink" title=""></a></h1><span id="more"></span><h1 id="内存是什么"><a href="#内存是什么" class="headerlink" title="内存是什么"></a>内存是什么</h1><ul><li><p>内存又称主存，是 CPU 能直接寻址的存储空间，由半导体器件制成</p></li><li><p>内存的特点是存取速率快</p></li><li><p>CPU、IO、磁盘、内存可以说是影响计算机性能关键因素</p></li><li><p>内存为进程的运行提供物理空间，同时作为快速CPU和慢速磁盘之间的适配器，</p></li></ul><h1 id="内存的作用"><a href="#内存的作用" class="headerlink" title="内存的作用"></a>内存的作用</h1><ul><li><p>暂时存放 cpu 的运算数据</p></li><li><p>硬盘等外部存储器交换的数据</p></li><li><p>保障 cpu 计算的稳定性和高性能</p></li></ul><h1 id="查看内存情况"><a href="#查看内存情况" class="headerlink" title="查看内存情况"></a>查看内存情况</h1><p>free命令是一个快速查看内存使用情况的方法，它是对 &#x2F;proc&#x2F;meminfo 收集到的信息的一个概述。</p><figure class="highlight ebnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs ebnf"><span class="hljs-attribute">free -h</span><br></code></pre></td></tr></table></figure><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs sh">zds@ubuntu ~ $ free -m   <span class="hljs-comment"># 以 Mb 为单位显示</span><br>              total        used        free      shared  buff/cache   available<br><span class="hljs-comment"># 物理内存</span><br>Mem:           2990        1528         383          49        1078        1217<br><span class="hljs-comment"># 虚拟内存</span><br>Swap:          2044           0        2044<br></code></pre></td></tr></table></figure><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><code class="hljs sh">zds@ubuntu ~ $ top<br><br><br>top - 23:43:07 up 32 min,  1 user,  load average: 0.17, 0.36, 0.34<br>Tasks: 230 total,   1 running, 229 sleeping,   0 stopped,   0 zombie<br>%Cpu(s): 12.9 us,  5.6 sy,  0.0 ni, 81.5 <span class="hljs-built_in">id</span>,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st<br>KiB Mem :  2029876 total,   148224 free,   998788 used,   882864 buff/cache<br>KiB Swap:  2094076 total,  2087304 free,     6772 used.   819128 avail Mem <br><br>   PID 进程号    PR 优先级  VIRT 进程占用的虚拟内存值<br>       USER 进程所有者              RES 进程占用的物理内存值<br>                     NI 优先级相对值       SHR 进程使用的共享内存值<br><br>   PID USER      PR  NI    VIRT    RES    SHR S %CPU %MEM     TIME+ COMMAND<br>   978 root      20   0  356740  84104  37752 S  8.9  4.1   0:19.39 Xorg    <br>  1909 zds       20   0 1023828 118576  80360 S  4.6  5.8   0:18.36 compiz       <br>  2439 zds       20   0  630364  52556  42052 S  4.3  2.6   0:08.29 gnome-terminal-   <br>  1945 zds       20   0  633568  35384  28860 S  0.7  1.7   0:10.46 sogou-qimpanel- <br>     7 root      20   0       0      0      0 S  0.3  0.0   0:01.94 rcu_sched   <br>   845 root      20   0  187344   9684   8508 S  0.3  0.5   0:03.35 vmtoolsd  <br>  1631 zds       20   0   43736   4216   2924 S  0.3  0.2   0:01.82 dbus-daemon <br>  1795 zds       20   0  564648  29760  24496 S  0.3  1.5   0:01.08 unity-panel-ser<br>  1958 zds       20   0 1026996  95708  27980 S  0.3  4.7   0:07.03 gnome-software<br>  1966 zds       20   0  496776  28904  25224 S  0.3  1.4   0:03.52 vmtoolsd   <br>  7336 zds       20   0   43652   3948   3340 R  0.3  0.2   0:01.25 top  <br>     1 root      20   0  119836   5652   4024 S  0.0  0.3   0:03.27 systemd <br>     2 root      20   0       0      0      0 S  0.0  0.0   0:00.00 kthreadd <br>     3 root      20   0       0      0      0 S  0.0  0.0   0:00.52 ksoftirqd/0<br>     5 root       0 -20       0      0      0 S  0.0  0.0   0:00.00 kworker/0:0H <br>     8 root      20   0       0      0      0 S  0.0  0.0   0:00.00 rcu_bh<br>     9 root      rt   0       0      0      0 S  0.0  0.0   0:00.00 migration/0<br>    10 root      rt   0       0      0      0 S  0.0  0.0   0:00.01 watchdog/0<br>    11 root      20   0       0      0      0 S  0.0  0.0   0:00.00 kdevtmpfs <br>    12 root       0 -20       0      0      0 S  0.0  0.0   0:00.00 netns <br>    13 root       0 -20       0      0      0 S  0.0  0.0   0:00.00 perf <br>    14 root      20   0       0      0      0 S  0.0  0.0   0:00.00 khungtaskd  <br></code></pre></td></tr></table></figure><p><strong>htop</strong>命令显示了每个进程的内存实时使用率。它提供了所有进程的常驻内存大小、程序总内存大小、共享库大小等的报告。列表可以水平及垂直滚动。</p><p><strong>top</strong>命令提供了实时的运行中的程序的资源使用统计。你可以根据内存的使用和大小来进行排序。</p><h1 id="Core-Dump"><a href="#Core-Dump" class="headerlink" title="Core Dump"></a>Core Dump</h1><ul><li>Core意思是内存, Dump的意思是扔出来, 堆出来。在开发（或使用）一个程序时，有时程序莫名其妙的down了, 却没有任何提示(有时提示core dumped)。虽然系统没事，但下次仍可能遇到相同问题。这时可查看有无形如core.PID的core文件生成，这个文件便是操作系统把程序down掉时的内存内容扔出来生成的，让debugger 做参考。这个动作叫 core dump。<ul><li>core dump又叫<strong>核心转储</strong>, 当程序运行过程中发生异常, 程序异常退出时, 由操作系统把程序当前的内存状况存储在一个core文件中, 叫core dump。简而言之，<font color="red">进程异常终止，进程用户空间的数据就会被写到磁盘core文件</font>。</li></ul></li></ul><h2 id="为何有时程序Down了，却没生成-Core文件"><a href="#为何有时程序Down了，却没生成-Core文件" class="headerlink" title="为何有时程序Down了，却没生成 Core文件"></a>为何有时程序Down了，却没生成 Core文件</h2><ul><li><font color="red">有时候程序down了, 不像编译错误会提示到文件某一行，而是没有任何信息</font>。一种办法是用gdb的step（linux下调试工具gdb是很强大的调试器）, 一步一步寻找，但要step一个上万行的代码让人难以想象。 更好的办法就是core file。</li><li><font color="red">如果core文件没有生成</font>，是因为core.PID的core文件的生成跟当前系统的环境设置有关系，<font color="red">系统默认core文件的大小为0</font>（注意core file size (blocks, -c) 0 这行，表示分配给core文件的长度（单位为字节，一个块的大小要分系统而定了），为0肯定无core文件，可修改之）</li><li>用ulimit命令查看和修改core文件的大小，使用<code>ulimit -a</code>查看大小，使用 <code>ulimit -c unlimited</code>表示对core文件不做限制 或 使用<code>ulimit -c 1024</code> 对core文件分配1024个字节</li><li><font color="red">程序运行过程出现aborted(core dumped)，ulimit -a，结果确实 core file size (blocks, -c) 0，无法生成中断文件</font></li><li>若修改后再运行程序便生成<code>core.PID</code>的core文件（<strong>core文件生成的位置一般和运行程序的路径相同, 文件名一般为core.进程号</strong>）。</li></ul><h2 id="如何使用core文件"><a href="#如何使用core文件" class="headerlink" title="如何使用core文件?"></a>如何使用core文件?</h2><ul><li>发生core dump后，使用gdb查看core文件内容, 以定位文件中引发core dump的行，在Linux下，查看core文件中的出错堆栈信息有二种方式，使用：<font color="red">gdb -c core.pid program_name</font>或gdb [program_name] [core.pid]可以进入gdb模式</li><li>在进入gdb后输入<font color="red">where并回车</font>，就可以指出是在哪一行被Down掉，在哪个函数内，由谁调用等等。</li><li>在进入gdb后输入<font color="red"> bt</font>，用bt命令查看backtrace以检查发生程序运行到哪里，来定位core dump的文件-&gt;行。</li></ul><h2 id="core-dump-原因"><a href="#core-dump-原因" class="headerlink" title="core dump 原因"></a>core dump 原因</h2><ul><li><p><font color="red">batch_size过大导致的。Aborted(core dumped)</font></p></li><li><p>线程被谋杀， 被谋杀者所在线程会抛出一个异常。Cancellation &amp; C++ Exception</p></li><li><p>pure virtual method called terminate called without an active exception 解决方案</p></li></ul><p>对于多线程的程序，这个错误的主要原因是当前对象已经被销毁或者正在被销毁，但是其又在被调用，导致了冲突。</p><ul><li>pure virtual method called</li></ul><hr><h1 id="查看存储空间："><a href="#查看存储空间：" class="headerlink" title="查看存储空间："></a>查看存储空间：</h1><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs sh">zds@ubuntu ~ $ <span class="hljs-built_in">df</span> -hl<br>文件系统         容量   已用  可用 已用% 挂载点<br>udev            972M     0  972M    0% /dev<br>tmpfs           199M  6.3M  192M    4% /run<br>/dev/sda1        23G  5.3G   17G   25% /<br>tmpfs           992M  212K  991M    1% /dev/shm<br>tmpfs           5.0M  4.0K  5.0M    1% /run/lock<br>tmpfs           992M     0  992M    0% /sys/fs/cgroup<br>tmpfs           199M   60K  199M    1% /run/user/1000 <br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>Linux</category>
      
    </categories>
    
    
    <tags>
      
      <tag>note</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Genome Survey</title>
    <link href="/GeekFocus/2022/02/23/2022-02-21-Survey/"/>
    <url>/GeekFocus/2022/02/23/2022-02-21-Survey/</url>
    
    <content type="html"><![CDATA[<h1 id="Genome-survey"><a href="#Genome-survey" class="headerlink" title="Genome survey"></a>Genome survey</h1><span id="more"></span><p>基因组杂合度和重复序列对后续基因组组装有很大影响。</p><p><strong>高杂合</strong>基因组往往无法合并姊妹染色体，导致组装结果<strong>偏大</strong>。</p><p>而<strong>重复序列</strong>在组装中被折叠，使组装中出现缺口、错误，导致组装结果<strong>偏小</strong>。</p><p>不同的生物基因组之间杂合率和重复序列含量差异巨大，因此在基因组测序前需要对基因组特征进行调研，以确定测序方案，周期等。</p><p>目前常用的调研手段有三种：</p><ol><li>用流式细胞仪测定细胞核内的<strong>DNA总量</strong></li><li>用核型分析方法，识别<strong>染色体数量、倍性</strong></li><li>用调研图，通过二代测序，估算<strong>基因组大小、杂合度、重复序列比例、GC含量</strong>等。</li></ol><p>不同技术手段不同侧重，其中<font color="red">调研图</font>以<font color="green">低成本，低难度和更多的评估内容</font>使用最多，同时<font color="red"><strong>Survey所测二代数据还可用于回比基因组，评估组装质量</strong></font>。调研图<font color="green">基于数学统计学手段</font>获取物种信息的方式，因此对于已经研究的较为清晰的物种——主要是<font color="green"><strong>普通二倍体和简单多倍体</strong></font>，其<font color="green">染色体条数、倍性、大概基因组大小是已知</font>，此时仅选择<strong>survey</strong>足以满足基因组特征需要，但对于<strong>多倍体复杂基因组</strong>更推荐<strong>补充核型分析和流式</strong>，以和调研图相互印证补充。</p><hr><p><strong>Survey 方案</strong></p><p>通过质控、NT比对，获得高质量的clean data，为后续分析奠定良好基础；</p><p>基因组Survey基于小片段文库的低深度测序数据（50X）左右；</p><p>通过K-mer分析，有效的评估基因组大小、GC含量、杂合度以及重复序列的含量等信息；</p><p>全面了解某一物种基因组特征的有效方法；</p><p>为后续的全基因denove测序的组装策略的制定提供理论依据。</p><p><strong>分析内容</strong>：污染程度评估，基因组大小评估，杂合度评估，重复率评估，GC含量评估。【初步了解三代组装难度和预期大小】</p><p><strong>基因组复杂度预估?</strong></p><blockquote><p>普通基因组的定义？<br>单倍体、纯合二倍体或者杂合度&lt;0.5%，且重复序列含量&lt;50%，GC含量为35%到65%之间的二倍体。</p><p>复杂基因组的定义？<br>杂合度&gt;0.5%，重复序列含量&gt;50%，多倍体，GC含量处于异常的范围（GC含量&lt;35%或者GC含量&gt;65%的二倍体）。</p><p><font color="red">二倍体复杂基因组进一步细分为</font><br><font color="red"> 微杂合基因组（0.5%&lt;杂合率&lt;&#x3D;0.8%)</font><br><font color="red"> 高杂合基因组（杂合率&gt;0.8%)</font><br> <font color="red">高重复基因组（重复序列比例&gt;50%）</font></p><p>基因组大小：<br> 基因组越大，测序花钱越多</p></blockquote><blockquote><ul><li>简单基因组: 杂合度低于0.5%, GC含量在35%~65%, 重复序列低于50%</li><li>二倍体普通基因组: 杂合度在0.5%~1.2%中间，重复序列低于50%。或杂合度低于0.5%，重复序列低于65%</li><li>高复杂基因组: 杂合度&gt;1.2% 或 重复率大于65%</li></ul></blockquote><hr><h1 id="质控"><a href="#质控" class="headerlink" title="质控"></a>质控</h1><p>各提出10,000对比对到<strong>NT库</strong>，如果都比对到同源物种，说明无污染，如果比对到细菌真菌，可能数据有污染。</p><h2 id="rawdata-qc"><a href="#rawdata-qc" class="headerlink" title="rawdata qc"></a>rawdata qc</h2><h2 id="trim"><a href="#trim" class="headerlink" title="trim"></a>trim</h2><h2 id="cleandata-qc"><a href="#cleandata-qc" class="headerlink" title="cleandata qc"></a>cleandata qc</h2><h2 id="NT数据库比对"><a href="#NT数据库比对" class="headerlink" title="NT数据库比对"></a>NT数据库比对</h2><p>Partially non-redundant nucleotide from all traditional divisions of GenBank, EMBL, and DDBJ excluding GSS,STS, PAT, EST, HTG, and WGS.</p><p><a href="https://ftp.ncbi.nih.gov/blast/db/FASTA/">NT库</a></p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs sh">blastn \<br>-query reads_2.fa \<br>-db /local_data1/public_data/database/genome_DB/nt/20190417_all/nt \<br>-out reads_2.csv \<br>-outfmt <span class="hljs-string">&quot;10 evalue length qseqid qlen qstart qend sacc slen sstart send pident nident sstrand qcovs qseq sseq sgi stitle&quot;</span> \<br>-num_threads 4 -evalue 1e-5 -max_target_seqs 1<br></code></pre></td></tr></table></figure><hr><p><a href="https://blog.csdn.net/u012110870/article/details/82500748">https://blog.csdn.net/u012110870/article/details/82500748</a></p><h1 id="k-mers"><a href="#k-mers" class="headerlink" title="k-mers"></a>k-mers</h1><p>最简单的策略就是基于k-mer对基因组做一个简单的了解, 使用jellyfish统计k-mers，然后作图</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs sh">jellyfish count  -m 21 -s 20G -t 20 -o 21mer_out  -C --min-qual-char=? &lt;(zcat test_1.fq.gz) &lt;(zcat test_2.fq.gz)<br><span class="hljs-comment"># -m k-mers的K</span><br><span class="hljs-comment"># -s Hash大小, 根据文件大小确定</span><br><span class="hljs-comment"># -t 线程</span><br><span class="hljs-comment"># -o 输出前缀</span><br><span class="hljs-comment"># -C 统计正负链</span><br><span class="hljs-comment"># --min-qual-char 过滤低质量碱基。 在Phred+33中,?=30</span><br>jellyfish histo -o 21mer_out.histo 21mer_out<br></code></pre></td></tr></table></figure><p>用R作图</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs stylus"><span class="hljs-function"><span class="hljs-title">pdf</span><span class="hljs-params">(<span class="hljs-string">&quot;21_mer.out.pdf&quot;</span>)</span></span><br>dataframe19 &lt;- read<span class="hljs-selector-class">.table</span>(<span class="hljs-string">&quot;21mer_out.histo&quot;</span>)<br><span class="hljs-function"><span class="hljs-title">plot</span><span class="hljs-params">(dataframe19[<span class="hljs-number">1</span>:<span class="hljs-number">200</span>,], type=<span class="hljs-string">&quot;l&quot;</span>)</span></span><br>dev<span class="hljs-selector-class">.off</span>()<br></code></pre></td></tr></table></figure><p>由于只有一个主峰，说明该物种的杂合度并不高，基本上也就是二倍体。如果图中出现多个峰，说明它可能是多倍体或者是基因组杂合度高。</p><p>推荐文献: Genomic DNA k-mer spectra: models and modalities</p><h1 id="基于组装"><a href="#基于组装" class="headerlink" title="基于组装"></a>基于组装</h1><p>基于K-mers可以较好的预测基因组大小，并定性的了解基因组的复杂情况，如果想更具体的了解基因组的复杂度，可以先将50X以上的段片段进行组装，然后进行分析。</p><p>组装的工具比较多，推荐用SOAPdenovo，因为速度快。abyss?</p><p>新建一个contig.config, 增加如下内容</p><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs ini"><span class="hljs-attr">max_rd_len</span>=<span class="hljs-number">150</span><br><span class="hljs-section">[LIB]</span><br><span class="hljs-attr">avg_ins</span>=<span class="hljs-number">200</span><br><span class="hljs-attr">reverse_seq</span>=<span class="hljs-number">0</span><br><span class="hljs-attr">asm_flags</span>=<span class="hljs-number">3</span><br><span class="hljs-attr">rd_len_cutoff</span>=<span class="hljs-number">100</span><br><span class="hljs-attr">rank</span>=<span class="hljs-number">1</span><br><span class="hljs-attr">pair_num_cutoff</span>=<span class="hljs-number">3</span><br><span class="hljs-attr">map_len</span>=<span class="hljs-number">32</span><br><span class="hljs-attr">q1</span>=read_1.fq<br><span class="hljs-attr">q2</span>=read_2.fq<br></code></pre></td></tr></table></figure><p>组装出参考序列</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs awk">~<span class="hljs-regexp">/opt/</span>biosoft<span class="hljs-regexp">/SOAPdenovo2/</span>SOAPdenovo-<span class="hljs-number">63</span>mer all -s contig.config -R -K <span class="hljs-number">63</span> -p <span class="hljs-number">30</span> -o assembly/graph<br></code></pre></td></tr></table></figure><p>最后graph.scafSeq是拼接后的序列, 提取出大于300bp的序列.</p><figure class="highlight stata"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs stata"># <span class="hljs-keyword">adjust</span> <span class="hljs-keyword">format</span><br>bioawk -c fastx -v name=1 &#x27;&#123;<span class="hljs-keyword">if</span>(<span class="hljs-built_in">length</span>(<span class="hljs-variable">$seq</span>)&gt;300) <span class="hljs-keyword">print</span> <span class="hljs-string">&quot;&gt;&quot;</span>name <span class="hljs-string">&quot;\n&quot;</span> <span class="hljs-variable">$seq</span>;name+=1&#125;&#x27; assembly/<span class="hljs-keyword">graph</span>.scafSeq &gt;contig.fa<br></code></pre></td></tr></table></figure><h1 id="杂合度估计"><a href="#杂合度估计" class="headerlink" title="杂合度估计"></a>杂合度估计</h1><p>将原来的序列回贴到contig上，并用samtools+bcftools进行snp calling.统计变异的碱基占总体的比例。</p><figure class="highlight perl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs perl"><span class="hljs-keyword">mkdir</span> -p <span class="hljs-keyword">index</span><br>bwa <span class="hljs-keyword">index</span> contig.fa -p <span class="hljs-keyword">index</span>/contig<br>bwa mem -v <span class="hljs-number">2</span> -t <span class="hljs-number">10</span> <span class="hljs-keyword">index</span>/contig read_1.fq read_2.f<span class="hljs-string">q | samtools sort -n &gt; align.bam</span><br><span class="hljs-string">samtools mpileup -f contig align.bam |</span> bcftools call -mv -Oz -o variants.gz<br></code></pre></td></tr></table></figure><p>一方面由于SOAPdenovo组装过程中会出错, 另一方面samtools在变异检测上也存在很高的假阳性, 所以总得先按照深度和质量过滤一批假阳性。</p><figure class="highlight 1c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs 1c">bcftools view -i &#x27; DP &gt; 30 &amp;&amp; MQ &gt; 30&#x27; -H variants.vcf.gz <span class="hljs-string">| wc -l</span><br><span class="hljs-meta"># 325219, 无过滤是445113</span><br></code></pre></td></tr></table></figure><p>变异数目占基因组大小的比例就是杂合度。我的contig大概是200M，找到0.3M左右的变异，也就是0.0015，即0.15%.</p><h1 id="重复序列估计"><a href="#重复序列估计" class="headerlink" title="重复序列估计"></a>重复序列估计</h1><p>基于同源注释，用RepeatMasker寻找重复序列. 这里要注意分析的fasta的ID不能过长，也就是最好是<code>&gt;scaffold_1</code>这种形式，不然会报错。</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs awk">~<span class="hljs-regexp">/opt/</span>biosoft<span class="hljs-regexp">/RepeatMsker/</span>RepeatMasker -e ncbi -species arabidopsis -pa <span class="hljs-number">10</span> -gff -dir ./ contig.fa<br><span class="hljs-comment"># -e ncbi</span><br><span class="hljs-comment"># -species 选择物种 用~/opt/biosoft/RepeatMasker/util/queryRepeatDatabase.pl -tree 了解</span><br><span class="hljs-comment"># -pa 并行计算</span><br><span class="hljs-comment"># -gff 输出gff注释</span><br><span class="hljs-comment"># -dir 输出路径</span><br></code></pre></td></tr></table></figure><p>输出结果中主要关注如下三个</p><ul><li>output.fa.masked, 将重复序列用N代替</li><li>output.fa.out.gff, 以gff2形式存放重复序列出现的位置</li><li>output.fa.tbl, 该文件记录着分类信息</li></ul><figure class="highlight asciidoc"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs asciidoc">==================================================<br>file name: anno.fasta<br>sequences:         62027<br>total length:  273135210 bp  (273135210 bp excl N/X-runs)<br>GC level:         36.80 %<br>bases masked:   79642191 bp ( 29.16 %)<br>==================================================<br></code></pre></td></tr></table></figure><p>也就是说我们的物种有30%的重复序列，作为参考，拟南芥125Mb 14%重复序列, 水稻389M，36%重复</p><hr><h1 id="Grand-Omics"><a href="#Grand-Omics" class="headerlink" title="Grand Omics"></a><font color="green">Grand Omics</font></h1><p>快速：K-mer分析方法，可快速确定基因组特征</p><p>专业：简单基因组和复杂基因组（高杂合、多倍体等）采用不同算法软件</p><p>建库：Illumina PE150普通文库；或MGI PE150 普通文库。总量 ≥ 1μg；推荐数据量 ≥ 50X</p><p>分析内容：原始数据质控；数据污染检测；基因组大小预估；基因组杂合度预估</p><h2 id="数据质控及污染评估"><a href="#数据质控及污染评估" class="headerlink" title="数据质控及污染评估"></a>数据质控及污染评估</h2><p>对原始数据质控过滤，然后对原始数据（Raw data）及过滤后数据（Clean data）进行质量统计。随机取100,000条质控后的reads，统计reads在<font color="red">nt库</font>中的分布情况及比对上的物种分布，以评估数据污染情况。</p><h2 id="基因组大小和杂合度估计"><a href="#基因组大小和杂合度估计" class="headerlink" title="基因组大小和杂合度估计"></a>基因组大小和杂合度估计</h2><p>利用<font color="red">偏正态分布模型（skew normal distribution model）</font>，<font color="red">负二项式模型 (negative binomial model)</font> 对K-mer 数据进行拟合分析，进行基因组大小以及杂合度的评估，并生成最终基因组评估结果。</p><p>一般选择<strong>17-mer</strong>评估基因组大小，ATCG四种碱基组成长度为17的核苷酸片段有4(17次方)<del>17G，足以覆盖一般的正常基因组；15mer</del>1G。对于正常基因组可能覆盖度不够，导致估计不准确。&gt;15G，采用19-mer或21-mer。K-mer越大，包含错误位点的K-mer越多。为了<strong>避免回文序列，K为奇数</strong>。</p><h2 id="GC-depth-分析及污染评估"><a href="#GC-depth-分析及污染评估" class="headerlink" title="GC-depth 分析及污染评估"></a>GC-depth 分析及污染评估</h2><p>对<font color="red">组装的基因组序列</font>以<font color="red">5kb为windows</font>，无重复计算片段的<font color="red">平均GC含量和平均深度</font>并作图。基于每一个windows对应的平均GC和平均深度进行绘图。可以根据此图分析测序数据是否存在GC偏向性以及样本是否存在污染。</p><h1 id="Biomarker"><a href="#Biomarker" class="headerlink" title="Biomarker"></a><font color="green">Biomarker</font></h1><p>基因组survey以测序技术为基础，基于小片段文库的低深度测序，通过K-mer分析，快速获得基因组大小、杂合度、重复序列比例等基本信息，为制定该物种的全基因组de novo测序策略提供有效依据。</p><h2 id="调研图分析原理"><a href="#调研图分析原理" class="headerlink" title="调研图分析原理"></a>调研图分析原理</h2><p><img src="/GeekFocus/./1.png" alt="5"></p><p><img src="/GeekFocus/2022-02-21-Survey/1.png" alt="5"></p><p>k-mer，将核酸序列以滑窗分成包含k个碱基的短序列，“mer”这个单词的来源<font color="red">monomeric unit，单体单元</font>。K一般为奇数（避免正反链混淆?）。统计所有reads中所出现的k-mer类型及各类型k-mer的深度（或者频率），绘制特定k-mer下不同深度k-mer片段的频数统计图，通常选择K-mer分布最多的峰为主峰，从而得到<font color="red"><strong>基因组大小&#x3D;K-mer总数&#x2F;K-mer主峰深度值</strong></font>。</p><p>由于基因组存在<font color="red">杂合位点和重复序列</font>，k-mer曲线不是标准泊松分布，在主峰前后出现其他的峰，如果存在一定<font color="red">杂合度</font>，会导致在<font color="red">主峰横坐标的二分之一处</font>出现<font color="red">杂合峰</font>，而一定的<font color="red">重复度</font>则会在<font color="red">主峰对应的横坐标整数倍</font>处出现<font color="red">重复峰</font>。</p><h2 id="调研图分析内容"><a href="#调研图分析内容" class="headerlink" title="调研图分析内容"></a>调研图分析内容</h2><p>评估基因组<font color="red">大小</font>；评估基因组<font color="red">杂合</font>情况；评估<font color="red">重复序列</font>含量；评估基因组<font color="red">GC含量</font>；为后续精细图阶段的文库构建提供策略建议。</p><h2 id="基因组调研图survey的意义"><a href="#基因组调研图survey的意义" class="headerlink" title="基因组调研图survey的意义"></a>基因组调研图survey的意义</h2><p>启动全基因组测序的<font color="red">必要前提</font></p><p>了解与<font color="red"><strong>近缘物种间</strong>的<strong>基因组差异</strong>信息</font></p><p>获得某<font color="red">物种基因组的基本信息及难易程度</font></p><h1 id="Novogene"><a href="#Novogene" class="headerlink" title="Novogene"></a><font color="green">Novogene</font></h1><p>方案：DNA10 ug；文库350bp；PE150测序，测序深度为50X</p><h2 id="分析内容"><a href="#分析内容" class="headerlink" title="分析内容"></a>分析内容</h2><ul><li>K-mer分析</li><li>预估物种基因组大小</li><li>GC含量和外源污染分析</li><li>杂合度评估</li><li>重复序列评估</li><li>初步组装</li><li>基于初步组装的版本，可以进行SSR标记开发和同源注释【highlevel】simple sequence repeats</li></ul><h1 id="BerryGenomics"><a href="#BerryGenomics" class="headerlink" title="BerryGenomics"></a><font color="green">BerryGenomics</font></h1><p>基于小片段文库低深度测序数据，通过K-mer分析，有效评估基因组大小、GC含量、杂合度高低及重复序列含量等信息，为后续的组装策略的制定提供理论依据。</p><p><a href="https://pdf.sciencedirectassets.com/272196/1-s2.0-S0092867419X0015X/1-s2.0-S0092867420306188/main.pdf?X-Amz-Security-Token=IQoJb3JpZ2luX2VjEOj//////////wEaCXVzLWVhc3QtMSJHMEUCIEP3b6JimIkwVtoSmPnQ7fbUGBl4eNBBDDnBn4Sgw6y2AiEA9ob5g/J4zQrFLsTKjhs51/F/1tP61OMYZBAruOkb0fgq+gMIQRAEGgwwNTkwMDM1NDY4NjUiDMQhUFOWJRI31LL0UyrXA4jlyI72DidSpx8zf2iw85fV3Vmv5GwQ6zAU0go3NjgbvnEQeGHSyjCD3bfuIdLxx9+JR3iu8nTJwgeiw9+Pub8vYWrjzALVOyDRYnN4C6P68gzwDtI75rViTKSOYGpm0LXGHIuNV3O6NG9GNYo9nKQUdsmQfjBcBVHGBhXgRhFbmvWhLVufPeyZIY/sw6wiX3diCmbAuE7tTj4O0tA4ht9m/9y/rMizkGh9ZPtbzZ7JDkZm0+cpNEzpq3cQrGGNFrTcYFMQLf9YYSiY5LNr+zDXEI/cud8Oj8u3J75X7AtKXVgDFx3WOLQId9J+kxO1tSZ5/glrj2Mrth4nSXKk2TcSj6sirRM7+QbGIcYbhUHe+97GuZSfy6tJSD8POUgAUJZwoh9mtVgEIgRBR3uHjlgquc2QL4w5HsPkDpKmCRjT5ZIlJKfBli2DLWB81D9uot9Aw5SNzZ+mx3uR2mpTibb5v54gw7HtVunol7a5sq4awm3L8KRSRvUwk+fwX38TdFUH7OxZaFWIlBk536NC4ceJTACy5V5Ae+f7lhfpLN5wHzi3JomqhWFjfqqDLY11VHUBE2hJ2MtKtSQwilpBH+qtouIVYoOLFsKgJGfh0HvzkymqMQdxizDUhM2QBjqlAa9D4CUBq0ExkdHUsNdoKZ3Mz+0m1f72NRgmttBXR/CcVH6PUnSta5nZU2WQy6dUTWTx6pl8YHzW/DDLcwdU82BkQOE1n6CSzHGjaKA75v3T4RWRU9wOiObTdjqpmmMKTp2xohm4N78+/ZejYhLhk1Tx/CnUl2ue4z1/Utn17JSca5oVGbePorLRmqyYs5F3oL08SP73vwHxeNaoI7f7ucpUWqEcHA==&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20220221T081720Z&X-Amz-SignedHeaders=host&X-Amz-Expires=300&X-Amz-Credential=ASIAQ3PHCVTYYN624BKH/20220221/us-east-1/s3/aws4_request&X-Amz-Signature=16e8a26f9b71e59d421ff693fe49b021ce1222b688728bb93ce93ea82fb5968d&hash=ccc160836e462b394593db49a0b599b8a106fca7b355f59e9e05635b2a62f335&host=68042c943591013ac2b2430a89b270f6af2c76d8dfd086a07176afe7c76c2c61&pii=S0092867420306188&tid=spdf-0c4aa40e-20ae-4f30-8d50-b9cee2090b93&sid=5071d2f0595c814bfc9b6e825f0c6315e333gxrqa&type=client&ua=570456075759005851&rr=6e0e89a71f5d7c4a">大豆高质量泛基因组图谱构建</a></p><p>我国大豆消费对外依赖严重，而提高大豆产量则必须对大豆种质的遗传多样性进行综合评价。中科院遗传与发育生物学研究所等单位与贝瑞基因合作，利用最新组装策略构建了高质量的基于图形的泛基因组。该研究利用Illumina平台对来自世界大豆主产国的2,898份大豆种质进行重测序（13×），利用PacBio（96×）、Bionano和Hi-C技术对26份代表性种质进行基因组组装和泛基因组构建。并以ZH13基因组为基准基因组，整合PAVs后构建基于基因组图谱。将重测序数据重新比对到该基因组进行SVs检测和GWAS分析。在开花的主效位点<em>E3</em>发现了5种不同的单倍型；种皮颜色相关基因<em>CHS</em>的<em>I</em>位点发现5种主要单倍型；14号染色体上的缺铁褪绿症QTL内存在一个调控Fe2+&#x2F;Zn2+转运蛋白基因<em>SoyZH13_14G179600</em>。</p><hr><h1 id="Pipeline"><a href="#Pipeline" class="headerlink" title="Pipeline"></a><font color="green">Pipeline</font></h1><ul><li><p><strong>K-mer analysis</strong> (genome size,  repetive seq, heterozygous)</p><ul><li><p><a href="http://www.cbcb.umd.edu/software/jellyfish/">JELLYFISH</a>是<a href="http://www.cbcb.umd.edu/">CBCB(Center for Bioinformatics and Computational Biology)</a>的Guillaume Marçais 和 <a href="http://www.cs.cmu.edu/~ckingsf/">Carl Kingsford</a> 研发的一款计数 DNA 的 k-mers 的软件。该软件运用 Hash 表来存储数据，同时能多线程运行，速度快，内存消耗小。该软件只能运行在64位的Linux系统下。其<a href="http://bioinformatics.oxfordjournals.org/content/27/6/764">文章</a>于2011年发表在杂志 <a href="http://bioinformatics.oxfordjournals.org/">Bioinformatics</a> 上。<a href="https://www.cnblogs.com/zhanmaomao/p/9285582.html">https://www.cnblogs.com/zhanmaomao/p/9285582.html</a>,  <a href="https://github.com/gmarcais/Jellyfish#:~:text=Jellyfish%20Overview%20Jellyfish%20is%20a%20tool%20for%20fast%2C,central%20step%20in%20many%20analyses%20of%20DNA%20sequence">https://github.com/gmarcais/Jellyfish#:~:text=Jellyfish%20Overview%20Jellyfish%20is%20a%20tool%20for%20fast%2C,central%20step%20in%20many%20analyses%20of%20DNA%20sequence</a>.</p></li><li><pre><code class="sh">$ wget 最新targz$ tar zxvf .tar.gz$ mkdir jellyfish$ cd jellyfish-2.3.0$ ./configure --prefix=Your/Path/to/jellyfish如果安装在当前目录中，会报错。$ make -j 8$ make install</code></pre></li></ul><table><thead><tr><th>jellyfish</th><th>Kmer</th><th>Clean</th><th>Insert</th><th>Depth</th><th>Kpeak</th><th>HetP</th><th>Heter</th><th>repeatP</th><th>Repeat</th><th>Size</th></tr></thead><tbody><tr><td>[4]</td><td>17</td><td>30.29G</td><td>220 bp</td><td>62.99X</td><td>54.98X</td><td>26X</td><td>0.18%</td><td>106X</td><td>291.49Mb?(60.60%)</td><td>480.97 Mb</td></tr><tr><td>[5]</td><td>21</td><td>54.23G</td><td>270bp</td><td>83.69×</td><td>69 ×</td><td>34 ×</td><td>0.72%</td><td>139 ×</td><td>43.22%</td><td>648.07 Mb</td></tr><tr><td>[6]?</td><td>17</td><td>89G</td><td>350bp</td><td></td><td>48x</td><td>24x</td><td>0.69%</td><td>96x</td><td><strong>91.05%</strong></td><td>1.86G</td></tr><tr><td>[7]</td><td>19[21,23,25,27]</td><td>54.99G</td><td>270bp</td><td>45.37x</td><td>38x</td><td>19x</td><td>0.33%</td><td>76x</td><td><strong>70.62%</strong></td><td>1.2G</td></tr><tr><td>[8]自源四倍</td><td>17</td><td>27G</td><td>220</td><td></td><td>57</td><td>28</td><td><strong>1.37%</strong></td><td>114</td><td>42.81%</td><td>800M</td></tr><tr><td>[9]</td><td>17</td><td></td><td></td><td></td><td>52</td><td>26</td><td><strong>2.28%</strong></td><td>104</td><td><strong>89.2%</strong></td><td>4159 M</td></tr></tbody></table><ul><li>[6] : K-mer analysis:1.8G; flow cytometry: 8.50 ± 0.38 Gb. 巨大偏差？杂合度0.69%，重复ratio 91.05%</li></ul></li><li><p><strong>assembly</strong></p><ul><li><p>[4] : soap devovo, abyss. </p><ul><li>K-mer 31, 54, 63, 70, 77 ,83. 结果只有77，105 Kmer soapdenovo； AByss K43</li><li>optimal k-mer size was selected from the N50 length</li><li>usable reads &gt; 200 bases were selected to realign the contig </li><li>paired-end relationship between reads was coincident between contigs</li><li>scaffolds were constructed using insert size paired-ends</li></ul></li><li><p>[5] :</p></li><li><p>[8] :conduct de novo assembly. K-mer sizes of 20, 37, 55, 63, 71, 77, 83, and 95 were examined using default parameters. Assembly with k-mer 63 by SOAP de novo was selected because it has the optimal reading for N50</p><table><thead><tr><th>SOAPdenovo2</th><th>K-mer</th><th>ConN50</th><th>N90</th><th>TotalCon</th><th>ScaN50</th><th>N90</th><th>TotalSca</th><th>Genome</th></tr></thead><tbody><tr><td>[4]</td><td>77</td><td>1.48k</td><td>236</td><td>405M</td><td>3.55k</td><td>375</td><td>409M</td><td>480.97 M</td></tr><tr><td>[5]</td><td>65</td><td>1.59k</td><td>379</td><td>449M</td><td>3.5k</td><td>1262</td><td>543M</td><td>648.07 M</td></tr><tr><td>[6]?</td><td>41</td><td>287</td><td>127</td><td></td><td>1138</td><td>150</td><td></td><td></td></tr><tr><td>[7]</td><td></td><td></td><td></td><td></td><td>191bp</td><td></td><td>1.37G</td><td>1.2G</td></tr><tr><td>[8]</td><td>63</td><td>1.08k</td><td>219</td><td>170M</td><td>1.96k</td><td>1110</td><td>173M</td><td>800M</td></tr><tr><td>[9]</td><td></td><td>533</td><td></td><td></td><td>778</td><td>119</td><td>4.5G</td><td>4159M</td></tr></tbody></table></li></ul></li><li><p>GC</p><ul><li>[4] mid GC: 38%,  too high (&gt;65%) and too low (&lt;25%)</li><li>[4] GC depth two layer: only one of the two sets of homologous chromosomes in the diploid was assembled, which resulted in the emergence of the lower layer</li><li>[5] GC depth map was divided into 2 layers (Fig. 2), which was mainly due to the high heterozygosity.</li><li><font color="red"><strong>找近缘的GC做比较；看是否GC分层</strong></font></li><li>[8] the GC depth was slightly blocked into 4 layers (Fig. 2), which was in part caused by the polyploidy and the 1.37% high heterozygosity rate. 自源四倍体</li></ul></li><li><p><strong>Repetitive sequences</strong></p><ul><li>[4] :<strong>LTR_FINDER, MITE-Hunter, RepeatScout, and PILER-DF, PASTEClassifier, Repeat Masker, SciRoKo</strong> <ul><li>repetitive sequences ~147.89 Mb, 47.55% of the genome,</li><li>class I transposable element; class II transposable element</li><li>SSR(167,859SSR);  motif types</li></ul></li><li>[5] : total of 851,957 SSRs were identified,<strong>MISA</strong>. <ul><li>245 motif types</li></ul></li><li>[7] : <strong>MIcro-SAtellite(MISA)</strong><ul><li>Identification and characterisation of SSR motifs.</li><li>SSR marker verification</li></ul></li></ul></li><li><p><strong>Gene predition &amp; annotation</strong></p></li></ul><hr><p>ref</p><p><a href="https://www.jianshu.com/p/092103a24ce4">https://www.jianshu.com/p/092103a24ce4</a></p><p><a href="https://zhuanlan.zhihu.com/p/366933242">https://zhuanlan.zhihu.com/p/366933242</a></p><p>[4] Genome Survey Sequencing for the Characterization of the Genetic Background of Rosa roxburghii Tratt and Leaf Ascorbate Metabolism Genes [Plos one]</p><p>[5] Genome survey sequencing and genetic diversity of cultivated <em>Akebia trifoliata</em> assessed via phenotypes and SSR markers [Molecular Biology Reports <strong>2.3IF</strong>]</p><p>[6] : Genome survey sequencing of red swamp crayfish <em>Procambarus clarkii</em> [<strong>2.3IF</strong>] </p><p>[7] Genome survey sequencing and characterization of simple sequence repeat (SSR) markers in Platostoma palustre (Blume) A.J.Paton (Chinese mesona) [scientific reports <strong>4.3IF</strong>]</p><p>[8] Genome survey sequencing of *Dioscorea zingiberensis [genome <strong>2.1IF</strong>]</p><p>[9]Genome survey sequencing of Atractylodes lancea and identification of its SSR markers[Bioscience Reports, IF3.84]</p>]]></content>
    
    
    <categories>
      
      <category>Biology</category>
      
    </categories>
    
    
    <tags>
      
      <tag>assembly</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>jellyfish &amp; Genomescope</title>
    <link href="/GeekFocus/2022/02/23/2022-02-23-jellyfish-genomescope/"/>
    <url>/GeekFocus/2022/02/23/2022-02-23-jellyfish-genomescope/</url>
    
    <content type="html"><![CDATA[<h1 id="A-fast-lock-free-approach-for-efficient-parallel-counting-of-occurrences-of-k-mers"><a href="#A-fast-lock-free-approach-for-efficient-parallel-counting-of-occurrences-of-k-mers" class="headerlink" title="A fast, lock-free approach for efficient parallel counting of occurrences of k-mers"></a>A fast, lock-free approach for efficient parallel counting of occurrences of k-mers</h1><span id="more"></span><h1 id="1-Paper-2011"><a href="#1-Paper-2011" class="headerlink" title="1. Paper-2011 :"></a><a href="https://pubmed.ncbi.nlm.nih.gov/21217122/">1. Paper-2011</a> :</h1><ul><li><p><font color="red">Counting the number of occurrences of every k-mer</font> </p></li><li><p><font color="green">genome assembly</font></p></li><li><p><font color="purple">error correction</font> of sequencing reads</p></li><li><p><font color="daekred">fast multiple sequence alignment</font> </p></li><li><p><font color="blue">repeat detection</font></p></li><li><p><strong>current</strong> k-mer counting tools <strong>too slow</strong> , <strong>memory intensive</strong></p></li><li><p>multicore computers facilities <strong>parallel computational paradigm</strong></p></li><li><p>multithreaded, <font color="red">lock-free hash table</font> </p></li><li><p><strong>k-mers up to 31</strong> </p></li><li><p><strong>suffix arrays</strong></p></li></ul><hr><h1 id="2-github-doc"><a href="#2-github-doc" class="headerlink" title="2. github-doc :"></a><font color="red"><a href="https://github.com/gmarcais/Jellyfish/tree/master/doc">2. github-doc</a></font> :</h1><h2 id="2-1-Counting-k-mers-in-sequencing-reads"><a href="#2-1-Counting-k-mers-in-sequencing-reads" class="headerlink" title="2.1 Counting k-mers in sequencing reads"></a>2.1 Counting k-mers in sequencing reads</h2><ul><li><p>The <code>-C</code> switch instructs to save in the hash only canonical规范 k-mers, while the count is the number of occurrences of both a k-mer and it reverse complement.</p></li><li><p><font color="green"><strong>-s</strong></font> 预估值设置：The size parameter (given with <font color="red">-s</font>) is an indication of <font color="red">the number k-mers [N*(L-K+1)]</font> that will be <font color="red"><strong>stored in the hash</strong></font>. For sequencing reads, this size should be the size of <font color="red">the genome plus the k-mers generated by sequencing errors</font>. For example, if the error rate is <font color="red">e</font> (e.g.Illumina reads, usually e~<font color="red">1%</font>), with an estimated genome size of G and a coverage of <font color="red">c</font>, the number of expected k-mers is <font color="red"><strong>G+Gcek</strong></font>.</p></li></ul><blockquote><p>NOTE: unlike in Jellyfish 1, this <code>-s</code> parameter is <font color="red">only an estimation</font>. <font color="red">If the size given is too small to fit all the k-mers, the hash size will be increased automatically or partial results will be written to disk and finally merged automatically</font>. Running <code>jellyfish merge</code> should never be necessary, as now jellyfish now takes care of this task on its own. </p></blockquote><ul><li><font color="green"><strong>-s 预估kmer以hash表存储所需内存大小，设置小了会自动扩大，并自动merge</strong></font>。</li><li>If the low frequency k-mers (k-mers occurring only once), which are mostly due to sequencing errors, are not of interest, one might consider counting only high-frequency k-mers (see section <a href="https://github.com/gmarcais/Jellyfish/tree/master/doc#Counting-high-frequency-k-mers">Counting high frequency k-mers</a>), which uses less memory and is potentially faster. <font color="green"><strong>低频k-mers由测序错误导致，只考虑高频减少内存使用提高速度</strong></font>。</li></ul><h2 id="2-2-Counting-k-mers-in-a-genome"><a href="#2-2-Counting-k-mers-in-a-genome" class="headerlink" title="2.2 Counting k-mers in a genome"></a>2.2 Counting k-mers in a genome</h2><ul><li>In an 【actual genome or finished sequence？】, a k-mer and its reverse complement are not equivalent, hence using the <code>-C</code> switch does not make sense. In addition, the size for the hash can be set directly to the size of the genome.</li><li>-C没有意义？哈希表的size直接设置为基因组大小？不够自动调整？</li></ul><h2 id="2-3-Counting-high-frequency-k-mers"><a href="#2-3-Counting-high-frequency-k-mers" class="headerlink" title="2.3 Counting high-frequency k-mers"></a>2.3 Counting high-frequency k-mers</h2><p>Jellyfish offers <font color="red">two way</font> to count only high-frequency k-mers (<font color="red"><strong>count &gt;1</strong></font>), which reduces significantly the memory usage. Both methods are based on using <font color="red">Bloom filters</font>. The first method is a one pass method, which <font color="red">provides approximate count for some percentage of the k-mers</font>. The second method is a two pass method which <font color="red">provides exact count</font>. In both methods, most of the low-frequency k-mers are not reported.</p><h3 id="2-3-1-One-pass-method"><a href="#2-3-1-One-pass-method" class="headerlink" title="2.3.1 One pass method"></a>2.3.1 One pass method</h3><h3 id="2-3-2-Two-passes-method"><a href="#2-3-2-Two-passes-method" class="headerlink" title="2.3.2 Two passes method"></a>2.3.2 Two passes method</h3><h2 id="2-4-Counting-a-subset-of-k-mers"><a href="#2-4-Counting-a-subset-of-k-mers" class="headerlink" title="2.4 Counting a subset of k-mers"></a>2.4 Counting a subset of k-mers</h2><ul><li>It is possible to count the number of occurrences of <font color="red">only a subset of</font> predefined k-mers, using the <font color="red"><strong>–if</strong></font> switch. Only count the 20-mers of chromosome 20 in chromosome 1 of human</li></ul><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sh">jellyfish count -m 20 -s 100M -C -t 10 -o 20and1.jf --<span class="hljs-keyword">if</span> chr20.fa chr1.fa<br></code></pre></td></tr></table></figure><ul><li><p>This <strong>reads all the canonical 20-mers from the file chr20.fa</strong> (<font color="green"><strong>but don’t count them</strong></font>) and <font color="green"><strong>loads them in memory</strong></font>. Then it <strong>reads chr1.fa and counts the number of occurrences of the 20-mers</strong> <font color="green"><strong>only of the k-mers already loaded in memory</strong></font>.</p></li><li><p>把chr20的kmer，存储。统计chr1的20-mer在上一步存储中已存在的部分的数目。？chr1和20的关联？</p></li><li><p>Now, the histogram will also report k-mers with a <font color="green"><strong>0 count</strong></font> (<font color="green"><strong>the 20-mers of chr20</strong></font> which <font color="green"><strong>do not exists in chr1</strong></font>):</p></li></ul><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs sh">$ jellyfish histo 20and1.jf | <span class="hljs-built_in">head</span> <br>0 49401674<br>1 1116213<br>2 425471<br></code></pre></td></tr></table></figure><p>Note that the file given to <code>--if</code> is a fasta file. If a list of k-mers is available instead (say one per line in a text file), it can be transformed into a fasta file with one k-mer per line using the following one liner Perl command:</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs sh">perl -ne <span class="hljs-string">&#x27;print(&quot;&gt;\n$_&quot;)&#x27;</span><br><span class="hljs-comment">#kmer line转fa，一行&gt;号，一行kmer</span><br></code></pre></td></tr></table></figure><h2 id="2-5-如何读取压缩文件"><a href="#2-5-如何读取压缩文件" class="headerlink" title="2.5 如何读取压缩文件"></a>2.5 如何读取压缩文件</h2><p> jellyfish只读入fq或fa</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs sh">zcat *.fastq.gz | jellyfish count /dev/fd/0 ...<br><span class="hljs-comment">#using the &lt;() redirection provided by the shell (e.g. bash, zsh):</span><br><span class="hljs-comment">#!/usr/bin/bash</span><br>jellyfish count &lt;(zcat file1.fastq.gz) &lt;(zcat file2.fasta.gz) ...<br></code></pre></td></tr></table></figure><hr><h1 id="3-Jellyfish介绍"><a href="#3-Jellyfish介绍" class="headerlink" title="3. Jellyfish介绍"></a>3. Jellyfish介绍</h1><p><a href="http://www.cbcb.umd.edu/software/jellyfish/">JELLYFISH</a>是<a href="http://www.cbcb.umd.edu/">CBCB(Center for Bioinformatics and Computational Biology)</a>的Guillaume Marçais 和 <a href="http://www.cs.cmu.edu/~ckingsf/">Carl Kingsford</a> 研发的一款计数 DNA 的 k-mers 的软件。该软件运用 Hash 表来存储数据，同时能多线程运行，速度快，内存消耗小。该软件只能运行在64位的Linux系统下。其<a href="http://bioinformatics.oxfordjournals.org/content/27/6/764">文章</a>于2011年发表在杂志 <a href="http://bioinformatics.oxfordjournals.org/">Bioinformatics</a> 上。</p><h1 id="4-Jellyfish安装"><a href="#4-Jellyfish安装" class="headerlink" title="4. Jellyfish安装"></a>4. Jellyfish安装</h1><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs sh">$ wget 最新targz<br>$ tar zxvf .tar.gz<br>$ <span class="hljs-built_in">mkdir</span> jellyfish<br>$ <span class="hljs-built_in">cd</span> jellyfish-2.3.0<br>$ ./configure --prefix=Your/Path/to/jellyfish<br>如果安装在当前目录中，会报错。<br>$ make -j 8<br>$ make install<br></code></pre></td></tr></table></figure><h1 id="5-Jellyfish使用"><a href="#5-Jellyfish使用" class="headerlink" title="5. Jellyfish使用"></a>5. Jellyfish使用</h1><h2 id="jellyfish-count-【count-kmers-to-estimate-genome-size】"><a href="#jellyfish-count-【count-kmers-to-estimate-genome-size】" class="headerlink" title="jellyfish count 【count kmers to estimate genome size】"></a>jellyfish count 【count kmers to estimate genome size】</h2><p>Theory:</p><ul><li>If k is large enough so that each kmer found is unique in the genome,</li><li>and if the genome length (e.g. 1,000,000) is much larger than the kmer length (e.g. 21),</li><li>and if no PCR or sequencing errors,</li><li>then the number of kmers will be approximately equal to the length of the genome.</li></ul><p>！！！！<font color="red">Kmer counting tutorial</font>: <a href="https://bioinformatics.uconn.edu/genome-size-estimation-tutorial/#">https://bioinformatics.uconn.edu/genome-size-estimation-tutorial/#</a></p><ul><li>Jellyfish: <a href="https://github.com/gmarcais/Jellyfish">https://github.com/gmarcais/Jellyfish</a></li><li>Further jellyfish steps : <a href="https://github.com/gmarcais/Jellyfish/tree/master/doc">https://github.com/gmarcais/Jellyfish/tree/master/doc</a></li></ul><p>Note: Aug 2019: conda install seems to work only with: conda install jellyfish&#x3D;2.2.3</p><p>Steps:</p><ul><li><font color="green">“&gt;Go through</font> the sequencing reads</li><li>For each <font color="green">new kmer seen</font>, <font color="green">add to table with count</font>.</li><li>If kmer <font color="green">seen before</font>, <font color="green">increment count</font>.</li><li>Find the <font color="green">average kmer frequency</font> (sequencing depth), e.g. 50</li><li><font color="green">Exclude kmers with a count of ~ 1</font>, as these are likely from <font color="green">errors</font></li><li>Add all the other kmers, and <font color="green"><strong>divide by average kmer frequency</strong></font> &#x3D;&gt; This is the approx genome length</li></ul><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">jellyfish</span> count -m <span class="hljs-number">21</span> -s <span class="hljs-number">100</span>M -t <span class="hljs-number">10</span> -C reads.fasta<br></code></pre></td></tr></table></figure><p>To use gzipped files: and <font color="green">paired-end reads</font>:</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">jellyfish</span> count -m <span class="hljs-number">21</span> -s <span class="hljs-number">100</span>M -t <span class="hljs-number">10</span> -C &lt;zcat R1.fq.gz) &lt;(zcat R2.fq.gz)<br></code></pre></td></tr></table></figure><ul><li>-m: kmer length, 21 is commonly used, <strong>17</strong></li><li>-s: size of hash table: should be genome size + extra kmers from seq errors. <font color="green">However, it does say that hash size <strong>will be increased automatically if needed</strong>.</font></li><li>-C: canonical. <font color="green">Reverse complement kmers are considered to be identical and are counted as the same thing</font>. <font color="green"><strong>This is recommended</strong></font>.</li><li>-t: number of threads</li><li>output: mer_counts.jf</li></ul><p>Plot the histogram:</p><figure class="highlight mipsasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs mipsasm"><span class="hljs-keyword">jellyfish </span>histo -t <span class="hljs-number">10</span> mer_counts.<span class="hljs-keyword">jf </span>&gt; reads.histo<br></code></pre></td></tr></table></figure><p><strong>???Plot the histogram with an x axis of one million instead of default 10,000</strong>:</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">jellyfish</span> histo -t <span class="hljs-number">10</span> --high=<span class="hljs-number">1000000</span> mer_counts.jf &gt; reads.histo<br></code></pre></td></tr></table></figure><ul><li>Discussion on setting to 1 million: <a href="https://github.com/schatzlab/genomescope/issues/22">https://github.com/schatzlab/genomescope/issues/22</a></li><li>There may be very high counts of some kmers due to chloroplast sequences, spike-in sequences, etc.</li></ul><blockquote><p>使用fastq文件在默认参数上和fasta文件没有区别。生成的hash结果为二进制文件。</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><code class="hljs sh">-m | --mer-len=&lt;num&gt;<br> 使用的k-mer的长度。如果基因组大小为G，则k-mer长度选择为: k ~= <span class="hljs-built_in">log</span>(200G)<br>/log(4)。<br>-s | --size=&lt;num&gt;<br> Hash 的大小。最好设置的值大于总的独特的(distinct)k-mer数,这样生成的文件只<br>有一个。若该值不够大，则会生成多个<span class="hljs-built_in">hash</span>文件，以数字区分文件名。该值识别 <br>M 和 G。<br>-t | --threads=&lt;num&gt;  default: 1<br> 使用的CPU线程数<br>-o | --output=&lt;string&gt;  default: mer_counts.jf<br> 输出的结果文件前缀<br>-c | --counter-len=&lt;num&gt;  default:7<br> k-mer的计数结果所占的比特数,默认支持的最大数字是2^7=128。对于基因组测序覆盖<br>度为N，则要使设置的该值要大于N。该值越大，消耗内存越大。<br>-out-counter-len=&lt;num&gt;  default:4<br> 输出的二进制<span class="hljs-built_in">hash</span>文件中的计数结果所占的字节数,一个字节是8比特。则默认支持的最大<br>数字是2^32=4.3G<br><span class="hljs-comment">#The count of k-mers which cannot be represented with the given number of bytes will have a value equal to the maximum value that can be represented. Meaning, if the counter field uses 1 byte, any k-mers with count greater or equal to 255 will be reported of having a count of 255.</span><br>-C | --both-strand  default: <span class="hljs-literal">false</span><br> 【对正义链和反义链都进行计数】<br>-q | --quake  default: <span class="hljs-literal">false</span><br> quake兼容模式<br>--quality-start=&lt;num&gt;  default: 64<br> 起始碱基质量的ASCII值，默认为PHRED64<br>--min-quality=&lt;num&gt;  default: 0<br> 支持的最小的碱基质量值，低于此值的碱基将由N代替<br>-L | --lower-count=&lt;num&gt;<br> 【不输出数目低于此值的k-mer】<br>-U | --upper-count=&lt;num&gt;<br> 【不输出数目高于此值的k-mer】<br><span class="hljs-comment">#low frequency and high frequency k-mers can be skipped using the --L and --U` switches respectively. Although it might be more appropriate to filter out the low frequency $k$-mers using Bloom filters, as shown in section Counting-high-frequency-k-mers.</span><br></code></pre></td></tr></table></figure></blockquote><h2 id="jellyfish-merge-合并"><a href="#jellyfish-merge-合并" class="headerlink" title="jellyfish merge 合并"></a>jellyfish merge 合并</h2><p>Count的输出结果为二进制文件，可能输出多个hash文件，需要hash文件合并一个文件, merge 命令。</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-comment">#The merge subcommand is of little direct use with version version 2 of Jellyfish</span><br><span class="hljs-comment">#The count subcommand will merge intermediary files automatically as needed.</span><br>jellyfish merge -o mer_counts_merged.jf hash1 hash2 ...<br></code></pre></td></tr></table></figure><blockquote><p>-o | –output&#x3D;<string>  default: mer_counts_merged.jf<br>    输出的结果文件<br>–out-counter-len&#x3D;<num>  default: 4<br>输出的二进制hash文件中的计数结果所占的字节数,一个字节是8比特。则默认支持的最大数字是2^32&#x3D;4.3G</p></blockquote><h2 id="jellyfish-stats-统计"><a href="#jellyfish-stats-统计" class="headerlink" title="jellyfish stats 统计"></a>jellyfish stats 统计</h2><p>k-mer的结果以hash的二进制文件结果给出，需要统计出k-mer总数，特异的k-mer数目，只出现过一次的kmer数，出现了最多的k-mer的数目等信息。以stats命令来运行。使用方法：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-comment">#Although these statistics could be computed from the histogram, it provides quick summary information</span><br>$ jellyfish stats <span class="hljs-built_in">hash</span><br>示例结果为：<br>Unique:    32355544    <span class="hljs-comment">#只出现过一次的k-mer的数目</span><br>Distinct:  88414020    <span class="hljs-comment">#特异性的k-mer数目，包含上一个的数据</span><br>Total:     432232807   <span class="hljs-comment">#总的k-mer数目</span><br>Max_count: 85348       <span class="hljs-comment">#同一个k-mer出现的最多的数目</span><br></code></pre></td></tr></table></figure><blockquote><p>-L | –lower-count&#x3D;<num><br>    不统计数目低于此值的k-mer<br>-U | –upper-count&#x3D;<num><br>    不统计数目高于此值的k-mer</p></blockquote><h2 id="jellyfish-histo-绘图"><a href="#jellyfish-histo-绘图" class="headerlink" title="jellyfish histo 绘图"></a>jellyfish histo 绘图</h2><p>对k-mer的计数结果有个直观的认识，则需要统计出现了x(x&#x3D;1,2,3…)次的kmer的数目y,以x，y为横纵坐标画出直方图。使用 histo 命令能给出 x 和 y 对应的值，将结果默认输出到标准输出。其使用方法为</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sh">jellyfish histo -l 1 -h 1000 <span class="hljs-built_in">hash</span><br></code></pre></td></tr></table></figure><blockquote><p>-l | –low&#x3D;<num>  default: 1<br>    最低的 x 轴的值。同时结果会将低于此值的所有的k-mer的数目作为 (x-1) 的值。因<br>此该值为 2 和 1 的结果是一致的。<br>-h | –high&#x3D;<num>  【default: 10000？？】<br>    最高的 x 轴的值。同时结果会将高于此值的所有的k-mer的数目的和作为 (x+1) 的值。<br>-i | –increment&#x3D;<num>  default: 1<br>    x 轴取值是每隔该数值取值<br>-t | –threads&#x3D;<num>  default: 1<br>    使用的CPU线程数<br>-f | –full  default: false<br>    全部的直方图</p></blockquote><h2 id="jellyfish-dump-结果文件格式转换"><a href="#jellyfish-dump-结果文件格式转换" class="headerlink" title="jellyfish dump 结果文件格式转换"></a>jellyfish dump 结果文件格式转换</h2><p>由于count命令生成的结果为二进制的，如有需要，则可以转换成可读文本文件。使用 dump 命令，使用方法：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs sh">jellyfish dump -c -t -U 1000 <span class="hljs-built_in">hash</span><br><span class="hljs-comment">#To output all the counts for all the k-mers in the file</span><br><span class="hljs-comment">#By default, the output is in FASTA format</span><br>jellyfish dump mer_counts.jf &gt; mer_counts_dumps.fa<br></code></pre></td></tr></table></figure><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs sh">-c | --colum  default: <span class="hljs-literal">false</span><br> 生成结果为2列，第一列为k-mer序列，第二列为对应的数目。默认情况下是是fasta格<br>式，fasta的头为k-mer的数目，fasta的序列为k-mer的序列。<br>-t | --tab  default: <span class="hljs-literal">false</span><br> 当 -c 参数存在时，以tab来进行分隔两行。默认是以空格来分开的。<br><span class="hljs-comment"># Low frequency and high frequency k-mers can be skipped with the `-L` and `-U` switches respectively.</span><br>-L | --lower-count=&lt;num&gt;<br> 不输出小于该值的k-mer<br>-U | --upper-count=&lt;num&gt;<br> 不输出高于该值的k-mer<br>-o | --output=&lt;file&gt;<br> 输出文件的路径和名称<br></code></pre></td></tr></table></figure><h2 id="jellyfish-query-查询"><a href="#jellyfish-query-查询" class="headerlink" title="jellyfish query 查询"></a>jellyfish query 查询</h2><p>如果需要从Hash结果中查询指定的k-mer出现的次数，则要是用 query 命令。从标准输入读取k-mer的序列，从标准输出得到k-mer对应的数目。使用方法</p><figure class="highlight arcade"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs arcade">jellyfish query <span class="hljs-built_in">hash</span><br></code></pre></td></tr></table></figure><blockquote><p>-C | –both-strands  default: false<br>   同时查询k-mer序列的正负链<br>-i | –input&#x3D;<file><br>   输入的文件<br>-o | –output&#x3D;<file><br>   输出的文件</p></blockquote><figure class="highlight mipsasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs mipsasm"><span class="hljs-keyword">jellyfish </span>query mer_counts.<span class="hljs-keyword">jf </span>AACGTTG<br></code></pre></td></tr></table></figure><h2 id="jellyfish-info"><a href="#jellyfish-info" class="headerlink" title="jellyfish info"></a>jellyfish info</h2><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-comment">#To get some information on 【how, when and where】 this jellyfish file was 【generated】, use the info subcommand</span><br><span class="hljs-comment">#outputs some information about the jellyfish file and the command used to generated it, in which directory and at what time the command was run</span><br>jellyfish info mer_counts.jf<br></code></pre></td></tr></table></figure><h2 id="jellyfish-mem"><a href="#jellyfish-mem" class="headerlink" title="jellyfish mem"></a>jellyfish mem</h2><p>The <code>mem</code> subcommand shows how much memory a count subcommand will need or conversely how large of a hash size will fit in a given amount of memory.</p><hr><p>ref：</p><p><a href="https://www.annasyme.com/docs/jellyfish.html">https://www.annasyme.com/docs/jellyfish.html</a></p><hr><h1 id="Genomescope"><a href="#Genomescope" class="headerlink" title="Genomescope"></a>Genomescope</h1><p>安装github最新</p><p><font color="red">githubdoc</font>  : <a href="https://github.com/schatzlab/genomescope">https://github.com/schatzlab/genomescope</a></p><p><font color="red">paperlink</font> : <a href="https://doi.org/10.1093/bioinformatics/btx153">https://doi.org/10.1093/bioinformatics/btx153</a></p><h2 id="数据准备"><a href="#数据准备" class="headerlink" title="数据准备"></a>数据准备</h2><p>将paired-end数据整合？将read2数据的序列反向重复后与read1文件合并？使用Trinity附带的fastool程序完成转换。</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs sh">$ zcat read_1.clean.fq.gz | <span class="hljs-variable">$Trinity_Home</span>/trinity-plugins/fastool/fastool --illumina-trinity --to-fasta &gt; reads_1.fasta<br>$ zcat read_2.clean.fq.gz | <span class="hljs-variable">$Trinity_Home</span>/trinity-plugins/fastool/fastool --rev --illumina-trinity --to-fasta &gt; reads_2.fasta<br>$ <span class="hljs-built_in">cat</span> reads_1.fasta reads_2.fasta &gt; both.fasta<br></code></pre></td></tr></table></figure><h2 id="统计kmer"><a href="#统计kmer" class="headerlink" title="统计kmer"></a>统计kmer</h2><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sh">jellyfish count -C -m [] -s [] -t [] s.fasta -o s.jf<br></code></pre></td></tr></table></figure><h2 id="绘直方图"><a href="#绘直方图" class="headerlink" title="绘直方图"></a>绘直方图</h2><figure class="highlight mipsasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs mipsasm"><span class="hljs-keyword">jellyfish </span>histo -t <span class="hljs-number">10</span> s.<span class="hljs-keyword">jf </span>&gt; s.histo<br></code></pre></td></tr></table></figure><h2 id="参数"><a href="#参数" class="headerlink" title="参数"></a>参数</h2><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs sh">-s 预估哈希表的大小，即G+Gce*k。G是Genome Size；c是coverage（genome survey测序通常低于100x）；e是测序错误率（illumina为1%）；k是kmer大小。<br>-C 表示考虑DNA正义与反义链，遇到反义kmer时，计入正义kmer频数中。<br></code></pre></td></tr></table></figure><h2 id="绘图"><a href="#绘图" class="headerlink" title="绘图"></a>绘图</h2><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sh">Rscript genomescope.R histogram_file k-mer_length read_length output_dir [kmer_max] [verbose]<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>Biology</category>
      
    </categories>
    
    
    <tags>
      
      <tag>assembly</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>HiFi-2-SMRT Sequencing - HiFi Reads [High fidelity reads]</title>
    <link href="/GeekFocus/2022/02/20/2022-02-20-HiFi-2-SMRT/"/>
    <url>/GeekFocus/2022/02/20/2022-02-20-HiFi-2-SMRT/</url>
    
    <content type="html"><![CDATA[<h1 id="主流三代测序平台Oxford-的-Nanopore，Pacific-Biosciences（-PacBio）的-Single-Molecule-Real-Time（SMRT）Sequencing"><a href="#主流三代测序平台Oxford-的-Nanopore，Pacific-Biosciences（-PacBio）的-Single-Molecule-Real-Time（SMRT）Sequencing" class="headerlink" title="主流三代测序平台Oxford 的 Nanopore，Pacific Biosciences（ PacBio）的 Single Molecule Real-Time（SMRT）Sequencing"></a>主流三代测序平台Oxford 的 Nanopore，Pacific Biosciences（ PacBio）的 Single Molecule Real-Time（SMRT）Sequencing</h1><span id="more"></span><p>Ref:<a href="https://zhuanlan.zhihu.com/p/339875837">https://zhuanlan.zhihu.com/p/339875837</a></p><p><a href="http://pacbiofileformats.readthedocs.io/en/5.0/">http://pacbiofileformats.readthedocs.io/en/5.0/</a></p><p>PacBio优势：</p><ul><li>在不影响吞吐量和准确性前提下，提供目前<font color="green">最长的读取长度</font></li></ul><p><img src="/GeekFocus/./1.png" alt="img"></p><ul><li>如果不含系统误差，准确度可达<font color="green"> 99.999％</font></li></ul><p><img src="/GeekFocus/./2.png" alt="img"></p><ul><li>可测取富<font color="green">含AT或GC区域</font>，<font color="green">高度重复序列</font>，<font color="green">回文序列</font>等，不会产生GC的较大偏差</li><li>可以直接<font color="green">测取化学修饰</font>，在<font color="green">表观遗传学</font>中有重要应用</li></ul><h1 id="文库构建"><a href="#文库构建" class="headerlink" title="文库构建"></a>文库构建</h1><p>将样本中的DNA或RNA分子提取后，构建<font color="green">哑铃状分子结构<strong>SMRTbell</strong></font>：</p><p><img src="/GeekFocus/./3.png" alt="img"></p><p>黄色，紫色：双链DNA分子; 蓝色：接头（Adapter）</p><p>文库分子展开，一个完整的<font color="green">圆环</font>：</p><p><img src="/GeekFocus/./4.png" alt="img"></p><p>圆环结构有利于周而复始的滚环复制，利于纠错。</p><p>将样本中所有的DNA片段都构建哑铃状分子结构，组成的集合叫<font color="green">文库</font>（SMRTbell Library），随后被放到测序芯片中。</p><p>以基因组HiFi文库为例（15-20K文库）。当得到gDNA后，先利用G-tube管或Megaruptor System将基因组<strong>片段化</strong>至合适大小，而后通过<strong>去除单链悬突</strong>、<strong>损伤修复</strong>和<strong>末端修复</strong>等步骤，得到完整的双链插入片段。接下来，通过将<strong>接头连接</strong>至双链DNA来创建SMRTbell文库，从而得到环状模板。完成接头连接后，需要对连接产物进行纯化，利用<strong>酶处理</strong>来消化线性或内部损伤环形DNA分子（游离的Hairpin Adapter、两端未连接Adapter的DNA模板、已成环但内部有损伤的DNA模板），酶处理完毕后，一般会利用<strong>Bulepippin</strong>或Sage ELF System切胶<strong>回收目标大小范围</strong>内的文库。文库质检</p><h1 id="测序芯片"><a href="#测序芯片" class="headerlink" title="测序芯片"></a>测序芯片</h1><p>以 RSII 测序平台为例，测序仪芯片（SMRT Cell）：</p><p><img src="/GeekFocus/./5.png" alt="img"></p><p>放大：上面整齐排列着<font color="green">15万个</font>直径为<font color="green">70纳米的测序微孔</font>（<font color="red">Zero-Model Waveguides，ZMWs</font>）。</p><p><img src="/GeekFocus/./6.png" alt="img"></p><h1 id="上机测序"><a href="#上机测序" class="headerlink" title="上机测序"></a>上机测序</h1><h2 id="1-构建测序复合物"><a href="#1-构建测序复合物" class="headerlink" title="1. 构建测序复合物"></a>1. <strong>构建测序复合物</strong></h2><p>测序复合物：聚合酶，测序模板，测序引物</p><p><img src="/GeekFocus/./7.png" alt="img"></p><h2 id="2-复合物撒入测序小孔"><a href="#2-复合物撒入测序小孔" class="headerlink" title="2. 复合物撒入测序小孔"></a>2. <strong>复合物撒入测序小孔</strong></h2><p><img src="/GeekFocus/./8.png" alt="img"></p><h2 id="3-固定测序复合物"><a href="#3-固定测序复合物" class="headerlink" title="3. 固定测序复合物"></a>3. <strong>固定测序复合物</strong></h2><p>由于<font color="green">聚合酶加了<strong>生物素</strong></font>，在<font color="green">芯片玻璃底板有<strong>链酶亲和素</strong></font>。利用生物素和链酶亲和素的亲和力，包含聚合酶的<strong>测序复合物会被<font color="green">固定</font>在玻璃底板。</strong></p><p><img src="/GeekFocus/./9.png" alt="img"></p><h2 id="4-构建带有荧光基团的dNTP"><a href="#4-构建带有荧光基团的dNTP" class="headerlink" title="4. 构建带有荧光基团的dNTP"></a>4. <strong>构建带有荧光基团的dNTP</strong></h2><p>在芯片溶液中含有许多游离dNTP，所谓游离dNTP就是随机飘在溶液中的dNTP。</p><p>ATGC四种碱基的dNTP，在磷酸基团上分别带有<font color="green">四种颜色的荧光基团</font>。</p><p><img src="/GeekFocus/./10.png" alt="img"></p><h2 id="5-边合成边测序"><a href="#5-边合成边测序" class="headerlink" title="5. 边合成边测序"></a>5. <strong>边合成边测序</strong></h2><p>在合成时，游离的dNTP被固定在底板上的酶捕获，<font color="green">激发光会从玻璃板底部发出</font>。</p><p><video src="2022-02-20-SMRT-sequencing/11.mp4"></video><br><strong>怎么保证每次测取一个碱基？</strong></p><p><img src="/GeekFocus/./12.png" alt="img"></p><p>由于测序小孔直径很小，激发光的穿透能力会逐渐衰减，只能在小孔中传输很短的距离，所以<font color="green">只有当dNTP足够靠近底部，荧光基团才会被激发光照到，发出荧光</font>。其他游离dNTP虽然也有可能飘到小孔底部被激发光照到，但这种情况极少。<br>在一个碱基合成结束后，带有荧光基团的磷酸基团会从dNTP上掉落，发生猝灭，不影响其他碱基的信号检测。 在发生测序的小孔有各自的DNA片段和测序复合物，同一时间发出不同颜色的激发光，机器会检测到如下的光信号，实际同时会得到多达几万个光点。</p><p><img src="/GeekFocus/./13.png" alt="img"></p><p>重复上述步骤，经过计算机分析光谱，最终我们拿到样本的测序文件。SMRT Sequencing 测序过程中，<font color="green">每秒读取三个碱基</font>，一个小时可检测大约一万多碱基。</p><h2 id="6-检测碱基甲基化"><a href="#6-检测碱基甲基化" class="headerlink" title="6. 检测碱基甲基化"></a>6. <strong>检测碱基甲基化</strong></h2><p>在SMRT Sequencing测序过程中，可以<font color="green">直接测到碱基被修饰状态</font>，聚合酶遇到碱基上带有甲基化的碱基，<font color="green">合成速度明显变慢</font>，而且<font color="green">光谱也会发生改变</font>。SMRT Sequencing 可以检测到碱基的甲基化修饰。</p><h1 id="测序模型"><a href="#测序模型" class="headerlink" title="测序模型"></a>测序模型</h1><h2 id="1-Circular-Consensus-Sequencing-CCS-–-HiFi"><a href="#1-Circular-Consensus-Sequencing-CCS-–-HiFi" class="headerlink" title="1. Circular Consensus Sequencing (CCS) – HiFi"></a>1. Circular Consensus Sequencing (CCS) – HiFi</h2><p>说这种测序模型前，就不得不提三代测序最大的缺点：<font color="green">碱基读取不准，错误率在12.5%</font>。每八个碱基读错一个。</p><p>碱基读取<font color="green">错误随机</font>，重读一遍同样位置的碱基，不一定发生相同错误。</p><p>对同一个序列，多测几遍，<font color="red">矫正</font>读错碱基。</p><p>滚环复制的优势: 利用测序复合物在<font color="red">环状文库分子循环测序</font><strong>同一个片段</strong>来<font color="green">消除错误率</font>。</p><p>HiFi reads（High Fidelity reads）是2019年由PacBio推出的基于<font color="red">环化共有序列（Circular Consensus Sequencing，CCS）</font>模式产生的既兼顾长读长（<font color="red">10-20kb</font>长度）又具有高精度（&gt;99%准确率）的测序结果。</p><p>超长酶读长中，去掉接头序列，即可获得多条subreads。多条subreads合并生成高度一致性的hifi reads。</p><p><video src="2022-02-20-SMRT-sequencing/14.mp4"></video><br>这种测序模型，复制出的 Reads叫 <font color="red">HiFi Reads [High fidelity reads]</font>，测序准确率 &gt; 99%。</p><p>HiFi reads are a <strong>type of data produced using the circular consensus sequencing (CCS) mode on one of the PacBio Sequel Systems</strong>.</p><p>HiFi reads（High fidelity reads）是 <font color="red">Sequel II</font>三代测序平台推出的兼顾长读长和高准确度的测序序列，一般采用CCS（Circular Consensus Sequencing）模式测序。</p><p>在单次测序中得到更多的HiFi reads往往需要<strong>平衡</strong>测序的 <font color="red">酶读长</font>和 <font color="red">插入片段的长度</font>，插入片段太长会导致酶无法进行滚环测序，插入片段太短又牺牲了三代长读长测序的优势。</p><p>根据前期的官方经验推荐，目前HiFi文库构建的<font color="red">插入片段一般为8-13 kb</font>左右。安诺优达构建约10 kb的HiFi文库在<font color="red">Sequel II</font>平台进行测序。原始下机数据单cell产出268 Gb数据，其中<font color="red">酶平均读长51 kb</font>，<font color="red">酶读长N50 124 kb</font>，<font color="red">subreads平均读长11 kb</font>，<font color="red">subreads N50 13 kb</font>。</p><ul><li>下机数据产出统计表</li></ul><p><img src="/GeekFocus/./15.png" alt="1562200674629303.png"></p><p>进一步利用官方软件调取CCS，设置最小pass数为3，经过调取获得CCS总数据量为<strong>22.43 Gb</strong>，CCS 序列数目为<strong>172.5万</strong>条<strong>，平均长度</strong>13 kb<strong>。与下机总数据量相比，</strong>目前CCS reads的得率约为8%，并且能够兼顾reads的读长，达到平均13 kb左右，数据质量相当不错??</p><ul><li>CCS数据产出统计表</li></ul><p><img src="/GeekFocus/./16.png" alt="1562200759526715.png"></p><p>对拿到的HiFi reads进行进一步的<font color="red">质量评估</font>，我们发现大部分HiFi reads的<font color="red">准确度?</font>都在0.95以上，其中约35%的reads（pass≥10）质量值达到QV30（99.9%），这样高质量的reads非常有助于研究者开展下游深入的研究。</p><ul><li>CCS质量分布图</li></ul><p><img src="/GeekFocus/./17.png" alt="1562200823347872.png"></p><p>同时兼顾长读长和高准确度的HiFi reads究竟有何用处呢？2019年<em>BioRxiv</em>题为“<strong>Highly-accurate long-read sequencing improves variant detection and assembly of a human genome</strong>”的文章。在这篇文章里研究者利用约30X的CCS reads组装人基因组，通过<font color="green">FALCON、Canu3和 wtdbg2</font>等不同软件进行组装，<font color="red">contig N50达到15.43-28.95 Mb</font>。从组装连续性来看，<strong>CCS reads能够做到与<font color="red">传统的CLR reads</font>组装相当的结果，重要的是基因组碱基准确度得到了明显提升，基因组组装消耗的计算资源和时间大幅下降</strong>。进一步利用CCS reads进行<font color="red">SNP、InDel等变异检测</font>，发现CCS reads在小的变异检出率和准确度上都有显著提升，数据结果与30X的Illumina数据分析结果基本接近。</p><ul><li>文章中CCS reads进行SNV和InDel calling统计表</li></ul><p><img src="/GeekFocus/./18.png" alt="1562200919110586.png"></p><p>综上，HiFi reads无论在<font color="red">基因组全变异检测（SNV、InDel、SV）</font>还是<font color="red">基因组<em>de novo</em></font>领域都适用。目前<font color="red">唯一的限制因素</font>是要获得足够的HiFi reads，测序成本投入比较<font color="red">昂贵</font>，从组装<strong>计算资源节省</strong>和<strong>项目时间缩短</strong>的角度看，HiFi reads未尝不是更好的选择。<strong>对于基因组<font color="red">重复序列较多的复杂基因组</font>，目前市场上<font color="red">传统长读长测序准确度不高</font>的特点给组装造成了一定的困难，高准确度的HiFi reads未来可能是一个更好的解决方案。</strong>而对于昆虫、中草药、藻类等重复序列较高、基因组较小的物种（＜700 Mb），目前利用一个8 M SMRT Cell 产出的数据量基本足以支持CCS组装，性价比更高。需要完善的HiFi文库建库流程和基于CCS reads组装的生信流程！</p><h2 id="2-Continuous-Long-Read-CLR-Sequencing"><a href="#2-Continuous-Long-Read-CLR-Sequencing" class="headerlink" title="2. Continuous Long Read (CLR) Sequencing"></a>2. Continuous Long Read (CLR) Sequencing</h2><p>这种测序的优势在于可以读取更长的 Reads。<font color="red">？为什么更长</font></p><p><img src="/GeekFocus/./19.gif" alt="img"></p><h1 id="其他影响因素"><a href="#其他影响因素" class="headerlink" title="其他影响因素"></a>其他影响因素</h1><h2 id="1-GC-bias-影响"><a href="#1-GC-bias-影响" class="headerlink" title="1. GC bias 影响"></a>1. <font color="red">GC bias 影响</font></h2><blockquote><p>什么是 GC bias？<br>PCR 时，如果模板里的<font color="red">G、C碱基含量高，PCR效率低</font>，A、T碱基含量高，PCR效率高。一般测序过程，如二代测序，都会有大量的PCR过程。这样就会有一个问题，<font color="red">G、C含量高的片段，读到的 Reads 数少</font>。</p></blockquote><p>SMRT 没有 PCR ，因此GC含量高低的 Reads 片段都会有相似的概率被测序， GC Bias 影响小。</p><h2 id="2-读长的限制因素"><a href="#2-读长的限制因素" class="headerlink" title="2. 读长的限制因素"></a>2. 读长的限制因素</h2><ul><li><strong>DNA模板断裂</strong>，用激发光长时间照射DNA链时，会发生断裂，DNA链会从酶上掉下来，测序终止。</li><li><strong>酶变性</strong>，酶被长时间照射时，酶会变性，失去聚合酶活性，测序终止。</li><li><strong>文库序列短</strong>，如果做文库序列片段大于 20~30 K ，且保证质量的文库是有技术难度的</li></ul><h2 id="3-测序通量"><a href="#3-测序通量" class="headerlink" title="3. 测序通量"></a>3. 测序通量</h2><p><img src="/GeekFocus/./20.png" alt="img"></p><p>目前，主流的测序平台有三种，各有利弊，可以根据自己的课题来选择。</p><p>以RSII为例，将测序复合物，随机撒到15万个小孔中，正好有一个<font color="red">复合物进入到单个小孔的概率符合泊松分布</font>。理论情况是</p><ul><li>1&#x2F;3 的小孔中有<font color="red">一个</font>测序复合物，正常信号</li><li>1&#x2F;3 的小孔什么都<font color="red">没有</font>，无信号</li><li>1&#x2F;3 的小孔中有<font color="red">两个以上的测序复合物</font>，杂乱信号</li></ul><p>五万个小孔 * 10kb，所以一张芯片大约会产出500M的数据。</p><hr><h1 id="三代下机数据（以sequel-平台为主）"><a href="#三代下机数据（以sequel-平台为主）" class="headerlink" title="三代下机数据（以sequel 平台为主）"></a>三代下机数据（以sequel 平台为主）</h1><h2 id="测序过程"><a href="#测序过程" class="headerlink" title="测序过程"></a>测序过程</h2><ul><li><font color="green">A adapter</font>通用接头，两端的接头可以一样也可以不一样</li><li><font color="green">B barcode</font>(客户自己设计)</li><li><font color="green">I insert </font>插入片段，即我们测序的目的片段</li><li>由于SMRTbell是环状的，测序过程是边合成边测序，因此可以沿着新链合成的方向不停地读取序列，读取一圈又一圈</li></ul><h2 id="测序结果"><a href="#测序结果" class="headerlink" title="测序结果"></a>测序结果</h2><ul><li>根据SMRTbell的形状以及测序的过程，我们容易知道，测序出来的reads如上图所示，由接头序列, 条码序列, 插入序列间隔线性分布，即ABIB-ABIB—ABIB-ABIB—…（A: adapter, B: barcode, I: insert）</li><li><font color="green">ZMW read</font> 是测序出来的完整结果，也即是<font color="green">polymerase read</font>，聚合酶合成过的所有的序列。</li><li>PostPrimary 分析后输出<font color="green">HQ region</font>，由ZMW read <font color="green">去除两端低质量</font>区域得到。</li></ul><h2 id="测序文件"><a href="#测序文件" class="headerlink" title="测序文件"></a>测序文件</h2><ul><li><p>RS II：<a href="https://www.itdaan.com/blog/2017/05/26/6e59c682169d236cb41a2b6ba146125e.html">https://www.itdaan.com/blog/2017/05/26/6e59c682169d236cb41a2b6ba146125e.html</a></p></li><li><p>Sequel</p><ul><li>在下机文件中，主要有三类文件，<font color="red">bam 文件</font>，<font color="red">bam.pbi 文件</font>，以及<font color="red">xml文件</font>。</li><li>无fastq文件，sequel平台中bam 文件成为了fq的替代者，更节约储存空间。这是文件格式的一个重大更新。</li><li>用于后续分析的文件一般是<font color="red">.subreads.bam</font>，这等同于<font color="red">RS II </font>中的<font color="red">.subreads.fastq</font></li><li>下面介绍三类主要文件的具体格式</li></ul></li></ul><h3 id="BAM"><a href="#BAM" class="headerlink" title="BAM"></a>BAM</h3><ul><li><p><font color="green">普通bam</font>文件大多是<font color="green">比对结果文件</font>，例如用重测序分析中BWA生成的bam文件就是reads与基因组的比对文件。但<font color="red">pacbio的下机文件是没有与基因组进行过比对过</font>的，其主要作用是<font color="red">储存序列</font>。</p></li><li><p>Bam文件主要分为两个部分，头一部分是<font color="red">Header</font>，储存测序的相关信息，另一部分也即是文件的主要部分是records，保存<font color="red">序列信息</font>。就以subreads.bam文件为例，分析下bam文件的具体格式。</p></li><li><p>可以用samtools view 命令查看bam文件</p><blockquote><p>第一列：reads信息</p><p>{movieName}&#x2F;{holeNumber}&#x2F;{qStart}_{qEnd}<br>[对于CCS：{movieName}&#x2F;{holeNumber}&#x2F;ccs]<br>MovieName 是cell的名字，holeNumer是ZMW孔的编号，qStart和qEnd是subreads相对于ZMW reads的位置。<br>第二列 (sum of flags)：比对信息 均为4 代表没有比对上，也表明了bam文件只储存了序列信息，而没有比对信息。<br>第三列 (RNAM)：参考序列 值为 ，代表无参考序列<br>第四列 (position) : 比对上的第一个碱基位置 0<br>第五列 (Mapping quality) : 比对质量分数 255<br>第六列 (CIGAR值) : 比对的具体情况<br>第七列 (MRNM, ) : mate 对应的染色体<br>第八列 (mate position) : mate对应的位置 0<br>第九列 (ISIZE, Inferred fragment size) : 推断的插入片段大小 0</p><p>第十列 (Sequence) : 序列信息 具体的ATCG<br>第十一列 (ASCII码) : 碱基质量分数 ASCII+33<br>第十二列: 可选区域 记录Reads 的总体属性包括信号长度，信号强度等信息。</p></blockquote></li></ul><ol><li>zmws.bam 以及ccs.bam似乎公司并不一定会提供</li><li>经过检查，一条zmw reads 可以产生多条 subreads，也就是说subreads.bam 中，序列只是被剪下来了。</li><li>scraps.bam 格式保存的是获取subreads时废弃的序列，包括adapter，以及一些低质量的序列</li><li><strong>CCS.bam保存的是矫正后的一致性序列</strong>。</li></ol><h3 id="BAM-pbi"><a href="#BAM-pbi" class="headerlink" title="BAM.pbi"></a>BAM.pbi</h3><ul><li><p>是bam文件的<font color="red">索引文件</font>(PacBio BAM index)，与上一个版本（<font color="red">RS II</font>）的<font color="red">*cmp.h5</font>文件<font color="red">兼容</font>，其格式类似于<font color="red">HDF5</font>， 通过<font color="red"><strong>BGZF格式压缩</strong></font>。</p></li><li><p>其存在主要有两个作用</p></li><li><h5 id="随机访问"><a href="#随机访问" class="headerlink" title="随机访问"></a><font color="red">随机</font>访问</h5><p>通过参考序列，基因组区域；通过read 组别；通过qurey name；通过ZMW；通过barcode；其他</p></li><li><h5 id="在无需完全访问BAM文件的情况下，获取信息"><a href="#在无需完全访问BAM文件的情况下，获取信息" class="headerlink" title="在无需完全访问BAM文件的情况下，获取信息"></a>在无需完全访问BAM文件的情况下，获取信息</h5></li></ul><p>   获取<font color="red">统计信息</font>；通过提供index访问记录信息</p><h3 id="xml"><a href="#xml" class="headerlink" title="xml"></a>xml</h3><ul><li>MetaData, 储存数据描述。可用于<strong>filter</strong> 或者<strong>subset</strong>等功能。</li><li>sts.xml 储存数据的统计信息。</li><li>SMRT Link CL tools in 5.0.0 dataset命令可以进行方便的操作。</li></ul><hr><h1 id="Pacbio-Sequel-下机数据实例"><a href="#Pacbio-Sequel-下机数据实例" class="headerlink" title="Pacbio Sequel 下机数据实例"></a>Pacbio Sequel 下机数据实例</h1><blockquote><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs stylus">&gt;m54134_180724_220656<span class="hljs-selector-class">.scraps</span><span class="hljs-selector-class">.bam</span><br>&gt;m54134_180724_220656<span class="hljs-selector-class">.subreads</span><span class="hljs-selector-class">.bam</span><br>&gt;m54134_180724_220656<span class="hljs-selector-class">.scraps</span><span class="hljs-selector-class">.bam</span><span class="hljs-selector-class">.pbi</span><br>&gt;m54134_180724_220656<span class="hljs-selector-class">.subreads</span><span class="hljs-selector-class">.bam</span><span class="hljs-selector-class">.pbi</span><br>&gt;m54134_180724_220656<span class="hljs-selector-class">.baz2bam_1</span><span class="hljs-selector-class">.log</span><br>&gt;m54134_180724_220656<span class="hljs-selector-class">.sts</span><span class="hljs-selector-class">.xml</span><br>&gt;m54134_180724_220656<span class="hljs-selector-class">.subreadset</span><span class="hljs-selector-class">.xml</span><br>&gt;m54134_180724_220656<span class="hljs-selector-class">.transferdone</span><br>&gt;m54134_180724_220656<span class="hljs-selector-class">.adapters</span>.fasta<br></code></pre></td></tr></table></figure></blockquote><p>m54134_180724_220656.subreads.bam</p><p><font color="red">m: 是movie 的缩写</font></p><p><font color="red">54134： 是设备的编号</font></p><p><font color="red">180724_220656： 是测序运行的开始时间，为2018年07月24日22时06分56秒</font></p><p><font color="red">subreads: 这部分是不同的数据类型，一般有scraps， subreads等</font></p><p><font color="red">bam: 这是数据的格式，一般有bam格式，xml，fasta格式等</font></p><p>BAM文件官网：<a href="https://pacbiofileformats.readthedocs.io/en/3.0/BAM.html">https://pacbiofileformats.readthedocs.io/en/3.0/BAM.html</a></p><p><a href="https://github.com/PacificBiosciences/PacBioFileFormats/blob/3.0/BAM.rst">https://github.com/PacificBiosciences/PacBioFileFormats/blob/3.0/BAM.rst</a></p><h1 id="CLR-HiFi-选择"><a href="#CLR-HiFi-选择" class="headerlink" title="CLR HiFi 选择"></a>CLR HiFi 选择</h1><p><img src="/GeekFocus/./29.png" alt="img"></p><p><img src="/GeekFocus/./30.png" alt="img"></p>]]></content>
    
    
    <categories>
      
      <category>Biology</category>
      
    </categories>
    
    
    <tags>
      
      <tag>assembly</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>HiFi-1-three-generation-sequencing-techniqie</title>
    <link href="/GeekFocus/2022/02/20/2022-02-20-HiFi-1/"/>
    <url>/GeekFocus/2022/02/20/2022-02-20-HiFi-1/</url>
    
    <content type="html"><![CDATA[<h1 id="第三代测序技术指单分子测序技术。不需要PCR扩增，实现对每一条DNA分子单独测序。也叫从头测序技术，即单分子实时DNA测序。"><a href="#第三代测序技术指单分子测序技术。不需要PCR扩增，实现对每一条DNA分子单独测序。也叫从头测序技术，即单分子实时DNA测序。" class="headerlink" title="第三代测序技术指单分子测序技术。不需要PCR扩增，实现对每一条DNA分子单独测序。也叫从头测序技术，即单分子实时DNA测序。"></a>第三代测序技术指单分子测序技术。不需要PCR扩增，实现对每一条DNA分子单独测序。也叫从头测序技术，即单分子实时DNA测序。</h1><span id="more"></span><h1 id="技术原理"><a href="#技术原理" class="headerlink" title="技术原理"></a>技术原理</h1><h2 id="1"><a href="#1" class="headerlink" title="1"></a>1</h2><p><font color="green">单分子荧光测序</font>，代表性技术为<font color="green">美国螺旋生物(Helicos)</font>的<font color="green">SMS技术</font>和<font color="green">美国太平洋生物(Pacific Bioscience)</font>的<font color="green">SMRT技术</font>。脱氧核苷酸荧光标记，显微镜实时记录荧光强度变化。当荧光标记脱氧核苷酸被掺入DNA链时，荧光同时在DNA链上测到。当它与DNA链形成化学键时，荧光基团被DNA聚合酶切除，荧光消失。荧光标记脱氧核苷酸不影响DNA聚合酶活性，荧光基团切除后，合成的DNA链和天然DNA链完全一样。</p><p>PacBio采用<font color="green">边合成边测序</font>方式，以其中一条DNA链为模板，通过DNA聚合酶合成另外一条链，进一步将荧光信号转变为碱基信号。同时PacBio已升级<font color="green">CCS测序模式</font>以获得<font color="green">长读长高保真（HiFi）15 kb reads</font>，由此提升基因组组装准确性。</p><h2 id="2"><a href="#2" class="headerlink" title="2"></a>2</h2><p><font color="green">纳米孔测序</font>，<font color="green">英国牛津纳米孔公司</font>。新型纳米孔测序法（nanopore sequencing）是采用电泳技术，借助<font color="green">电泳驱动单个分子逐一通过纳米孔</font>实现测序。纳米孔直径非常细小，仅允许单个核酸聚合物通过，而ATCG<font color="green">单个碱基带电性质</font>不一样，通过<font color="green">电信号差异</font>检测出通过碱基类别，实现测序。</p><p>Nanopore当单链DNA分子穿过纳米孔，相对于每个核苷酸，获得不同电流信号。记录每个孔的离子电流变化，并基于<font color="red">马尔可夫模型</font>或<font color="red">递归神经网络</font>的方法将其转换为碱基序列。此外，<font color="green">Ultra-long reads (ULRs) </font>是ONT平台的另一重要特征，并具有促进<font color="green">大型基因组组装</font>潜力。</p><table><thead><tr><th>De novo研究</th><th>研究内容</th><th></th></tr></thead><tbody><tr><td>基因组组装</td><td>多软件组装、组装结果评估</td><td></td></tr><tr><td>基因预测与注释</td><td>编码基因预测；重复序列注释和转座元件分类；非编码RNA注释；假基因注释等</td><td></td></tr><tr><td>Hi-C辅助基因组组装</td><td>有效数据评估；Contig聚类、排序及定向分析；挂载结果评估</td><td></td></tr><tr><td>生物学问题解析</td><td>比较基因组学研究</td><td>基因家族聚类；</td></tr><tr><td></td><td></td><td>系统发育树的构建；</td></tr><tr><td></td><td></td><td>基因家族扩张与收缩分析；</td></tr><tr><td></td><td></td><td>物种分化时间推算；</td></tr><tr><td></td><td></td><td>LTR形成时间估算；</td></tr><tr><td></td><td></td><td>全基因组复制事件；</td></tr><tr><td></td><td></td><td>选择压力分析</td></tr><tr><td></td><td>特定生物学问题剖析</td><td>结合组学研究方法，深入对某物种生物学问题进行解析</td></tr></tbody></table><p><img src="/GeekFocus/./13.png" alt="33"></p><p>草莓基因家族聚类分析</p><p><img src="/GeekFocus/./14.png" alt="44"></p><p>薏苡全基因组复制事件分析</p><p><img src="/GeekFocus/./15.png" alt="img"></p><p>开心果系统进化树与基因家族收缩扩张分析</p><p><img src="/GeekFocus/./16.png" alt="img"></p><p>陆地棉亚基因组共线性分析</p><h1 id="关键点"><a href="#关键点" class="headerlink" title="关键点"></a>关键点</h1><p>第一：<font color="green">显微镜</font>实时记录DNA链荧光时，<font color="green">DNA链周围众多荧光标记脱氧核苷酸</font>形成非常强大的<font color="green">荧光背景</font>。强大荧光背景阻碍单分子荧光探测。Pacific Biosciences公司发明了一种<font color="green">直径只有几十纳米的纳米孔</font>[zero-mode waveguides (ZMWs)]，单分子的<font color="green">DNA聚合酶</font>被固定在孔内。在小孔内，DNA链<font color="green">周围荧光标记</font>的脱氧核苷酸<font color="green">有限</font>，而且由于A，T，C，G这四种荧光标记的脱氧核苷酸非常快速地从外面进入到孔内又出去，形成了非常<font color="green">稳定的背景荧光信号</font>。当某一种荧光标记的脱氧核苷酸被掺入到DNA链时，特定颜色的<font color="green">荧光会持续一小段时间</font>，直到新的化学键形成，荧光基团被DNA聚合酶切除为止。</p><p>第二：<font color="green">共聚焦显微镜</font>实时快速地对集成在<font color="green">板上的无数纳米小孔同时记录</font>。</p><h1 id="技术特点"><a href="#技术特点" class="headerlink" title="技术特点"></a>技术特点</h1><p>1、实现DNA聚合酶内在自身的<font color="green">反应速度</font>，一秒测10个碱基，测序速度是<font color="green">化学法测序2万倍</font>。</p><p>2、实现了DNA聚合酶内在自身的<font color="green">延续性</font>，一个反应可测非常长的序列。二代测序可以测到上百个碱基，但是三代测序可测几千个碱基。</p><p>3、<font color="green">精度</font>非常高，达到<font color="green">99.9999%</font>。</p><p>4、直接测<font color="green">RNA序列</font> (<strong>ISO</strong>)。既然<font color="green">DNA聚合酶</font>能够实时观测，那么以RNA为模板复制<font color="green">DNA的逆转录酶</font>也同样可以。RNA直接测序，将大大降低体外逆转录产生的系统误差。</p><p>5、第二个是直接测<font color="green">甲基化DNA序列</font>。实际上DNA聚合酶<font color="red"><strong>复制A、T、C、G的速度不一样</strong></font>。<font color="red"><strong>正常的C或者甲基化的C为模板，DNA聚合酶停顿的时间不同</strong></font>。根据时间不同，可以<font color="red"><strong>判断模板的C是否甲基化</strong></font>。</p><h1 id="平台比较"><a href="#平台比较" class="headerlink" title="平台比较"></a>平台比较</h1><table><thead><tr><th></th><th></th><th></th><th></th><th></th><th></th><th></th><th></th></tr></thead><tbody><tr><td>测序方法&#x2F;平台</td><td>公司</td><td>方法&#x2F;酶</td><td>测序长度</td><td>每个循环的数据产出量</td><td>每个循环耗时</td><td>主要错误来源</td><td></td></tr><tr><td>第三代测序技术</td><td>Heliscope&#x2F;HelicosGenetic AnalysisSystem</td><td>Helicos</td><td>边合成边测序&#x2F;DNA聚合酶</td><td>30-35 bp</td><td>21-28 Gb</td><td>8 d</td><td>替换</td></tr><tr><td>SMRT</td><td>Pacific Biosciences</td><td>边合成边测序&#x2F;DNA聚合酶</td><td>100000 bp</td><td></td><td></td><td></td><td></td></tr><tr><td>纳米孔单分子</td><td>Oxford Nanopore</td><td>电信号测序&#x2F;核酸外切酶</td><td>无限长</td><td></td><td></td><td></td><td></td></tr></tbody></table><h1 id="应用"><a href="#应用" class="headerlink" title="应用"></a>应用</h1><h2 id="基因组测序"><a href="#基因组测序" class="headerlink" title="基因组测序"></a>基因组测序</h2><p>由于具有读长长的特点，SMRT测序平台在基因组测序中能<font color="green"><strong>降低测序后的Contig数量</strong></font>，明显<font color="green"><strong>减少</strong></font>后续基因组<font color="green"><strong>拼接和注释工作量</strong></font>，节省大量时间。Christophern等仅仅用0.5的Pacbio RS系统长度的数据与二代测序(NGS)的测序数据，对<strong>马达加斯加指猴</strong>基因组进行拼装，大幅度<font color="green">提高</font>数据的<font color="green">质量和完整度</font>，同时借助Pacbio RS将原有<font color="green">Contig数量减少10倍</font>。DavidA．等利用Pachio RS平台C2试剂通过全球合作几天内就完成了从<font color="green"><strong>德国大肠杆菌疫情</strong></font>中获得的<font color="green">大肠杆菌样品</font>以及<font color="green">近似菌株</font>的测序和数据分析，最终获得<font color="green">2900bp平均读长</font>以及<font color="green">99.998%一致性准确度</font>。在对<font color="green"><strong>霍乱病菌</strong></font>的研究中第三代测序技术已初现锋芒。研究人员对<font color="green">5株霍乱菌株</font>的基因组进行了测序研究，并与其他<font color="green">23株霍乱弧菌</font>的<font color="green">基因组进行对比</font>。结果发现海地霍乱菌株与2002年和2008年孟加拉国变异霍乱弧菌ElTorO1菌株之间关系密切，而与1991年拉丁美洲霍乱分离株的关系较远。相对NGS的优势就是能<font color="red">更快获得结果</font>，因此该系统在<font color="red">鉴定新的病原体和细菌</font>的基因组测序方面得到广泛应用。</p><h2 id="甲基化研究"><a href="#甲基化研究" class="headerlink" title="甲基化研究"></a>甲基化研究</h2><p><strong>SMRT技术</strong>对DNA<strong>聚合酶</strong>的工作状态<strong>实时监测</strong>，聚合酶<strong>合成每一个碱基</strong>，都有<strong>一个时间段</strong>，而当模板碱基<strong>带有修饰时</strong>，聚合酶会<strong>慢下来</strong>，使<strong>带有修饰的碱基两个相邻的脉冲峰</strong>之间的<strong>距离</strong>和<strong>参考序列的距离之间的比值</strong>结果<strong>大于1</strong>，由此就可以推断这个位置有修饰。甲基化研究中关于<strong>5mC和5hmC</strong>（5mC的羟基化形式）是甲基化研究中的热点。但<strong>现有测序方法无法区分</strong>5mC和5hmC。<strong>美国芝加哥大学</strong>利用<strong>SMRT</strong>测序技术和<strong>5hmC的选择性化学标记方法</strong>来高通量检测5hmC。通过聚合酶动力学提供的信息，可直接检测到<font color="green">DNA甲基化</font>，包括<font color="red">N6甲基腺嘌呤、5mC和5hmC</font>，为表观遗传学研究打开了一条通路。</p><h2 id="突变鉴定（SNP检测）"><a href="#突变鉴定（SNP检测）" class="headerlink" title="突变鉴定（SNP检测）"></a>突变鉴定（SNP检测）</h2><p>单分子测序的分辨率具有不可比拟的优势，而且没有PCR扩增，就<font color="green">没有扩增引入的碱基错误</font>，该优势使其在<font color="green">特定序列的SNP检测</font>，<font color="green">稀有突变及其频率测定</font>中大显身手。例如在医学研究中，对于FLT3基因是否是急性髓细胞白血病（AML）的有效治疗靶标一直存在质疑。研究人员用单分子测序分析耐药性患者基因，意外发现耐药性与FLT3基因下游出现的稀有新突变有关，重新证明了FLT3基因是这种最常见白血病—急性髓细胞白血病（AML）的有效治疗靶标，打破了一直以来对于这一基因靶标的疑惑。凭借PacBio平均3000bp的读长，获得了更多基因下游的宝贵信息，而基于单核酸分子的测序能够<font color="red"><strong>检测到低频率（低至1%）罕见突变</strong></font>，正是这项成果的关键所在。</p><hr><p><img src="/GeekFocus/./1.png" alt="img"></p><h1 id="第一代测序"><a href="#第一代测序" class="headerlink" title="第一代测序"></a>第一代测序</h1><p>第一代DNA测序技术用的是1975年由桑格（Sanger）和考尔森（Coulson）开创的链终止法或者是1976-1977年由马克西姆（Maxam）和吉尔伯特（Gilbert）发明的化学法（链降解）. 并在1977年，桑格测定了第一个基因组序列，是噬菌体X174的，全长5375个碱基1。自此，人类获得了窥探生命遗传差异本质的能力，并以此为开端步入基因组学时代。研究人员在Sanger法的多年实践之中不断对其进行改进。在2001年，完成的首个人类基因组图谱就是以改进了的Sanger法为其测序基础，Sanger法核心原理是：由于ddNTP的2’和3’都不含羟基，其在DNA的合成过程中不能形成磷酸二酯键，因此可以用来中断DNA合成反应，在4个DNA合成反应体系中分别加入一定比例带有放射性同位素标记的ddNTP（分为：ddATP,ddCTP,ddGTP和ddTTP），通过凝胶电泳和放射自显影后可以根据电泳带的位置确定待测分子的DNA序列（图2）。这个<a href="http://smcg.cifn.unam.mx/enp-unam/03-EstructuraDelGenoma/animaciones/secuencia.swf">网址</a>为sanger测序法制作了一个小短片，形象而生动。</p><p>　　值得注意的是，就在测序技术起步发展的这一时期中，除了Sanger法之外还出现了一些其他的测序技术，如焦磷酸测序法、链接酶法等。其中，焦磷酸测序法是后来Roche公司454技术所使用的测序方法2–4，而连接酶测序法是后来ABI公司SOLID技术使用的测序方法2,4，但他们的共同核心手段都是利用了Sanger1中的可中断DNA合成反应的dNTP。</p><p><img src="/GeekFocus/./2.png" alt="img"></p><h1 id="第二代测序"><a href="#第二代测序" class="headerlink" title="第二代测序"></a>第二代测序</h1><p>总的说来，第一代测序技术的主要特点是测序读长可达1000bp，准确性高达99.999%，但其测序成本高，通量低等方面的缺点，严重影响了其真正大规模的应用。因而第一代测序技术并不是最理想的测序方法。经过不断的技术开发和改进，以Roche公司的454技术、illumina公司的Solexa，Hiseq技术和ABI公司的Solid技术为标记的第二代测序技术诞生了。第二代测序技术大大降低了测序成本的同时，还大幅提高了测序速度，并且保持了高准确性，以前完成一个人类基因组的测序需要3年时间，而使用二代测序技术则仅仅需要1周，但在序列读长方面比起第一代测序技术则要短很多。表1和图3对第一代和第二代测序技术各自的特点以及测序成本作了一个简单的比较5，以下我将对这三种主要的第二代测序技术的主要原理和特点作一个简单的介绍。 </p><p><img src="/GeekFocus/./3.png" alt="img"></p><h2 id="Illumina"><a href="#Illumina" class="headerlink" title="Illumina"></a>Illumina</h2><p>　　Illumina公司的Solexa和Hiseq应该说是目前全球使用量最大的第二代测序机器，这两个系列的技术核心原理是相同的2,4。这两个系列的机器采用的都是边合成边测序的方法，它的测序过程主要分为以下4步，如图4.</p><p>​     （1）DNA待测文库构建</p><p>　　利用超声波把待测的DNA样本打断成小片段，目前除了组装之外和一些其他的特殊要求之外，主要是打断成200-500bp长的序列片段，并在这些小片段的两端添加上不同的接头，构建出单链DNA文库。</p><p>​     （2）Flowcell</p><p>　　Flowcell是用于吸附流动DNA片段的槽道，当文库建好后，这些文库中的DNA在通过flowcell的时候会随机附着在flowcell表面的channel上。每个Flowcell有8个channel，每个channel的表面都附有很多接头，这些接头能和建库过程中加在DNA片段两端的接头相互配对（这就是为什么flowcell能吸附建库后的DNA的原因），并能支持DNA在其表面进行桥式PCR的扩增。</p><p>​     （3）桥式PCR扩增与变性</p><p>　　桥式PCR以Flowcell表面所固定的接头为模板，进行桥形扩增，如图4.a所示。经过不断的扩增和变性循环，最终每个DNA片段都将在各自的位置上集中成束，每一个束都含有单个DNA模板的很多分拷贝，进行这一过程的目的在于实现将碱基的信号强度放大，以达到测序所需的信号要求。 </p><p>（4）测序</p><p>　　测序方法采用边合成边测序的方法。向反应体系中同时添加DNA聚合酶、接头引物和带有碱基特异荧光标记的4中dNTP（如同Sanger测序法）。这些dNTP的3’-OH被化学方法所保护，因而每次只能添加一个dNTP。在dNTP被添加到合成链上后，所有未使用的游离dNTP和DNA聚合酶会被洗脱掉。接着，再加入激发荧光所需的缓冲液，用激光激发荧光信号，并有光学设备完成荧光信号的记录，最后利用计算机分析将光学信号转化为测序碱基。这样荧光信号记录完成后，再加入化学试剂淬灭荧光信号并去除dNTP 3’-OH保护基团，以便能进行下一轮的测序反应。Illumina的这种测序技术每次只添加一个dNTP的特点能够很好的地解决同聚物长度的准确测量问题，它的主要测序错误来源是碱基的替换，目前它的测序错误率在1%-1.5%之间，测序周期以人类基因组重测序为例，30x测序深度大约为1周。</p><p><img src="/GeekFocus/./4.png" alt="img"></p><p><img src="/GeekFocus/./5.png" alt="img"></p><h2 id="Roche-454"><a href="#Roche-454" class="headerlink" title="Roche 454"></a>Roche 454</h2><p>Roche 454测序系统是第一个商业化运营二代测序技术的平台。它的主要测序原理是（图5 abc）2：</p><p>（1）DNA文库制备</p><p>　　454测序系统的文件构建方式和illumina的不同，它是利用喷雾法将待测DNA打断成300-800bp长的小片段，并在片段两端加上不同的接头，或将待测DNA变性后用杂交引物进行PCR扩增，连接载体，构建单链DNA文库（图5a）。</p><p>（2）Emulsion PCR （乳液PCR，其实是一个注水到油的独特过程）</p><p>454当然DNA扩增过程也和illumina的截然不同，它将这些单链DNA结合在水油包被的直径约28um的磁珠上，并在其上面孵育、退火。</p><p>　　乳液PCR最大的特点是可以形成数目庞大的独立反应空间以进行DNA扩增。其关键技术是“注水到油”（水包油），基本过程是在PCR反应前，将包含PCR所有反应成分的水溶液注入到高速旋转的矿物油表面，水溶液瞬间形成无数个被矿物油包裹的小水滴。这些小水滴就构成了独立的PCR反应空间。理想状态下，每个小水滴只含一个DNA模板和一个磁珠。</p><p>　　这些被小水滴包被的磁珠表面含有与接头互补的DNA序列，因此这些单链DNA序列能够特异地结合在磁珠上。同时孵育体系中含有PCR反应试剂，所以保证了每个与磁珠结合的小片段都能独立进行PCR扩增，并且扩增产物仍可以结合到磁珠上。当反应完成后，可以破坏孵育体系并将带有DNA的磁珠富集下来。进过扩增，每个小片段都将被扩增约100万倍，从而达到下一步测序所要求的DNA量。</p><p>（3）焦磷酸测序</p><p>　　测序前需要先用一种聚合酶和单链结合蛋白处理带有DNA的磁珠，接着将磁珠放在一种PTP平板上。这种平板上特制有许多直径约为44um的小孔，每个小孔仅能容纳一个磁珠，通过这种方法来固定每个磁珠的位置，以便检测接下来的测序反应过程。　　</p><p>　　测序方法采用焦磷酸测序法，将一种比PTP板上小孔直径更小的磁珠放入小孔中，启动测序反应。测序反应以磁珠上大量扩增出的单链DNA为模板，每次反应加入一种dNTP进行合成反应。如果dNTP能与待测序列配对，则会在合成后释放焦磷酸基团。释放的焦磷酸基团会与反应体系中的ATP硫酸化学酶反应生成ATP。生成的ATP和荧光素酶共同氧化使测序反应中的荧光素分子并发出荧光，同时由PTP板另一侧的CCD照相机记录，最后通过计算机进行光信号处理而获得最终的测序结果。由于每一种dNTP在反应中产生的荧光颜色不同，因此可以根据荧光的颜色来判断被测分子的序列。反应结束后，游离的dNTP会在双磷酸酶的作用下降解ATP，从而导致荧光淬灭，以便使测序反应进入下一个循环。由于454测序技术中，每个测序反应都在PTP板上独立的小孔中进行，因而能大大降低相互间的干扰和测序偏差。454技术最大的优势在于其能获得较长的测序读长，当前454技术的平均读长可达400bp，并且454技术和illumina的Solexa和Hiseq技术不同，它最主要的一个缺点是无法准确测量同聚物的长度，如当序列中存在类似于PolyA的情况时，测序反应会一次加入多个T，而所加入的T的个数只能通过荧光强度推测获得，这就有可能导致结果不准确。也正是由于这一原因，454技术会在测序过程中引入插入和缺失的测序错误。 </p><p><img src="/GeekFocus/./6.png" alt="img"></p><p><img src="/GeekFocus/./7.png" alt="img"></p><p><img src="/GeekFocus/./8.png" alt="img"></p><h2 id="Solid技术"><a href="#Solid技术" class="headerlink" title="Solid技术"></a>Solid技术</h2><p>Solid测序技术是ABI公司于2007年开始投入用于商业测序应用的仪器。它基于连接酶法，即利用DNA连接酶在连接过程之中测序（图6）2,4。它的原理是：</p><p><img src="/GeekFocus/./9.png" alt="img"></p><p>　（1）DNA文库构建</p><p>​              　　片段打断并在片段两端加上测序接头，连接载体，构建单链DNA文库。</p><p>​           （2）Emulsion PCR</p><p>　　Solid的PCR过程也和454的方法类似，同样采用小水滴emulsion PCR，但这些微珠比起454系统来说则要小得多，只有1um。在扩增的同时对扩增产物的3’端进行修饰，这是为下一步的测序过程作的准备。3’修饰的微珠会被沉积在一块玻片上。在微珠上样的过程中，沉积小室将每张玻片分成1个、4个或8个测序区域（图6-a）。Solid系统最大的优点就是每张玻片能容纳比454更高密度的微珠，在同一系统中轻松实现更高的通量。</p><p>​           （3）连接酶测序</p><p>　　这一步是Solid测序的独特之处。它并没有采用以前测序时所常用的DNA聚合酶，而是采用了连接酶。Solid连接反应的底物是8碱基单链荧光探针混合物，这里将其简单表示为：3’-XXnnnzzz-5’。连接反应中，这些探针按照碱基互补规则与单链DNA模板链配对。探针的5’末端分别标记了CY5、Texas Red、CY3、6-FAM这4种颜色的荧光染料（图6-a）。这个8碱基单链荧光探针中，第1和第2位碱基（XX）上的碱基是确定的，并根据种类的不同在6-8位（zzz）上加上了不同的荧光标记。这是Solid的独特测序法，两个碱基确定一个荧光信号，相当于一次能决定两个碱基。这种测序方法也称之为两碱基测序法。当荧光探针能够与DNA模板链配对而连接上时，就会发出代表第1，2位碱基的荧光信号，图6-a和图6-b中的比色版所表示的是第1，2位碱基的不同组合与荧光颜色的关系。在记录下荧光信号后，通过化学方法在第5和第6位碱基之间进行切割，这样就能移除荧光信号，以便进行下一个位置的测序。不过值得注意的是，通过这种测序方法，每次测序的位置都相差5位。即第一次是第1、2位，第二次是第6、7位……在测到末尾后，要将新合成的链变性，洗脱。接着用引物n-1进行第二轮测序。引物n-1与引物n的区别是，二者在与接头配对的位置上相差一个碱基（图6-a. 8）。也即是，通过引物n-1在引物n的基础上将测序位置往3’端移动一个碱基位置，因而就能测定第0、1位和第5、6位……第二轮测序完成，依此类推，直至第五轮测序，最终可以完成所有位置的碱基测序，并且每个位置的碱基均被检测了两次。该技术的读长在2×50bp，后续序列拼接同样比较复杂。由于双次检测，这一技术的原始测序准确性高达99.94%，而15x覆盖率时的准确性更是达到了99.999%，应该说是目前第二代测序技术中准确性最高的了。但在荧光解码阶段，鉴于其是双碱基确定一个荧光信号，因而一旦发生错误就容易产生连锁的解码错误。</p><p><img src="/GeekFocus/./10.png" alt="img"></p><h1 id="第三代测序技术"><a href="#第三代测序技术" class="headerlink" title="第三代测序技术"></a>第三代测序技术</h1><p>以PacBio公司的<font color="red">SMRT</font>和<font color="red">Oxford Nanopore Technologies纳米孔单分子测序技术</font>，被称之为第三代测序技术。与前两代相比，最大的特点是单分子测序，测序过程<font color="red">无需PCR</font>扩增。</p><p>　　PacBio SMRT技术也应用了边合成边测序思想，并以SMRT芯片为测序载体。基本原理： DNA聚合酶和模板结合,4色荧光标记 4 种碱基（即是dNTP）,在碱基配对阶段,不同碱基加入,发不同光,根据<font color="green">光的波长与峰值</font>判断进入碱基类型。 DNA 聚合酶是实现超长读长的关键之一,读长主要跟<font color="red">酶的活性保持</font>有关,它主要受激光对其造成的损伤所影响。</p><p>​PacBio SMRT技术的一个关键是怎样将反应信号与周围游离碱基的<font color="red">强大荧光背景</font>区别。<font color="red"><strong>ZMW（零模波导孔）原理</strong></font>：如同微波炉壁上可看到的很多密集小孔。小孔直径有考究,如果直径大于微波波长,能量就会在衍射效应的作用下穿透面板而泄露出来，从而与周围小孔相互干扰。如果孔径小于波长,能量不会辐射到周围，而是保持直线状态（光衍射的原理）,从而可起保护作用。同理,在一个反应管(SMRTCell:单分子实时反应孔)中有许多这样的圆形纳米小孔, 即 ZMW(零模波导孔),外径 100多纳米,比检测激光波长小(数百纳米),激光从底部打上去后不能穿透小孔进入上方溶液区,能量被限制在一个小范围(体积20X 10-21 L)里,正好足够覆盖需要检测的部分,使得信号仅来自这个小反应区域,孔外过多游离核苷酸单体依然留在黑暗中,从而实现将背景降到最低。另外，可以通过检测相邻两个碱基之间的测序时间，来检测一些碱基修饰情况，既如果碱基存在修饰，则通过聚合酶时的速度会减慢，相邻两峰之间的距离增大，可以通过这个来之间检测甲基化等信息（图7）。SMRT技术的测序速度很快，每秒约10个dNTP。但是，同时其测序<font color="red">错误率比较高</font>（这几乎是目前单分子测序技术的通病），达到<font color="red">15%</font>,但好在它的出错是随机的，并不会像第二代测序技术那样存在测序错误的偏向，因而可以通过<font color="red">多次测序来进行有效的纠错</font>。</p><p><img src="/GeekFocus/./11.png" alt="img"></p><p>Oxford Nanopore Technologies公司所开发的纳米单分子测序技术与以往的测序技术皆不同，它是基于电信号而不是光信号的测序技术。该技术的关键之一是，他们设计了一种特殊的纳米孔，孔内共价结合有分子接头。当DNA碱基通过纳米孔时，它们使电荷发生变化，从而短暂地影响流过纳米孔的电流强度（每种碱基所影响的电流变化幅度是不同的），灵敏的电子设备检测到这些变化从而鉴定所通过的碱基。</p><p>　　该公司在去年基因组生物学技术进展年会(AGBT)上推出第一款商业化的纳米孔测序仪，引起了科学界的极大关注。纳米孔测序（和其他第三代测序技术）有望解决目前测序平台的不足，纳米孔测序的主要特点是：读长很长，大约在几十kb，甚至100 kb;错误率目前介于1%至4%，且是随机错误，而不是聚集在读取的两端;数据可实时读取;通量很高(30x人类基因组有望在一天内完成);起始DNA在测序过程中不被破坏;以及样品制备简单又便宜。理论上，它也能直接测序RNA。</p><p>　　纳米孔单分子测序计算还有另一大特点，它能够直接读取出甲基化的胞嘧啶，而不必像传统方法那样对基因组进行bisulfite处理。这对于在基因组水平直接研究表观遗传相关现象有极大的帮助。并且改方法的测序准确性可达99.8%，而且一旦发现测序错误也能较容易地进行纠正。但目前似乎还没有应用该技术的相关报道。</p><p><img src="/GeekFocus/./12.png" alt="img"></p><h1 id="其他测序技术"><a href="#其他测序技术" class="headerlink" title="其他测序技术"></a>其他测序技术</h1><p>目前还有一种基于半导体芯片的新一代革命性测序技术——Ion Torrent6。该技术使用了一种布满小孔的高密度半导体芯片， 一个小孔就是一个测序反应池。当DNA聚合酶把核苷酸聚合到延伸中的DNA链上时，会释放出一个氢离子，反应池中的PH发生改变，位于池下的离子感受器感受到H+离子信号，H+离子信号再直接转化为数字信号，从而读出DNA序列（图9）。这一技术的发明人同时也是454测序技术的发明人之一——Jonathan Rothberg，它的文库和样本制备跟454技术很像，甚至可以说就是454的翻版，只是测序过程中不是通过检测焦磷酸荧光显色，而是通过检测H+信号的变化来获得序列碱基信息。Ion Torrent相比于其他测序技术来说，不需要昂贵的物理成像等设备，因此，成本相对来说会低，体积也会比较小，同时操作也要更为简单，速度也相当快速，除了2天文库制作时间，整个上机测序可在2-3.5小时内完成，不过整个芯片的通量并不高，目前是10G左右，但非常适合小基因组和外显子验证的测序。    </p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>以上，对各代测序技术的原理做了简要的阐述，这三代测序技术的特点比较汇总在以下表1和表2中。其中测序成本，读长和通量是评估该测序技术先进与否的三个重要指标。第一代和第二代测序技术除了通量和成本上的差异之外，其测序核心原理（除Solid是边连接边测序之外）都是基于边合成边测序的思想。第二代测序技术的优点是成本较之一代大大下降，通量大大提升，但缺点是所引入PCR过程会在一定程度上增加测序的错误率，并且具有系统偏向性，同时读长也比较短。第三代测序技术是为了解决第二代所存在的缺点而开发的，它的根本特点是单分子测序，不需要任何PCR的过程，这是为了能有效避免因PCR偏向性而导致的系统错误，同时提高读长，并要保持二代技术的高通量，低成本的优点。</p><table><thead><tr><th><strong>第<strong><strong>X</strong></strong>代</strong></th><th><strong>公司</strong></th><th><strong>平台名称</strong></th><th><strong>测序方法</strong></th><th><strong>检测方法</strong></th><th><strong>大约读长</strong><strong>(<strong><strong>碱基数</strong></strong>)</strong></th><th><strong>优点</strong></th><th><strong>相对局限性</strong></th></tr></thead><tbody><tr><td>第一代</td><td>ABI&#x2F;生命技术公司</td><td>3130xL-3730xL</td><td>桑格-毛细管电泳测序法</td><td>荧光&#x2F;光学</td><td>600-1000</td><td>高读长，准确度一次性达标率高，能很好处理重复序列和多聚序列</td><td>通量低；样品制备成本高，使之难以做大量的平行测序</td></tr><tr><td>第一代</td><td>贝克曼</td><td>GeXP遗传分析系统</td><td>桑格-毛细管电泳测序法</td><td>荧光&#x2F;光学</td><td>600-1000</td><td>高读长，准确度一次性达标率高，能很好处理重复序列和多聚序列；易小型化</td><td>通量低；单个样品的制备成本相对较高</td></tr><tr><td>第二代</td><td>Roche&#x2F;454</td><td>基因组测序仪FLX系统</td><td>焦磷酸测序法</td><td>光学</td><td>230-400</td><td>在第二代中最高读长；比第一代的测序通量大</td><td>样品制备较难；难于处理重复和同种碱基多聚区域；试剂冲洗带来错误累积；仪器昂贵</td></tr><tr><td>第二代</td><td>Illumina</td><td>HiSeq2000,HiSeq2500&#x2F;MiSeq</td><td>可逆链终止物和合成测序法</td><td>荧光&#x2F;光学</td><td><strong>2x150</strong></td><td>很高测序通量</td><td>仪器昂贵；用于数据删节和分析的费用很高</td></tr><tr><td>第二代</td><td>ABI&#x2F;Solid</td><td>5500xlSolid系统</td><td>连接测序法</td><td>荧光&#x2F;光学</td><td>25-35</td><td>很高测序通量；在广为接受的几种第二代平台中，所要拼接出人类基因组的试剂成本最低</td><td>测序运行时间长；读长短，造成成本高，数据分析困难和基因组拼接困难；仪器昂贵</td></tr><tr><td>第二代</td><td>赫利克斯</td><td>Heliscope</td><td>单分子合成测序法</td><td>荧光&#x2F;光学</td><td>25-30</td><td>高通量；在第二代中属于单分子性质的测序技术</td><td>读长短，推高了测序成本，降低了基因组拼接的质量；仪器非常昂贵</td></tr><tr><td>第三代</td><td>太平洋生物科学公司</td><td>PacBio RS</td><td>实时单分子DNA测序</td><td>荧光&#x2F;光学</td><td>~1000</td><td>高平均读长，比第一代的测序时间降低；不需要扩增；最长单个读长接近3000碱基</td><td>并不能高效地将DNA聚合酶加到测序阵列中；准确性一次性达标的机会低（81-83%）；DNA聚合酶在阵列中降解；总体上每个碱基测序成本高（仪器昂贵）；</td></tr><tr><td>第三代</td><td>全基因组学公司</td><td>GeXP遗传分析系统</td><td>复合探针锚杂交和连接技术</td><td>荧光&#x2F;光学</td><td>10</td><td>在第三代中通量最高；在所有测序技术中，用于拼接一个人基因组的试剂成本最低；每个测序步骤独立，使错误的累积变得最低</td><td>低读长； 模板制备妨碍长重复序列区域测序；样品制备费事；尚无商业化供应的仪器</td></tr><tr><td>第三代</td><td>Ion Torrent&#x2F;生命技术公司</td><td>个人基因组测序仪（PGM）</td><td>合成测序法</td><td>以离子敏感场效应晶体管检测pH值变化</td><td>100-200</td><td>对核酸碱基的掺入可直接测定；在自然条件下进行DNA合成（不需要使用修饰过的碱基）</td><td>一步步的洗脱过程可导致错误累积；阅读高重复和同种多聚序列时有潜在困难；</td></tr><tr><td>第三代</td><td>牛津纳米孔公司</td><td>gridION</td><td>纳米孔外切酶测序</td><td>电流</td><td>尚未定量</td><td>有潜力达到高读长；可以成本生产纳米孔；无需荧光标记或光学手段</td><td>切断的核苷酸可能被读错方向；难于生产出带多重平行孔的装置</td></tr></tbody></table><hr><p>ref</p><p><a href="https://www.cnblogs.com/huangshujia/p/3233693.html">https://www.cnblogs.com/huangshujia/p/3233693.html</a></p><p><a href="http://www.biomarker.com.cn/technology-services/denovo3">http://www.biomarker.com.cn/technology-services/denovo3</a></p><p><a href="https://zhuanlan.zhihu.com/p/339875837">https://zhuanlan.zhihu.com/p/339875837</a></p>]]></content>
    
    
    <categories>
      
      <category>Biology</category>
      
    </categories>
    
    
    <tags>
      
      <tag>assembly</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>assembly</title>
    <link href="/GeekFocus/2022/02/19/2022-02-19_assembly/"/>
    <url>/GeekFocus/2022/02/19/2022-02-19_assembly/</url>
    
    <content type="html"><![CDATA[<p>Pacbio</p><span id="more"></span><p><a href="https://www.bilibili.com/video/BV1pD4y1R7nK">https://www.bilibili.com/video/BV1pD4y1R7nK</a></p><h1 id="1目标，现状和影响因素"><a href="#1目标，现状和影响因素" class="headerlink" title="1目标，现状和影响因素"></a>1目标，现状和影响因素</h1><h2 id="追求"><a href="#追求" class="headerlink" title="追求"></a>追求</h2><p>基因组组装：连续度contigN50，准确度，速度。</p><p>仪器：Pacbio</p><p>实验：CLR，CCS文库</p><p>软件：Canu，Falcon，Smartdenovo，WTDBG</p><h2 id="挑战"><a href="#挑战" class="headerlink" title="挑战"></a>挑战</h2><p>复杂度：基因组重复度，杂合度。<strong>Survey</strong></p><p>数据量：CLR：100X左右；HIFI：25X（纠错后）</p><p>算法是否合适：OLC，DBG</p><p>数据质量：Pacbio：碱基质量（纠错CDS？Q40？）；ONT：序列长度</p><h1 id="2基因组组装的软件使用方法"><a href="#2基因组组装的软件使用方法" class="headerlink" title="2基因组组装的软件使用方法"></a>2基因组组装的软件使用方法</h1><h2 id="组装软件"><a href="#组装软件" class="headerlink" title="组装软件"></a>组装软件</h2><ul><li>Canu：三代数据主流软件，具有纠错，修正和组装功能</li></ul><p>比较慢，准确度高，连续度表现优秀的概率高</p><ul><li>Falcon：PB公司推荐，可用于杂合度较高或亲缘关系较远物种组装</li></ul><p>适合一定的杂合基因组，可以装出haplotype区域，一定杂合的基因可以利用hic数据进行Mb级别的phasing</p><ul><li>Smart Denovo适用PB和ONT，无纠错</li><li>WTDBG：内存及存储占用少，速度快</li></ul><p>速度快，对重复序列敏感，简单基因组组装效果比较好</p><ul><li>Hifiasm：适用HiFi。速度快，连续度高，完整性高</li><li>HiCanu：适用HiFi</li><li>根据基因组特征，选择合适软件进行组装或者多软件配合使用组装获得高质量物种基因组</li></ul><h2 id="评估软件"><a href="#评估软件" class="headerlink" title="评估软件"></a>评估软件</h2><ul><li>BUSCO</li><li></li></ul><h1 id="3超大基因组的组装经验"><a href="#3超大基因组的组装经验" class="headerlink" title="3超大基因组的组装经验"></a>3超大基因组的组装经验</h1><p>数据量大：运算量大，软件适应性，组装结果，存储需求</p><h1 id="4基因组组装展望"><a href="#4基因组组装展望" class="headerlink" title="4基因组组装展望"></a>4基因组组装展望</h1><p>CSS组装，未来趋势。</p><hr><h1 id="三代数据预处理"><a href="#三代数据预处理" class="headerlink" title="三代数据预处理"></a>三代数据预处理</h1><h2 id="了解三代数据预处理中的输入和输出数据"><a href="#了解三代数据预处理中的输入和输出数据" class="headerlink" title="了解三代数据预处理中的输入和输出数据"></a>了解三代数据预处理中的输入和输出数据</h2><h2 id="三代上机文库简介"><a href="#三代上机文库简介" class="headerlink" title="三代上机文库简介"></a>三代上机文库简介</h2><h2 id="了解数据质量矫正的方法"><a href="#了解数据质量矫正的方法" class="headerlink" title="了解数据质量矫正的方法"></a>了解数据质量矫正的方法</h2><h2 id="如何评价数据质量和有效产出比"><a href="#如何评价数据质量和有效产出比" class="headerlink" title="如何评价数据质量和有效产出比"></a>如何评价数据质量和有效产出比</h2>]]></content>
    
    
    <categories>
      
      <category>Biology</category>
      
    </categories>
    
    
    <tags>
      
      <tag>assembly</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>ggplot2</title>
    <link href="/GeekFocus/2022/02/18/2022-02-18-ggplot2/"/>
    <url>/GeekFocus/2022/02/18/2022-02-18-ggplot2/</url>
    
    <content type="html"><![CDATA[<p>Ggplot2</p><span id="more"></span><p>reorder降序实现(加**<font color="red">-</font>**号)：</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs R">ggplot<span class="hljs-punctuation">(</span>data<span class="hljs-punctuation">,</span>aes<span class="hljs-punctuation">(</span>x<span class="hljs-operator">=</span>reorder<span class="hljs-punctuation">(</span>v1<span class="hljs-punctuation">,</span>v2<span class="hljs-punctuation">)</span><span class="hljs-punctuation">,</span>y<span class="hljs-operator">=</span>v2<span class="hljs-punctuation">)</span><span class="hljs-punctuation">)</span><span class="hljs-operator">+</span>genom_bar<span class="hljs-punctuation">(</span>stat <span class="hljs-operator">=</span> <span class="hljs-string">&quot;identity&quot;</span><span class="hljs-punctuation">)</span><br><br>ggplot<span class="hljs-punctuation">(</span>data<span class="hljs-punctuation">,</span>aes<span class="hljs-punctuation">(</span>x<span class="hljs-operator">=</span>reorder<span class="hljs-punctuation">(</span>v1<span class="hljs-punctuation">,</span><span class="hljs-operator">-</span>v2<span class="hljs-punctuation">)</span><span class="hljs-punctuation">,</span>y<span class="hljs-operator">=</span>v2<span class="hljs-punctuation">)</span><span class="hljs-punctuation">)</span><span class="hljs-operator">+</span>genom_bar<span class="hljs-punctuation">(</span>stat <span class="hljs-operator">=</span> <span class="hljs-string">&quot;identity&quot;</span><span class="hljs-punctuation">)</span><br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>R</category>
      
    </categories>
    
    
    <tags>
      
      <tag>ggplot2</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>染色质三维结构图谱 Hi-C</title>
    <link href="/GeekFocus/2022/02/16/2022-02-16-chromosome-structure-Hi-C/"/>
    <url>/GeekFocus/2022/02/16/2022-02-16-chromosome-structure-Hi-C/</url>
    
    <content type="html"><![CDATA[<h1 id="Hi-C技术，以高通量测序为手段，以3C技术为基础的染色质构象捕捉技术。-三维基因组。"><a href="#Hi-C技术，以高通量测序为手段，以3C技术为基础的染色质构象捕捉技术。-三维基因组。" class="headerlink" title="Hi-C技术，以高通量测序为手段，以3C技术为基础的染色质构象捕捉技术。-三维基因组。"></a>Hi-C技术，以高通量测序为手段，以3C技术为基础的染色质构象捕捉技术。-三维基因组。</h1><span id="more"></span><p><img src="/GeekFocus/./0.png" alt="img"></p><h1 id="1-C技术"><a href="#1-C技术" class="headerlink" title="1. C技术"></a>1. C技术</h1><h2 id="1-1-3C（一对一）"><a href="#1-1-3C（一对一）" class="headerlink" title="1.1 3C（一对一）"></a>1.1 3C（一对一）</h2><ul><li><p>基因组捕获技术（Chromosome conformation capture，3C）是最早研究三维基因组的技术，需要<font color="green">提前知道互作区域</font>，才能<font color="green">量化一对基因组基因座之间的互作</font>。</p></li><li><p>3C技术2002年Deker提出，目的捕获染色体的interaction，假设染色体中的interaction以蛋白为介导。通过限制酶酶切，补平，连接，打断，PCR后，若染色体A，B两点相互作用，根据这两点特异序列的引物能PCR出产物，验证interaction。每<font color="green">一对位点的验证</font>需要<font color="green">设计一对特异性引物</font>。</p></li></ul><h2 id="1-2-4C（一对多）"><a href="#1-2-4C（一对多）" class="headerlink" title="1.2 4C（一对多）"></a>1.2 4C（一对多）</h2><ul><li><p>染色体构象捕获芯片（Chromosome conformation capture-on-chip，4C ），可以捕获<font color="green">一个基因区域</font>和其他区域间的互相作用。该技术不需要知道作用区域的先验知识就可以使用。</p></li><li><p>3C较麻烦，后设计双酶切位点，然后<font color="green">成环</font>，保证只需要设计一对引物就可以检测一个位点对多个位点的相互作用，4C有circle的意思。</p></li></ul><h2 id="1-3-5C（多对多）"><a href="#1-3-5C（多对多）" class="headerlink" title="1.3 5C（多对多）"></a>1.3 5C（多对多）</h2><p>染色体构象捕获碳拷贝（Chromosome conformation capture carbon copy，5C） ，可以检测<font color="green">某段区域内所有的互作</font>，但是该<font color="red">区域一般&lt;1 Mb</font>。覆盖度问题造成该技术<font color="green">不适用于全基因组测序</font>。</p><h2 id="1-4-Hi-C（全部互作）"><a href="#1-4-Hi-C（全部互作）" class="headerlink" title="1.4 Hi-C（全部互作）"></a>1.4 <font color="red">Hi-C（全部互作）</font></h2><ul><li><p>高通量基因组捕获技术（High-throughput&#x2F;resolution chromosome conformation capture），基本解决了上述技术的缺点，可以实现<font color="green">全基因组覆盖</font>检测<font color="green">全部未知互作区域</font>。</p></li><li><p>Hi-C基本步骤，甲醛交联，限制酶切，末端补平加biotin，平末端连接，超声破碎，biotin富集，建库测序。整个过程没有特异引物存在。</p></li><li><p>将线性距离远，空间结构近的DNA片段进行交联，并将交联的DNA片段富集，高通量测序，对测序数据分析可以揭示染色质的远程互作，推导出基因组的三维空间结构的可能的记忆之间的调控关系。</p></li><li><p>\1. 通过Scaffold间的交互频率大小，可以对已组装的基因组序列进行纠错（基因组更准确）。</p><p>\2. 基因信息不再仅仅是contig片段，而是被划分至染色体上，成为染色体水平。</p><p>\3. 无需辛苦的构建群体，单一一个体就能实现染色体定位。</p><p>\4. 相比遗传图谱，标记密度更大，序列定位更完整（能把更多的contig挂至染色体上!信息更全面！）</p><p>\5. 染色体重排等结构变异研究可以开展啦~(研究可以更深入！）</p><p>\6. QTL、GWAS可以定位区间到某个染色体啦~（追踪变异！）</p><p>\7. 该物种的三维基因结构、染色体互作及动态变化可以解析啦~（从基因到表观！全方位解析）</p></li></ul><h2 id="1-5-ChIP-loop-基于免疫沉淀"><a href="#1-5-ChIP-loop-基于免疫沉淀" class="headerlink" title="1.5 ChIP-loop (基于免疫沉淀)"></a>1.5 ChIP-loop (基于免疫沉淀)</h2><p>该技术将 3C 与 ChIP-seq 结合，可以检测<font color="red">目的蛋白质介导</font>的<font color="red">两个目的基因区域互作</font>。</p><h2 id="1-6-ChIA-PET-基于免疫沉淀"><a href="#1-6-ChIA-PET-基于免疫沉淀" class="headerlink" title="1.6 ChIA-PET (基于免疫沉淀)"></a>1.6 ChIA-PET (基于免疫沉淀)</h2><p>该技术将 HiC 与 ChIP-seq 结合，可以检测<font color="red">目的蛋白质的所有互相作用</font>。 用特异性抗体富集interaction信息，比如CTCF，pol II抗体，类似步骤建库测序。<font color="red">ChIA-PET数据是Hi-C数据的子集</font>。</p><hr><table><thead><tr><th></th><th>互作</th><th>覆盖</th><th>作用</th><th>研究应用</th></tr></thead><tbody><tr><td>3C</td><td>单对单</td><td>&lt;1Mb</td><td>检测已知<font color="red">基因组基因区域之间</font>的互作</td><td>确定已知启动子和增强子之间的互作</td></tr><tr><td>4C</td><td>一对多</td><td>全基因组</td><td>确定<font color="red">基因某组区域</font>与<font color="red">其他区域的互作</font></td><td>与已知LCR(locus control regions)区互作的全部基因和元件</td></tr><tr><td>5C</td><td>多对多</td><td>&lt;1Mb</td><td>确定<font color="red">染色体特定区域</font>的全部高级结构</td><td>确定染色体特定区域的全部高级结构</td></tr><tr><td>Hi-C</td><td>全部互作</td><td>全基因组</td><td>检测<font color="red">全基因组</font>范围的<font color="red">全部高级结构</font></td><td>全基因组范围所有染色体互作</td></tr><tr><td>ChIP-loop</td><td>一对一</td><td>&lt;1Mb</td><td>检测目的蛋白介导的<font color="red">两个目的基因区域互作</font></td><td></td></tr><tr><td>ChIA-PET</td><td>全部互作</td><td>全基因组</td><td>检测<font color="red">目的蛋白质的所有互作</font></td><td>构建已知转录因子介导的染色质互作</td></tr></tbody></table><hr><h1 id="2-技术原理"><a href="#2-技术原理" class="headerlink" title="2. 技术原理"></a>2. 技术原理</h1><p><img src="/GeekFocus/./1.png" alt="img"></p><p><img src="/GeekFocus/./8.png" alt="img"></p><h2 id="2-1-甲醛固定"><a href="#2-1-甲醛固定" class="headerlink" title="2.1 甲醛固定"></a>2.1 甲醛固定</h2><p>先加入甲醛将基因组中参与<font color="red">染色质互作的蛋白质凝固</font>。一般将活体样本在室温用 1-3%的甲醛处理 10-30min，但是此步骤会<font color="green">减少限制内切酶</font>对DNA序列的消化<font color="green">效率</font>，需要严格控制。</p><p><img src="/GeekFocus/./2.png" alt="img"></p><h2 id="2-2-酶切序列"><a href="#2-2-酶切序列" class="headerlink" title="2.2 酶切序列"></a>2.2 酶切序列</h2><p>用限制性内切酶切割基因组，打断后的片段大小会影响测序分辨率，一般有两种酶可供选择：6bp 的限制性内切酶，4bp 的限制性内切酶。后者具有更高的分辨率。EcoR1 或 HindIII 用于每4000bp切割一次基因组，在人类基因组中产生约100万个片段。<br><img src="/GeekFocus/./3.png" alt="img"></p><h2 id="2-3-末端修复"><a href="#2-3-末端修复" class="headerlink" title="2.3 末端修复"></a>2.3 末端修复</h2><p>得到的片段具有平末端或粘性末端，然后将<font color="red">末端补平修复，加入生物素</font>。【生物素pull-down保证只有连接的部分用于分析。读长reads被定位到基因组上，当这一对读长发现在不同片段上的时候，对<font color="red">互作片段进行相应评分</font>。一个包含基因组所有片段的<font color="red">连接频率矩阵被构建</font>。】</p><p><img src="/GeekFocus/./4.png" alt="img"></p><h2 id="2-4-连接及解交联"><a href="#2-4-连接及解交联" class="headerlink" title="2.4 连接及解交联"></a>2.4 连接及解交联</h2><p>使用 <font color="red">T4 DNA连接酶连接互作片段形成环状</font>。将连接DNA片段的<font color="red">蛋白质消化掉</font>，得到交联片段。</p><p><img src="/GeekFocus/./5.png" alt="img"></p><h2 id="2-5-序列打断"><a href="#2-5-序列打断" class="headerlink" title="2.5 序列打断"></a>2.5 序列打断</h2><p>使用超声波或其他方式，再次打断片段。</p><p><img src="/GeekFocus/./6.png" alt="img"></p><h2 id="2-6-上机测序"><a href="#2-6-上机测序" class="headerlink" title="2.6 上机测序"></a>2.6 上机测序</h2><p>用<font color="red">磁珠将带生物素的捕获</font>，制作文库，上机测序。</p><p><img src="/GeekFocus/./7.png" alt="img"></p><h1 id="3-Hi-C应用"><a href="#3-Hi-C应用" class="headerlink" title="3. Hi-C应用"></a>3. Hi-C应用</h1><ul><li><font color="red">量化</font>在三维空间中基因组的<font color="red">染色质间交联</font>（cross-linked chromatin ）</li><li>解析<font color="red">全基因组互作<strong>模式</strong></font>，如<font color="red">启动子和增强子互作</font></li><li>构建<font color="red">三维空间结构<strong>模型</strong></font>，如研究基因组三维结构特征：<strong>compartment，TAD，loop</strong>等</li><li>构建<font color="red">全基因组互作<strong>图谱</strong></font></li><li><font color="red">辅助提升<strong>基因组组装</strong></font></li><li>构建<font color="red">基因组<strong>单体型图谱</strong></font></li></ul><h1 id="4-分析流程"><a href="#4-分析流程" class="headerlink" title="4. 分析流程"></a>4. 分析流程</h1><h2 id="4-1-基本分析"><a href="#4-1-基本分析" class="headerlink" title="4.1 基本分析"></a>4.1 基本分析</h2><p><img src="/GeekFocus/./9.png" alt="img"></p><p>Ferhat Ay et al;2015</p><ul><li>(a)首先是<font color="green">质控</font>，过滤后高质量的FASTQ数据（PE，150bp），如果比对软件<font color="red">不支持split mapping</font>，一般选用<font color="red">迭代比对</font>，因为连接处由于是基因组外的碱基，可能比对不上。<strong>从序列左端25bp开始比对，如果有唯一比对，则停止，如果多个比对位置，则再继续延伸5bp，直到出现唯一比对</strong>。或选择<strong>支持split mapping的软件进行比对</strong>，可以通过<strong>分段比对处理</strong>。</li><li>(b)选择高质量的比对数据</li><li>(c)HiC特异的<font color="green">比对标准</font></li><li>(d)对Vaild pairs进行<font color="green">矫正</font>。矫正完可以得到<font color="green">互作矩阵</font>。</li></ul><p><img src="/GeekFocus/./10.png" alt="img"></p><p>Bryan R. Lajoie et al;2014</p><h2 id="4-2-Hi-C可视化"><a href="#4-2-Hi-C可视化" class="headerlink" title="4.2 Hi-C可视化"></a>4.2 Hi-C可视化</h2><p><img src="/GeekFocus/./11.png" alt="img"></p><h2 id="4-3-序列过滤"><a href="#4-3-序列过滤" class="headerlink" title="4.3 序列过滤"></a>4.3 序列过滤</h2><p>​<img src="/GeekFocus/./12.png" alt="img"></p><h2 id="4-4-数据矫正"><a href="#4-4-数据矫正" class="headerlink" title="4.4 数据矫正"></a>4.4 数据矫正</h2><p>​<img src="/GeekFocus/./13.png" alt="img"></p><p>Eitan Yaffe &amp; Amos Tanay；2011</p><p>​<img src="/GeekFocus/./14.png" alt="img"></p><h1 id="5-分析"><a href="#5-分析" class="headerlink" title="5. 分析"></a>5. 分析</h1><h2 id="5-1-cis-x2F-trans互作比例"><a href="#5-1-cis-x2F-trans互作比例" class="headerlink" title="5.1 cis&#x2F;trans互作比例"></a>5.1 cis&#x2F;trans互作比例</h2><p>​<img src="/GeekFocus/./15.png" alt="img"></p><h2 id="5-2-互作频率与距离有关"><a href="#5-2-互作频率与距离有关" class="headerlink" title="5.2 互作频率与距离有关"></a>5.2 互作频率与距离有关</h2><p>​<img src="/GeekFocus/./16.png" alt="img"></p><h2 id="5-3-compartment分析"><a href="#5-3-compartment分析" class="headerlink" title="5.3 compartment分析"></a>5.3 compartment分析</h2><p><img src="/GeekFocus/./17.png" alt="img"></p><h2 id="5-4-TAD分析"><a href="#5-4-TAD分析" class="headerlink" title="5.4 TAD分析"></a>5.4 TAD分析</h2><p><img src="/GeekFocus/./18.png" alt="img"></p><p>Hi-C辅助TAD结构研究（<em>Wang et al</em>., Nature Commuications 2018）</p><h2 id="5-5-显著互作分析"><a href="#5-5-显著互作分析" class="headerlink" title="5.5 显著互作分析"></a>5.5 显著互作分析</h2><p><img src="/GeekFocus/./19.png" alt="img"></p><h1 id="6-应用"><a href="#6-应用" class="headerlink" title="6. 应用"></a>6. 应用</h1><h2 id="6-1-解析全基因组互作模式"><a href="#6-1-解析全基因组互作模式" class="headerlink" title="6.1 解析全基因组互作模式"></a>6.1 解析全基因组互作模式</h2><p><img src="/GeekFocus/./20.png" alt="img"></p><p><img src="/GeekFocus/./21.png" alt="img"></p><h2 id="6-2-辅助提升基因组组装"><a href="#6-2-辅助提升基因组组装" class="headerlink" title="6.2 辅助提升基因组组装"></a>6.2 辅助提升基因组组装</h2><p><img src="/GeekFocus/./22.png" alt="img"></p><ul><li><p>Hi-C辅助陆地棉与海岛棉基因组染色体水平组装（<em>Wang et al</em>.,Nature Genetics 2018）</p></li><li><p>Hi-C无需群体，单一个体就能实现染色体定位。很多物种都无法构建遗传群体，包括大部分高等动物、野生动植物、林木、果树等等。Hi-C是通过染色体上空间距离、线性距离的不同而导致的交互频率的不同来完成染色体的定位，所以不需要构建群体。</p></li><li><p>标记密度更大，序列定位更完整。相比遗传图谱，染色质之间的交互频率具有更高的标记密度，如此高密度的图谱不仅可以挂载上长的Scaffold，较短的Scaffold也可以被定位，所以通过Hi-C技术，一般可以将90%以上基因组序列定位到染色体。</p></li><li><p>可以对已组装的基因组进行纠错。通过Scaffold间的交互频率大小，可以对已组装的基因组序列进行纠错。</p></li></ul><h3 id="6-2-1-数据统计和过滤；"><a href="#6-2-1-数据统计和过滤；" class="headerlink" title="6.2.1 数据统计和过滤；"></a>6.2.1 数据统计和过滤；</h3><h3 id="6-2-2-Hi-C文库评估；"><a href="#6-2-2-Hi-C文库评估；" class="headerlink" title="6.2.2 Hi-C文库评估；"></a>6.2.2 Hi-C文库评估；</h3><h3 id="6-2-3Hi-C染色体定位；"><a href="#6-2-3Hi-C染色体定位；" class="headerlink" title="6.2.3Hi-C染色体定位；"></a>6.2.3Hi-C染色体定位；</h3><p>​    ✓ 组装序列染色体群组划分；</p><p>   ✓  组装序列各群组内排序；</p><p>   ✓  组装序列各群组内定向；</p><h3 id="6-2-4-Hi-C定位后统计评估；"><a href="#6-2-4-Hi-C定位后统计评估；" class="headerlink" title="6.2.4 Hi-C定位后统计评估；"></a>6.2.4 Hi-C定位后统计评估；</h3><p>​    ✓  近缘物种参考基因组评估；</p><p>​    ✓  遗传标记评估；</p><p><img src="/GeekFocus/./24.png" alt="img"></p><h2 id="6-3-构建基因组单体型图谱"><a href="#6-3-构建基因组单体型图谱" class="headerlink" title="6.3 构建基因组单体型图谱"></a>6.3 构建基因组单体型图谱</h2><p><img src="/GeekFocus/./23.png" alt="img"></p><h1 id="7-文献案例"><a href="#7-文献案例" class="headerlink" title="7. 文献案例"></a>7. 文献案例</h1><h2 id="7-1"><a href="#7-1" class="headerlink" title="7.1"></a>7.1</h2><p><strong>物种：棉花</strong></p><p><strong>题目：</strong>Genome sequence of<em>Gossypium herbaceum</em>and genome updates of<em>Gossypium arboreum</em>and<em>Gossypium hirsutum</em>provide insights into cotton A-genome evolution</p><p><strong>期刊：</strong>Nature genetics</p><p><strong>影响因子：</strong>25.455</p><p><strong>研究单位：</strong>武汉大学</p><p><strong>主要研究内容：</strong></p><p>2020年4月13日，武汉大学朱玉贤院士团队关于草棉、亚洲棉和陆地棉基因组研究成果发表在国际著名期刊Nature genetics。该研究利用了PacBio三代分子测序和北京百迈客生物技术有限公司的Hi-C技术绘制了三个高质量棉花基因图谱，发现了三种棉花中多个染色体易位与倒位事件，解决了围绕A基因组起源的现有争议性概念，确定了与棉花纤维长度这一重要农艺性状相关的丰富的候选基因，并为棉花遗传改良提供了宝贵的基因组资源。</p><p><img src="/GeekFocus/./25.png" alt="草棉与亚洲棉基因组Hi-C热图"></p><h2 id="7-2"><a href="#7-2" class="headerlink" title="7.2"></a>7.2</h2><p><strong>物种：珙桐</strong></p><p><strong>题目：</strong><a href="https://link.zhihu.com/?target=http://tour.biocloud.net/article/v1/into/articleDetail/31970919">Genomic analyses of a “living fossil”: The endangered dove-tree</a></p><p><strong>期刊：</strong>Molecular Ecology Resources</p><p><strong>影响因子：</strong>7.049</p><p><strong>研究单位：</strong>四川大学</p><p><strong>主要研究内容：</strong>2020年1月四川大学刘建全团队破译了中国特有的濒危物种珙桐（<em>Davidia involucrata</em>）基因组，相关成果发表在著名期刊Molecular Ecology Resources上。四川大学刘建全教授和杨勇志博士为该论文的通讯作者，陈阳和马涛教授为并列一作。该研究利用单分子实时测序SMRT和北京百迈客生物技术有限公司的Hi-C技术组装了一个高质量、染色体体水平的珙桐基因组，研究发现苞片中光合作用相关基因几乎缺失或表达减少，而抗菌、抗冷、抗水等抗逆相关基因在苞片中高度表达，突出了苞片在保护花和吸引授粉者中的重要作用。有效群体大小等研究分析了珙桐的生存机制和濒危原因。在未来气候持续变暖的背景下，研究结果为保护这独特的濒危物种提供了依据。</p><p><img src="/GeekFocus/./26.png" alt="珙桐基因组Hi-C热图"></p><h2 id="7-3"><a href="#7-3" class="headerlink" title="7.3"></a>7.3</h2><p><strong>物种：二倍体草莓</strong></p><p><strong>题目：</strong><a href="https://link.zhihu.com/?target=http://tour.biocloud.net/article/v1/into/articleDetail/32003918">The high-quality genome of diploid strawberry (Fragaria nilgerrensis) provides new insights into anthocyanin accumulation</a></p><p><strong>期刊：</strong>Plant Biotechnology Journal</p><p><strong>影响因子：</strong>6.84</p><p><strong>研究单位：</strong>沈阳农业大学</p><p><strong>主要研究内容：</strong></p><p>2020年1月31日沈阳农业大学张志宏研究团队与北京百迈客生物科技有限公司合作，基于单分子实时测序PacBio和染色体构象捕获Hi-C技术，成功构建亚洲东部和东南部地区特有的野生二倍体草莓——黄毛草莓（<em>Fragaria nilgerrensis</em>）高质量基因图谱，相关研究成果发表在知名期刊Plant Biotechnology Journal上。文中通过比较基因组学等系列分析找寻到可能与黄毛草莓特异表型以及环境适应性相关的扩张基因，以及可能与其白色果实相关的变异。该研究为草莓属物种的生物学以及比较基因组学研究提供了宝贵的遗传资源。</p><p><img src="/GeekFocus/./27.png" alt="黄毛草莓基因组Hi-C热图"></p><h2 id="7-4"><a href="#7-4" class="headerlink" title="7.4"></a>7.4</h2><p><strong>物种：油桐</strong></p><p><strong>题目：</strong><a href="https://link.zhihu.com/?target=http://tour.biocloud.net/article/v1/into/articleDetail/32224189">Tung Tree (Vernicia fordii) Genome Provides A Resource for Understanding Genome Evolution and Improved Oil Production</a></p><p><strong>期刊：</strong>Genomics Proteomics &amp; Bioinformatics</p><p><strong>影响因子：</strong>6.597</p><p><strong>研究单位：</strong>中南林业科技大学</p><p><strong>主要研究内容：</strong></p><p>2020年4月7日，Genomics Proteomics &amp; Bioinformatics 在线发表了由中南林业科技大学谭晓风团队牵头完成的油桐基因组研究论文。该研究利用Illumina+PacBio组装了1.12Gb油桐基因组，并通过北京百迈客生物技术有限公司的Hi-C技术将95.15%的序列挂载到11条染色体上。基于比较基因组等系列相关研究解析了油桐基因组进化和桐油生物合成的分子机制。该研究为理解基因组演化、以及油脂产量的分子育种与遗传改良都提供了宝贵的遗传资源，为油桐种质资源保护、分子遗传学研究、良种选育及加工利用，奠定了重要的科学基础。</p><p><img src="/GeekFocus/./28.png" alt="油桐基因组circos图"></p><h2 id="7-5"><a href="#7-5" class="headerlink" title="7.5"></a>7.5</h2><p><strong>物种：亚麻</strong></p><p><strong>题目：</strong><a href="https://link.zhihu.com/?target=http://tour.biocloud.net/article/v1/into/articleDetail/32240956">Genomic Comparison and Population Diversity Analysis Provide Insights into the Domestication and Improvement of Flax</a></p><p><strong>期刊：</strong>iScience</p><p><strong>影响因子：</strong>——</p><p><strong>研究单位：</strong>甘肃省农业科学院</p><p><strong>主要研究内容：</strong></p><p>2020年4月24日，由甘肃省农科院和北京百迈客等单位合作的亚麻基因组研究成果荣登iScience, 其中张建平研究员，党占海研究员，刘头明研究员，百迈客CEO郑洪坤为本文通讯作者。该研究使用Illumina技术对油用亚麻品种Longya-10、纤维亚麻品种Heiya-14和pale flax分别进行测序与组装，后期利用HiC技术与遗传图谱辅助Longya-10基因组组装，将434 scaffolds组装至染色体水平。通过比较基因组及群体进化等研究探索油用及纤维用亚麻在驯化中受到的选择作用，以及可能在重塑亚麻形态结构中起着至关重要作用的相关基因。该研究揭示了对亚麻驯化和改良有重要影响的基因，这将有助于今后的分子育种。</p><p><img src="/GeekFocus/./29.png" alt="亚麻基因组Hi-C热图"></p><h2 id="7-6"><a href="#7-6" class="headerlink" title="7.6"></a>7.6</h2><p><strong>物种：枇杷</strong></p><p><strong>题目：</strong><a href="https://link.zhihu.com/?target=http://tour.biocloud.net/article/v1/into/articleDetail/32141509">Chromosome-level genome assembly and annotation of the loquat (Eriobotrya japonica) genome</a></p><p><strong>期刊</strong>：Gigascience</p><p><strong>影响因子：</strong>4.688</p><p><strong>研究单位：</strong>上海市农业科学院</p><p><strong>主要研究内容：</strong></p><p>2020年2月6日，上海市农业科学院张学英研究员团队于知名期刊Gigascience上首次发表枇杷基因组相关研究论文，该研究中基于北京百迈客生物科技有限公司的Nanopore测序和Hi-C染色体构象捕获技术，构建了高质量的枇杷基因组。文中通过与苹果、水蜜桃、梨、覆盆莓、月季和野草莓的蛋白质序列比较，探索了枇杷的全基因组复制与进化事件，并进行了染色体重排分析。该研究提供了宝贵的染色体水平基因组数据，为研究枇杷性状提供了重要的基因组数据。</p><p><img src="/GeekFocus/./30.png" alt="枇杷基因组circos图"></p><h2 id="7-7"><a href="#7-7" class="headerlink" title="7.7"></a>7.7</h2><p><strong>物种：板蓝根（菘蓝）</strong></p><p><strong>题目：</strong><a href="https://link.zhihu.com/?target=http://tour.biocloud.net/article/v1/into/articleDetail/32025321">A chromosome-scale genome assembly of Isatis indigotica, an important medicinal plant used in traditional Chinese medicine</a></p><p><strong>期刊：</strong> Horticulture Research</p><p><strong>影响因子：</strong>3.640</p><p><strong>研究单位：</strong>四川大学</p><p><strong>主要研究内：</strong></p><p>2020年2 月1日，四川大学生命科学学院刘建全课题组与华中农业大学作物遗传改良国家重点实验室李再云课题组首次完成了菘蓝（<em>Isatis indigotica</em>，2n&#x3D;14）染色体级别基因组图谱绘制。该研究利用Pacbio测序(140X)结合北京百迈客生物技术有限公司的Hi-C技术（284X）组装得到294Mb高质量基因组（contigN50&#x3D;1.2Mb）。基于同源搜索和功能注释，确定了该物种主要化合物（如吲哚类、萜类、黄酮、木脂素等物质）的可能生物合成通路和相关的候选基因。该研究强调了基因组测序在鉴定药用植物代谢产物合成候选基因中的重要性，为今后十字花科植物比较基因组等研究提供了重要遗传信息。</p><p><img src="/GeekFocus/./31.png" alt="菘蓝基因组Hi-C热图"></p><h2 id="7-8"><a href="#7-8" class="headerlink" title="7.8"></a>7.8</h2><h6 id="以更新的亚洲棉A基因组为基础的243份二倍体棉的重要农艺性状的研究"><a href="#以更新的亚洲棉A基因组为基础的243份二倍体棉的重要农艺性状的研究" class="headerlink" title="以更新的亚洲棉A基因组为基础的243份二倍体棉的重要农艺性状的研究"></a>以更新的亚洲棉A基因组为基础的243份二倍体棉的重要农艺性状的研究</h6><h6 id="RESEQUENCING-OF-243-DIPLOID-COTTON-ACCESSIONS-BASED-ON-AN-UPDATED-A-GENOME-IDENTIFIES-THE-GENETIC-BASIS-OF-KEY-AGRONOMIC-TRAITS"><a href="#RESEQUENCING-OF-243-DIPLOID-COTTON-ACCESSIONS-BASED-ON-AN-UPDATED-A-GENOME-IDENTIFIES-THE-GENETIC-BASIS-OF-KEY-AGRONOMIC-TRAITS" class="headerlink" title="RESEQUENCING OF 243 DIPLOID COTTON ACCESSIONS BASED ON AN UPDATED A GENOME IDENTIFIES THE GENETIC BASIS OF KEY AGRONOMIC TRAITS"></a>RESEQUENCING OF 243 DIPLOID COTTON ACCESSIONS BASED ON AN UPDATED A GENOME IDENTIFIES THE GENETIC BASIS OF KEY AGRONOMIC TRAITS</h6><p>期刊：Nature Genetics</p><p>影响因子：27.125</p><p>发表单位：中国农业科学院棉花研究所、北京百迈客生物科技有限公司等</p><p>发表年份：2018年5月</p><p>研究背景：</p><p>棉花是研究植物多倍化的有价值的资源。亚洲棉(<em>Gossypium arboreum</em>)和草棉(<em>Gossypium herbaceum</em>)的祖先是现代栽培异源四倍体棉花A亚基因组的供体。 本研究中，利用了三代PacBio和Hi-C技术，重新组装了高质量的亚洲棉基因组，分析了243份二倍体棉花种质的群体结构和基因组分化趋势，同时确定了一些有助于棉花皮棉产量遗传改良的候选基因位点。</p><p>研究结果：</p><p>1、亚洲棉三代基因组组装：</p><p>利用三代测序和Hi-C相结合的方法进行亚洲棉基因组组装。共计获得了142.54 Gb ，组装1.71 Gb亚洲棉基因组，Contig N50&#x3D;1.1 Mb，最长的Contig为12.37 Mb。利用Hi-C技术将组装的1573 Mb的数据定位到13条染色体上，与已经发表的基因组相比，当Hi-C数据比对到更新的基因组后，对角线外的不一致性明显减少（图1 a-b）</p><p><img src="/GeekFocus/./33.png" alt="img"></p><p>图1 HI-C数据在两版亚洲棉基因组上的比对</p><p>2、二倍体棉花群体遗传进化分析：</p><p>对230份亚洲棉和13份草棉重测序，进行基因组比对、系统发育树、群体结构分析、PCA、LD和选择性清除分析得出亚洲棉和草棉（A）与雷蒙德氏棉同时进行了分化；亚洲棉起源于中国南部，随后被引入长江和黄河地区，大多数具有驯化相关特性的种质都经历了地理隔离（图2）。</p><p><img src="/GeekFocus/./34.png" alt="img"></p><p>图2 二倍体棉群体进化和群体结构分析</p><p>3、亚洲棉的全基因组关联分析（GWAS）：</p><p>对来自不同环境下的11个重要性状进行全基因组关联分析，鉴定了亚洲棉11个重要农艺性状的98个显著关联位点，GaKASIII的非同义替换（半胱氨酸&#x2F;精氨酸替换）使得棉籽中的脂肪酸组成（C16:0和C16:1）发生了变化；发现棉花枯萎病抗性与GaGSTF9基因的表达激活相关。选择了亚洲棉种质中的158份有绒毛和57份无绒毛材料进行GWAS关联分析，发现与毛状体和纤维发育有关信息（图3）。</p><p><img src="/GeekFocus/./35.png" alt="img"></p><p>图3 二倍体棉群体进化和群体结构分析</p><p>研究结论：</p><p>利用三代测序+Hi-C技术完成了亚洲棉基因组的重新组装，将基因组组装指标从72 Kb提升到1.1 Mb，为亚洲棉后续的群体遗传学等相关研究奠定了基础；通过群体遗传进化等相关分析，发现亚洲棉和草棉(A型)与雷蒙德氏棉(D型)同时进行了分化，并证明了亚洲棉起源于中国南部，随后被引入长江和黄河地区；整合GWAS与QTL等分析方法，对亚洲棉脂肪酸含量，抗病性及棉绒生长发育相关基因进行定位，并进行相关功能验证，促进了亚洲棉复杂农艺性状的改良。</p><h2 id="7-9"><a href="#7-9" class="headerlink" title="7.9"></a>7.9</h2><h6 id="二倍体、野生和栽培四倍体花生比较基因组分析揭示亚基因组不对称进化和改良"><a href="#二倍体、野生和栽培四倍体花生比较基因组分析揭示亚基因组不对称进化和改良" class="headerlink" title="二倍体、野生和栽培四倍体花生比较基因组分析揭示亚基因组不对称进化和改良"></a>二倍体、野生和栽培四倍体花生比较基因组分析揭示亚基因组不对称进化和改良</h6><h6 id="COMPARISON-OF-ARACHIS-MONTICOLA-WITH-DIPLOID-AND-CULTIVATED-TETRAPLOID-GENOMES-REVEALS-ASYMMETRIC-SUBGENOME-EVOLUTION-AND-IMPROVEMENT-OF-PEANUT"><a href="#COMPARISON-OF-ARACHIS-MONTICOLA-WITH-DIPLOID-AND-CULTIVATED-TETRAPLOID-GENOMES-REVEALS-ASYMMETRIC-SUBGENOME-EVOLUTION-AND-IMPROVEMENT-OF-PEANUT" class="headerlink" title="COMPARISON OF ARACHIS MONTICOLA WITH DIPLOID AND CULTIVATED TETRAPLOID GENOMES REVEALS ASYMMETRIC SUBGENOME EVOLUTION AND IMPROVEMENT OF PEANUT"></a>COMPARISON OF <em>ARACHIS MONTICOLA</em> WITH DIPLOID AND CULTIVATED TETRAPLOID GENOMES REVEALS ASYMMETRIC SUBGENOME EVOLUTION AND IMPROVEMENT OF PEANUT</h6><p>期刊：Advanced Science</p><p>影响因子：15.804</p><p>发表单位：河南农业大学、北京百迈客生物科技有限公司等</p><p>发表年份：2019年11月</p><p>研究背景：</p><p>花生作为我国重要的经济作物，是提供重要的蛋白和油料的基础。花生属一共包括30个二倍体品种，1个异源四倍体野生花生(<em>A. monticola</em>)和1个栽培花生(<em>A. hypogaea</em>)。作为栽培花生农艺性状改良的重要野生资源供体，野生四倍体花生一直是国内外学者的研究热点。研究中对花生属唯一的野生异源四倍体花生<em>Arachis monticola</em>基因组进行了研究，同时对17个野生二倍体花生（AA;BB;EE;KK和CC）与30个野生和栽培四倍体花生进行了重测序分析。</p><p>研究结果：</p><p>1、野生四倍体花生基因组denovo及与栽培四倍体花生的比较分析：</p><p>基于 Illumina、PacBio 、Hi-C和光学图谱数据，组装<em>Arachis monticola</em>(2n &#x3D; 4x &#x3D; 40)基因组大小为2.62 Gb ，contigs N50&#x3D;106.66 Kb，scaffolds N50&#x3D;124.92 Mb；与栽培四倍体花生<em>A. hypogaea</em>基因组结构变异高度保守，且比野生祖先二倍体更加保守；</p><p>2、A、B亚基因组的单系起源和多样性：</p><p>对17个二倍体野生种（AA、BB、EE、KK和CC）和30个野生和栽培四倍体花生进行了进化树和PCA分析。结果表明，栽培四倍体花生与野生四倍体花生最接近， A和B亚基因组的单系起源（图1）；</p><p><img src="/GeekFocus/./36.png" alt="img"></p><p>3、四倍体花生不对称亚基因组进化及表达差异 <strong>：</strong></p><p>栽培花生和野生花生的亚基因组间的同源序列交换率（HSE）分别为2.46%和2.54%。野生花生中A到B的HSE富集的基因为类黄酮生物合成和昼夜节律途径的基因，暗示不对称HSEs在生物学功能中的作用；</p><p>4、SV对荚发育和驯化相关基因表达的影响及抗病基因鉴定 <strong>：</strong></p><p>对野生四倍体花生和栽培四倍体花生不同发育阶段荚果的SV分析发现SV在荚果发育过程中基因表达的变化上可能起着重要作用；同时在栽培四倍体花生中鉴定到190个SV抗病基因（SV-RGAs），其中32个基因在接种后易感组或抗性组中表现出显著的表达变化（图2）。</p><p><img src="/GeekFocus/./37.png" alt="img"></p><p>研究结论：</p><p>充分注释了高质量野生四倍体花生基因组，揭示了花生亚基因组单系起源和遗传进化模型，表明了野生和栽培四倍体花生亚基因组发生了不对称进化；此外，野生花生中存在的独特等位基因可以改善栽培花生的抗性和荚果大小等形状，为研究多倍体基因组进化、作物驯化和基因组辅助花生生产改良提供独特的价值。</p><hr><p><img src="/GeekFocus/./32.png" alt="其他"></p><p>北京百迈客自启动Hi-C技术研究以来，自主开发Hi-C排图软件，具有实验+生物信息分析专利双保护，也是中国市场上能独立完成Hi-C实验——数据分析的测序企业之一！并完成上千个物种，近万个文库构建；文库含酶切位点有效数据比例最高达93%以上，针对物种推出定制化内切酶服务；实现多倍体物种的Hi-C辅助基因组组装，<strong>挂载效率最高达100%。</strong></p><p>另外为了让更多科研工作者体验Hi-C建库，百迈客在成功构建多种物种Hi-C建库测序的经验上，正式推出了Biomarker Hi-C Library Prep Kit for Illumina。</p><p>Biomarker Hi-C Library Prep Kit for Illumina涵盖了Hi-C实验全部环节，包括甲醛交联、Hi-C提取和Hi-C文库构建，适用于细胞系、动物和植物组织样本。1套Hi-C试剂盒包含5个反应，1个反应构建的文库可用于200Gb数据量的测序，试剂盒构建的文库适用于Illumina测序平台。</p><hr><p>Ref:<a href="https://www.zhihu.com/question/48308074">https://www.zhihu.com/question/48308074</a></p><p><a href="https://cloud.tencent.com/developer/article/1625366">https://cloud.tencent.com/developer/article/1625366</a></p><p><a href="http://www.biomarker.com.cn/technology-services/hi-c">http://www.biomarker.com.cn/technology-services/hi-c</a></p><p><a href="https://zhuanlan.zhihu.com/p/140795830">https://zhuanlan.zhihu.com/p/140795830</a></p>]]></content>
    
    
    <categories>
      
      <category>Biology</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Hi-C</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>选择基因</title>
    <link href="/GeekFocus/2022/02/16/2022-02-16-select-gene/"/>
    <url>/GeekFocus/2022/02/16/2022-02-16-select-gene/</url>
    
    <content type="html"><![CDATA[<h1 id="选择基因-selector-genes-是一类决定体节发育的基因。"><a href="#选择基因-selector-genes-是一类决定体节发育的基因。" class="headerlink" title="选择基因(selector genes)是一类决定体节发育的基因。"></a>选择基因(selector genes)是一类决定体节发育的基因。</h1><span id="more"></span><p>有<font color="green">两簇选择基因</font>在控制<font color="green">果蝇外部结构</font>的正确发育途径中起关键作用：<font color="green">双胸复合物(bithorax complex,BX-C)</font>和<font color="green">触角足复合物(antennapedia complex,ANT-C)</font>。BX-C含有三个结构基因，分别是：<font color="green">Ultrabithorax(Ubx)、Abdominal A(abdA)和Abdominal B(abdB)</font>，它们<font color="green">各编码一种具有同源框的转录因子。这三个基因都含有很多内含子</font>，这些内含子对于调节这些基因在不同<a href="https://baike.baidu.com/item/%E5%89%AF%E8%8A%82">副节</a>进行不同的表达具有重要作用。ANT-C<a href="https://baike.baidu.com/item/%E5%9F%BA%E5%9B%A0%E7%B0%87">基因簇</a>含有5个基因：<font color="green">labial(lab)、proboscipedia(pb)、Deformed(Dfd)、Sex combs reduced(Scr)和antennapedia(Antp)</font>。这两簇基因都定位于<font color="green">3号染色体</font>。ANT-C簇编码的蛋白质控制<font color="green">0-5副节</font>的发育，BX-C基因簇编码的蛋白质控制<font color="green">5-14</font>副节的发育。</p>]]></content>
    
    
    <categories>
      
      <category>Biology</category>
      
    </categories>
    
    
    <tags>
      
      <tag>note</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>染色质三维结构图谱 Micro-C</title>
    <link href="/GeekFocus/2022/02/16/2022-02-16-chromosome-structure-Micro-C/"/>
    <url>/GeekFocus/2022/02/16/2022-02-16-chromosome-structure-Micro-C/</url>
    
    <content type="html"><![CDATA[<h1 id="Micro-C"><a href="#Micro-C" class="headerlink" title="Micro-C"></a>Micro-C</h1><span id="more"></span><h1 id="Micro-C-1"><a href="#Micro-C-1" class="headerlink" title="Micro-C"></a>Micro-C</h1><p>染色质结构与基因表达的调控密切相关（如<font color="green">常染色质&#x2F;异染色质</font>）。随着近年<font color="green">染色质构象捕捉技术</font>的发展，了解到细胞核内的DNA存在着<font color="green">多重结构调节机制</font>，例如<font color="green">A&#x2F;B染色质区室（compartment）</font>和<font color="green">拓扑结构域（TAD）</font>。大小分别在<font color="green">百万碱基</font>和<font color="green">十万碱基</font>左右。由于测序深度和技术条件限制，<font color="green">Hi-C很难达到更高分辨率</font>，<strong>限制</strong>了分析关于单个基因，以及启动子（P）、增强子（E）等<font color="green">调控元件之间相互作用</font>。</p><p>Molecular Cell杂志发表背靠背文章Resolving the 3D Landscape of Transcription-Linked Mammalian Chromatin Folding和Ultrastructural Details of Mammalian Chromosome Architecture。<font color="green">一种新的染色质构象捕捉技术名为Micro-C</font>。Micro-C达到<strong>单核小体长度（～200bp）</strong>左右的<strong>分辨率</strong>，可以观察到更为精细的染色质结构。</p><p>Micro-C和Hi-C在实验步骤上最大的不同，在于Micro-C先对核小体上缠绕的DNA做交联，而后用MNase切断核小体之间的连接DNA。以Tjian和Darzacq实验室的文章为例，他们对38个小鼠干细胞进行Micro-C测序，总共获得约26亿个reads。<strong>相似测序深度</strong>下<strong>20kb精度</strong>的<strong>Micro-C图谱与Hi-C结果相似</strong>，但在<strong>100至20kb的精度之间</strong>，<strong>Micro-C</strong>展示<strong>Hi-C不具备</strong>的<strong>精细</strong>结构，例如很多有关基因启动子和增强子的结构域、条带和点圈。从Hi-C可以得到约6000个DNA环（loop），即高度相互作用的一对区域。而Micro-C可以得到约30000个。</p><p>在证实了Micro-C具备可重复性和高精度之后，进一步分析，<font color="green">相比Hi-C，Micro-C独特</font>的主要在于可探查<font color="green">调控元件之间相互作用</font>，如EP，PP等。其中有些相互作用形成了比传统TAD小的结构域。研究者通过隔离分值的分析得到了大约13万个这样的结构域边界。这些<font color="green">边界通常有着活跃转录的基因和动态的核小体结构</font>，而与之前所了解的，<font color="green">以CTCF和Cohesin为标志的TAD边界</font>有很大<font color="green">不同</font>。</p><p>利用<strong>回归模型</strong>分析了这些<strong>结构域边界</strong>和<strong>表关遗传特征</strong>的<strong>关联性</strong>。<font color="green">CTCF</font>和<font color="green">Cohesin</font>在<font color="green">决定边界位置</font>最重要，然而决定<font color="green">边界强度</font>却主要是<font color="green">转录活跃的标志物</font>，如<font color="green">H3K4me3修饰和染色质开放度</font>等。进一步发现边界也存在很大差别，将其分为五类：<font color="red">转录相关</font>；<font color="red">干细胞特异性增强子</font>；<font color="red">一般增强子</font>；<font color="red">抑制型</font>；<font color="red">CTCF-Cohesin相关型</font>。各有不同的化学修饰。</p><p>选取了一些代表性的区域发现，不仅<strong>启动子、增强子和CTCF之间相互作用</strong>，在<strong>聚梳抑制区</strong>还可以观察到显著的<strong>“巢状”环</strong>。<strong>CTCF相互作用范围较长</strong>，而<strong>Pol II</strong>介导的相互作用则<strong>较短</strong>。基因附近的相互作用越紧密，其转录活性也常常越高。进一步<strong>证明</strong><font color="green">转录对染色质折叠</font>的影响，利用<font color="green">药物抑制转录</font>。对比观察到，<font color="green">TAD等大尺度结构无变化</font>，然而<font color="green">基因附近的相互作用</font>条纹<font color="green">大大减弱</font>，证明了这些条纹团确实是由转录过程导致的。</p><p>两篇文章显示了<strong>哺乳动物</strong>的<font color="green">染色质相互作用</font>还有<font color="green">更多的精细结构等待开发</font>。更高精度的数据能帮助人们理解这些<strong>结构的形成和对基因转录的影响</strong>。</p><p>原文链接：<a href="https://mp.weixin.qq.com/s?__biz=MzA3MzQyNjY1MQ==&amp;mid=2652482974&amp;idx=3&amp;sn=acc0381ecc6ab6779e335510b87de062&amp;chksm=84e23e2ab395b73">https://mp.weixin.qq.com/s?__biz=MzA3MzQyNjY1MQ==&amp;mid=2652482974&amp;idx=3&amp;sn=acc0381ecc6ab6779e335510b87de062&amp;chksm=84e23e2ab395b73</a></p><hr><p><font color="green">染色质高级结构</font>由不同层次的结构单元组成。从<font color="green">区块（compartment）</font>，<font color="green">拓扑结构域（TAD）</font>，到单个的<font color="green">环（loop）</font>，这些大小不同的单元各有特征，也对<strong>染色质功能</strong>和<strong>基因表达</strong>起到多种多样的<strong>调控</strong>。CTCF蛋白扮演了重要的角色。</p><p><font color="red">CTCF</font>常常位于<strong>TAD和loop的边界</strong>，起到“<font color="red">隔离子</font>”的作用。近年来提出的loop extrusion模型也认为<font color="green">CTCF和cohesin的协调作用是loop形成的普遍机理</font>。虽然有假设，却一直不清楚CTCF<font color="red">如何作用</font>于染色质，并导致复杂结构形成。CTCF蛋白的各个结构域，除了同DNA结合的11-ZF外，其他结构域功能？</p><p>2019年9月12日，Molecular Cell杂志发表背靠背文章“Distinct Classes of ChromatinLoops Revealed by Deletion of anRNA-Binding Region in CTCF”和“RNA Interactions Are Essentialfor CTCF-Mediated Genome Organization”<strong>，</strong>共同揭示<font color="green">CTCF与RNA的相互作用</font>对CTCF功能的重要意义。</p><p>之前研究发现<font color="green">CTCF常在细胞中成簇聚集</font>。为研究聚集的<font color="green">机理</font>，在细胞中分别加入<font color="green">DNase和RNase</font>。结果吃惊，被认为是DNA结合蛋白的CTCF的聚合对<font color="green">DNase并不敏感</font>，而<font color="green">RNase却显著减少了CTCF的互相结合</font>。 结合之前研究，CTCF上的ZF10和ZF11结构域有一段具有RNA结合功能（<font color="red">RNA-binding region</font>，<strong>RBR</strong>），其中<strong>38个氨基酸</strong>对其结合是必不可少。研究者于是在<font color="red">小鼠干细胞</font>上将这段被称为<font color="red">RBRi的片段替换</font>，发现<font color="green">缺陷型细胞</font>的<strong>CTCF表达水平</strong>虽然<strong>无明显变化</strong>，<strong>生长却慢了2倍</strong>，显示<strong>RBRi</strong>可能具有重要的<strong>生理作用</strong>。RBRi缺陷的CTCF在细胞中和RNA的<font color="green">结合减少但却没有完全消失</font>。研究者接着对<strong>RBRi缺陷和不缺陷的CTCF</strong>分别做了荧光<strong>标记</strong>。结果<strong>野生型CTCF</strong>呈现了明显<strong>更高程度聚团</strong>。不过这些结果并<strong>不排除RBRi间接作用</strong>于其他因子的可能。</p><p><img src="/GeekFocus/./1.png" alt="img"></p><p>研究者接着分析了**<font color="red">RBRi片段功能和Compartment，TAD，Loop三大结构单元的关系</font><strong>。对</strong>RBRi缺陷<strong>和</strong>野生型<strong>细胞</strong>Micro-C测序<strong>。Micro-C是一种比Hi-C清晰度更高的研究基因组范围染色质相互作用的方法。RBRi的<font color="green">缺陷并不影响compartment形成</font>，但却</strong><font color="red">大范围改变了TAD和loop的结构</font>**。将RBRi<font color="green">替换后</font>，小鼠细胞内<font color="green">TAD的数目和强度都有所减少</font>，其中<font color="green">大部分同TAD边缘CTCF和Cohesin的ChIP-seq信号变化一致</font>。RBRi的替换也使得<font color="green"><strong>Micro-C</strong></font>热图上的<font color="green"><strong>条带（strip）变长</strong></font>，这符合loop extrusion模型的假设。而loop的改变更为有趣–有些loop完全明显削弱（38%～57%），而有些loop却完好无损甚至增强了。研究者于是<font color="green"><strong>将loop分成RBRi依赖和不依赖两类</strong></font>，并发现它们具有不同的转录因子结合特征。他们还据此假设，这两类loop同CTCF有不同的结合方式，因此稳定性也不同。这也许可以解释为什么不是所有的CTCF位点都会形成loop。最后，发现大约500个基因由于RBRi的替换产生了差异表达。</p><p><img src="/GeekFocus/./2.png" alt="img"></p><p>Danny Reinberg实验室则将目光集中在<strong>CTCF的ZF1和ZF10结构域</strong>上。他们发现对小鼠细胞的转录抑制在没有降低CTCF表达水平的前提下，减少了CTCF在全基因组范围的结合程度。<font color="red">ZF1或ZF10缺陷的CTCF与RNA的结合能力都大大减少，并且在一定程度导致CTCF结合位点和基因表达改变。而不同的是，ZF1缺陷使得大部分CTCF loop消失，而ZF10缺陷型细胞的loop却仍然保持完好。</font></p><p><strong>这两篇背靠背文章共同揭示了CTCF的RNA结合域</strong>（RBR）<strong>在CTCF发挥正常功能中扮演着重要的角色。</strong></p>]]></content>
    
    
    <categories>
      
      <category>Biology</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Micro-C</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>CTCF</title>
    <link href="/GeekFocus/2022/02/15/2022-02-15-CTCF/"/>
    <url>/GeekFocus/2022/02/15/2022-02-15-CTCF/</url>
    
    <content type="html"><![CDATA[<h1 id="【paper1】CTCF-the-protein-the-binding-partners-the-binding-sites-and-their-chromatin-loops"><a href="#【paper1】CTCF-the-protein-the-binding-partners-the-binding-sites-and-their-chromatin-loops" class="headerlink" title="【paper1】CTCF: the protein, the binding partners, the binding sites and their chromatin loops"></a>【paper1】CTCF: the protein, the binding partners, the binding sites and their chromatin loops</h1><span id="more"></span><p>review: <a href="https://pubmed.ncbi.nlm.nih.gov/23650640/">https://pubmed.ncbi.nlm.nih.gov/23650640/</a></p><h1 id="CTCF-the-protein-the-binding-partners-the-binding-sites-and-their-chromatin-loops"><a href="#CTCF-the-protein-the-binding-partners-the-binding-sites-and-their-chromatin-loops" class="headerlink" title="CTCF: the protein, the binding partners, the binding sites and their chromatin loops"></a>CTCF: the protein, the binding partners, the binding sites and their chromatin loops</h1><p>CTCF:蛋白质，结合伙伴，结合位点和染色质环</p><p>CTCF什么都有。转录因子与成千上万个基因组位点结合，有些是组织特异性的，有些是超保守的。它可以作为<strong>转录激活因子</strong>、<strong>抑制子</strong>和<strong>绝缘子</strong>，并可以<strong>暂停转录</strong>。CTCF<strong>结合</strong>在<strong>染色质结构域边界</strong>，<strong>增强子</strong>和<strong>启动子</strong>，以及<strong>基因区</strong>。它可以吸引许多其他转录因子到染色质，包括组织特异性转录激活因子、抑制子、粘连蛋白和RNA聚合酶II，并形成染色质环。因此，CTCF在特定基因组位点的确切功能是不可预测的。它似乎是由相关的转录因子、结合位点相对于基因转录起始位点的位置、以及该位点在染色质环中与其他ctcf位点的结合、与增强子或启动子的结合决定的。该review将讨论CTCF结合事件的全基因组特征，以及这个显著的转录因子的位点特异性功能。</p><ol><li>introduction</li></ol><p>CTCF是一种普遍表达的必需蛋白，在许多方面都是一种特殊的转录因子。它最初被描述为转录<strong>抑制</strong>因子，但也被发现作为转录<strong>激活</strong>因子。还具有<strong>绝缘体活性</strong>:当它位于增强子和基因启动子之间时，它阻断它们的通信并阻止转录激活。通过<strong>ChIP-seq</strong>系统研究，在<strong>不同物种的许多组织</strong>中绘制CTCF在基因组尺度的结合事件。结果显示基因组被<strong>无数的CTCF结合位点</strong>所覆盖。与大多数其他转录因子相比，CTCF似乎<strong>更容易</strong>与基因间序列<strong>结合</strong>，通常<strong>距</strong>离转录起始位点(<strong>TSS</strong>)<strong>较远</strong>。CTCF是<strong>最早被证实介导染色质成环</strong>的蛋白之一。进一步观察到，它经常会<strong>结合</strong>到位于细胞核中不同位置的<strong>染色体区域之间的边界</strong>，<strong>结合</strong>具有<strong>不同表观遗传特征</strong>和&#x2F;或<strong>不同转录活性</strong>的<strong>区域边界</strong>，以及最近确定的<strong>拓扑域之间的边界</strong>，这是空间上确定的<strong>染色体单位</strong>，在其中<strong>序列优先相互作用</strong>。本文讨论CTCF的研究，并评估其在<strong>基因组折叠</strong>和<strong>基因表达</strong>中的功能。</p><ol start="2"><li>CTCF在<strong>Β-globin</strong>和<strong>h19-igf2</strong>位点:一个短暂的历史</li></ol><p>多功能DNA结合蛋白CTCF的功能最初是在<strong>单个位点</strong>上探索的，特别是在<strong>β-珠蛋白位点</strong>和<strong>印迹H19-Igf2位点</strong>。<strong>chicken β-珠蛋白位点</strong>在其5 ‘侧携带一个DNaseI超敏位点(5 ‘ hs4)，该位点将该位点<strong>与邻近的异染色质分离</strong>，该位点被发现能够<strong>阻断增强子活性</strong>。CTCF随后被证明与5 ‘ hs4的绝缘体活性有关。人和小鼠的β-珠蛋白位点也位于不活跃染色质的大染色体区域内，并类似地被ctcf结合位点包围。这些被怀疑会对进入的异染色质形成屏障，但它们的缺失不会导致β-珠蛋白位点的关闭或失活。<strong>染色体构象捕获(3C)技术</strong>的应用使β-珠蛋白CTCF位点的物理相互作用成为可能。它们形成<strong>大染色质环</strong>，包括β-珠蛋白的主要调节元件，<strong>Locus control region基因位点控制区(LCR)<strong>及其</strong>基因</strong>。这些环是红细胞特异性的，在lcr介导的β-珠蛋白基因高表达之前，在红细胞祖细胞中形成(图1a;)。据推测，CTCF环可以<strong>促进LCR与其靶基因之间的后续空间相互作用</strong>，但这方面的证据仍然缺乏。</p><p><img src="/GeekFocus/./1.png"></p><p>Figure 1. CTCF，染色质环和特定基因位点的转录调控。(a)<strong>位于β-珠蛋白位点的基因</strong>受<strong>基因位点控制区(LCR)*<em><strong>控制。</strong>ctcf结合位点相互作用</em>*，形成</strong>染色质枢纽<strong>，其中包含</strong>LCR和β-珠蛋白基因<strong>。在</strong>红细胞分化<strong>时，</strong>红细胞特异性转录因子和内聚蛋白能够形成一个活跃的染色质枢纽<strong>，其中</strong>LCR与基因接触并增强其表达<strong>。(b) H19和Igf2基因的印迹表达是通过CTCF在印迹控制区(ICR)的甲基化依赖结合介导的。(i)在父系等位基因上，ICR的甲基化</strong>阻止CTCF结合**，并通过远端增强子(E)与Igf2启动子的接触介导Igf2基因的表达。(ii) <strong>CTCF结合在ICR上阻断了Igf2基因和远端增强子之间的通信</strong>，从而导致母源等位基因H19基因的表达。</p><p>印迹H19&#x2F;Igf2位点。该位点包含一个<strong>差异甲基化区域</strong>，称为<strong>印迹控制区(ICR)<strong>，位于H19和Igf2基因之间。ICR决定了H19在</strong>母体等位基因</strong>上<strong>活跃</strong>，而<strong>Igf2</strong>则是从<strong>父系等位基因转录</strong>而来的。当CTCF被发现以<strong>甲基化依赖</strong>的方式与<strong>ICR结合</strong>时，CTCF进入了这个阶段:<strong>CTCF与未甲基化的母源ICR的结合阻</strong>止了H19基因附近的共享增强子<strong>跨越并激活</strong>Igf2。在<strong>父系等位基因CTCF不能发挥其绝缘体活性，因为DNA甲基化阻止了其与ICR的结合</strong>(图1b;)。染色质环再次形成，似乎对ICR的功能很重要。带有增强子和启动子的等位基因特异性染色质环是由母体的、与ctcf结合的ICR形成的，这表明这种接触可能是ctcf介导的绝缘体活性的基础。总的来说，早期关于CTCF在β-珠蛋白和H19-Igf2位点功能的研究表明，该蛋白可以<strong>干扰启动子-增强子通信</strong>。CTCF可以在其结合位点之间形成染色质环，也可能与其他调控序列形成染色质环。</p><ol start="3"><li>CTCF通过基因组与染色质边界、增强子和基因启动子结合</li></ol><p>通过ChIP对全基因组结合位点的定位发现，CTCF可与数万个基因组位点结合。在不同的细胞类型中，大约<strong>三分之一的位点相对保守</strong>。一项对五种哺乳动物肝脏中CTCF结合谱的物种间比较发现，物种和组织之间大约有5000个超<strong>保守位点</strong>。这些似乎是<strong>高亲和力的结合位点</strong>，提示亲和力的差异可能与的保守强度有关。逆转录因子的激活产生了物种特异性的CTCF结合位点的扩展，这种形式的基因组进化在哺乳动物中仍然高度活跃。基于一致motif评分对CTCF结合位点进行分类得出了类似的结论:<strong>高占用位点似乎在所有细胞类型中都是保守的，而低占用位点则更受组织限制</strong>。</p><p>CTCF一致结合序列包含CpG，因此可能受到DNA甲基化的影响。CTCF能够在<strong>体外结合甲基化DNA序列</strong>，但<strong>优先结合未甲基化的序列</strong>，在H19-Igf2位点也可以看到。事实上，DNA甲基化似乎在CTCF的一些组织特异性结合事件中发挥作用。此外，<strong>CTCF</strong>可以通过与两种与DNA甲基化相关的酶:多聚(adp -核糖)聚合酶1 (<strong>PARP1</strong>)和无处不在表达的DNA(胞嘧啶-5)甲基转移酶1 (<strong>DNMT1</strong>)形成<strong>复合物来影响DNA甲基化</strong>。<strong>CTCF激活PARP1, PARP1在DNMT1上添加adp -核糖基团使DNMT1失活，从而维持无甲基CpGs的存在</strong>。</p><p><strong>部分CTCF结合位点</strong>在<strong>活性染色质</strong>(<strong>高H2K5Ac</strong>)和<strong>非活性</strong>染色质结构域(<strong>高H3K27me3</strong>)之<strong>间</strong>的过渡<strong>富集</strong>。对于逆转录转座的CTCF结合位点似乎尤其如此。CTCF位点经常位于所谓的<strong>膜相关域</strong>(lad)旁边。lad是与<strong>覆盖核膜内侧的层状蛋白网络相关的染色体区域</strong>;这些染色体区域往往是<strong>转录不活跃</strong>的。它的存在提示<strong>CTCF有助于染色质的三维结构的组织</strong>。在果蝇中，CTCF的抑制导致非活性域内H3K27me3水平的降低，表明CTCF在边界上的结合是<strong>维持抑制</strong>所必需的。CTCF的关联伴随着细胞分化过程中<strong>活性域和非活性域的重置</strong>，进一步表明它的功能是<strong>分离不同的染色质状态</strong>。一些lad在细胞分化过程中也会发生动态变化[35]，但CTCF是否与这些差异lad的边界结合目前尚不清楚。</p><p>尽管CTCF结合常出现在TSSs远端，但它确实与<strong>基因密度有很强的相关性</strong>(图2a,b)。事实上，CTCF在转录调控中<strong>直接作用的证据来自于早期对单个基因的研究</strong>。在全基因组范围内，部分CTCF位点与<strong>启动子特异性H3K4me3标记共定位</strong>，另一部分与<strong>增强子标记H3K4me1重合</strong>。启动子上的CTCF结合事件在组织中趋于<strong>保守</strong>，而CTCF与增强子的结合则更受<strong>组织限制</strong>。</p><p><img src="/GeekFocus/./2.png"></p><p>Figure2. CTCF在染色质生物学中的广泛作用。(a) CTCF结合位点的全基因组功能分类，采用Chen et al.[36]。(b) (i) CTCF结合位点位于<strong>分离活性域和非活性域的边界</strong>上。CTCF结合到(ii)<strong>增强子</strong>样序列和(iv)基因<strong>启动子</strong>上可以促进这些序列之间的环环相扣。(iii) CTCF结合在<strong>增强子和基因启动子之间</strong>，可以<strong>阻断</strong>增强子与其目标启动子之间的相互作用。</p><ol start="4"><li>CTCF和内聚蛋白共享DNA结合位点</li><li>5.ctcf和其他绑定伙伴</li><li>CTCF在单个基因位点的功能</li><li>CTCF介导的全基因组染色质环</li></ol><p>CTCF的基因组结合位点(通过全基因组<strong>ChIP</strong>)与<strong>Hi-C</strong>生成的<strong>genome-wide DNA contact map</strong>的计算交叉表明，CTCF参与染色体之间和基因组内的染色质相互作用。染色质相互作用分析与配对末端标记测序<strong>Chromatin interaction analysis with paired-end tag sequencing (ChIA-PET)</strong> 结合了ChIP和3C方法，用于研究由<strong>感兴趣的蛋白质介导的全基因组DNA相互作用</strong>。当靶向CTCF时，ChIA-PET揭示了蛋白介导的大约<strong>1500个染色体内</strong>和<strong>300个染色体间</strong>的相互作用。随后，根据<strong>组蛋白标记</strong>的分布，对<strong>染色体内环</strong>所包围的<strong>区域(10-200 kb)进行聚类</strong>。这表明CTCF环可以包含从环外非活性染色质分离出来的活性染色质，反之亦然。CTCF还可以同时<strong>捕获染色质环中的增强子和启动子</strong>。在大约<strong>40000个CTCF结合位点</strong>中，只有<strong>一小部分</strong>参与了大约1500个CTCF介导的<strong>环</strong>。这意味着不是所有CTCF介导的相互作用都被识别出来了，或者<strong>大多数CTCF位点没有参与环的形成</strong>。</p><p>后者很可能是正确的，因为5C(<strong>chromosome conformation capture carbon copy</strong>染色体构象捕获碳复制)技术表明，在1%的基因组中，大多数CTCF位点不参与染色质环，无论它们是否被内聚蛋白共同占据。<strong>CTCF结合序列常被基因启动子跳过，与增强子或更远的CTCF位点进行接触</strong>。</p><p>最近大量的全基因组DNA相互作用数据集有助于<strong>评估CTCF对染色体拓扑的影响</strong>。染色体上靠近<strong>CTCF结合位点的序列</strong>显示在它们的DNA接触中存在偏倚:它们与<strong>CTCF位点同侧</strong>的其他<strong>序列的相互作用</strong>大于与<strong>CTCF位点跨侧</strong>的序列的相互作用(图3a;)。同样的结果也出现在果蝇中另一种不同的绝缘体蛋白上:它与一个位点的结合阻止了侧翼序列在这个位点上相互接触。有趣的是，这可能为绝缘体的功能提供了一种解释:它们可以阻止DNA在绝缘序列上的空间接触。在一个特别详细的全基因组DNA接触研究中，<strong>拓扑域</strong>被定义;它们是<strong>平均大小为1mb的染色体区域</strong>，其中<strong>序列优先相互作用</strong>。在组织之间，甚至在物种之间，拓扑结构域具有很强的<strong>保持性</strong>，这表明这些结构域对<strong>细胞的特异性身份没有贡献</strong>。有趣的是，CTCF结合位点在这些<strong>区域边界周围的20kb窗口中富集</strong>(图3b)，再次强调了其作为<strong>染色质组织者</strong>的作用。其中一项研究表明，边界的破坏会导致拓扑域的混合，并导致相关基因的表达失调[79]。不同于拓扑域本身，域内的接触在分化过程中是变化的。在这里，CTCF似乎发挥了作用，可能适应基因表达的发育变化。</p><p><img src="/GeekFocus/./3.png"></p><p>Fig 3. CTCF通过阻碍DNA在其结合位点上的接触而起到绝缘体的作用。(a) CTCF<strong>阻碍其结合位点在10kb以内的序列跨越</strong>。<strong>线的厚度减小表明交互作用的概率减小</strong>。(b) CTCF结合位点常出现在拓扑域的边界处。(i) ESCs和皮质的Hi-c数据，用小鼠第12号染色体序列之间的颜色编码接触频率。<strong>三角形</strong>显示和突出<strong>拓扑域</strong>，是<strong>染色体序列优先相互作用的区域</strong>。(ii)层关联域(LAD)数据，LAD边界与拓扑域边界重合。(iii) CTCF ChIP-seq profiles，显示在边界的CTCF结合位点簇。请注意，这种CTCF集群在其他地方也存在，特别是在非lad地区。显示区域:chr12: 112.3-119.3 Mb (mm9)。</p><ol start="8"><li>结论</li></ol><p>尽管CTCF一直是研究的热点，但它仍然是一种<strong>神秘的转录因子</strong>。它与基因组中成千上万个位点结合，与大量其他转录因子相互作用。它常被发现参与染色质<strong>环</strong>，有时有，有时没有<strong>内聚蛋白</strong>的参与。它可以<strong>与其他CTCF结合位点</strong>形<strong>成</strong>染色质<strong>环</strong>，也可以与<strong>增强子</strong>和<strong>启动子</strong>序列形<strong>成</strong>染色质<strong>环</strong>。CTCF不仅与基因内外的序列结合，也与<strong>基因体内</strong>的<strong>序列结合</strong>，在基因体内它似乎能够<strong>暂停滑动聚合酶分子</strong>。最后，CTCF结合位点仍然作为<strong>反转录转座序列</strong>活跃地跳跃，使CTCF结合景观在不同哺乳动物物种之间具有多样性。</p><p>可以解释CTCF与染色质关联的许多，<strong>有时是相反的功能</strong>后果的统一主题可能是其<strong>成环能力</strong>。根据环中包含的序列和环外的序列，由CTCF形成的染色质可能会<strong>促进或阻碍增强子和靶基因之间的三维接触</strong>，从而产生不同的转录结果。许多问题仍然存在:为什么一些CTCF位点形成染色质环而另一些则没有?这在多大程度上依赖于相关的蛋白质因子?当蛋白质与染色质结合时，它是如何设法与这么多其他转录因子相互作用的?一种可能是CTCF作为染色质扫描转录因子的路障，当遇到结合蛋白时，这些转录因子以某种方式被困住。ctcf介导的染色体间接触有何相关性?CTCF是否通过阻止3D DNA接触来阻断增强子-启动子通信?或者绝缘是否涉及绝缘体序列与增强剂和启动剂的物理相互作用?这些问题的答案需要能够预测给定的CTCF结合事件是否在功能上不相关，是否会引起转录激活或抑制，是否会干扰转录激活或会产生染色质边界。</p>]]></content>
    
    
    <categories>
      
      <category>Biology</category>
      
    </categories>
    
    
    <tags>
      
      <tag>paper</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【GO】【KEGG】</title>
    <link href="/GeekFocus/2021/12/20/2021-12-20-GO_KEGG_post/"/>
    <url>/GeekFocus/2021/12/20/2021-12-20-GO_KEGG_post/</url>
    
    <content type="html"><![CDATA[<h2 id="Oryza-Sativa-【Gene-ID】【GO】【KEGG】"><a href="#Oryza-Sativa-【Gene-ID】【GO】【KEGG】" class="headerlink" title="Oryza Sativa 【Gene ID】【GO】【KEGG】"></a>Oryza Sativa 【Gene ID】【GO】【KEGG】</h2><span id="more"></span><p><strong>GO分析</strong>：基因-&gt;功能类群</p><p>**KEGG(Pathway)**：基因-&gt;代谢网络</p><p><strong>GO&#x2F;KEGG选取目标基因</strong></p><ul><li><p>指标：Enrichment score，p值，FDR</p></li><li><p>pathway：p和FDR越小越好，问题是有时本就不易富集出，如何取舍</p></li><li><p>GO：p，FDR，Enrichmentscore（越大越容易受到影响）</p></li><li><p><font color="green">fold change较大的基因</font>（up，down）</p></li><li><p>可能有用的蛋白，PPI？</p></li></ul><p>GO: 研究的基因哪些通路？是否变化</p><p><strong>KEGG筛选方法：</strong></p><ul><li>先看KEGG的聚类分析结果（感兴趣研究方向有关的基因是不是有差异）→ GO分为三个分枝，先看BP分枝（感兴趣研究方向有关的基因是不是有差异）→挑选和我们研究比较相关的→后期验证：选FC比较大，验证成功率会高一些</li><li>根据Rich factor值、Qvalue值或<font color="green">富集到此通路上的基因个数来衡量KEGG的富集程度</font>，找到富集最显著的通路</li><li>找自己感兴趣的：高原反应-&gt;呼吸功能相关通路，免疫系统-&gt;炎症因子、TNF相关通路</li><li>从通路中去找到<font color="green">表达倍数显著的基因进行验证</font>，进一步解释相关分子表达机制</li></ul><p><strong>目标表示</strong></p><p>HOTAIR出没于胞核（CC），参与了组蛋白甲基化调控引发癌基因沉默（BP），具体是结合PRC2复合物以及LSD1（MF）</p><hr><p><strong>转录组数据中筛选关键基因</strong></p><p>筛选关键基因的方法有3类：</p><p>1.表达量﹢功能富集</p><p>2.表达量﹢实验</p><p>3.表达量﹢序列</p><p>上面的三种方法不难看出，筛选关键基因的<font color="green">核心</font>是<font color="green">表达量</font>，其实转录组的核心就是以表达量为核心展开其他分析的，然后再附加其他一些信息，找出目标基因；最后将分析结果与研究目的巧妙融合，如果再做一些基因功能实验验证（高分必备，可不做），一篇高质量的文章就ok了。</p><p><strong>1.表达量﹢功能富集</strong></p><p>Zhu T, Wang X, Xu Z, Xu J, Li R, et al. (2020) Screening of key genes responsible for Pennisetum setaceum ‘Rubrum’ leaf color using tranome sequencing. PLOS ONE 15(11): e0242618.</p><p>该文研究对象狼尾草观赏草植物，<font color="green">高光</font>环产紫色叶子，<font color="green">低光</font>产浅紫色或绿色叶子。该文鉴定与<font color="green">叶片着色相关的关键基因</font>，并阐明参与狼尾草叶子的颜色变化的分子机制。</p><p>差异表达基因分析总共鉴定了19043个DEGs，与T0（未处理阶段的叶子）阶段的表达相比，在T1（遮阴12天后新叶子完全变绿的阶段）阶段上调和下调的基因分别为10761和8642。<font color="green">KEGG富集分析发现，显著富集的通路主要有类黄酮的生物合成，黄酮和黄酮醇的生物合成以及类胡萝卜素的生物合成</font>。<font color="red">基因筛选(显著KEGG内的基因筛选？)</font>发现存在与<strong>叶绿素代谢</strong>有关的31个差异表达基因，其中21个与叶绿素的生物<strong>合成</strong>有关，有10个与叶绿素的<strong>降解</strong>有关，以及3个与叶绿素<strong>降解调控</strong>有关的转录因子，<strong>花青素的合成和积</strong>累有31个关键酶基因，4个可能参与<strong>花色苷代谢调控</strong>的转录因子（图1所示） 。</p><p><img src="/GeekFocus/./selectDEG.png" alt="selectDEG"></p><p>快速筛选出感兴趣的基因：基因长度、基因在样品中的表达量、<strong>差异倍数</strong>、<strong>注释信息</strong>等。</p><p><font color="green">找显著通路里的基因。做一个信息表。</font></p><p><strong>2.表达量﹢实验</strong></p><p>Wang A, Chao T, Ji Z, Xuan R, Liu S, Guo M, Wang G, Wang J. 2020. Tranome analysis reveals potential immune function-related regulatory genes&#x2F;pathways of female Lubo goat submandibular glands at different developmental stages. PeerJ 8:e9947.</p><p>课题组前期的基因功能实验或文献查阅来借助别人的已经验证过的基因功能结果，之后再根据表达量筛选关键基因。</p><p>转录组研究的目的就是寻找与实验设计相关的关键基因，一般来说研究某生理现象都先要阅读大量文献来判断该实验的可行性。如转录组分析揭示了雌性鲁波<strong>山羊下颌腺</strong>在<strong>不同发育阶段</strong>的潜在<strong>免疫功能相关调节基因</strong>或途径</p><p>该文研究的目的是通过<strong>转录组测序</strong>来<strong>定位</strong>差异表达基因（DEG）在<strong>三个不同阶段的表达谱</strong>，预测在<strong>不同发育阶段</strong>的<strong>下颌下腺的免疫功能</strong>。由于<strong>人、小鼠、大鼠、牛</strong>的下颌腺都检测到了<strong>相关抗体</strong>，并且研究发现了下颌腺中的<strong>类红细胞分化因子、内皮素、肝细胞生长因子（HGF）、转移性生长因子（MGF）、转化生长因子-α（TGF-α）和其他因子</strong>。所以在<strong>后续的基因筛选中会重点关注相关因子的表达基因</strong>。</p><p>从上面例子中可以发现一个<strong>套路</strong>，先查阅模式生物中该方面的研究结果，然后再结合自己的研究项目筛选出基因，并且<strong>重点关注模式生物中已知的功能基因有没有较大的差异倍数</strong>。</p><hr><p>ref：</p><p><a href="https://zhuanlan.zhihu.com/p/78093534">https://zhuanlan.zhihu.com/p/78093534</a></p><p><a href="https://www.sohu.com/a/437865907_278730">https://www.sohu.com/a/437865907_278730</a></p><hr><h1 id="转录组图形专题之差异基因相关图形"><a href="#转录组图形专题之差异基因相关图形" class="headerlink" title="转录组图形专题之差异基因相关图形"></a>转录组图形专题之差异基因相关图形</h1><p>雷达图、热图、柱状图、韦恩图、火山图</p><p><a href="https://www.sohu.com/a/428207189_278730">https://www.sohu.com/a/428207189_278730</a></p><h1 id="全套的富集分析相关图形详解"><a href="#全套的富集分析相关图形详解" class="headerlink" title="全套的富集分析相关图形详解"></a>全套的富集分析相关图形详解</h1><p>柱形图，气泡图，圈图，z-score图，网络图</p><p><a href="https://www.sohu.com/a/436470973_278730">https://www.sohu.com/a/436470973_278730</a></p>]]></content>
    
    
    <categories>
      
      <category>Biology</category>
      
    </categories>
    
    
    <tags>
      
      <tag>O_Sativa</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Linux command awk</title>
    <link href="/GeekFocus/2021/12/17/2021-12-17-Linux_awk_command/"/>
    <url>/GeekFocus/2021/12/17/2021-12-17-Linux_awk_command/</url>
    
    <content type="html"><![CDATA[<h2 id="Linux-command-【awk】"><a href="#Linux-command-【awk】" class="headerlink" title="Linux command 【awk】"></a>Linux command 【awk】</h2><span id="more"></span><h1 id="Linux-awk-命令"><a href="#Linux-awk-命令" class="headerlink" title="Linux awk 命令"></a>Linux awk 命令</h1><p><a href="https://www.runoob.com/linux/linux-command-manual.html"><img src="https://www.runoob.com/images/up.gif" alt="Linux 命令大全"> Linux 命令大全</a></p><p>AWK 是一种<font color='green'>处理文本文件</font>的语言，是一个强大的文本分析工具。</p><p>之所以叫 AWK 是因为其取了三位创始人 Alfred <strong>A</strong>ho，Peter <strong>W</strong>einberger, 和 Brian <strong>K</strong>ernighan 的 Family Name 的首字符。</p><h3 id="语法"><a href="#语法" class="headerlink" title="语法"></a>语法</h3><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs sh">awk [选项参数] <span class="hljs-string">&#x27;script&#x27;</span> var=value file(s)<br>或<br>awk [选项参数] -f scriptfile var=value file(s)<br></code></pre></td></tr></table></figure><p><strong>选项参数说明：</strong></p><ul><li>-F fs or –field-separator fs<br>指定输入文件折分隔符，fs是一个字符串或者是一个正则表达式，如<font color='green'>-F:</font>。</li><li>-v var&#x3D;value or –asign var&#x3D;value<br>赋值一个用户定义变量。</li><li>-f scripfile or –file scriptfile<br>从脚本文件中读取awk命令。</li><li>-W posix<br>打开兼容模式。但有以下限制，不识别：&#x2F;x、函数关键字、func、换码序列以及当fs是一个空格时，将新行作为一个域分隔符；操作符<strong>和</strong>&#x3D;不能代替^和^&#x3D;；fflush无效?</li><li>-W version or –version<br>打印<font color='green'>bug报告信息</font>的版本。</li></ul><hr><h2 id="基本用法"><a href="#基本用法" class="headerlink" title="基本用法"></a>基本用法</h2><p>log.txt文本内容如下：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs sh">2 this is a <span class="hljs-built_in">test</span><br>3 Are you like awk<br>This<span class="hljs-string">&#x27;s a test</span><br><span class="hljs-string">10 There are orange,apple,mongo</span><br></code></pre></td></tr></table></figure><p>用法一：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sh">awk <span class="hljs-string">&#x27;&#123;[pattern] action&#125;&#x27;</span> &#123;filenames&#125;   <span class="hljs-comment"># 行匹配语句 awk &#x27;&#x27; 只能用单引号</span><br></code></pre></td></tr></table></figure><p>实例：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-comment"># 每行按空格或TAB分割，输出文本中的1、4项</span><br> $ awk <span class="hljs-string">&#x27;&#123;print $1,$4&#125;&#x27;</span> log.txt<br> ---------------------------------------------<br> 2 a<br> 3 like<br> This<span class="hljs-string">&#x27;s</span><br><span class="hljs-string"> 10 orange,apple,mongo</span><br><span class="hljs-string"> # 格式化输出</span><br><span class="hljs-string"> $ awk &#x27;</span>&#123;<span class="hljs-built_in">printf</span> <span class="hljs-string">&quot;%-8s %-10s\n&quot;</span>,<span class="hljs-variable">$1</span>,<span class="hljs-variable">$4</span>&#125;<span class="hljs-string">&#x27; log.txt</span><br><span class="hljs-string"> ---------------------------------------------</span><br><span class="hljs-string"> 2        a</span><br><span class="hljs-string"> 3        like</span><br><span class="hljs-string"> This&#x27;</span>s<br> 10       orange,apple,mongo<br> <br></code></pre></td></tr></table></figure><p><font color='green'>用法二：</font></p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sh">awk -F  <span class="hljs-comment">#-F相当于内置变量FS, 指定分割字符</span><br></code></pre></td></tr></table></figure><p>实例：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-comment"># 使用&quot;,&quot;分割</span><br> $  awk -F, <span class="hljs-string">&#x27;&#123;print $1,$2&#125;&#x27;</span>   log.txt<br> ---------------------------------------------<br> 2 this is a <span class="hljs-built_in">test</span><br> 3 Are you like awk<br> This<span class="hljs-string">&#x27;s a test</span><br><span class="hljs-string"> 10 There are orange apple</span><br><span class="hljs-string"> # 或者使用内建变量</span><br><span class="hljs-string"> $ awk &#x27;</span>BEGIN&#123;FS=<span class="hljs-string">&quot;,&quot;</span>&#125; &#123;<span class="hljs-built_in">print</span> <span class="hljs-variable">$1</span>,<span class="hljs-variable">$2</span>&#125;<span class="hljs-string">&#x27;     log.txt</span><br><span class="hljs-string"> ---------------------------------------------</span><br><span class="hljs-string"> 2 this is a test</span><br><span class="hljs-string"> 3 Are you like awk</span><br><span class="hljs-string"> This&#x27;</span>s a <span class="hljs-built_in">test</span><br> 10 There are orange apple<br> <span class="hljs-comment">#! 使用多个分隔符.先使用空格分割，然后对分割结果再使用&quot;,&quot;分割</span><br> $ awk -F <span class="hljs-string">&#x27;[ ,]&#x27;</span>  <span class="hljs-string">&#x27;&#123;print $1,$2,$5&#125;&#x27;</span>   log.txt<br> ---------------------------------------------<br> 2 this <span class="hljs-built_in">test</span><br> 3 Are awk<br> This<span class="hljs-string">&#x27;s a</span><br><span class="hljs-string"> 10 There apple</span><br></code></pre></td></tr></table></figure><p><font color='green'>用法三：</font>-va -vb</p><figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs nginx"><span class="hljs-attribute">awk</span> -v  <span class="hljs-comment"># 设置变量</span><br></code></pre></td></tr></table></figure><p>实例：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs sh">$ awk -va=1 <span class="hljs-string">&#x27;&#123;print $1,$1+a&#125;&#x27;</span> log.txt<br>---------------------------------------------<br>2 3<br>3 4<br>This<span class="hljs-string">&#x27;s 1</span><br><span class="hljs-string">10 11</span><br><span class="hljs-string">$ awk -va=1 -vb=s &#x27;</span>&#123;<span class="hljs-built_in">print</span> <span class="hljs-variable">$1</span>,<span class="hljs-variable">$1</span>+a,<span class="hljs-variable">$1b</span>&#125;<span class="hljs-string">&#x27; log.txt</span><br><span class="hljs-string">---------------------------------------------</span><br><span class="hljs-string">2 3 2s</span><br><span class="hljs-string">3 4 3s</span><br><span class="hljs-string">This&#x27;</span>s 1 This<span class="hljs-string">&#x27;ss</span><br><span class="hljs-string">10 11 10s</span><br></code></pre></td></tr></table></figure><p>用法四：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sh">awk -f &#123;awk脚本&#125; &#123;文件名&#125;<br></code></pre></td></tr></table></figure><p>实例：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sh">$ awk -f cal.awk log.txt<br></code></pre></td></tr></table></figure><hr><h2 id="运算符"><a href="#运算符" class="headerlink" title="运算符"></a>运算符</h2><table><thead><tr><th align="left">运算符</th><th align="left">描述</th></tr></thead><tbody><tr><td align="left">&#x3D; +&#x3D; -&#x3D; *&#x3D; &#x2F;&#x3D; %&#x3D; ^&#x3D; **&#x3D;</td><td align="left">赋值</td></tr><tr><td align="left">?:</td><td align="left">C条件表达式</td></tr><tr><td align="left">||</td><td align="left">逻辑或</td></tr><tr><td align="left">&amp;&amp;</td><td align="left">逻辑与</td></tr><tr><td align="left">~ 和 !~</td><td align="left">匹配正则表达式和不匹配正则表达式</td></tr><tr><td align="left">&lt; &lt;&#x3D; &gt; &gt;&#x3D; !&#x3D; &#x3D;&#x3D;</td><td align="left">关系运算符</td></tr><tr><td align="left">空格</td><td align="left">连接</td></tr><tr><td align="left">+ -</td><td align="left">加，减</td></tr><tr><td align="left">* &#x2F; %</td><td align="left">乘，除与求余</td></tr><tr><td align="left">+ - !</td><td align="left">一元加，减和逻辑非</td></tr><tr><td align="left">^ ***</td><td align="left">求幂</td></tr><tr><td align="left">++ –</td><td align="left">增加或减少，作为前缀或后缀</td></tr><tr><td align="left">$</td><td align="left">字段引用</td></tr><tr><td align="left">in</td><td align="left">数组成员</td></tr></tbody></table><p>过滤第一列大于2的行</p><figure class="highlight 1c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs 1c">$ awk &#x27;$1&gt;2&#x27; <span class="hljs-built_in">log</span>.txt    <span class="hljs-meta">#命令</span><br><span class="hljs-meta">#输出</span><br><span class="hljs-number">3</span> Are you like awk<br>This&#x27;s a test<br>10 There are orange,apple,mongo<br></code></pre></td></tr></table></figure><p>过滤第一列等于2的行</p><figure class="highlight nsis"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs nsis">$ awk <span class="hljs-string">&#x27;<span class="hljs-variable">$1</span>==2 &#123;print <span class="hljs-variable">$1</span>,<span class="hljs-variable">$3</span>&#125;&#x27;</span> log.txt    <span class="hljs-comment">#命令</span><br><span class="hljs-comment">#输出</span><br><span class="hljs-number">2</span> is<br></code></pre></td></tr></table></figure><p><font color='green'>过滤第一列大于2并且第二列等于’Are’的行</font></p><figure class="highlight nsis"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs nsis">$ awk <span class="hljs-string">&#x27;<span class="hljs-variable">$1</span>&gt;2 &amp;&amp; <span class="hljs-variable">$2</span>==&quot;Are&quot; &#123;print <span class="hljs-variable">$1</span>,<span class="hljs-variable">$2</span>,<span class="hljs-variable">$3</span>&#125;&#x27;</span> log.txt    <span class="hljs-comment">#命令</span><br><span class="hljs-comment">#输出</span><br><span class="hljs-number">3</span> Are you<br></code></pre></td></tr></table></figure><hr><h2 id="内建变量"><a href="#内建变量" class="headerlink" title="内建变量"></a>内建变量</h2><table><thead><tr><th align="left">变量</th><th align="left">描述</th></tr></thead><tbody><tr><td align="left">$n</td><td align="left">当前记录的<font color='green'>第n个字段</font>，字段间由FS分隔</td></tr><tr><td align="left"><font color='red'>$0</font></td><td align="left"><font color='green'>完整的输入记录</font></td></tr><tr><td align="left">ARGC</td><td align="left">命令行参数的数目</td></tr><tr><td align="left">ARGIND</td><td align="left">命令行中当前文件的位置(从0开始算)</td></tr><tr><td align="left">ARGV</td><td align="left">包含命令行参数的数组</td></tr><tr><td align="left">CONVFMT</td><td align="left">数字转换格式(默认值为%.6g)ENVIRON环境变量关联数组</td></tr><tr><td align="left">ERRNO</td><td align="left">最后一个系统错误的描述</td></tr><tr><td align="left">FIELDWIDTHS</td><td align="left">字段宽度列表(用空格键分隔)</td></tr><tr><td align="left">FILENAME</td><td align="left">当前文件名</td></tr><tr><td align="left"><strong>FNR</strong></td><td align="left">各文件分别计数的行号</td></tr><tr><td align="left"><strong>FS</strong></td><td align="left">字段分隔符(默认是任何空格)</td></tr><tr><td align="left">IGNORECASE</td><td align="left">如果为真，则进行忽略大小写的匹配</td></tr><tr><td align="left"><strong>NF</strong></td><td align="left">一条记录的字段的数目</td></tr><tr><td align="left"><strong>NR</strong></td><td align="left">已经读出的记录数，就是行号，从1开始</td></tr><tr><td align="left">OFMT</td><td align="left">数字的输出格式(默认值是%.6g)</td></tr><tr><td align="left"><strong>OFS</strong></td><td align="left">输出字段分隔符，默认值与输入字段分隔符一致。</td></tr><tr><td align="left"><strong>ORS</strong></td><td align="left">输出记录分隔符(默认值是一个换行符)</td></tr><tr><td align="left">RLENGTH</td><td align="left">由match函数所匹配的字符串的长度</td></tr><tr><td align="left">RS</td><td align="left">记录分隔符(默认是一个换行符)</td></tr><tr><td align="left">RSTART</td><td align="left">由match函数所匹配的字符串的第一个位置</td></tr><tr><td align="left">SUBSEP</td><td align="left">数组下标分隔符(默认值是&#x2F;034)</td></tr></tbody></table><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-comment">#看各变量值</span><br>$ awk <span class="hljs-string">&#x27;BEGIN&#123;printf &quot;%4s %4s %4s %4s %4s %4s %4s %4s %4s\n&quot;,&quot;FILENAME&quot;,&quot;ARGC&quot;,&quot;FNR&quot;,&quot;FS&quot;,&quot;NF&quot;,&quot;NR&quot;,&quot;OFS&quot;,&quot;ORS&quot;,&quot;RS&quot;;printf &quot;---------------------------------------------\n&quot;&#125; &#123;printf &quot;%4s %4s %4s %4s %4s %4s %4s %4s %4s\n&quot;,FILENAME,ARGC,FNR,FS,NF,NR,OFS,ORS,RS&#125;&#x27;</span>  log.txt<br>FILENAME ARGC  FNR   FS   NF   NR  OFS  ORS   RS<br>---------------------------------------------<br>log.txt    2    1         5    1<br>log.txt    2    2         5    2<br>log.txt    2    3         3    3<br>log.txt    2    4         4    4<br><br><span class="hljs-comment"># 输出顺序号 NR, 匹配文本行号</span><br>$ awk <span class="hljs-string">&#x27;&#123;print NR,FNR,$1,$2,$3&#125;&#x27;</span> log.txt<br>---------------------------------------------<br>1 1 2 this is<br>2 2 3 Are you<br>3 3 This<span class="hljs-string">&#x27;s a test</span><br><span class="hljs-string">4 4 10 There are</span><br><span class="hljs-string"># 指定输出分割符</span><br><span class="hljs-string">$  awk &#x27;</span>&#123;<span class="hljs-built_in">print</span> <span class="hljs-variable">$1</span>,<span class="hljs-variable">$2</span>,<span class="hljs-variable">$5</span>&#125;<span class="hljs-string">&#x27; OFS=&quot; $ &quot;  log.txt</span><br><span class="hljs-string">---------------------------------------------</span><br><span class="hljs-string">2 $ this $ test</span><br><span class="hljs-string">3 $ Are $ awk</span><br><span class="hljs-string">This&#x27;</span>s $ a $<br>10 $ There $<br></code></pre></td></tr></table></figure><hr><h2 id="使用正则，字符串匹配"><a href="#使用正则，字符串匹配" class="headerlink" title="使用正则，字符串匹配"></a><font color='green'>使用正则，字符串匹配</font></h2><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-comment"># 输出第二列包含 &quot;th&quot;，并打印第二列与第四列</span><br>$ awk <span class="hljs-string">&#x27;$2 ~ /th/ &#123;print $2,$4&#125;&#x27;</span> log.txt<br>---------------------------------------------<br>this a<br><span class="hljs-comment">#$0是b.txt每一行全部字段，-i &#123;&#125; a.txt 一行一行赋值给 &#123;&#125;</span><br><span class="hljs-built_in">cat</span> a.txt | xargs -i awk <span class="hljs-string">&#x27;BEGIN&#123;FS=&quot;\t&quot;&#125; $0 ~/&#123;&#125;/ &#123; print &#125;&#x27;</span> b.txt &gt; c.txt<br></code></pre></td></tr></table></figure><p><strong>~ 表示模式开始。&#x2F;&#x2F; 中是模式。</strong></p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-comment"># 输出包含 &quot;re&quot; 的行</span><br>$ awk <span class="hljs-string">&#x27;/re/ &#x27;</span> log.txt<br>---------------------------------------------<br>3 Are you like awk<br>10 There are orange,apple,mongo<br></code></pre></td></tr></table></figure><hr><h2 id="忽略大小写"><a href="#忽略大小写" class="headerlink" title="忽略大小写"></a>忽略大小写</h2><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs sh">$ awk <span class="hljs-string">&#x27;BEGIN&#123;IGNORECASE=1&#125; /this/&#x27;</span> log.txt<br>---------------------------------------------<br>2 this is a <span class="hljs-built_in">test</span><br>This<span class="hljs-string">&#x27;s a test</span><br></code></pre></td></tr></table></figure><hr><h2 id="模式取反"><a href="#模式取反" class="headerlink" title="模式取反"></a>模式取反</h2><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs sh">this is<br>Are you<br>This<span class="hljs-string">&#x27;s a test</span><br><span class="hljs-string">There are</span><br><span class="hljs-string"></span><br><span class="hljs-string">$ awk &#x27;</span><span class="hljs-variable">$2</span> !~ /th/ &#123;<span class="hljs-built_in">print</span> <span class="hljs-variable">$2</span>,<span class="hljs-variable">$4</span>&#125;<span class="hljs-string">&#x27; log.txt</span><br><span class="hljs-string">---------------------------------------------</span><br><span class="hljs-string">Are like</span><br><span class="hljs-string">a</span><br><span class="hljs-string">There orange,apple,mongo</span><br><span class="hljs-string">$ awk &#x27;</span>!/th/ &#123;<span class="hljs-built_in">print</span> <span class="hljs-variable">$2</span>,<span class="hljs-variable">$4</span>&#125;<span class="hljs-string">&#x27; log.txt</span><br><span class="hljs-string">---------------------------------------------</span><br><span class="hljs-string">Are like</span><br><span class="hljs-string">a</span><br><span class="hljs-string">There orange,apple,mongo</span><br></code></pre></td></tr></table></figure><hr><h2 id="awk脚本"><a href="#awk脚本" class="headerlink" title="awk脚本"></a>awk脚本</h2><p>关于 awk 脚本，我们需要注意两个关键词 BEGIN 和 END。</p><ul><li>BEGIN{ 这里面放的是<font color='green'>执行前</font>的语句 }</li><li>END {这里面放的是处理完<font color='green'>所有的行后要执行</font>的语句 }</li><li>{这里面放的是处理<font color='green'>每一行时</font>要执行的语句}</li></ul><p>假设有这么一个文件（学生成绩表）：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs sh">$ <span class="hljs-built_in">cat</span> score.txt<br>Marry   2143 78 84 77<br>Jack    2321 66 78 45<br>Tom     2122 48 77 71<br>Mike    2537 87 97 95<br>Bob     2415 40 57 62<br></code></pre></td></tr></table></figure><p>我们的 awk 脚本如下：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs sh">$ <span class="hljs-built_in">cat</span> cal.awk<br><span class="hljs-comment">#!/bin/awk -f</span><br><span class="hljs-comment">#运行前</span><br>BEGIN &#123;<br>    math = 0<br>    english = 0<br>    computer = 0<br> <br>    <span class="hljs-built_in">printf</span> <span class="hljs-string">&quot;NAME    NO.   MATH  ENGLISH  COMPUTER   TOTAL\n&quot;</span><br>    <span class="hljs-built_in">printf</span> <span class="hljs-string">&quot;---------------------------------------------\n&quot;</span><br>&#125;<br><span class="hljs-comment">#运行中</span><br>&#123;<br>    math+=<span class="hljs-variable">$3</span><br>    english+=<span class="hljs-variable">$4</span><br>    computer+=<span class="hljs-variable">$5</span><br>    <span class="hljs-built_in">printf</span> <span class="hljs-string">&quot;%-6s %-6s %4d %8d %8d %8d\n&quot;</span>, <span class="hljs-variable">$1</span>, <span class="hljs-variable">$2</span>, <span class="hljs-variable">$3</span>,<span class="hljs-variable">$4</span>,<span class="hljs-variable">$5</span>, <span class="hljs-variable">$3</span>+<span class="hljs-variable">$4</span>+<span class="hljs-variable">$5</span><br>&#125;<br><span class="hljs-comment">#运行后</span><br>END &#123;<br>    <span class="hljs-built_in">printf</span> <span class="hljs-string">&quot;---------------------------------------------\n&quot;</span><br>    <span class="hljs-built_in">printf</span> <span class="hljs-string">&quot;  TOTAL:%10d %8d %8d \n&quot;</span>, math, english, computer<br>    <span class="hljs-built_in">printf</span> <span class="hljs-string">&quot;AVERAGE:%10.2f %8.2f %8.2f\n&quot;</span>, math/NR, english/NR, computer/NR<br>&#125;<br></code></pre></td></tr></table></figure><p>我们来看一下执行结果：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs sh">$ awk -f cal.awk score.txt<br>NAME    NO.   MATH  ENGLISH  COMPUTER   TOTAL<br>---------------------------------------------<br>Marry  2143     78       84       77      239<br>Jack   2321     66       78       45      189<br>Tom    2122     48       77       71      196<br>Mike   2537     87       97       95      279<br>Bob    2415     40       57       62      159<br>---------------------------------------------<br>  TOTAL:       319      393      350<br>AVERAGE:     63.80    78.60    70.00<br></code></pre></td></tr></table></figure><hr><h2 id="另外一些实例"><a href="#另外一些实例" class="headerlink" title="另外一些实例"></a>另外一些实例</h2><p>AWK 的 hello world 程序为：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sh">BEGIN &#123; <span class="hljs-built_in">print</span> <span class="hljs-string">&quot;Hello, world!&quot;</span> &#125;<br></code></pre></td></tr></table></figure><p>计算文件大小</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs sh">$ <span class="hljs-built_in">ls</span> -l *.txt | awk <span class="hljs-string">&#x27;&#123;sum+=$5&#125; END &#123;print sum&#125;&#x27;</span><br>--------------------------------------------------<br>666581<br></code></pre></td></tr></table></figure><p>从文件中找出<font color='green'>长度大于 80 的行</font>：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sh">awk <span class="hljs-string">&#x27;length&gt;80&#x27;</span> log.txt<br></code></pre></td></tr></table></figure><p>打印九九乘法表</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-built_in">seq</span> 9 | sed <span class="hljs-string">&#x27;H;g&#x27;</span> | awk -v RS=<span class="hljs-string">&#x27;&#x27;</span> <span class="hljs-string">&#x27;&#123;for(i=1;i&lt;=NF;i++)printf(&quot;%dx%d=%d%s&quot;, i, NR, i*NR, i==NR?&quot;\n&quot;:&quot;\t&quot;)&#125;&#x27;</span><br></code></pre></td></tr></table></figure><blockquote><p>更多内容：</p><ul><li><a href="https://www.runoob.com/w3cnote/awk-work-principle.html">AWK 工作原理</a></li><li><a href="https://www.runoob.com/w3cnote/awk-arrays.html">AWK 数组</a></li><li><a href="https://www.runoob.com/w3cnote/awk-if-loop.html">AWK 条件语句与循环</a></li><li><a href="https://www.runoob.com/w3cnote/awk-user-defined-functions.html">AWK 用户自定义函数</a></li><li><a href="https://www.runoob.com/w3cnote/awk-built-in-functions.html">AWK 内置函数</a></li><li><a href="https://www.runoob.com/w3cnote/8-awesome-awk-built-in-variables.html">8 个有力的 Awk 内建变量</a></li><li><a href="http://www.gnu.org/software/gawk/manual/gawk.html">AWK 官方手册</a></li></ul></blockquote><p><strong>awk、sed、grep更适合的方向：</strong></p><ul><li>grep 更适合单纯的查找或匹配文本</li><li>sed 更适合编辑匹配到的文本</li><li>awk 更适合格式化文本，对文本进行较复杂格式处理</li></ul><p>关于awk内建变量个人见解，简单易懂</p><p>解释一下变量：</p><p>变量：分为内置变量和自定义变量;输入分隔符FS和输出分隔符OFS都属于内置变量。</p><p>内置变量就是awk预定义好的、内置在awk内部的变量，而自定义变量就是用户定义的变量。</p><ul><li>FS(Field Separator)：输入字段分隔符， 默认为空白字符</li><li>OFS(Out of Field Separator)：输出字段分隔符， 默认为空白字符</li><li>RS(Record Separator)：输入记录分隔符(输入换行符)， 指定输入时的换行符</li><li>ORS(Output Record Separate)：输出记录分隔符（输出换行符），输出时用指定符号代替换行符</li><li>NF(Number for Field)：当前行的字段的个数(即当前行被分割成了几列)</li><li>NR(Number of Record)：行号，当前处理的文本行的行号。</li><li>FNR：各文件分别计数的行号</li><li>ARGC：命令行参数的个数</li><li>ARGV：数组，保存的是命令行所给定的各参数</li></ul><p><strong>自定义变量的方法</strong></p><ul><li>方法一：-v varname&#x3D;value ，变量名区分字符大小写。</li><li>方法二：在program中直接定义。</li></ul>]]></content>
    
    
    <categories>
      
      <category>Linux</category>
      
    </categories>
    
    
    <tags>
      
      <tag>awk</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Linux command xargs</title>
    <link href="/GeekFocus/2021/12/17/2021-12-17-Linux_xargs_command/"/>
    <url>/GeekFocus/2021/12/17/2021-12-17-Linux_xargs_command/</url>
    
    <content type="html"><![CDATA[<h2 id="Linux-command-【xargs】"><a href="#Linux-command-【xargs】" class="headerlink" title="Linux command 【xargs】"></a>Linux command 【xargs】</h2><span id="more"></span><h1 id="Linux-xargs-命令"><a href="#Linux-xargs-命令" class="headerlink" title="Linux xargs 命令"></a>Linux xargs 命令</h1><p>xargs（英文全拼： eXtended ARGuments）是给<font color='green'>命令传递参数</font>的一个过滤器，也是<font color='green'>组合多个命令</font>的一个工具。</p><p>xargs 可以将管道或标准输入（stdin）数据转换成命令行参数，也能够从文件的输出中读取数据。</p><p>xargs 也可以将单行或多行文本输入转换为其他格式，例如<font color='green'>多行变单行，单行变多行</font>。</p><p>xargs 默认命令是 echo，这意味着通过<font color='green'>管道传递给 xargs 的输入包含换行和空白</font>，通过 xargs 的处理，<font color='green'>换行和空白将被空格取代</font>。</p><p>xargs 是一个强有力的命令，它能够捕获一个命令的输出，然后传递给另外一个命令。</p><p>之所以能用到这个命令，关键是由于很多命令不支持|管道来传递参数，而日常工作中有有这个必要，所以就有了 xargs 命令，例如：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs sh">find /sbin -perm +700 |<span class="hljs-built_in">ls</span> -l       <span class="hljs-comment">#这个命令是错误的</span><br>find /sbin -perm +700 |xargs <span class="hljs-built_in">ls</span> -l   <span class="hljs-comment">#这样才是正确的</span><br></code></pre></td></tr></table></figure><p>xargs 一般是和管道一起使用。</p><p><strong>命令格式：</strong></p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sh">somecommand |xargs -item  <span class="hljs-built_in">command</span><br></code></pre></td></tr></table></figure><p><strong>参数：</strong></p><ul><li>-a file 从文件中读入作为 stdin</li><li>-e flag ，注意有的时候可能会是-E，flag必须是一个以空格分隔的标志，当xargs分析到含有flag这个标志的时候就停止。</li><li>-p 当每次执行一个argument的时候询问一次用户。</li><li>-n num 后面加次数，表示命令在执行的时候一次用的argument的个数，默认是用所有的。</li><li>-t 表示先打印命令，然后再执行。</li><li><font color='green'>-i 或是-I</font>，这得看linux支持了，将xargs的每项名称，一般是<font color='green'>一行一行赋值给 {}，可以用 {} 代替</font>。</li><li>-r no-run-if-empty 当xargs的输入为空的时候则停止xargs，不用再去执行了。</li><li>-s num 命令行的最大字符数，指的是 xargs 后面那个命令的最大命令行字符数。</li><li><font color='green'>-L num 从标准输入一次读取 num 行送给 command 命令</font>。</li><li>-l 同 -L。</li><li>-d delim 分隔符，默认的xargs分隔符是回车，argument的分隔符是空格，这里修改的是xargs的分隔符。</li><li>-x exit的意思，主要是配合-s使用。。</li><li>-P 修改最大的进程数，默认是1，为0时候为as many as it can ，这个例子我没有想到，应该平时都用不到的吧。</li></ul><h3 id="实例"><a href="#实例" class="headerlink" title="实例"></a>实例</h3><p>xargs 用作替换工具，读取输入数据重新格式化后输出。</p><p>定义一个测试文件，内有多行文本数据：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-comment"># cat test.txt</span><br><br>a b c d e f g<br>h i j k l m n<br>o p q<br>r s t<br>u v w x y z<br></code></pre></td></tr></table></figure><p><font color='green'>多行输入单行输出：</font></p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-comment"># cat test.txt | xargs</span><br>a b c d e f g h i j k l m n o p q r s t u v w x y z<br></code></pre></td></tr></table></figure><p><font color='green'>-n 选项多行输出：</font></p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-comment"># cat test.txt | xargs -n3</span><br><br>a b c<br>d e f<br>g h i<br>j k l<br>m n o<br>p q r<br>s t u<br>v w x<br>y z<br></code></pre></td></tr></table></figure><p>-d 选项可以自定义一个定界符：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-comment"># echo &quot;nameXnameXnameXname&quot; | xargs -dX</span><br><br>name name name name<br></code></pre></td></tr></table></figure><p>结合 -n 选项使用：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-comment"># echo &quot;nameXnameXnameXname&quot; | xargs -dX -n2</span><br><br>name name<br>name name<br></code></pre></td></tr></table></figure><p>读取 stdin，将格式化后的参数传递给命令</p><p>假设一个命令为 sk.sh 和一个保存参数的文件 arg.txt：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-meta">#!/bin/bash</span><br><span class="hljs-comment">#sk.sh命令内容，打印出所有参数。</span><br><br><span class="hljs-built_in">echo</span> $*<br></code></pre></td></tr></table></figure><p>arg.txt文件内容：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-comment"># cat arg.txt</span><br><br>aaa<br>bbb<br>ccc<br></code></pre></td></tr></table></figure><p>xargs 的一个选项 -I，使用 -I 指定一个替换字符串 {}，这个字符串在 xargs 扩展时会被替换掉，当 -I 与 xargs 结合使用，每一个参数命令都会被执行一次：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-comment"># cat arg.txt | xargs -I &#123;&#125; ./sk.sh -p &#123;&#125; -l</span><br><br>-p aaa -l<br>-p bbb -l<br>-p ccc -l<br></code></pre></td></tr></table></figure><p>复制所有图片文件到 &#x2F;data&#x2F;images 目录下：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-built_in">ls</span> *.jpg | xargs -n1 -I &#123;&#125; <span class="hljs-built_in">cp</span> &#123;&#125; /data/images<br></code></pre></td></tr></table></figure><p>xargs 结合 find 使用</p><p>用 rm 删除太多的文件时候，可能得到一个错误信息：**&#x2F;bin&#x2F;rm Argument list too long.** 用 xargs 去避免这个问题：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sh">find . -<span class="hljs-built_in">type</span> f -name <span class="hljs-string">&quot;*.log&quot;</span> -print0 | xargs -0 <span class="hljs-built_in">rm</span> -f<br></code></pre></td></tr></table></figure><p>xargs -0 将 \0 作为定界符。</p><p>统计一个源代码目录中所有 php 文件的行数：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sh">find . -<span class="hljs-built_in">type</span> f -name <span class="hljs-string">&quot;*.php&quot;</span> -print0 | xargs -0 <span class="hljs-built_in">wc</span> -l<br></code></pre></td></tr></table></figure><p>查找所有的 jpg 文件，并且压缩它们：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sh">find . -<span class="hljs-built_in">type</span> f -name <span class="hljs-string">&quot;*.jpg&quot;</span> -<span class="hljs-built_in">print</span> | xargs tar -czvf images.tar.gz<br></code></pre></td></tr></table></figure><p>xargs 其他应用</p><p>假如有<font color='green'>一个文件包含了很多希望下载的 URL</font>，你能够使用 xargs下载所有链接：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-comment"># cat url-list.txt | xargs wget -c</span><br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>Linux</category>
      
    </categories>
    
    
    <tags>
      
      <tag>xargs</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Oryza Sativa 【Gene ID】【GO】【KEGG】</title>
    <link href="/GeekFocus/2021/12/16/2021-12-16-osa_GO_KEGG/"/>
    <url>/GeekFocus/2021/12/16/2021-12-16-osa_GO_KEGG/</url>
    
    <content type="html"><![CDATA[<h2 id="Oryza-Sativa-【Gene-ID】【GO】【KEGG】"><a href="#Oryza-Sativa-【Gene-ID】【GO】【KEGG】" class="headerlink" title="Oryza Sativa 【Gene ID】【GO】【KEGG】"></a>Oryza Sativa 【Gene ID】【GO】【KEGG】</h2><span id="more"></span><h1 id="O-sativa-ID-区分"><a href="#O-sativa-ID-区分" class="headerlink" title="O_sativa ID 区分"></a>O_sativa ID 区分</h1><ul><li><p>MSU, <font color='red'>RGAP7.0</font>(rice genome annotation project)：<strong>LOC_Os01g01010.1</strong>,  LOC_Osp#g#####，<strong>LOC_Os-Chr-g-number</strong></p></li><li><p><font color='red'>RAP</font>(the rice annotation project), IRGSP-1.0: <strong>Os06t0664200</strong>，<strong>Os-Chr-g-number</strong></p></li><li><p><font color='red'>KEGG支持</font>：osa：RefSeq ID（Gene ID：<strong>4334374</strong>）；dosa：RAP-DB ID（<strong>Os06t0664200-01</strong>）</p></li><li><p>疑问：RAP-DB ID为什么和IRGSP-1.0 ID多了个-01：RAP-Locus与RAP ID不同</p></li><li><p>clusterProfiler可能是目前KEGG富集分析最好的软件，因为能<strong>爬取最新的KEGG在线版数据库</strong>，而不是用不再更新的KEGG.db。</p></li><li><p>对于RGAP水稻的基因编号，如LOC_Os01g01010.1 我们要把它变成<code>Os06t0664200-01</code> RAP-ID的命名方式，符合<code>dosa</code>的要求。</p></li></ul><h2 id="转化id"><a href="#转化id" class="headerlink" title="转化id"></a>转化id</h2><ul><li><p>下载一个各个ID对应的文件：<a href="https://shigen.nig.ac.jp/rice/oryzabase/download/riceId%E3%80%82%E5%AF%B9%E4%BA%8ERGAP%E6%B0%B4%E7%A8%BB%E7%9A%84%E5%9F%BA%E5%9B%A0%E7%BC%96%E5%8F%B7%EF%BC%8C%E5%A6%82LOC_Os01g01010.1">https://shigen.nig.ac.jp/rice/oryzabase/download/riceId。对于RGAP水稻的基因编号，如LOC_Os01g01010.1</a> 把它变成<code>Os06t0664200-01</code> RAP-ID的命名方式，符合<code>dosa</code>的要求。</p></li><li><p>日本晴数据库：<a href="https://shigen.nig.ac.jp/rice/oryzabase">https://shigen.nig.ac.jp/rice/oryzabase</a></p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ grep LOC_Os01g01010.1  rice_id_20140620174522.txt<br>Os01g0100100    Os01t0100100-01 J075199P03      301700  J075199P03              LOC_Os01g01010.1        AK242339<br><span class="hljs-built_in">cat</span> LOC.txt | xargs -i awk <span class="hljs-string">&#x27;BEGIN&#123;FS=&quot;\t&quot;&#125;  $0 ~/&#123;&#125;/ &#123; print $2&#125;&#x27;</span> rice_id_20140620174522.txt &gt; RAP_id.txt<br></code></pre></td></tr></table></figure><hr><h1 id="超几何分布"><a href="#超几何分布" class="headerlink" title="超几何分布"></a>超几何分布</h1><p>它描述了从有限N个物件（其中包含M个指定种类的物件）中抽出n个物件，成功抽出该指定种类的物件的次数（不放回）。称为超几何分布。</p><p><a href="https://baike.baidu.com/item/%E8%B6%85%E5%87%A0%E4%BD%95%E5%88%86%E5%B8%83/4782968">https://baike.baidu.com/item/超几何分布/4782968</a></p><hr><h1 id="GO-enrichment：web"><a href="#GO-enrichment：web" class="headerlink" title="GO enrichment：web"></a>GO enrichment：web</h1><blockquote><p>网站：<a href="http://systemsbiology.cau.edu.cn/agriGOv2">http://systemsbiology.cau.edu.cn/agriGOv2</a>  华大</p></blockquote><h1 id="GO-enrichment：R-clusterProfiler"><a href="#GO-enrichment：R-clusterProfiler" class="headerlink" title="GO enrichment：R clusterProfiler"></a>GO enrichment：R clusterProfiler</h1><p><strong>X</strong> clusterprofiler不能用来做GO的富集分析，因为其20个物种中不包括水稻；</p><h2 id="获取Orgdb，"><a href="#获取Orgdb，" class="headerlink" title="获取Orgdb，"></a>获取Orgdb，</h2><p>AnnotationHub在线检索并抓取OrgDb</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs R"><span class="hljs-operator">&gt;</span> require<span class="hljs-punctuation">(</span>AnnotationHub<span class="hljs-punctuation">)</span><br><span class="hljs-operator">&gt;</span> hub <span class="hljs-operator">&lt;-</span> AnnotationHub<span class="hljs-punctuation">(</span><span class="hljs-punctuation">)</span><br><span class="hljs-operator">&gt;</span> query<span class="hljs-punctuation">(</span>hub<span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;oryza sativa&quot;</span><span class="hljs-punctuation">)</span><br>title<br>  AH10561 <span class="hljs-operator">|</span> hom.Oryza_sativa.inp8.sqlite<br>  AH55775 <span class="hljs-operator">|</span> org.Oryza_sativa_Japonica_Group.eg.sqlite<br><span class="hljs-operator">&gt;</span> rice <span class="hljs-operator">&lt;-</span> hub<span class="hljs-punctuation">[[</span><span class="hljs-string">&#x27;AH55775&#x27;</span><span class="hljs-punctuation">]</span><span class="hljs-punctuation">]</span><br></code></pre></td></tr></table></figure><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs r"><span class="hljs-operator">&gt;</span> <span class="hljs-built_in">length</span><span class="hljs-punctuation">(</span>keys<span class="hljs-punctuation">(</span>rice<span class="hljs-punctuation">)</span><span class="hljs-punctuation">)</span><span class="hljs-punctuation">[</span><span class="hljs-number">1</span><span class="hljs-punctuation">]</span><br><span class="hljs-comment">#通过检索，org.Oryza_sativa_Japonica_Group.eg.sqlite就是我们所要的OrgDb，可以通过相应的accession number, AH55775 抓取文件，并存入了rice对象中，它包含了32639个基因的注释</span><br></code></pre></td></tr></table></figure><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs r"><span class="hljs-comment">#这个OrgDb，包含有以下一些注释信息:</span><br><span class="hljs-operator">&gt;</span> columns<span class="hljs-punctuation">(</span>rice<span class="hljs-punctuation">)</span><br> <span class="hljs-punctuation">[</span><span class="hljs-number">1</span><span class="hljs-punctuation">]</span> <span class="hljs-string">&quot;ACCNUM&quot;</span>      <span class="hljs-string">&quot;ALIAS&quot;</span>       <span class="hljs-string">&quot;CHR&quot;</span>         <span class="hljs-string">&quot;ENTREZID&quot;</span>    <span class="hljs-string">&quot;EVIDENCE&quot;</span><br> <span class="hljs-punctuation">[</span><span class="hljs-number">6</span><span class="hljs-punctuation">]</span> <span class="hljs-string">&quot;EVIDENCEALL&quot;</span> <span class="hljs-string">&quot;GENENAME&quot;</span>    <span class="hljs-string">&quot;GID&quot;</span>         <span class="hljs-string">&quot;GO&quot;</span>          <span class="hljs-string">&quot;GOALL&quot;</span><br><span class="hljs-punctuation">[</span><span class="hljs-number">11</span><span class="hljs-punctuation">]</span> <span class="hljs-string">&quot;ONTOLOGY&quot;</span>    <span class="hljs-string">&quot;ONTOLOGYALL&quot;</span> <span class="hljs-string">&quot;PMID&quot;</span>        <span class="hljs-string">&quot;REFSEQ&quot;</span>      <span class="hljs-string">&quot;SYMBOL&quot;</span><br>  <span class="hljs-punctuation">[</span><span class="hljs-number">16</span><span class="hljs-punctuation">]</span> <span class="hljs-string">&quot;UNIGENE&quot;</span><br></code></pre></td></tr></table></figure><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><code class="hljs R"><span class="hljs-comment">##我们可以使用bitr来转换ID，甚至于直接检索GO注释：</span><br><span class="hljs-operator">&gt;</span> require<span class="hljs-punctuation">(</span>clusterProfiler<span class="hljs-punctuation">)</span><br><span class="hljs-operator">&gt;</span> bitr<span class="hljs-punctuation">(</span>keys<span class="hljs-punctuation">(</span>rice<span class="hljs-punctuation">)</span><span class="hljs-punctuation">[</span><span class="hljs-number">1</span><span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&#x27;ENTREZID&#x27;</span><span class="hljs-punctuation">,</span> <span class="hljs-built_in">c</span><span class="hljs-punctuation">(</span><span class="hljs-string">&quot;REFSEQ&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;GO&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;ONTOLOGY&quot;</span><span class="hljs-punctuation">)</span><span class="hljs-punctuation">,</span> rice<span class="hljs-punctuation">)</span><br><span class="hljs-string">&#x27;select()&#x27;</span> returned <span class="hljs-number">1</span><span class="hljs-operator">:</span>many mapping between keys and columns<br>  ENTREZID      REFSEQ         GO ONTOLOGY<br><span class="hljs-number">1</span>  <span class="hljs-number">3131385</span> NP_039457.2 GO<span class="hljs-operator">:</span><span class="hljs-number">0005739</span>       CC<br><span class="hljs-number">2</span>  <span class="hljs-number">3131385</span> NP_039457.2 GO<span class="hljs-operator">:</span><span class="hljs-number">0005763</span>       CC<br><span class="hljs-comment">##GO富集分析</span><br><span class="hljs-operator">&gt;</span> sample_genes <span class="hljs-operator">&lt;-</span> keys<span class="hljs-punctuation">(</span>rice<span class="hljs-punctuation">)</span><span class="hljs-punctuation">[</span><span class="hljs-number">1</span><span class="hljs-operator">:</span><span class="hljs-number">100</span><span class="hljs-punctuation">]</span><br><span class="hljs-operator">&gt;</span> head<span class="hljs-punctuation">(</span>sample_genes<span class="hljs-punctuation">)</span><br><span class="hljs-punctuation">[</span><span class="hljs-number">1</span><span class="hljs-punctuation">]</span> <span class="hljs-string">&quot;3131385&quot;</span> <span class="hljs-string">&quot;3131390&quot;</span> <span class="hljs-string">&quot;3131391&quot;</span> <span class="hljs-string">&quot;3131392&quot;</span> <span class="hljs-string">&quot;3131393&quot;</span> <span class="hljs-string">&quot;3131394&quot;</span><br><span class="hljs-comment">##这里只是简单地使用ID列表中前100个ENTREZ基因ID，也可以使用其它的ID，通过借助于bitr进行转换，或者通过给enrichGO指定ID类型(keyType参数）。</span><br><span class="hljs-operator">&gt;</span> 有了OrgDb，使用起来，就跟文档中使用人类基因做为例子一样，用法一致，并且也可以通过clusterProfiler所提供的各种可视化函数对结果进行展示：<br><br><span class="hljs-operator">&gt;</span> require<span class="hljs-punctuation">(</span>clusterProfiler<span class="hljs-punctuation">)</span><br><span class="hljs-operator">&gt;</span> res <span class="hljs-operator">=</span> enrichGO<span class="hljs-punctuation">(</span>sample_genes<span class="hljs-punctuation">,</span> OrgDb<span class="hljs-operator">=</span>rice<span class="hljs-punctuation">,</span> pvalueCutoff<span class="hljs-operator">=</span><span class="hljs-number">1</span><span class="hljs-punctuation">,</span> qvalueCutoff<span class="hljs-operator">=</span><span class="hljs-number">1</span><span class="hljs-punctuation">)</span><br><span class="hljs-operator">&gt;</span> res<br><span class="hljs-comment">#</span><br><span class="hljs-comment"># over-representation test</span><br><span class="hljs-comment">#</span><br><span class="hljs-comment">#...@organism    Oryza sativa_Japonica_Group</span><br><span class="hljs-comment">#...@ontology    MF</span><br><span class="hljs-comment">#...@keytype     ENTREZID</span><br><span class="hljs-comment">#...@gene        chr [1:100] &quot;3131385&quot; &quot;3131390&quot; &quot;3131391&quot; &quot;3131392&quot; &quot;3131393&quot; &quot;3131394&quot; ...</span><br><span class="hljs-comment">#...pvalues adjusted by &#x27;BH&#x27; with cutoff &lt;1</span><br><span class="hljs-comment">#...28 enriched terms found</span><br><span class="hljs-string">&#x27;data.frame&#x27;</span><span class="hljs-operator">:</span>   <span class="hljs-number">28</span> obs. of  <span class="hljs-number">9</span> variables<span class="hljs-operator">:</span><br> <span class="hljs-operator">$</span> ID         <span class="hljs-operator">:</span> chr  <span class="hljs-string">&quot;GO:0003735&quot;</span> <span class="hljs-string">&quot;GO:0005198&quot;</span> <span class="hljs-string">&quot;GO:0003723&quot;</span> <span class="hljs-string">&quot;GO:0016830&quot;</span> ...<br> <span class="hljs-operator">$</span> Description<span class="hljs-operator">:</span> chr  <span class="hljs-string">&quot;structural constituent of ribosome&quot;</span> <span class="hljs-string">&quot;structural molecule activity&quot;</span> <span class="hljs-string">&quot;RNA binding&quot;</span> <span class="hljs-string">&quot;carbon-carbon lyase activity&quot;</span> ...<br> <span class="hljs-operator">$</span> GeneRatio  <span class="hljs-operator">:</span> chr  <span class="hljs-string">&quot;7/12&quot;</span> <span class="hljs-string">&quot;7/12&quot;</span> <span class="hljs-string">&quot;2/12&quot;</span> <span class="hljs-string">&quot;1/12&quot;</span> ...<br> <span class="hljs-operator">$</span> BgRatio    <span class="hljs-operator">:</span> chr  <span class="hljs-string">&quot;22/478&quot;</span> <span class="hljs-string">&quot;22/478&quot;</span> <span class="hljs-string">&quot;14/478&quot;</span> <span class="hljs-string">&quot;10/478&quot;</span> ...<br> <span class="hljs-operator">$</span> pvalue     <span class="hljs-operator">:</span> num  <span class="hljs-number">1.08e-07</span> <span class="hljs-number">1.08e-07</span> <span class="hljs-number">4.45e-02</span> <span class="hljs-number">2.26e-01</span> <span class="hljs-number">3.24e-01</span> ...<br> <span class="hljs-operator">$</span> p.adjust   <span class="hljs-operator">:</span> num  <span class="hljs-number">1.52e-06</span> <span class="hljs-number">1.52e-06</span> <span class="hljs-number">4.15e-01</span> <span class="hljs-number">1.00</span> <span class="hljs-number">1.00</span> ...<br> <span class="hljs-operator">$</span> qvalue     <span class="hljs-operator">:</span> num  <span class="hljs-number">1.42e-06</span> <span class="hljs-number">1.42e-06</span> <span class="hljs-number">3.90e-01</span> <span class="hljs-number">9.40e-01</span> <span class="hljs-number">9.40e-01</span> ...<br> <span class="hljs-operator">$</span> geneID     <span class="hljs-operator">:</span> chr  <span class="hljs-string">&quot;3131425/3131435/3131436/3131439/3131441/3131442/3131457&quot;</span> <span class="hljs-string">&quot;3131425/3131435/3131436/3131439/3131441/3131442/3131457&quot;</span> <span class="hljs-string">&quot;3131425/3131457&quot;</span> <span class="hljs-string">&quot;3131463&quot;</span> ...<br> <span class="hljs-operator">$</span> Count      <span class="hljs-operator">:</span> int  <span class="hljs-number">7</span> <span class="hljs-number">7</span> <span class="hljs-number">2</span> <span class="hljs-number">1</span> <span class="hljs-number">3</span> <span class="hljs-number">1</span> <span class="hljs-number">2</span> <span class="hljs-number">4</span> <span class="hljs-number">4</span> <span class="hljs-number">1</span> ...<br></code></pre></td></tr></table></figure><figure class="highlight objectivec"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs objectivec">sly &lt;- ah[[<span class="hljs-string">&quot;AH61992&quot;</span>]]<br>sly<br>saveDb(sly,file=<span class="hljs-string">&quot;sly.orgdb&quot;</span>)<br>laodDb(file=<span class="hljs-string">&quot;sly.orgdb&quot;</span>)<br></code></pre></td></tr></table></figure><p>plant_GSEA: MSU-&gt;Uniprot</p><p>david:Uniprot-&gt;Entrez_id</p><hr><h1 id="KEGG-enrichment：R-clusterProfiler"><a href="#KEGG-enrichment：R-clusterProfiler" class="headerlink" title="KEGG enrichment：R clusterProfiler"></a>KEGG enrichment：R clusterProfiler</h1><ol><li><p>enrichKEGG</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs r">enrichKEGG<span class="hljs-punctuation">(</span>gene<span class="hljs-punctuation">,</span> organism <span class="hljs-operator">=</span> <span class="hljs-string">&quot;hsa&quot;</span><span class="hljs-punctuation">,</span> keyType <span class="hljs-operator">=</span> <span class="hljs-string">&quot;kegg&quot;</span><span class="hljs-punctuation">,</span> pvalueCutoff <span class="hljs-operator">=</span> <span class="hljs-number">0.05</span><span class="hljs-punctuation">,</span><br>  pAdjustMethod <span class="hljs-operator">=</span> <span class="hljs-string">&quot;BH&quot;</span><span class="hljs-punctuation">,</span> universe<span class="hljs-punctuation">,</span> minGSSize <span class="hljs-operator">=</span> <span class="hljs-number">10</span><span class="hljs-punctuation">,</span> maxGSSize <span class="hljs-operator">=</span> <span class="hljs-number">500</span><span class="hljs-punctuation">,</span><br>  qvalueCutoff <span class="hljs-operator">=</span> <span class="hljs-number">0.2</span><span class="hljs-punctuation">,</span> use_internal_data <span class="hljs-operator">=</span> <span class="hljs-literal">FALSE</span><span class="hljs-punctuation">)</span><br><span class="hljs-comment">#gene： 基因名，要和keyType对应</span><br><span class="hljs-comment">#organism: 需要参考 http://www.genome.jp/kegg/catalog/org_list.html</span><br><span class="hljs-comment">#keyType: 基因的命名方式， “kegg”, ‘ncbi-geneid’, ‘ncib-proteinid’ and ‘uniprot’选择其一</span><br><span class="hljs-comment">#enrichKEGG的一个关键在于理解它是如何获取数据的。在线爬取数据库，相当于在KEGG上手动输入基因名查询。</span><br><span class="hljs-comment">#所以，把enrichKEGG当做浏览器，试出合适的keytypes。</span><br></code></pre></td></tr></table></figure></li><li></li></ol><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs R">library<span class="hljs-punctuation">(</span>clusterProfiler<span class="hljs-punctuation">)</span><br><span class="hljs-comment"># 对于GID</span><br>kk <span class="hljs-operator">&lt;-</span> enrichkegg<span class="hljs-punctuation">(</span>gid_list<span class="hljs-punctuation">,</span>organism<span class="hljs-operator">=</span><span class="hljs-string">&#x27;osa&#x27;</span><span class="hljs-punctuation">,</span>keyType <span class="hljs-operator">=</span> <span class="hljs-string">&#x27;kegg&#x27;</span><span class="hljs-punctuation">,</span>pvalueCutoff<span class="hljs-operator">=</span><span class="hljs-number">0.05</span><span class="hljs-punctuation">,</span> pAdjustMethod<span class="hljs-operator">=</span><span class="hljs-string">&#x27;BH&#x27;</span><span class="hljs-punctuation">,</span>qvalueCutoff<span class="hljs-operator">=</span><span class="hljs-number">0.1</span><span class="hljs-punctuation">)</span><br><br><span class="hljs-comment"># 对于RAP_ID</span><br>kk <span class="hljs-operator">&lt;-</span> enrichkegg<span class="hljs-punctuation">(</span>rap_list<span class="hljs-punctuation">,</span>organism<span class="hljs-operator">=</span><span class="hljs-string">&#x27;dosa&#x27;</span><span class="hljs-punctuation">,</span>keyType <span class="hljs-operator">=</span> <span class="hljs-string">&#x27;kegg&#x27;</span><span class="hljs-punctuation">,</span>pvalueCutoff<span class="hljs-operator">=</span><span class="hljs-number">0.05</span><span class="hljs-punctuation">,</span> pAdjustMethod<span class="hljs-operator">=</span><span class="hljs-string">&#x27;BH&#x27;</span><span class="hljs-punctuation">,</span>qvalueCutoff<span class="hljs-operator">=</span><span class="hljs-number">0.1</span><span class="hljs-punctuation">)</span><br><br>write.table<span class="hljs-punctuation">(</span>ekk<span class="hljs-punctuation">,</span><span class="hljs-string">&quot;kegg.txt&quot;</span><span class="hljs-punctuation">,</span>sep <span class="hljs-operator">=</span> <span class="hljs-string">&quot;\t&quot;</span><span class="hljs-punctuation">,</span><span class="hljs-built_in">quote</span> <span class="hljs-operator">=</span> <span class="hljs-built_in">F</span><span class="hljs-punctuation">,</span>row.names <span class="hljs-operator">=</span> <span class="hljs-built_in">F</span><span class="hljs-punctuation">)</span><br>barplot<span class="hljs-punctuation">(</span>ekk<span class="hljs-punctuation">,</span>showCategory <span class="hljs-operator">=</span> <span class="hljs-number">15</span><span class="hljs-punctuation">,</span>title <span class="hljs-operator">=</span> <span class="hljs-string">&quot;EnrichmentKEGG&quot;</span><span class="hljs-punctuation">)</span><br></code></pre></td></tr></table></figure><ol start="3"><li>若差异基因集（如500个）本身确实没有生物学功能偏好性，非常有可能无显著富集的kegg通路。</li></ol><p>修改代码，比如：</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs r">kk.down <span class="hljs-operator">&lt;-</span> enrichKEGG<span class="hljs-punctuation">(</span>gene <span class="hljs-operator">=</span> gene_down<span class="hljs-punctuation">,</span><br>                        organism <span class="hljs-operator">=</span> <span class="hljs-string">&#x27;hsa&#x27;</span><span class="hljs-punctuation">,</span> <br>                        pvalueCutoff <span class="hljs-operator">=</span> <span class="hljs-number">0.9</span><span class="hljs-punctuation">,</span><br>                        qvalueCutoff <span class="hljs-operator">=</span><span class="hljs-number">0.9</span><span class="hljs-punctuation">)</span><br><span class="hljs-comment"># 需要自己差异分析筛选得到 gene_down 基因集 ，然后进行超几何分布检验</span><br><span class="hljs-comment">#再调整阈值</span><br></code></pre></td></tr></table></figure><ol start="4"><li><p>或可去MSigDB（Molecular Signatures Database<a href="https://www.gsea-msigdb.org/gsea/msigdb%EF%BC%89%E7%9C%8B%E5%85%B6%E5%AE%83%E5%8A%9F%E8%83%BD%E5%9F%BA%E5%9B%A0%E9%9B%86%E6%98%AF%E5%90%A6%E5%8F%AF%E4%BB%A5%E5%AF%8C%E9%9B%86%EF%BC%8CMSigDB%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B8%AD%E5%AE%9A%E4%B9%89%E4%BA%86%E5%B7%B2%E7%9F%A5%E7%9A%84%E5%9F%BA%E5%9B%A0%E9%9B%86%E5%90%88%EF%BC%9A%E5%8C%85%E6%8B%ACH%E5%92%8CC1-C7%E5%85%AB%E4%B8%AA%E7%B3%BB%E5%88%97%EF%BC%88Collection%EF%BC%89%EF%BC%8C%E6%A4%8D%E7%89%A9%E9%80%82%E7%94%A8%EF%BC%9F">https://www.gsea-msigdb.org/gsea/msigdb）看其它功能基因集是否可以富集，MSigDB数据库中定义了已知的基因集合：包括H和C1-C7八个系列（Collection），植物适用？</a></p></li><li><p><a href="https://zhuanlan.zhihu.com/p/150744437">GSEA分析</a>，不依赖于差异分析本身,植物适用？</p></li></ol><hr><h1 id="KEGG数据库不会下载？了解下API！"><a href="#KEGG数据库不会下载？了解下API！" class="headerlink" title="KEGG数据库不会下载？了解下API！"></a>KEGG数据库不会下载？了解下API！</h1><ol><li><p>KEGG数据库并不提供免费、批量蛋白序列下载，其官方提供在线分析工具BlastKOALA（<a href="https://link.zhihu.com/?target=https://www.kegg.jp/blastkoala/">https://www.kegg.jp/blastkoala/</a>）等可用于KEGG数据库的注释分析。此外还有其他一些在线分析工具例如很常用的KAAS（<a href="https://link.zhihu.com/?target=https://www.genome.jp/tools/kaas/">https://www.genome.jp/tools/kaas/</a>）等。在线工具内部参数未知。</p></li><li><p>KEGG API（<a href="https://www.kegg.jp/kegg/rest/keggapi.html%EF%BC%89%E6%98%AF%E5%92%8CKEGG%E5%86%85%E6%A0%B8%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%9B%E8%A1%8C%E4%BA%A4%E4%BA%92%E7%9A%84%E7%A8%8B%E5%BA%8F%E7%95%8C%E9%9D%A2%EF%BC%8C%E5%85%81%E8%AE%B8%E7%94%A8%E6%88%B7%E5%9F%BA%E4%BA%8E%E8%AF%A5%E7%95%8C%E9%9D%A2%E6%A3%80%E7%B4%A2KEGG%E6%95%B0%E6%8D%AE%E5%BA%93%EF%BC%8C[%E4%B8%8B%E8%BD%BD](https://zhuanlan.zhihu.com/p/76195765)">https://www.kegg.jp/kegg/rest/keggapi.html）是和KEGG内核数据库进行交互的程序界面，允许用户基于该界面检索KEGG数据库，[下载](https://zhuanlan.zhihu.com/p/76195765)</a></p><p>(1)<a href="https://mp.weixin.qq.com/s/YlJbkIg9It9On5HWRPPgmQ">https://mp.weixin.qq.com/s/YlJbkIg9It9On5HWRPPgmQ</a></p><p>(2)<a href="https://mp.weixin.qq.com/s/F3dRgHBI4a2atvz0O_pukA">https://mp.weixin.qq.com/s/F3dRgHBI4a2atvz0O_pukA</a></p><p>(3)<a href="https://mp.weixin.qq.com/s/oDDIlWXsLyTCh18bEEysmQ">https://mp.weixin.qq.com/s/oDDIlWXsLyTCh18bEEysmQ</a></p></li></ol>]]></content>
    
    
    <categories>
      
      <category>Biology</category>
      
    </categories>
    
    
    <tags>
      
      <tag>geneID</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>KMeans</title>
    <link href="/GeekFocus/2021/11/15/2021-11-15-kmeans/"/>
    <url>/GeekFocus/2021/11/15/2021-11-15-kmeans/</url>
    
    <content type="html"><![CDATA[<p>监督学习</p><p>无监督学习：数据无标注甚至非结构化。KMeans…</p><span id="more"></span><h1 id="KMeans"><a href="#KMeans" class="headerlink" title="KMeans"></a>KMeans</h1><h2 id="简介-聚类与KMeans"><a href="#简介-聚类与KMeans" class="headerlink" title="简介-聚类与KMeans"></a>简介-聚类与KMeans</h2><blockquote><ul><li><strong>聚类（Clustering）</strong>：将数据对象分为多个类或者簇 (Cluster)，使同一簇对象间较高相似度，不同簇对象差别较大。</li><li><strong>划分（Partitioning）</strong>：聚类可基于划分，也可基于分层。划分即将对象划分成不同簇，而分层将对象分等级。</li><li><strong>排他（Exclusive）</strong>：一个数据对象，只能被划分到一个簇。如果一个数据对象可被划分到多个簇，则称为可重叠（Overlapping）。</li><li><strong>距离（Distance）</strong>：基于距离的聚类将距离近的相似对象聚在一起。基于<font color="red">概率分布模型的聚类？</font>在一组对象中，找到符合特定分布模型的对象的集合，不一定是距离最近的或者最相似的，而是能完美的呈现出概率分布模型所描述的模型。</li><li>欧氏距离：欧几里得度量二维和三维空间中的欧氏距离就是两点之间的实际距离</li></ul></blockquote><ul><li><p>与分类、序列标注不同，聚类事先并不知道任何样本标签，通过数据之间内在关系把样本划分为若干类别，使得同类别样本之间的相似度高，不同类别相似度低（增大类内聚，减少类间距）。</p></li><li><p>聚类属于非监督学习，K均值聚类最基础常用。基本思想，<font color='green'>通过迭代寻找K个簇（Cluster），使聚类结果对应的损失函数最小</font>。终止条件是没有（或最小数目）对象被重新分配给不同的聚类，没有（或最小数目）聚类中心再发生变化，误差平方和局部最小。<font color='red'>损失函数定义为各个样本距离所属簇中心点的误差平方和</font>：</p></li></ul><p><img src="/GeekFocus/./1.png"></p><p>xi代表第i个样本，ci是xi所属的簇，uci代表簇对应中心点，M是样本总数。</p><ul><li><p>？损失函数本质是衡量模型的拟合效果，有求解参数需求的算法，才会有损失函数。Kmeans 不求解什么参数，它的模型本质也没有在拟合数据，而是在对数据进行一 种探索。在决策树中有衡量分类效果的指标准确度<code>accuracy</code>，准确度所对应的损失叫做泛化误差，但不能通过最小化泛化误差来求解某个模型中需要的信息，只是希望模型的效果上表现出来的泛化误差 很小。因此决策树，KNN 等算法，是绝对没有损失函数的。</p></li><li><table><thead><tr><th>距离度量对比</th><th>质心</th><th>Inertia</th></tr></thead><tbody><tr><td>欧几里得距离</td><td>均值</td><td>最小化每个样本点到质心的欧式距离之和</td></tr><tr><td>曼哈顿距离</td><td>中位数</td><td>最小化每个样本点到质心的曼哈顿距离之和</td></tr><tr><td>余弦距离</td><td>均值</td><td>最小化每个样本点到质心的余弦距离之和</td></tr></tbody></table></li><li><p>上述问题是<font color='green'>NP-Hard</font>问题。一般是采用坐标下降（Coordinate Decendet）方法求解。坐标下降法属于非梯度优化方法，每一步迭代中沿着一个坐标轴方向探索，通过循环使用不同的坐标达到求解目标函数的局部最小值。</p></li></ul><p><img src="/GeekFocus/./4.png"></p><p>如上图，假设两维度x，y：</p><ol><li>首先选择初始位置(x,y)，假设x未知将y的值代入目标函数中，令目标函数导数0，求得此时最佳x值。</li><li>又假设y未知将刚求得x的值代入目标函数，令目标函数导数0，求得此时最佳y。</li><li>重复执行第1步第2步，目标函数逐渐接近极小值点，直到达到了极小值点停止。</li></ol><p>收敛的过程如红色箭头所示。更多维度时，同理，一次只对一个维度最优化。</p><p>坐标下降法一般要求目标函数是可微的凸函数(局部最小值即全局最小值?)，此时求得的极小值才能是全局最小值。</p><p>使用K-Means前，可先用PCA使各个变量间尽可能独立。否则如两变量间有较强关联性，函数收敛速度会非常慢。</p><h2 id="步骤"><a href="#步骤" class="headerlink" title="步骤"></a>步骤</h2><p>KMeans的核心目标是将给定的数据集划分成K个簇（K是超参），并给出每个样本数据对应的中心点。具体步骤非常简单，可以分为4步：</p><p><img src="/GeekFocus/./2.png"></p><p><strong>KMeans最核心的部分就是先固定中心点，调整每个样本所属的类别来减少J；再固定每个样本的类别，调整中心点继续减小J 。两个过程交替循环， J 单调递减直到最（极）小值，中心点和样本划分的类别同时收敛。</strong></p><p><img src="/GeekFocus/./3.png"></p><p><img src="/GeekFocus/./5.png"></p><h1 id="优缺点优化策略"><a href="#优缺点优化策略" class="headerlink" title="优缺点优化策略"></a>优缺点优化策略</h1><p>KMenas优点：</p><ul><li>高效可伸缩，计算复杂度 为<font color='green'>O(NKt)</font>接近于线性（N是数据量，K是聚类总数，t是迭代轮数）。</li><li><font color='green'>收敛速度快</font>，原理通俗易懂，可解释性强。</li></ul><p>KMeans明显缺点：</p><ul><li>受<font color='green'>初始值</font>和<font color='green'>异常</font>影响，聚类结果可能不是全局最优而是<font color='green'>局部最优</font>。</li><li><font color='green'>K</font>是超参数，按<font color='green'>经验选择</font></li><li><font color='green'>样本点只能划分到单一的类中</font></li><li>只能发现球状的簇。</li><li>初始值对结果影响较大，可能每次聚类结果都不一样。</li></ul><p>根据以上特点，我们可以从下面几个角度对算法做调优</p><ol><li><strong>数据预处理：归一化和异常点过滤</strong></li></ol><p><strong>KMeans本质是基于欧式距离度量的数据划分方法，均值和方差大的维度将对数据聚类结果产生决定性影响。</strong>聚类前对数据（<strong>具体的说是每一个维度的特征</strong>）做<font color='green'>归一化</font>和<font color='green'>单位统一</font>至关重要。<font color='green'>异常值</font>会对均值计算产生较大影响，导致<strong>中心偏移</strong>，<font color='green'>噪声点最好能提前过滤</font>。</p><p><strong>2.合理选择K值</strong></p><p>K值的选择一般基于实验和多次实验结果。例如采用<strong>手肘法</strong>，尝试不同K值并将对应的损失函数画成折线。手肘法认为图上的<strong>拐点就是K的最佳值</strong>（上图对应K&#x3D;3）。</p><p><strong>Gap Statistic方法</strong>。只需要找到最大的Gap Statistic对应的K(自动)。</p><p>沿用第一节中<font color='green'>损失函数</font>记为 Dk，当分为K类时，Gap Statistic定义为： Gap(k)&#x3D;E(logDk)-logDk 。 E(logDk)是logDk的期望，一般由<font color='green'>蒙特卡洛模拟</font>产生。在<font color='green'>样本所在的区域内按照均匀分布随机地产生和原始样本数一样多的随机样本</font>，对这个<font color='green'>随机样本做KMeans</font>，得到一个<font color='green'>Dk</font>，<font color='green'>重复多次</font>计算出 E(logDk)的近似值。</p><p><strong>Gap(K) 的物理含义是<font color='green'>随机样本的损失与实际样本的损失之差</font>。Gap越<font color='green'>大</font>说明聚类的效果越好</strong>。随着K的变化Gap(K)几乎维持一条直线保持不变。说明这些样本间没有明显的类别关系，<font color='green'>数据分布几乎和均匀分布一致</font>，近似随机。此时聚类没有意义。</p><p><strong>3.改进初始值的选择</strong></p><p>采取随机选择K个中心，<font color='green'>可能导致不同中心点距离很近</font>，需<font color='green'>更多的迭代次数才能收敛</font>。如在选择初始中心点时<strong>不同的中心尽可能远离</strong>，效果更好。这类算法中，以K-Means++算法最具影响力。</p><p><strong>4.采用核函数?</strong></p><p>主要思想是通过一个非线性映射，将输入空间中的数据点映射到高位的特征空间中，并在新的空间进行聚类。非线性映射增加了数据点线性可分的概率（与SVM中使用核函数思想类似）对于非凸的数据分布可以达到更为准确的聚类结果。</p><ol start="5"><li>从EM算法解释KMeans</li></ol><p>EM（Expectation-Maximum）算法即期望最大化算法，是最常见的隐变量估计方法。EM算法是一种迭代优化策略，每一次迭代都分为两步：期望步（E）、极大步（M）。<strong>EM算法的提出最初是为了解决数据缺失情况下的参数估计问题</strong>，基本思想是首先根据已有的观测数据，通过极大似然估计估计出模型的参数；再根据上一步估计出的参数值估计缺失数据的值；最后根据估计出的缺失数据和原有的观测数据重新对参数值进行估计，反复迭代直到收敛。</p><hr><p>K均值聚类是使用<a href="https://baike.baidu.com/item/%E6%9C%80%E5%A4%A7%E6%9C%9F%E6%9C%9B%E7%AE%97%E6%B3%95/10180861">最大期望算法</a>（Expectation-Maximization algorithm）求解的<a href="https://baike.baidu.com/item/%E9%AB%98%E6%96%AF%E6%B7%B7%E5%90%88%E6%A8%A1%E5%9E%8B/8878468">高斯混合模型</a>（Gaussian Mixture Model, GMM）在<a href="https://baike.baidu.com/item/%E6%AD%A3%E6%80%81%E5%88%86%E5%B8%83/829892">正态分布</a>的协方差为单位矩阵，且隐变量的后验分布为一组<a href="https://baike.baidu.com/item/%E7%8B%84%E6%8B%89%E5%85%8B%CE%B4%E5%87%BD%E6%95%B0/5760582">狄拉克δ函数</a>时所得到的特例?</p><p>Python</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">import</span> random<br><span class="hljs-keyword">import</span> sys<br><span class="hljs-keyword">import</span> time<br><span class="hljs-keyword">class</span> <span class="hljs-title class_">KMeansClusterer</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self,ndarray,cluster_num</span>):<br>        self.ndarray = ndarray<br>        self.cluster_num = cluster_num<br>        self.points=self.__pick_start_point(ndarray,cluster_num)<br>         <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">cluster</span>(<span class="hljs-params">self</span>):<br>        result = []<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(self.cluster_num):<br>            result.append([])<br>        <span class="hljs-keyword">for</span> item <span class="hljs-keyword">in</span> self.ndarray:<br>            distance_min = sys.maxsize<br>            index=-<span class="hljs-number">1</span><br>            <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(self.points)):                <br>                distance = self.__distance(item,self.points[i])<br>                <span class="hljs-keyword">if</span> distance &lt; distance_min:<br>                    distance_min = distance<br>                    index = i<br>            result[index] = result[index] + [item.tolist()]<br>        new_center=[]<br>        <span class="hljs-keyword">for</span> item <span class="hljs-keyword">in</span> result:<br>            new_center.append(self.__center(item).tolist())<br>        <span class="hljs-comment"># 中心点未改变，说明达到稳态，结束递归</span><br>        <span class="hljs-keyword">if</span> (self.points==new_center).<span class="hljs-built_in">all</span>():<br>            <span class="hljs-keyword">return</span> result<br>         <br>        self.points=np.array(new_center)<br>        <span class="hljs-keyword">return</span> self.cluster()<br>             <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__center</span>(<span class="hljs-params">self,<span class="hljs-built_in">list</span></span>):<br>        <span class="hljs-string">&#x27;&#x27;&#x27;计算一组坐标的中心点</span><br><span class="hljs-string">        &#x27;&#x27;&#x27;</span><br>        <span class="hljs-comment"># 计算每一列的平均值</span><br>        <span class="hljs-keyword">return</span> np.array(<span class="hljs-built_in">list</span>).mean(axis=<span class="hljs-number">0</span>)<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__distance</span>(<span class="hljs-params">self,p1,p2</span>):<br>        <span class="hljs-string">&#x27;&#x27;&#x27;计算两点间距</span><br><span class="hljs-string">        &#x27;&#x27;&#x27;</span><br>        tmp=<span class="hljs-number">0</span><br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(p1)):<br>            tmp += <span class="hljs-built_in">pow</span>(p1[i]-p2[i],<span class="hljs-number">2</span>)<br>        <span class="hljs-keyword">return</span> <span class="hljs-built_in">pow</span>(tmp,<span class="hljs-number">0.5</span>)<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__pick_start_point</span>(<span class="hljs-params">self,ndarray,cluster_num</span>):<br>        <br>        <span class="hljs-keyword">if</span> cluster_num &lt;<span class="hljs-number">0</span> <span class="hljs-keyword">or</span> cluster_num &gt; ndarray.shape[<span class="hljs-number">0</span>]:<br>            <span class="hljs-keyword">raise</span> Exception(<span class="hljs-string">&quot;簇数设置有误&quot;</span>)<br>      <br>        <span class="hljs-comment"># 随机点的下标</span><br>        indexes=random.sample(np.arange(<span class="hljs-number">0</span>,ndarray.shape[<span class="hljs-number">0</span>],step=<span class="hljs-number">1</span>).tolist(),cluster_num)<br>        points=[]<br>        <span class="hljs-keyword">for</span> index <span class="hljs-keyword">in</span> indexes:<br>            points.append(ndarray[index].tolist())<br>        <span class="hljs-keyword">return</span> np.array(points)<br></code></pre></td></tr></table></figure><hr><h2 id="KMeans-and-gaussian-mixture-model"><a href="#KMeans-and-gaussian-mixture-model" class="headerlink" title="KMeans and gaussian mixture model"></a>KMeans and gaussian mixture model</h2><p>数据表示：kmeans单个点对cluster建模（假设各clus数据是圆形或高位球形）。GMM，使用高斯分布表示</p><p>数据先验：kmeans，假设各clus先验概率一样，实际clus数据量可能不均匀。clusA10000，B100，新样本不考虑与AB相似度，属于A概率大。GMM对数据先验进行建模。</p><p>相似度衡量：Kmeans的欧式距离假设各个维度对相似度衡量作用一样。GMM相似度衡量使用后验概率通过引入协方差矩阵，对各个维度数据的不同重要性建模。</p><p>数据分配：kmeans各样本只属于相似度最高clus（hard clusting），GMM使用后验概率对各个clus按比例分配（fuzzy clustering？）。</p><hr><h2 id="k-means-聚类算法"><a href="#k-means-聚类算法" class="headerlink" title="k-means++聚类算法"></a>k-means++聚类算法</h2><p><code>KMeans</code>算法，<code>KMeans</code>在聚类之前首先需初始化k个簇中心，因此 <code>KMeans</code> 算法对初值敏感，对于不同的初始值，会导致不同聚类结果。若初始化随机，很有可能 k簇中心都在同一个簇，这种情况 <code>KMeans</code> 很大程度上都不会收敛到全局最小。</p><p>为优化选择初始质心的方法，2007 年 Arthur,等 三人发表了论文“k-means++: <code>The advantages of careful seeding</code>，<code>sklearn.cluster.KMeans</code> 中默认参数为 <code>init=&#39;k-means++&#39;</code> ，其算法原理为在初始化簇中心时，逐个选取 k个簇中心，且离其他簇中心越远的样本越有可能被选为下个簇中心。</p><p>算法步骤：</p><p><img src="/GeekFocus/./6.png"></p><hr><p>ref：</p><p><a href="https://zhuanlan.zhihu.com/p/184686598">https://zhuanlan.zhihu.com/p/184686598</a></p><p><a href="https://www.cnblogs.com/gaochundong/p/kmeans_clustering.html">https://www.cnblogs.com/gaochundong/p/kmeans_clustering.html</a></p><p><a href="https://www.zhihu.com/question/31296149">https://www.zhihu.com/question/31296149</a></p><p><a href="https://zhuanlan.zhihu.com/p/342052190#:~:text=KMeans%20">https://zhuanlan.zhihu.com/p/342052190#:~:text=KMeans%20</a></p>]]></content>
    
    
    <categories>
      
      <category>algorithm</category>
      
    </categories>
    
    
    <tags>
      
      <tag>algorithm</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>ATAC-seq-4【Macs2/3 Installation】</title>
    <link href="/GeekFocus/2021/10/29/2021-10-30-ATAC-seq-4-macs3-install/"/>
    <url>/GeekFocus/2021/10/29/2021-10-30-ATAC-seq-4-macs3-install/</url>
    
    <content type="html"><![CDATA[<h3 id="Macs2-x2F-3-installation-Debug-Record"><a href="#Macs2-x2F-3-installation-Debug-Record" class="headerlink" title="Macs2&#x2F;3 installation Debug Record"></a>Macs2&#x2F;3 installation Debug Record</h3><span id="more"></span><p>macs2 installation record<br>install conda<br>creat work environment<br>install numpy1.17<br>python setup.py install –prefix ….&#x2F;software&#x2F;MACS</p><figure class="highlight clean"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs clean">####################################ERROR1#############################################<br>#MACS3/fermi-lite/ksw.c:<span class="hljs-number">31</span>:<span class="hljs-number">26</span>: fatal error: lib/x86/sse2.h: No such file or directory<br># #include <span class="hljs-string">&quot;lib/x86/sse2.h&quot;</span>                      ^<br>#compilation terminated.<br>#error: command <span class="hljs-string">&#x27;gcc&#x27;</span> failed <span class="hljs-keyword">with</span> exit status <span class="hljs-number">1</span><br>######################################################################################<br></code></pre></td></tr></table></figure><p><a href="https://github.com/macs3-project/MACS/issues/473">https://github.com/macs3-project/MACS/issues/473</a><br>zip downloaded from github zip is not complete in the deep dir<br>git clone <a href="https://github.com/macs3-project/MACS.git">https://github.com/macs3-project/MACS.git</a> –recursive<br>or download absent files</p><figure class="highlight clean"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs clean">####################################ERROR2#############################################<br>Checking .pth file support <span class="hljs-keyword">in</span> ..../software/MACS2/lib/python3<span class="hljs-number">.8</span>/site-packages/<br>..../.conda/envs/atacseq/bin/python -E -c pass<br>TEST FAILED: ..../software/MACS2/lib/python3<span class="hljs-number">.8</span>/site-packages/ does NOT support .pth files<br>bad install directory or PYTHONPATH<br><br>You are attempting to install a package to a directory that is not<br>on PYTHONPATH and which Python does not read <span class="hljs-string">&quot;.pth&quot;</span> files <span class="hljs-keyword">from</span>.  The<br>installation directory you specified (via --install-dir, --prefix, or<br>the distutils default setting) was:<br><br>    ..../software/MACS2/lib/python3<span class="hljs-number">.8</span>/site-packages/<br><br>and your PYTHONPATH environment variable currently contains:<br><br>    <span class="hljs-string">&#x27;&#x27;</span><br><br>Here are some <span class="hljs-keyword">of</span> your options for correcting the problem:<br><br>* You can choose a different installation directory, i.e., one that is<br>  on PYTHONPATH or supports .pth files<br><br>* You can add the installation directory to the PYTHONPATH environment<br>  variable.  (It must then also be on PYTHONPATH whenever you run<br>  Python and want to use the package(s) you are installing.)<br><br>* You can set up the installation directory to support <span class="hljs-string">&quot;.pth&quot;</span> files by<br>  using one <span class="hljs-keyword">of</span> the approaches described here:<br><br>  https:<span class="hljs-comment">//setuptools.readthedocs.io/en/latest/deprecated/easy_install.html#custom-installation-locations</span><br></code></pre></td></tr></table></figure><p>[ok]export PYTHONPATH&#x3D;${PYTHONPATH}:….&#x2F;software&#x2F;MACS2&#x2F;lib&#x2F;python3.9&#x2F;site-packages&#x2F;</p><p>directly set PYTHONPATH&#x3D;….&#x2F;software&#x2F;MACS2&#x2F;lib&#x2F;python3.9&#x2F;site-packages&#x2F; in ~&#x2F;.bashrc was failed.</p><figure class="highlight clean"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs clean">####################################ERROR3#############################################<br>error: package directory <span class="hljs-string">&#x27;MACS2&#x27;</span> does not exist<br>#######################################################################################<br></code></pre></td></tr></table></figure><p>zip Dir was not complete, tried .tar.gz </p><figure class="highlight clean"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs clean">####################################ERROR4#############################################<br>Traceback (most recent call last):<br>  File <span class="hljs-string">&quot;..../software/MACS3/bin/macs3&quot;</span>, line <span class="hljs-number">4</span>, <span class="hljs-keyword">in</span> &lt;<span class="hljs-keyword">module</span>&gt;<br>    __import__(<span class="hljs-string">&#x27;pkg_resources&#x27;</span>).run_script(<span class="hljs-string">&#x27;MACS3==3.0.0a6&#x27;</span>, <span class="hljs-string">&#x27;macs3&#x27;</span>)<br>  File <span class="hljs-string">&quot;..../miniconda3/lib/python3.9/site-packages/pkg_resources/__init__.py&quot;</span>, line <span class="hljs-number">3243</span>, <span class="hljs-keyword">in</span> &lt;<span class="hljs-keyword">module</span>&gt;<br>    def _initialize_master_working_set():<br>  File <span class="hljs-string">&quot;..../miniconda3/lib/python3.9/site-packages/pkg_resources/__init__.py&quot;</span>, line <span class="hljs-number">3226</span>, <span class="hljs-keyword">in</span> _call_aside<br>    f(*args, **kwargs)<br>  File <span class="hljs-string">&quot;..../miniconda3/lib/python3.9/site-packages/pkg_resources/__init__.py&quot;</span>, line <span class="hljs-number">3255</span>, <span class="hljs-keyword">in</span> _initialize_master_working_set<br>    working_set = WorkingSet._build_master()<br>  File <span class="hljs-string">&quot;..../miniconda3/lib/python3.9/site-packages/pkg_resources/__init__.py&quot;</span>, line <span class="hljs-number">568</span>, <span class="hljs-keyword">in</span> _build_master<br>    ws.require(__requires__)<br>  File <span class="hljs-string">&quot;..../miniconda3/lib/python3.9/site-packages/pkg_resources/__init__.py&quot;</span>, line <span class="hljs-number">886</span>, <span class="hljs-keyword">in</span> require<br>    needed = self.resolve(parse_requirements(requirements))<br>  File <span class="hljs-string">&quot;..../miniconda3/lib/python3.9/site-packages/pkg_resources/__init__.py&quot;</span>, line <span class="hljs-number">772</span>, <span class="hljs-keyword">in</span> resolve<br>    raise DistributionNotFound(req, requirers)<br>pkg_resources.DistributionNotFound: The <span class="hljs-string">&#x27;Cython&gt;=0.29&#x27;</span> distribution was not found and is required by MACS3``<br></code></pre></td></tr></table></figure><p><code>conda install Cython=0.29</code></p><p><a href="https://pypi.org/project/cykhash/">https://pypi.org/project/cykhash/</a><br><code>pip install cykhash</code><br>Collecting cykhash<br>  Using cached cykhash-1.0.2-cp39-cp39-linux_x86_64.whl<br>Installing collected packages: cykhash<br>Successfully installed cykhash-1.0.2</p><p>python setup.py install –prefix ….&#x2F;software&#x2F;MACS2</p><p>success</p>]]></content>
    
    
    <categories>
      
      <category>Software</category>
      
    </categories>
    
    
    <tags>
      
      <tag>debug</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>ATAC-seq-5【PeakCalling-MACS2】</title>
    <link href="/GeekFocus/2021/10/29/2021-10-30-ATAC-seq-5-macs2-info/"/>
    <url>/GeekFocus/2021/10/29/2021-10-30-ATAC-seq-5-macs2-info/</url>
    
    <content type="html"><![CDATA[<h2 id="MACS2-detail"><a href="#MACS2-detail" class="headerlink" title="MACS2 detail"></a>MACS2 detail</h2><span id="more"></span><h3 id="粗略介绍MACS基本原理。"><a href="#粗略介绍MACS基本原理。" class="headerlink" title="粗略介绍MACS基本原理。"></a>粗略介绍MACS基本原理。</h3><p>TF在基因组上的结合是随机过程，基因组的每个位置都有机会结合某个TF，只是概率不一样，peak出现的位置，是TF结合热点，而peak-calling就为了找这些热点。</p><p>如何定义热点？通俗讲，热点是这样一些位置，这些位置多次被测得的read所覆盖（我们测的是一个细胞群体，read出现次数多，说明该位置被TF结合的几率大）。read数达到多少才叫多？就要用到统计检验。假设TF在基因组上的分布没有任何规律，那么测序得到的read在基因组上的分布也必然是随机的，某个碱基上覆盖的read的数目应服从二项分布。和抽小球的过程类似。当n很大，p很小时，二项分布近似用泊松分布替代，在这里：<br><img src="/GeekFocus/./1.png"></p><p>拉姆达是泊松分布唯一参数，n是测序read总数目，l是单个read长度，s是基因组大小。有了分布，可以算出在某个置信概率（如0.00001）下，随机情况下，某个碱基上可以覆盖的read数目的最小值，当实际观察到的read数目超过这个值（单侧检验）时，认为该碱基是TF的一个结合热点。反过来，针对每一个read数目，我们也可以算出对应的置信概率P。</p><p>但这只是简化模型，实际情况复杂好多。由于测序、mapping过程内在<font color=red>偏好性</font>，以及不同染色质间的差异性，相比全基因组，某些碱基可能内在地会被更多的read所覆盖，这种情况得到的很多peak可能都是假的。MACS考虑到这点，<font color=red>当对某个碱基进行假设检验，MACS只考虑该碱基附近染色质区段（如10k），此时上述公式中n表示附近10k区间内的read数目，s被置为10k</font>。当有对照组（Control，相比实验组没有用抗体捕获TF或用了一个通用抗体）存在，利用Control组的数据构建泊松分布，<font color=red>没有Control时，利用实验组，稍大一点的局部区间（比如50k）</font>的数据构建泊松分布。</p><p>还有一个问题，read只是跟随着TF一起沉淀下来的DNA fragment的末端，read的位置并不是真实的TF结合位置。所以在peak-calling之前，延伸read是必须的。不同TF大小不一样，对read延伸的长度也理应不同.测得的<font color=red>read最终其实会近似地平均分配到正负链</font>，对于一个TF结合热点，read在附近正负链上会近似地形成<font color=red>“双峰”</font>。MACS会以<font color=red>某个window size扫描基因组，统计每个window里面read的富集程度，然后抽取（比如1000个）合适的（read富集程度适中，过少，无法建立模型，过大，可能反映的只是某种偏好性）window作样本，建立“双峰模型”</font>。最后，两个峰之间的距离就被认为是<font color=red>TF的长度D，每个read将延伸D&#x2F;2</font>。见下图：</p><p><img src="/GeekFocus/./2.png"></p><p>当有对照组，MACS会进行两次peak calling。第一次以实验组（Treatment）为实验组，对照组为对照组，第二次颠倒，以实验组为对照组，对照组为实验组。之后，MACS对每一个P计算了相应的FDR（False Discovery Rate）值：</p><p><img src="/GeekFocus/./3.png"></p><p>表示第二次peak calling（颠倒的）得到的置信概率小于P的peak的个数。表示第一次peak calling得到的置信概率小于P的peak的个数。FDR综合利用了实验组和对照组的信息，显然，FDR越小越好。</p><h3 id="MACS-peak-calling-pipeline："><a href="#MACS-peak-calling-pipeline：" class="headerlink" title="MACS peak-calling pipeline："></a>MACS peak-calling pipeline：</h3><p>在某些情况下，如对组蛋白修饰的ChIP-seq数据peak-calling时，“双峰模型”会建立失败，<font color=red>因为组蛋白修饰往往并不是孤立存在的，可能很长一段染色质区间都被同一个组蛋白修饰占据，组蛋白修饰的peak并不典型。</font>这时，只要多加一个参数：</p><p><font color=red>–nomodel –shiftsize&#x3D;number</font></p><p>–nomodel将<font color=red>略过“双峰模型”建立的过程</font>，而<font color=red>–shiftsize将人为指定reads延伸的长度</font>。<font color=red>一个核小体上大概缠绕着147bpDNA</font>，在对组蛋白修饰做peak-calling时可以指定：</p><p><font color=red>–nomodel –shiftsize&#x3D;73</font></p><p>CTCF_peaks.bed详细列出了每一个peak的位置信息和可信度（最后一列：)，BED文件格式详见：<a href="http://genome.ucsc.edu/FAQ/FAQformat.html#format1">http://genome.ucsc.edu/FAQ/FAQformat.html#format1</a></p><p>其他常用参数：-bw number 建立“双峰模型”过程中window size的一半，默认300bp.<br><font color=red>-p Pvalue</font>设定peak置信概率的临界值（threshold），默认0.00001?(macs2 callpeak -h: pvalue not set, dont use p and q value at the same time)，对于H3k36me3、H3k27me3、H3k9me3等具有“非常规”特征的peak（broad peak）而言，此参数可以稍微设大一点，比如0.001。</p><p>-m number1,number2 建立“双峰模型”用到，设定挑选的window上reads的富集程度（<font color=red>fold enrichment</font>，相对全基因组而言），默认10,30。</p><p>-slocal&#x3D;number -llocal&#x3D;number 共同确定MACS动态计算时所考察的局部区间的长度。默认参数，-slocal&#x3D;1000 -llocal&#x3D;10000。除了建立“双峰模型”，在寻找peak过程中，MACS依然会以2倍于-bw的window扫描基因组，对于当前window而言（-slocal,-llocal取默认参数）：</p><p>-w&#x2F;-B 建立wig或BED格式的raw signal（最高精确到每个碱基上reads的覆盖情况）文件，默认每条染色体建一个。</p><p>-S 只建立一个raw signal文件。</p><p>-space 与-w搭配使用，确定wig文件的分辨率，默认10bp。</p><hr><p>link：<a href="https://www.plob.org/article/7227.html">https://www.plob.org/article/7227.html</a></p><hr><p><a href="https://github.com/macs3-project/MACS/blob/master/docs/callpeak.md">https://github.com/macs3-project/MACS/blob/master/docs/callpeak.md</a></p><p>Pay attention to BAMPE(pair end) and BED(shift extend) mode</p><h1 id="f-x2F-format-FORMAT"><a href="#f-x2F-format-FORMAT" class="headerlink" title="-f&#x2F;--format FORMAT"></a><code>-f</code>&#x2F;<code>--format FORMAT</code></h1><p>Format of tag file can be <code>ELAND</code>, <code>BED</code>, <code>ELANDMULTI</code>, <code>ELANDEXPORT</code>, <code>SAM</code>, <code>BAM</code>, <code>BOWTIE</code>, <code>BAMPE</code>, or <code>BEDPE</code>. Default is <code>AUTO</code> which will allow MACS to decide the format automatically. <code>AUTO</code> is also useful when you combine different formats of files. Note that MACS <font color="red"><strong>can’t detect</strong></font> <code>BAMPE</code> or <code>BEDPE</code> format with <code>AUTO</code>, and you have to implicitly specify the format for <code>BAMPE</code> and <code>BEDPE</code>.</p><p>Nowadays, the most common formats are <code>BED</code> or <code>BAM</code> (including <code>BEDPE</code> and <code>BAMPE</code>). Our recommendation is to convert your data to<code>BED</code> or <code>BAM</code> first.</p><p>Also, MACS3 can detect and read gzipped file. For example, <code>.bed.gz</code> file can be directly used without being uncompressed with <code>--format BED</code>.</p><h1 id="BAM-SAM-not-use"><a href="#BAM-SAM-not-use" class="headerlink" title="BAM/SAM(not use)"></a>BAM<code>/</code>SAM(not use)</h1><p>If the format is <code>BAM</code>&#x2F;<code>SAM</code>, please check the definition in (<a href="http://samtools.sourceforge.net/samtools.shtml">http://samtools.sourceforge.net/samtools.shtml</a>). If the <code>BAM</code> file is generated for paired-end data, MACS will <font color="red"><strong>only keep the left mate</strong></font>(5’ end) tag. However, when format <code>BAMPE</code> is specified, MACS will use the <font color="red"><strong>real fragments[BAMPE]</strong></font> inferred from alignment results for reads pileup.</p><h1 id="BAMPE-pair-end"><a href="#BAMPE-pair-end" class="headerlink" title="BAMPE(pair end)"></a>BAMPE(pair end)</h1><p>A <font color="red"><strong>special mode</strong> will be triggered</font> while the format is specified as <code>BAMPE</code> or <code>BEDPE</code>. In this way, MACS3 will process the <code>BAM</code> or <code>BED</code> files as paired-end data. Instead of building a bimodal distribution of plus and minus strand reads to predict fragment size, MACS3 will <font color="red">use <strong>actual insert sizes of pairs of reads</strong></font> to build fragment pileup.</p><p>The <code>BAMPE</code> format is just a <code>BAM</code> format containing paired-end alignment information, such as those from <code>BWA</code> or <code>BOWTIE</code>.</p><p>The <code>BEDPE</code> format is a simplified and more flexible <code>BED</code> format, which <font color="red">only contains the first three columns(then, how to get pair info??)</font> defining the chromosome name, left and right position of the fragment from Paired-end sequencing. Please note, this is NOT the same format used by <code>BEDTOOLS</code>, and the <code>BEDTOOLS</code> version of <code>BEDPE</code> is actually not in a standard <code>BED</code> format. You can use MACS3 subcommand <code>randsample</code> to convert a <code>BAM</code> file containing paired-end information to a <code>BEDPE</code> format file:</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs stylus">macs3 randsample -<span class="hljs-selector-tag">i</span> the_BAMPE_file<span class="hljs-selector-class">.bam</span> -f BAMPE -<span class="hljs-selector-tag">p</span> <span class="hljs-number">100</span> -o the_BEDPE_file.bed<br></code></pre></td></tr></table></figure><h1 id="BED-shift-extend-mode"><a href="#BED-shift-extend-mode" class="headerlink" title="BED(shift extend) mode"></a>BED(shift extend) mode</h1><p>The BED format can be found at <a href="http://genome.ucsc.edu/FAQ/FAQformat#format1">UCSC genome browser website</a>.</p><p>The essential columns in BED format input are the 1st column <code>chromosome name</code>, the 2nd <code>start position</code>, the 3rd <code>end position</code>, and the<font color="red"> <strong>6th, strand</strong></font>.(<font color="red"><strong>usage for extending to 5’</strong>) keep the <strong>Tn5 break point in the middle of the peak</strong></font></p><p>Note that, for <code>BED</code> format, the <font color="red"><strong>6th</strong></font> column of strand information is required by MACS. And please pay attention that the coordinates in BED format are zero-based and half-open. See more detail at <a href="http://genome.ucsc.edu/FAQ/FAQtracks#tracks1">UCSC site</a>.</p><h1 id="slocal-llocal"><a href="#slocal-llocal" class="headerlink" title="--slocal, --llocal"></a><code>--slocal</code>, <code>--llocal</code></h1><p>These two parameters control which two levels of regions will be checked around the peak regions to calculate the maximum lambda as local lambda. <font color="red"><strong>By default</strong></font>, MACS considers <strong>1000bp</strong> for small local region(<code>--slocal</code>), and <strong>10000bps</strong> for large local region(<code>--llocal</code>) which captures the bias from a long-range effect like an open chromatin domain. You can tweak these according to your project. Remember that if the region is set too small, a sharp spike in the input data may kill a significant peak.</p><h1 id="nomodel"><a href="#nomodel" class="headerlink" title="--nomodel"></a><code>--nomodel</code></h1><p>While on, MACS will bypass building the shifting model.</p><h1 id="extsize"><a href="#extsize" class="headerlink" title="--extsize"></a><code>--extsize</code></h1><p>While <code>--nomodel</code> is set, MACS uses this parameter to extend reads in 5’-&gt;3’ direction to fix-sized fragments. For example, if the size of the binding region for your transcription factor is 200 bp, and you want to bypass the model building by MACS, this parameter can be set as 200. This option is only valid when <code>--nomodel</code> is set or when MACS fails to build model and <code>--fix-bimodal</code> is on.</p><h3 id="shift"><a href="#shift" class="headerlink" title="--shift"></a><code>--shift</code></h3><p>Note, this is NOT the legacy <code>--shiftsize</code> option which is replaced by <code>--extsize</code>! You can set an arbitrary shift in bp here. Please Use discretion while setting it other than the default value (0). When <code>--nomodel</code> is set, MACS will use this value to move cutting ends (5’) then apply <code>--extsize</code> from 5’ to 3’ direction to extend them to fragments. <font color="red">When this value is <strong>negative</strong>, ends will be moved toward 3’-&gt;5’ direction</font>, otherwise 5’-&gt;3’ direction. <font color="red"><strong>Recommended</strong> to keep it as <strong>default 0 for ChIP-Seq</strong> datasets</font>, or -1 * half of <em>EXTSIZE</em> together with <code>--extsize</code> option for detecting enriched cutting loci such as certain DNAseI-Seq datasets. Note, you can’t set values other than 0 if the format is <strong>BAMPE or BEDPE</strong>(<strong>nouse in setting nomodel</strong>) for paired-end data. The default is 0.</p><p>Here are some examples for combining <code>--shift</code> and <code>--extsize</code>:</p><ol><li>To find enriched cutting sites such as some DNAse-Seq datasets. In this case, all 5’ ends of sequenced reads should be extended in both directions to smooth the pileup signals. If the wanted smoothing window is 200bps, then use <code>--nomodel --shift -100 --extsize 200</code>.</li><li>For certain nucleosome-seq data, we need to pile up the centers of nucleosomes using a half-nucleosome size for wavelet analysis (e.g. NPS algorithm). Since the DNA wrapped on nucleosome is about 147bps, this option can be used: <code>--nomodel --shift 37 --extsize 73</code>.</li></ol><h3 id="keep-dup"><a href="#keep-dup" class="headerlink" title="--keep-dup"></a><code>--keep-dup</code></h3><p>It controls the MACS behavior towards duplicate tags at the exact same location – the same coordination and the same strand. The default<code>auto</code> option makes MACS calculate the maximum tags at the exact same location based on binomial distribution using 1e-5 as p-value cutoff; and the <code>all</code> option keeps every tag. If an integer is given, at most this number of tags will be kept at the same location. The default is to keep one tag at the same location. Default: 1</p><h3 id="broad"><a href="#broad" class="headerlink" title="--broad"></a><code>--broad</code></h3><p>When this flag is on, MACS will try to composite broad regions in BED12 ( a gene-model-like format ) by putting nearby highly enriched regions into a broad region with loose cutoff. The broad region is controlled by another cutoff through <code>--broad-cutoff</code>. Please note that, the <code>max-gap</code> value for merging nearby weaker&#x2F;broad peaks is 4 times of <code>max-gap</code> for merging nearby stronger peaks. The later one can be controlled by <code>--max-gap</code> option, and by default it is the average fragment&#x2F;insertion length in the PE data. DEFAULT: False</p><h3 id="broad-cutoff"><a href="#broad-cutoff" class="headerlink" title="--broad-cutoff"></a><code>--broad-cutoff</code></h3><p>Cutoff for the broad region. This option is not available unless <code>--broad</code> is set. If <code>-p</code> is set, this is a p-value cutoff, otherwise, it’s a q-value cutoff. DEFAULT: 0.1</p>]]></content>
    
    
    <categories>
      
      <category>Software</category>
      
    </categories>
    
    
    <tags>
      
      <tag>atac-seq</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【ATAC-seq-3】【hbctraining_pipeline】</title>
    <link href="/GeekFocus/2021/10/26/2021-10-30-ATAC-seq-3-hbctraining/"/>
    <url>/GeekFocus/2021/10/26/2021-10-30-ATAC-seq-3-hbctraining/</url>
    
    <content type="html"><![CDATA[<p>ATAC-seq &amp;ChIP-seq</p><span id="more"></span><hr><h2 id="https-github-com-hbctraining-In-depth-NGS-Data-Analysis-Course-tree-master-sessionV-lessons"><a href="#https-github-com-hbctraining-In-depth-NGS-Data-Analysis-Course-tree-master-sessionV-lessons" class="headerlink" title="https://github.com/hbctraining/In-depth-NGS-Data-Analysis-Course/tree/master/sessionV/lessons"></a><a href="https://github.com/hbctraining/In-depth-NGS-Data-Analysis-Course/tree/master/sessionV/lessons">https://github.com/hbctraining/In-depth-NGS-Data-Analysis-Course/tree/master/sessionV/lessons</a></h2><!-- more --><p>算法，参数，输出。</p><h2 id="Peak-calling"><a href="#Peak-calling" class="headerlink" title="Peak calling"></a>Peak calling</h2><p><img src="https://img-blog.csdnimg.cn/f2741798d4f04f708412c97b2e6ef045.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAYmFubmVyRHI=,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"><br>ChIP-seq实验，从比对文件中观察到<code>正/负链</code>上以<code>结合位点为中心</code>的非对称reads<br>密度。<br>For ChIP-seq experiments, what we observe from the alignment files is a strand asymmetry with read densities on the +&#x2F;- strand, centered around the binding site. <code>The 5’ ends of the selected fragments</code> will form <code>groups</code> on the positive- and negative-strand. The <code>distributions</code> of these groups are then assessed using <code>statistical measures</code> and <code>compared against background</code> (input or mock IP samples) to determine if the site of enrichment is likely to be a real binding site.</p><p><img src="https://img-blog.csdnimg.cn/a5f4429afb3348be91f68d90d4011065.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAYmFubmVyRHI=,size_20,color_FFFFFF,t_70,g_se,x_16" alt="加粗样式"><br><code>ChIP-seq analysis algorithms</code> are specialized in identifying one of <code>two types of enrichment</code> (or have specific methods for each): <code>broad peaks or broad domains</code> (i.e. <code>histone modifications that cover entire gene bodies</code>) or <code>narrow peaks</code> ( <code>transcription factor binding</code>). <code>Narrow peaks are easier to detect</code> as we are looking for regions that have higher amplitude and are easier to distinguish from the background, compared to broad or dispersed marks. There are also <code>‘mixed’ binding profiles</code> which can be hard for algorithms to discern. An example of this is the binding properties of <code>PolII</code>, which binds at promotor and across the length of the gene resulting in mixed signals (<code>narrow and broad</code>).</p><figure class="highlight mipsasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs mipsasm">NOTE：ChIP-seq的分析方法可以鉴定两种类型的富集模式：<span class="hljs-keyword">broad </span>domains和narrow peaks。<span class="hljs-keyword">broad </span>domains，如组蛋白修饰在整个基因<span class="hljs-keyword">body区域的分布；narrow </span>peak，如转录因子的结合。narrow peak相对于<span class="hljs-keyword">broad </span>或者分散的marks更易被检测到。也有一些混合的结合图谱，如PolII包括narrow和<span class="hljs-keyword">broad信号。</span><br></code></pre></td></tr></table></figure><h2 id="MACS2"><a href="#MACS2" class="headerlink" title="MACS2"></a>MACS2</h2><p>MACS2是最常用的call peaks工具。 The MACS algorithm captures the influence of <code>genome complexity</code> to evaluate the significance of enriched ChIP regions。全称<code>Model-based Analysis of ChIP-Seq</code>，最初设计用来<code>鉴定转录因子结合位点</code>（also suited for <code>larger</code> regions），也可用于<code>其他类型</code>的富集方式测序。<br>MACS通过整合<code>序列标签位置信息</code>和<code>方向</code>信息提高<code>结合位点</code>的<code>空间分辨率</code>（ <code>improves</code> the <code>spatial resolution of binding sites</code> through <code>combining the information of both sequencing tag position and orientation</code>）。单独使用或加对照（ <code>increases specificity</code> of the peak calls）。<br><img src="https://img-blog.csdnimg.cn/3929b0f60a01477ea09402760205f200.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAYmFubmVyRHI=,size_17,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></p><h3 id="1-Remove-redundancy"><a href="#1-Remove-redundancy" class="headerlink" title="1. Remove redundancy"></a>1. Remove redundancy</h3><p><code>Why worry about duplicates?</code> <code>Reads with the same start position</code> are <code>considered duplicates</code>. These duplicates can arise from experimental artifacts, but can also contribute to genuine ChIP-signal. (相同起点的reads被认为是duplicates，可能由于实验误差造成，<code>也可能是ChIP信号</code>)</p><ul><li><code>坏 duplicates</code>: If initial starting <code>material is low</code> this can lead to <code>overamplification</code> of this material before sequencing. Any <code>biases in PCR</code> will compound this problem and can lead to <code>artificially enriched regions</code>. Also <code>blacklisted (repeat) regions</code> with ultra high signal will also be high in duplicates. <code>Masking these regions</code> prior to analysis can help remove this problem。 实验材料量少，过度扩增，PCR偏差，人为富集区域。<code>blacklist（重复）区域？怎么获得</code>，屏蔽该区域。</li><li><code>好 duplicates</code>: You can expect some <code>biological duplicates with ChIP-seq</code> since you are only sequencing a small <code>part of the genome</code>. This number can increase if your depth of coverage is excessive or if your protein only binds to few sites. If there are a good proportion of biological dupicates, <code>removal</code> can lead to an <code>underestimation of the ChIP signal</code>. 有ChIP-seq意义的生物学意义duplicates ，测序基因组小部分。覆盖深度过多，蛋白质与少数位点结合，duplicates会增加。去除此类会导致对ChIP信号的低估。</li><li>Consider your <code>enrichment efficiency</code> and <code>sequencing depth</code>. Try to <code>discriminate</code> via genome browser of your non-deduplicated data. Bona fide peaks will have <code>multiple overlapping</code> reads with <code>offsets</code>, while samples with only PCR duplicates will stack up perfectly without offsets. A possible solution to distinguishing biological duplicate from PCR artifact would be to include UMIs into your experimental setup. 考虑<code>富集效率</code>和<code>测序深度</code>。通过<code>基因组浏览器区别</code>。<code>真正的峰</code>会有多个<code>重叠reads和偏移量</code>，<code>PCR重复没有偏移量</code>。如何区分：实验设计考虑<a href="https://www.sohu.com/a/471483238_120055884">UMIs</a>（<code>UMI将被用于合并PCR复制物</code>）。</li><li>Retain duplicates for differential binding analysis. 保留duplicates 用于差异结合分析 <code>why</code>？retain和keep区别？</li><li>If you are expecting binding in repetitive regions, use paired-end sequencing and keep duplicates. 研究重复区域，使用pariedend测序并<code>保持重复？</code></li><li>call peak之前就remove dup<h3 id="2-0-Shift-size-d"><a href="#2-0-Shift-size-d" class="headerlink" title="2.0 Shift size d"></a>2.0 <code>Shift size d</code></h3></li><li>真实结合位点周围的tag density应显示<code>双峰富集</code>(<code>成对峰</code>)。MACS利用这种双峰模式 <code>empirically model the shifting size</code>，精确定位结合位点。</li><li>为了找到<code>成对峰</code>来<code>构建模型</code>，MACS首先<code>扫描整个数据集</code>，寻找<code>高度显著富集区域</code>。只利用ChIP样本，给定超声大小sonication size(<code>bandwidth</code>)和high-confidence fold-enrichment(<code>mfold</code>)， MACS <code>slides two bandwidth windows</code> across the genome to find <code>regions with tags more than mfold enriched</code> relative to a <code>random tag genome distribution</code>.</li><li>MACS<code>随机抽取1000个高质量峰</code>，<code>分离正链和负链标签</code>，aligns them by the midpoint between their centers。The <code>distance between the modes of the two peaks in the alignment is defined as ‘d’</code> and represents the estimated fragment length. MACS shifts all the tags by d&#x2F;2 toward the 3’ ends to the most likely protein-DNA interaction sites.<br><img src="https://img-blog.csdnimg.cn/eeefe600965542478444f761de31db17.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAYmFubmVyRHI=,size_10,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></li></ul><h3 id="2-Select-1000-regions-with-a-10-to-30-fold-enrichment-relative-to-the-genome-background"><a href="#2-Select-1000-regions-with-a-10-to-30-fold-enrichment-relative-to-the-genome-background" class="headerlink" title="2. Select 1000 regions with a 10- to 30-fold enrichment relative to the genome background"></a>2. Select 1000 regions with a 10- to 30-fold enrichment relative to the genome background</h3><h3 id="3-Build-model-and-estimate-DNA-fragment-size-d"><a href="#3-Build-model-and-estimate-DNA-fragment-size-d" class="headerlink" title="3. Build model and estimate DNA fragment size d"></a>3. Build model and estimate DNA fragment size d</h3><h3 id="4-Shift-reads-toward-3’end-by-d"><a href="#4-Shift-reads-toward-3’end-by-d" class="headerlink" title="4. Shift reads toward 3’end by d"></a>4. Shift reads toward 3’end by d</h3><h3 id="5-Scale-two-libraries-if-have-control"><a href="#5-Scale-two-libraries-if-have-control" class="headerlink" title="5. Scale two libraries(if have control)"></a>5. Scale two libraries(if have control)</h3><p>For experiments in which <code>sequence depth differs</code> between input and treatment samples, MACS linearly scales the total control tag count to be the same as the total ChIP tag count. The default behaviour is for the <code>larger sample to be scaled down</code>. </p><h3 id="6-0-Effective-genome-length"><a href="#6-0-Effective-genome-length" class="headerlink" title="6.0 Effective genome length"></a>6.0 Effective genome length</h3><p>To calculate λBG from tag count, MAC2 requires the <code>effective genome size or the size of the genome that is mappable</code>. Mappability is related to the <code>uniqueness of the k-mers</code> at a particular position the genome. <code>Low-complexity</code> and <code>repetitive regions</code> have <code>low uniqueness</code>, which means <code>low mappability</code>. Therefore we need to provide the effective genome length to correct for the loss of true signals in low-mappable regions. 提供<code>有效基因组长度</code>，以<code>纠正低定位区域真实信号丢失</code>。<br><img src="https://img-blog.csdnimg.cn/5571c4b228cb4706805ba0853c546c3c.png" alt="在这里插入图片描述"><br><code>如何获得？</code>The MACS2 software has some <code>pre-computed values</code> for <code>commonly used</code> organisms (human, mouse, worm and fly，<code>rice？</code>). more accurate values? The <code>deepTools</code> docs has additional pre-computed values for more recent builds but also has some good materials on <code>how to go about computing</code> it.</p><h3 id="6-Call-candidate-peaks-relative-to-genome-background"><a href="#6-Call-candidate-peaks-relative-to-genome-background" class="headerlink" title="6. Call candidate peaks relative to genome background"></a>6. Call candidate peaks relative to genome background</h3><p>After MACS <code>shifts every tag by d/2</code>, it then <code>slides across the genome</code> using a window size of <code>2d</code> to <code>find candidate peaks</code>.  The <code>tag distribution</code> along the genome can be modeled by a <code>Poisson distribution</code>.  The Poisson is a one parameter model, where the parameter <code>λ is the expected number of reads in that window</code>.</p><h3 id="7-Calculate-dynamic-λ-for-candidate-peaks"><a href="#7-Calculate-dynamic-λ-for-candidate-peaks" class="headerlink" title="7. Calculate dynamic λ for candidate peaks"></a>7. Calculate dynamic λ for candidate peaks</h3><p><img src="https://img-blog.csdnimg.cn/eaac9c4b4c294be3b8b3b3caf7c35a21.png" alt="在这里插入图片描述"><br>泊松分布的参数λ是单位时间(或单位面积)内随机事件的平均发生次数。 泊松分布的期望和方差均为λ.<br>Instead of using a uniform λ estimated from the whole genome, MACS uses a <code>dynamic parameter, λlocal</code>, defined for <code>each candidate peak</code>. The lambda parameter is estimated from the control sample and is deduced by taking the maximum value across <code>various window sizes</code>:</p><blockquote><p>λlocal &#x3D; max(λBG, λ1k, λ5k, λ10k).</p></blockquote><p>In this way lambda <code>captures the influence of local biases</code>, and is robust against occasional low tag counts at small local regions. Possible sources for these biases include local chromatin structure, DNA amplification and sequencing bias, and genome copy number variation. 通过使用动态lambda捕获局部偏差的影响，并且对小局部区域中<code>偶尔出现的low tag counts</code>表现较好。<code>偏差可能来源</code>包括局部染色质结构、DNA扩增和测序偏差以及基因组拷贝数变化。<br><img src="https://img-blog.csdnimg.cn/3c7c645b299e45b2b7975d6327d421bc.png" alt="在这里插入图片描述"><br>A region is considered to have a <code>significant tag enrichment</code> if the <code>p-value &lt; 10e-5</code> (可设置). This is a Poisson distribution p-value based on λ.</p><p>Overlapping enriched peaks are merged, and each tag position is <code>extended ‘d’ bases？</code> from its center. The location in the <code>peak with the highest fragment pileup堆积</code>, hereafter referred to as the summit峰顶, is <code>predicted as the precise binding location</code>. The <code>ratio between the ChIP-seq tag count and λlocal？</code> is reported as the fold enrichment.</p><h3 id="8-Calculate-P-value-and-filter-candidate-peaks"><a href="#8-Calculate-P-value-and-filter-candidate-peaks" class="headerlink" title="8. Calculate P value and filter candidate peaks"></a>8. Calculate P value and filter candidate peaks</h3><h3 id="9-Calculate-FDR-by-exchanging-treatment-and-control"><a href="#9-Calculate-FDR-by-exchanging-treatment-and-control" class="headerlink" title="9. Calculate FDR by exchanging treatment and control"></a>9. Calculate FDR by exchanging treatment and control</h3><p>Each peak is considered an independent test and thus, when we encounter thousands of significant peaks detected in a sample we have a multiple testing problem. In <code>MACSv1.4</code>, the FDR was determined <code>empirically by exchanging the ChIP and control samples</code>. However, in <code>MACS2</code>, p-values are now corrected for multiple comparison using the <code>Benjamini-Hochberg correction</code>.</p><h2 id="MACS2-参数"><a href="#MACS2-参数" class="headerlink" title="MACS2 参数"></a>MACS2 参数</h2><h3 id="1-Input-file-options"><a href="#1-Input-file-options" class="headerlink" title="1. Input file options"></a>1. Input file options</h3><ul><li><code>-t</code> : The IP data file (this is the only REQUIRED parameter for MACS) 实验组</li><li><code>-c</code> : Control or mock data 对照</li><li><code>-f</code> : 输入文件格式，默认值“AUTO” ，bam sam bed</li><li><code>-g</code> :  <code>mappable genome size</code> which is defined as the genome size which can be sequenced; some precompiled values provided.</li><li>hs: 2.7e9人类基因组有效大小(UCSC human hg18 assembly)<h3 id="2-Output-arguments"><a href="#2-Output-arguments" class="headerlink" title="2. Output arguments"></a>2. Output arguments</h3></li><li><code>-outdir</code> : 输出文件夹</li><li><code>-n</code> : 文件前缀</li><li><code>-B/--bdg</code> : store the fragment pileup, control lambda, -log10pvalue and -log10qvalue scores in bedGraph files 输出bedgraph格式的文件<h3 id="3-Shifting-model-arguments"><a href="#3-Shifting-model-arguments" class="headerlink" title="3. Shifting model arguments"></a>3. Shifting model arguments</h3></li><li><code>-s</code> : <code>size of sequencing tags</code>. Default, MACS will use the <code>first 10 sequences</code> from your input treatment file to determine it</li><li><code>--bw</code> : The bandwidth which is used to <code>scan the genome</code> ONLY for model building. Can be set to the expected sonication fragment size.</li><li><code>--mfold</code> : <code>upper and lower limit</code> for model building</li><li><code>--nomodel</code>：<code>和extsize、shift是配套使用</code>，有这个参数才可设置extsize和shift。</li><li><code>--extsize</code>：当设置了nomodel时，MACS会用–extsize这个参数从<code>5&#39;-&gt;3&#39;方向扩展reads修复fragments</code>。如转录因子结合范围200bp，设置这个参数是200。</li><li><code>--shift</code>：当设置了–nomodel，MACS用这个参数从<code>5&#39; 端移动剪切</code>，然后用–extsize延伸，如果–shift是负值表示从3’端方向移动。建议ChIP-seq数据集这个值保持默认值为0？，对于检测富集剪切位点如DNAseq数据集设置为EXTSIZE的一半。</li></ul><figure class="highlight brainfuck"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs brainfuck"><span class="hljs-comment">想找富集剪切位点，如DNAse</span><span class="hljs-literal">-</span><span class="hljs-comment">seq，所有5&#x27;端的序列reads应该从两个方向延伸，如果想设置移动的窗口是200bp，参数设置如下：</span><br><span class="hljs-literal">--</span><span class="hljs-comment">nomodel</span> <span class="hljs-literal">--</span><span class="hljs-comment">shift</span> <span class="hljs-literal">-</span><span class="hljs-comment">100</span> <span class="hljs-literal">--</span><span class="hljs-comment">extsize 200</span><br><span class="hljs-comment">对nucleosome</span><span class="hljs-literal">-</span><span class="hljs-comment">seq数据，用核小体大小的一半进行extsize</span><span class="hljs-string">,</span><span class="hljs-comment">所以参数设置如下：</span><br><span class="hljs-literal">--</span><span class="hljs-comment">nomodel</span> <span class="hljs-literal">--</span><span class="hljs-comment">shift 37</span> <span class="hljs-literal">--</span><span class="hljs-comment">extsize 73</span><br></code></pre></td></tr></table></figure><p><code>ATAC-seq</code>关心的是在哪切断，断点才是peak的中心，所以使用shift模型，–shift -75或-100<br>对人细胞系ATAC-seq 数据call peak的参数设置：</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs stylus">macs2 callpeak -t H1hesc<span class="hljs-selector-class">.final</span><span class="hljs-selector-class">.bam</span> -n sample <span class="hljs-attr">--shift</span> -<span class="hljs-number">100</span> <span class="hljs-attr">--extsize</span> <span class="hljs-number">200</span> <span class="hljs-attr">--nomodel</span> -B <span class="hljs-attr">--SPMR</span> -g hs <span class="hljs-attr">--outdir</span> Macs2_out <span class="hljs-number">2</span>&gt; sample<span class="hljs-selector-class">.macs2</span>.log<br></code></pre></td></tr></table></figure><h3 id="4-Peak-calling-arguments"><a href="#4-Peak-calling-arguments" class="headerlink" title="4. Peak calling arguments"></a>4. Peak calling arguments</h3><ul><li><code>-q</code> : q-value (minimum FDR) cutoff <code>q value默认值是0.05，与pvalue不能同时使用。</code></li><li><code>-p</code> : p-value cutoff (instead of q-value cutoff)</li><li><code>--nolambda</code> : do not consider the local bias&#x2F;lambda at peak candidate regions。不要考虑在峰值候选区域的局部偏差&#x2F;λ</li><li><code>--broad</code> : broad peak calling，narrow peak和broad peak</li></ul><p> Relaxing the <code>q-value</code> does not behave as expected in this case since it is partially tied to peak widths. Ideally, if you <code>relaxed the thresholds</code>, you would simply get <code>more peaks</code> but with MACS2 relaxing thresholds also results in <code>wider peaks</code>. q值与峰宽有一定的联系。理想情况下，如果放宽阈值，您将简单地获得更多的峰值，但是使用MACS2放松阈值也会导致更宽的峰值。</p><figure class="highlight livescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs livescript">macs2 callpeak -t bowtie2/H1hesc_Nanog_Rep1_aln.bam <span class="hljs-string">\</span><br>-c bowtie2/H1hesc_Input_Rep1_aln.bam <span class="hljs-string">\</span><br> -f BAM -g <span class="hljs-number">1.3e+8</span> <span class="hljs-string">\</span><br>-n Nanog-rep1 <span class="hljs-string">\</span><br>--outdir macs2 <span class="hljs-number">2</span>&gt; macs2/Nanog-rep1-macs2.log<br></code></pre></td></tr></table></figure><h2 id="MACS2-Output-files"><a href="#MACS2-Output-files" class="headerlink" title="MACS2 Output files"></a>MACS2 Output files</h2><h3 id="narrowPeak"><a href="#narrowPeak" class="headerlink" title="narrowPeak"></a>narrowPeak</h3><p>A narrowPeak (<code>.narrowPeak</code>) file is used by the ENCODE project to provide <code>called peaks of signal enrichment</code> based on pooled, normalized (interpreted) data. It is a <code>BED 6+4 format</code>, which means the <code>first 6 columns of a standard BED file</code> with <code>4 additional</code> fields:<br><img src="https://img-blog.csdnimg.cn/7bd1ca4fcb3847daacc450a91989b5cd.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAYmFubmVyRHI=,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></p><h3 id="WIG-format"><a href="#WIG-format" class="headerlink" title="WIG format"></a>WIG format</h3><p>Wiggle format (WIG) allows the <code>display</code> of continuous-valued data in a track format. Wiggle format is <code>line-oriented</code>. It is composed of declaration lines and data lines, and require a separate wiggle track definition line. There are two options for formatting wiggle data: variableStep and fixedStep. These formats were developed to allow the file to be written as compactly as possible.</p><h3 id="BedGraph-format"><a href="#BedGraph-format" class="headerlink" title="BedGraph format"></a>BedGraph format</h3><p>The BedGraph format also allows display of continuous-valued data in track format. This display type is useful for probability scores and transcriptome data. This track type is similar to the wiggle (WIG) format, but unlike the wiggle format, data exported in the bedGraph format are preserved in their original state. For the purposes of visualization, these can be interchangeable.</p><ul><li><p><code>_peaks.narrowPeak</code>: BED6+4 format file which contains the peak locations together with peak summit, pvalue and qvalue。<code>BED6+4格式，可以上传到UCSC浏览。</code></p><ul><li>1：染色体号</li><li>2：peak起始位点</li><li>3：结束位点</li><li>4：peak name</li><li>5：int(-10*log10qvalue)</li><li>6 ：正负链</li><li>7：fold change</li><li>8：-log10pvalue</li><li>9：-log10qvalue</li><li>10：relative summit position to peak start（？）</li></ul></li><li><p><code>_peaks.xls</code>: a tabular file which contains information about called peaks. Additional information includes pileup and fold enrichment。<code>含peak信息的tab分割的文件，前几行显示callpeak命令</code>。</p><ul><li>染色体号</li><li>peak起始位点</li><li>peak结束位点</li><li>peak区域长度</li><li>peak的峰值位点（summit position）</li><li>peak 峰值的高度（pileup height at peak summit, -log10(pvalue) for the peak summit）</li><li>peak的富集倍数（相对于random Poisson distribution with local lambda）</li><li>XLS里的坐标和bed格式的坐标还不一样，起始坐标需要减1才与narrowPeak的起始坐标一样。</li></ul></li><li><p><code>_summits.bed</code>: peak summits locations for every peak. To find the motifs at the binding sites, this file is recommended。BED格式的文件，包含peak的summits位置，第5列是-log10pvalue。如果想找motif，推荐使用此文件。</p></li><li><p><code>_model.R</code>: an R script which you can use to produce a PDF image about the model based on your data and cross-correlation plot</p></li><li><p><code>_control_lambda.bdg</code>: bedGraph format for input sample</p></li><li><p><code>_treat_pileup.bdg</code>: bedGraph format for treatment sample。bedGraph格式，可以导入UCSC或者转换为bigwig格式。两种bfg文件：treat_pileup, and control_lambda.</p></li><li><p><code>NAME_peaks.broadPeak</code>： BED6+3格式与narrowPeak类似，只是没有第10列。</p></li></ul><p>R作图the first plot illustrates the distance between the modes from which the shift size was determined？<br><img src="https://img-blog.csdnimg.cn/3d941b11b37c4b7687b11e6766a9daff.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAYmFubmVyRHI=,size_13,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"><br>The second plot is the cross-correlation plot. This is a graphical representation of the Pearson correlation of positive- and negative- strand tag densities, shifting the strands relative to each other by increasing distance？</p><figure class="highlight mipsasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs mipsasm">xls文件<br>文件包含信息还是比较多的，和narrowPeak唯一不同的是peak的起始位置需要减<span class="hljs-number">1</span>才是<span class="hljs-keyword">bed格式的文件，另外还包含fold_enrichment </span>和narrowPeak的fold change 对应，-log10pvalue,-log10qvalue,peak长度，peak 峰值位置等。<br>narrowPeak文件<br>和xls文件信息类似<br>summits.<span class="hljs-keyword">bed文件</span><br><span class="hljs-keyword"></span>包含峰的位置信息和-log10pvalue<br><span class="hljs-keyword">bdg文件</span><br><span class="hljs-keyword"></span><span class="hljs-keyword">bdg文件适合导入UCSC或IGV进行谱图可视化，或者转换为bigwig格式再进行可视化。</span><br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>NGS</category>
      
    </categories>
    
    
    <tags>
      
      <tag>pipeline</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【Assembly】【hifiasm】</title>
    <link href="/GeekFocus/2021/10/20/2022-02-02-hifiasm/"/>
    <url>/GeekFocus/2021/10/20/2022-02-02-hifiasm/</url>
    
    <content type="html"><![CDATA[<p>Nat. Methods hifiasm</p><span id="more"></span><hr><h2 id="Nat-Methods-等位基因组组装算法hifiasm（20210202）"><a href="#Nat-Methods-等位基因组组装算法hifiasm（20210202）" class="headerlink" title="Nat. Methods|等位基因组组装算法hifiasm（20210202）"></a>Nat. Methods|等位基因组组装算法hifiasm（20210202）</h2><p>paper：<a href="https://pubmed.ncbi.nlm.nih.gov/33526886/">Haplotype-resolved de novo assembly using phased assembly graphs with hifiasm</a><br>该研究提出一种全新的单倍型基因组组装算法hifiasm，能够有效地对<font color=red>大型复杂基因组生成高质量的单倍型组装结果</font>。</p><!-- more --><h3 id="单倍型组装难点"><a href="#单倍型组装难点" class="headerlink" title="单倍型组装难点"></a>单倍型组装难点</h3><p>单倍型基因组组装是研究基因组结构与变异的最理想方式。由于技术的局限，大多数组装算法倾向于将不同单倍型有损的压缩成一条混合的代表性序列。对于自然界中主流的二倍体和多倍体样本而言，这类方法损失了大量的单倍型信息。这使得长久以来，研究人员难以对高杂合、高重复的基因组进行深入的分析。</p><p>为了解决这个难题，一些组装算法首先生成混合的代表性序列，接着从代表性序列中恢复出不同的单倍型信息。但是，由于代表性序列本身已经丢失了大量的信息，这类方法难以获得高质量的单倍型组装结果。</p><p>近期的组装算法通过额外的信息，如家系(Trio binning)或者Hi-C等数据，预先全局性的将待组装的测序读段划分到不同单倍型，再进行分别组装，从而试图获得高质量的单倍型组装结果。但是对于低杂合的样本而言，这种方法难以做到完美的预先划分，因此容易产生组装错误。</p><h3 id="Hifiasm-算法"><a href="#Hifiasm-算法" class="headerlink" title="Hifiasm 算法"></a>Hifiasm 算法</h3><p>在本研究中，研究人员提出了一种全新的针对PacBio HiFi (High-Fidelity reads) 数据的单倍型组装算法hifiasm。该算法有两项重要创新。</p><p>第一，提出了单倍型敏感的组装思路，使得在组装的全过程中能够无损的保留单倍型信息，同时也极大的提升了对基因组高重复和复杂区域的解析能力。</p><p>第二，提出了Graph-binning的分型策略，其利用组装图的结构信息对全局分型结果进行校正，从而极大地提高了单倍型组装的质量。Graph-binning不对待组装的测序读段进行预先全局划分，因此能够克服划分错误带来组装问题。</p><h3 id="组装结果"><a href="#组装结果" class="headerlink" title="组装结果"></a>组装结果</h3><p>研究人员在不同的数据集上测试了hifiasm算法。对于不同大小，不同杂合度和不同单倍型数量的动物和植物基因组，hifiasm能够产生质量最高的组装结果。尤其值得注意的是，hifiasm仅用三天时间，就完成27Gb超大加州红杉基因组的组装，并且组装结果的连续性7倍于其他算法。</p><p>对于人类基因组，hifiasm也能取得最好的效果。相比于现有算法，hifiasm所产生的组装结果连续性最高，同时也正确解析了最多的复杂和高重复区域，如MHC (主要组织相容性复合体)和centromere (着丝端粒)。尤其对于人类二倍体样本HG002和HG00733，hifiasm产生的组装结果的连续性3倍于其他算法，并成功保留了最多的变异信息。</p><p><a href="http://www.evolution.ynu.edu.cn/info/1016/1208.htm">http://www.evolution.ynu.edu.cn/info/1016/1208.htm</a></p>]]></content>
    
    
    <categories>
      
      <category>Software</category>
      
    </categories>
    
    
    <tags>
      
      <tag>assembly</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【ATAC-seq-2】【Harvard FAS Informatics】</title>
    <link href="/GeekFocus/2021/10/14/2021-10-30-ATAC-seq-2-harvard/"/>
    <url>/GeekFocus/2021/10/14/2021-10-30-ATAC-seq-2-harvard/</url>
    
    <content type="html"><![CDATA[<h2 id="ATAC-seq数据质量评估注意"><a href="#ATAC-seq数据质量评估注意" class="headerlink" title="ATAC-seq数据质量评估注意"></a>ATAC-seq数据质量评估注意</h2><span id="more"></span><p><code>ENCODE</code>的ATACseq<a href="https://www.encodeproject.org/atac-seq/">数据标准</a>。</p><h3 id="Uniform-Processing-Pipeline-Restrictions"><a href="#Uniform-Processing-Pipeline-Restrictions" class="headerlink" title="Uniform Processing Pipeline Restrictions"></a>Uniform Processing Pipeline Restrictions</h3><ul><li>The <code>read length</code> prior to any trimming should be a minimum of <code>45 base pairs</code>.</li><li>Sequencing may be <code>paired</code>- or <code>single</code>-ended, <code>sequencing type</code> is specified and <code>paired sequences</code> are indicated.</li><li>All <code>Illumina platforms</code> are supported for use in the uniform pipeline, though <code>data from different platforms should be processed separately</code>; colorspace (<code>SOLiD</code>) reads are <code>not</code> supported. </li><li><code>Barcodes</code>, if present in the fastq, must be <code>indicated</code>.</li><li><code>Library insert size</code> range must be <code>indicated</code>. <h3 id="Current-Standards"><a href="#Current-Standards" class="headerlink" title="Current Standards"></a>Current Standards</h3></li></ul><ol><li>必须有两次或更多次<code>生物学重复</code>（稀有样本也必须做两次<code>技术重复</code>）</li><li>每次重复要有25million非冗余，非线粒体，能够回帖的fragment（单端25 million reads，<code>双端50 million reads</code>&#x3D;25 million fragment）</li><li>回帖率&gt;95%, &gt;80%可接受。</li><li>用<code>IDR(Irreproducible Discovery Rate)</code>计算重复一致性，rescue和self consisty ratios 都&gt;2</li><li>用以下指标控制PCR扩增对文库复杂性的影响： <code>Non-Redundant Fraction (NRF)</code> and PCR Bottlenecking Coefficients 1 and 2, or PBC1 and PBC2：NRF&gt;0.9, PBC1&gt;0.9, PBC2&gt;3</li><li>peak文件必须满足如下要求：<blockquote><p>每个重复peak数&gt;150000，&gt;100000可接受（ENCODE的ATAC-seq的peak file没法用）<br>IDR peak&gt;70000,&gt;50000可接受<br>要存在无核小体区NFR<br>存在单核小体峰，好的ATACseq数据应包含核小体，既能看开放染色质，又能看核小体</p></blockquote></li><li>The fraction of reads in called peak regions(FRip score)&gt;0.3,&gt;0.2 可以接受。对于稀有样本不要求FRiP但TSS富集还是要作为关键的衡量信噪比的指标。</li><li>TSS富集分数阈值与参考基因组相关。</li></ol><h2 id="ATACseq-主干分析流程"><a href="#ATACseq-主干分析流程" class="headerlink" title="ATACseq 主干分析流程"></a>ATACseq 主干分析流程</h2><p>reference：<br><strong>1.文章</strong>：<a href="https://peerj.com/articles/4040/">https://peerj.com/articles/4040/</a><br><strong>2.CHIPseq课程</strong>：<a href="https://github.com/hbctraining/In-depth-NGS-Data-Analysis-Course/tree/master/sessionV/lessons">https://github.com/hbctraining/In-depth-NGS-Data-Analysis-Course/tree/master/sessionV/lessons</a><br><strong>3.Harvard FAS Informatics - ATAC-seq Guidelines</strong>：<a href="https://informatics.fas.harvard.edu/atac-seq-guidelines.html">https://informatics.fas.harvard.edu/atac-seq-guidelines.html</a></p><h2 id="Harvard-FAS-Informatics-ATAC-seq-Guidelines"><a href="#Harvard-FAS-Informatics-ATAC-seq-Guidelines" class="headerlink" title="Harvard FAS Informatics - ATAC-seq Guidelines"></a><a href="https://informatics.fas.harvard.edu/atac-seq-guidelines.html">Harvard FAS Informatics - ATAC-seq Guidelines</a></h2><h3 id="Experimental-design"><a href="#Experimental-design" class="headerlink" title="Experimental design"></a>Experimental design</h3><p><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4374986/">Detailed protocol</a></p><ul><li>Replicates</li><li>Controls：一般<code>不设置对照</code>。作用有限，费用。没有转座酶处理的样本测序</li><li>PCR amplification：<code>尽可能少</code>地使用<code>PCR循环</code>来扩增样本，减少干扰</li><li>Sequencing depth：最佳测序深度取决于<code>参考基因组的大小</code>和<code>预期染色质的开放程度</code>。人类样本的研究推荐每个样本超过5000万个reads。</li><li>Sequencing mode：(1) ATACseq推荐使用paired-end。paired-end sequencing, helps to <code>reduce these alignment ambiguities</code>. (2) we are interested in <code>knowing both ends of the DNA fragments generated by the assay</code>, since the ends indicate where the transposase inserted. (3) <strong><code>PCR duplicates are identified more accurately</code></strong>.  PCR duplicates are <code>artifacts of the procedure</code>, and they should be removed as part of the analysis pipeline . <code>Computational programs that remove PCR duplicates typically identify duplicates based on comparing ends of aligned reads</code>. With <strong><code>single-end reads</code></strong>, there is <code>only one position to compare</code>, and so any <code>reads whose 5&#39; ends match are considered duplicates</code>. Thus, <code>many false positives</code> may result, and perfectly <code>good reads are removed</code> from further analysis. <strong><code>Paired-end sequencing</code></strong>, <code>both ends of the original DNA fragments are defined</code>. <code>To be declared a duplicate, both ends of one fragment need to match both ends of another fragment</code>, which is far <code>less likely to occur by chance</code>. Therefore, paired-end sequencing leads to <code>fewer false positives</code>.</li><li>Mitochondria: 众所周知ATAC-seq数据通常包含很大比例的<code>来自线粒体DNA的reads</code>（<em>线粒体DNA是裸露的，也可以被Tn5酶识别切割，植物叶绿体</em>）。线粒体基因组中没有ATAC-seq感兴趣的峰，这些reads在计算中被丢弃，浪费测序资源。可在测序前使用洗涤剂<a href="https://www.nature.com/articles/nmeth.4396">去除样本中的线粒体</a>。</li></ul><h3 id="Quality-control"><a href="#Quality-control" class="headerlink" title="Quality control"></a>Quality control</h3><h4 id="FastQC"><a href="#FastQC" class="headerlink" title="FastQC"></a>FastQC</h4><p>Process a file of <code>20 million reads</code> in about <code>5 minutes</code> with less than <code>250MB memory</code> used. Quality scores, GC levels, PCR duplicates, and adapter content.</p><h4 id="Adapter-removal"><a href="#Adapter-removal" class="headerlink" title="Adapter removal"></a>Adapter removal</h4><p>For reads derived from <code>short DNA fragments</code>, the <code>3&#39; ends may contain portions of the Illumina sequencing adapter</code>.  </p><h5 id="Cutadapt"><a href="#Cutadapt" class="headerlink" title="Cutadapt"></a><a href="https://cutadapt.readthedocs.io/en/stable/guide.html">Cutadapt</a></h5><h5 id="NGmerge"><a href="#NGmerge" class="headerlink" title="NGmerge"></a><a href="https://bmcbioinformatics.biomedcentral.com/articles/10.1186/s12859-018-2579-2">NGmerge</a></h5><p>Unlike cutadapt, NGmerge <code>does not require</code> that the <code>adapter sequences</code> be provided, <code>nor</code> does it <code>require a parameter for the minimum length of adapter to match</code> (in fact, it <code>does not perform adapter matching</code> at all).For input files of <code>20 million paired reads</code>, NGmerge should run in <code>less than one hour on a single core</code>, with minimal memory usage.<br><img src="https://img-blog.csdnimg.cn/e2669cfa1a184ec2b7026fe528f9c97a.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAYmFubmVyRHI=,size_20,color_FFFFFF,t_70,g_se,x_16" alt="请添加图片描述"></p><h5 id="Just-adapter-removal"><a href="#Just-adapter-removal" class="headerlink" title="Just adapter removal"></a>Just adapter removal</h5><p>Other than adapter removal, we <code>do not recommend any trimming of the reads.</code> Such adjustments can complicate later steps, such as the identification of PCR duplicates.</p><h3 id="Alignment"><a href="#Alignment" class="headerlink" title="Alignment"></a>Alignment</h3><p>Two of the most popular alignment program are BWA and <code>Bowtie2</code>.</p><h4 id="Genome-indexing"><a href="#Genome-indexing" class="headerlink" title="Genome indexing"></a>Genome indexing</h4><p>For many model organisms, the genome and pre-built reference indexes are available from <a href="https://support.illumina.com/sequencing/sequencing_software/igenome.html">iGenomes</a>.<br>Otherwise, Bowtie2 indexes are made from a FASTA genome file using the program <code>bowtie2-build</code>:</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs xml">bowtie2-build  <span class="hljs-tag">&lt;<span class="hljs-name">genome.fa</span>&gt;</span>  <span class="hljs-tag">&lt;<span class="hljs-name">genomeIndexName</span>&gt;</span><br></code></pre></td></tr></table></figure><h4 id="Alignment-1"><a href="#Alignment-1" class="headerlink" title="Alignment"></a>Alignment</h4><p><a href="http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml">Bowtie2 parameters</a>. Here are a few that <code>may benefit the alignment of an ATAC-seq dataset</code> :</p><p><code>-X &lt;int&gt;</code> : Maximum DNA fragment length (<code>default 500bp</code>). If you anticipate that you may have DNA fragments <code>longer than</code> the default value, you should <code>increase</code> this parameter accordingly; otherwise, alignments from such fragments are considered not properly paired (see Fig. 3B below).<br><code>--very-sensitive</code> : Bowtie2 has a number of alignment and effort parameters that interact in complex (and sometimes unexpected) ways. Preset collections of these parameters are provided for convenience; the default is –sensitive, but <code>better alignment results</code> are frequently achieved with –very-sensitive.<br><code>-k &lt;int&gt;</code> : Maximum number of alignments to report per read. By default, Bowtie2 reports at most one alignment per read, and if multiple equivalent alignments exist, it chooses one randomly.<br><code>-p &lt;int&gt;</code> : Number of <code>cores</code> on which to run</p><figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs vim">bowtie2  --very-sensitive  -<span class="hljs-keyword">k</span> <span class="hljs-number">10</span>  -<span class="hljs-keyword">x</span> <span class="hljs-symbol">&lt;genomeIndexName&gt;</span>  -<span class="hljs-number">1</span> <span class="hljs-symbol">&lt;name&gt;</span>_1.fastq.gz  -<span class="hljs-number">2</span> <span class="hljs-symbol">&lt;name&gt;</span>_2.fastq.gz  \<br>  |  samtools <span class="hljs-keyword">view</span>  -<span class="hljs-keyword">u</span>  -  \<br>  |  samtools <span class="hljs-keyword">sort</span>  -n  -<span class="hljs-keyword">o</span> <span class="hljs-symbol">&lt;BAM&gt;</span>  -<br></code></pre></td></tr></table></figure><ul><li>For input files of <code>20 million</code> paired reads, this command takes around <code>five hours</code> on Cannon(1 core too slow). One could specify eight cores for Bowtie2 with <code>-p 8</code> and adjust the request in the <code>SLURM script</code> to <code>#SBATCH -n 10</code> (that is, <code>eight</code> cores for <code>Bowtie2</code> and <code>one each</code> for <code>SAMtools view</code> and <code>sort</code>). </li><li>Bowtie2 also provides (via stderr) a summary of the mapping results, separated according to uniqueness and alignment type.</li></ul><p><img src="https://img-blog.csdnimg.cn/9f961cf3106f4c99b6e85bd1c3f6e373.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAYmFubmVyRHI=,size_20,color_FFFFFF,t_70,g_se,x_16" alt="请添加图片描述"><br> Alignment types for paired-end reads. <strong>A</strong>: Properly paired alignments (“<code>concordant</code>“) have the reads <code>aligned in opposite orientations</code> on the <code>same reference</code> sequence (chromosome). The reads <code>may overlap</code> to some extent (bottom). <strong>B</strong>: A read alignment (for <code>R1</code>) can be <code>unpaired</code> for several reasons: if the read’s mate (<code>R2</code>) is <code>unaligned</code> (<code>upper left</code>), <code>aligns to a different chromosome</code> (<code>upper right</code>), aligns in the <code>incorrect orientation</code> (<code>middle</code> cases), or aligns in the correct orientation but at an <code>invalid distance</code> (<code>bottom</code>). In all cases except the upper left, the R2 read alignment is also unpaired, and the read pair align discordantly (though Bowtie2 also requires uniqueness for such alignments to be counted as discordant).</p><p>Generich 版本</p><h3 id="Peak-calling"><a href="#Peak-calling" class="headerlink" title="Peak calling"></a>Peak calling</h3><h4 id="推荐新的Generich"><a href="#推荐新的Generich" class="headerlink" title="推荐新的Generich???"></a>推荐新的<a href="https://github.com/jsh58/Genrich"><code>Generich</code></a>???</h4><p>Genrich was designed to be able to <code>run all of the post-alignment steps</code> through <code>peak-calling with one command</code>. It also possesses a few <code>novel features</code>. Consider the following attributes:</p><ul><li><strong>Removal of mitochondrial reads</strong>. Genrich <code>disregards all alignments to the mitochondrial</code> chromosome with <code>-e chrM</code>.</li><li><strong>Removal of PCR duplicates</strong>. Genrich follows a <code>systematic procedure</code> to <code>remove PCR duplicates</code> with <code>-r</code>. Note that this evaluation <code>takes into account multimapping reads</code> (see next), which is <code>not provided by other alignment-based duplicate-removal programs</code>, such as <code>Picard&#39;s MarkDuplicates</code>.<br><strong>Analysis of multimapping reads</strong>. 重复区域多的基因组可能导致非唯一mapping。 Non-uniquely aligned reads can be removed by filtering based on MAPQ scores with <code>samtools</code>, but this effectively renders certain genomic regions inaccessible to the assay. With Genrich, <code>reads with multiple alignments are analyzed</code> by adding a fractional count to each location. Genrich’s <code>statistical model</code> accommodates these values.<br>Along these same lines, Genrich considers the entire reference genome to be part of the assay. If there are chromosomes or genomic regions that should be excluded from analysis, these can be specified by <code>-e or -E</code>, and Genrich will adjust the <code>genome length calculation</code> accordingly. There is no need to <code>guesstimate an &quot;effective&quot; genome size</code> like with MACS2.<br><strong>Analysis of multiple replicates</strong>. When alignment files for multiple replicates are provided to Genrich, it <code>calls peaks for the replicates collectively</code>. <code>No more IDR</code>. Done.<br><strong>Interpretation of alignments suitable for ATAC-seq</strong>. Genrich provides an ATAC-seq analysis mode (-j) in which, rather than inferring the full fragments from the alignments, intervals are interpreted that are centered on transposase cut sites (the ends of each DNA fragment). Only properly paired alignments are analyzed by default, but there is an option to consider unpaired alignments as well (-y) (Fig. 4).</li></ul><p><img src="https://img-blog.csdnimg.cn/abb30e7406834c91b7e456ff14e23742.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAYmFubmVyRHI=,size_20,color_FFFFFF,t_70,g_se,x_16" alt="请添加图片描述"></p><ul><li>Our previous recommendation was to run <code>MACS2</code> with <code>-f BAMPE</code>, which is similar to the <code>default analysis mode of Genrich</code> (<strong>inferring full fragments, rather than cut site intervals</strong>). Others have attempted to interpret cut site intervals with MACS2 by using the <code>--shif</code>t and <code>--extsize</code> arguments, but these arguments are ignored in <code>BAMPE</code> mode. They do work in the default (<code>BAM</code>) mode, but then, with paired-end reads, <code>most of the alignments are automatically discarded</code> (half of the properly paired alignments and all of the unpaired alignments; secondary alignments are never considered). Is it worse to interpret full fragments that may be less informative biologically, or to disregard more than half of the sequence data? A complicated question. The correct answer is: <strong>use Genrich.</strong><h4 id="Genrich"><a href="#Genrich" class="headerlink" title="Genrich"></a>Genrich</h4><strong>most important parameters and options of Genrich for analyzing ATAC-seq：</strong></li></ul><p><code>-j</code> : ATAC-seq mode (<strong>must</strong> be specified)<br><code>-d &lt;int&gt;</code> : Expand cut sites to the given length (default 100bp)<br><code>-y</code> : Analyze <strong>unpaired</strong> alignments<br><code>-r</code> : Remove PCR duplicates<br><code>-e &lt;arg&gt;</code> : Chromosomes (reference sequences) to exclude. Can be a comma-separated list, e.g. <code>-e chrM,chrY</code>.<br><code>-E &lt;file&gt;</code> : Input BED file(s) of genomic regions to exclude, such as ‘N’ homopolymers or high mappability regions<br><code>-q &lt;float&gt;</code> : Maximum q-value (FDR-adjusted p-value) for peak calling (default 0.05). An unadjusted p-value threshold can be used instead with <code>-p &lt;float&gt;</code>.<br><code>-a &lt;float&gt;</code> : Minimum area under the curve (total significance) for a peak (default 20.0). <code>Increasing</code> this value results in <code>fewer</code> but <code>higher confidence</code> peaks.<br><code>-v</code> : Verbose mode</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs xml">Genrich  -t <span class="hljs-tag">&lt;<span class="hljs-name">BAM</span>&gt;</span>  -o <span class="hljs-tag">&lt;<span class="hljs-name">OUT</span>&gt;</span>  -j  -y  -r  -e chrM  -v<br></code></pre></td></tr></table></figure><ul><li>对于重复data,  <code>-t &lt;BAM1&gt;,&lt;BAM2&gt;</code>.</li><li>The output file produced by Genrich is in <a href="https://genome.ucsc.edu/FAQ/FAQformat.html#format12"><code>ENCODE narrowPeak format</code></a>, listing the genomic coordinates of each peak called and various statistics.</li><li>Speed： a single BAM containing <code>146.3 million alignments</code> was analyzed by Genrich in <code>10.5min</code> with <code>17.1GB of memory</code> . In general, input BAM(s) of more alignments take longer to analyze, but the memory usage should not increase greatly. Note that <code>Genrich is not multithreaded</code>, so it runs on a single core only.</li><li>Those who wish to explore the results of varying the <code>peak-calling parameters (-q/-p, -a, -l, -g)</code> should consider having Genrich produce a log file when it parses the SAM&#x2F;BAM files (for example, with <code>-f &lt;LOG&gt;</code> added to the above command). Then, Genrich can call peaks directly from the log file with the <code>-P</code> option（调参数使用此法节省内存和时间）:</li></ul><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">Genrich</span>  -P  -f &lt;LOG&gt;  -o &lt;OUT2&gt;  -p <span class="hljs-number">0</span>.<span class="hljs-number">01</span>  -a <span class="hljs-number">200</span>  -v<br></code></pre></td></tr></table></figure><h3 id="NEXT-Steps"><a href="#NEXT-Steps" class="headerlink" title="NEXT Steps"></a>NEXT Steps</h3><h4 id="Visualization"><a href="#Visualization" class="headerlink" title="Visualization"></a>Visualization</h4><p>For ATAC-seq in model organisms, the <code>peak file produced by Genrich</code> can be <code>uploaded</code> directly to the <a href="https://genome.ucsc.edu/cgi-bin/hgCustom">UCSC genome browser</a>. Add header.</p><figure class="highlight elm"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs elm"><span class="hljs-title">track</span> <span class="hljs-keyword">type</span>=narrowPeak<br></code></pre></td></tr></table></figure><p>An alternative visualization tool is the <a href="http://software.broadinstitute.org/software/igv/">Integrative Genomics Viewer (IGV)</a>. Peak files can be loaded directly (File → Load from File). <strong>Viewing BAM files with IGV requires that they be sorted by coordinate and indexed</strong> using <a href="http://www.htslib.org/doc/samtools.html">SAMtools</a>. However, the BAMs show the read alignments, <code>not the full fragments generated by the ATAC</code> <code>nor the cut site intervals</code> analyzed by Genrich. To view the intervals, one can use the optional output <code>BED file</code> produced by Genrich with <code>-b</code>.</p><h4 id="Comparing-peak-files"><a href="#Comparing-peak-files" class="headerlink" title="Comparing peak files"></a>Comparing peak files</h4><p>Determining genomic regions that are <code>common or different to a set of peak files</code> is best accomplished with <a href="http://bedtools.readthedocs.io/en/latest/index.html">BEDTools</a>, a suite of software tools that enables “genome arithmetic.”<br>For example, <a href="http://bedtools.readthedocs.io/en/latest/content/tools/intersect.html">bedtools intersect</a> determines regions that are <strong><code>common</code></strong> to two peak files. Finding <strong><code>differences</code></strong> between two peak files, such as control vs. experimental groups, is accomplished via <a href="http://bedtools.readthedocs.io/en/latest/content/tools/subtract.html">bedtools subtract</a>.</p><h4 id="Annotation"><a href="#Annotation" class="headerlink" title="Annotation"></a>Annotation</h4><p>It is helpful to know <code>what genomic features are near the peaks</code> called by Genrich. One program that is commonly used to annotate peaks is <a href="https://bioconductor.org/packages/release/bioc/html/ChIPseeker.html">ChIPseeker</a>. ChIPseeker was originally designed to be used in the analysis of ChIP-seq, but it works just <code>as well with ATAC-seq.</code><br>ChIPseeker <strong>requires</strong> that the <code>genome of interest be annotated with locations of genes and other features</code>. The <a href="https://bioconductor.org/packages/release/bioc/vignettes/ChIPseeker/inst/doc/ChIPseeker.html">ChIPseeker user guide</a> is extremely helpful in using this R&#x2F;Bioconductor package.</p><h4 id="Motif-finding"><a href="#Motif-finding" class="headerlink" title="Motif finding"></a>Motif finding</h4><p><a href="http://homer.ucsd.edu/homer/introduction/basics.html">HOMER</a> is a suite of software designed for <a href="http://homer.ucsd.edu/homer/ngs/peakMotifs.html">motif discovery</a>. It takes a <code>peak file as input</code> and <code>checks for the enrichment</code> of both <code>known sequence motifs</code> and <code>de novo motifs</code>.</p><p>MACS2版本</p><h4 id="Alignment（same）"><a href="#Alignment（same）" class="headerlink" title="Alignment（same）"></a>Alignment（same）</h4><figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs vim">bowtie2  --very-sensitive  -<span class="hljs-keyword">x</span> <span class="hljs-symbol">&lt;genomeIndexName&gt;</span>  -<span class="hljs-number">1</span> <span class="hljs-symbol">&lt;name&gt;</span>_1.fastq.gz  -<span class="hljs-number">2</span> <span class="hljs-symbol">&lt;name&gt;</span>_2.fastq.gz \<br> |  samtools <span class="hljs-keyword">view</span> -<span class="hljs-keyword">u</span> -  \<br> |  samtools <span class="hljs-keyword">sort</span> -  &gt;  <span class="hljs-symbol">&lt;BAM&gt;</span><br></code></pre></td></tr></table></figure><h4 id="Alignment-adjustments"><a href="#Alignment-adjustments" class="headerlink" title="Alignment adjustments"></a>Alignment adjustments</h4><h5 id="Mitochondrial-reads"><a href="#Mitochondrial-reads" class="headerlink" title="Mitochondrial reads"></a>Mitochondrial reads</h5><ul><li>ATAC-seq datasets usually contain a large percentage of reads that are derived from mitochondrial DNA (<a href="http://seqanswers.com/forums/showthread.php?t=35318">discussion</a>). Using <a href="https://www.nature.com/articles/s41598-017-02547-w">CRISPR to reduce mitochondrial contamination</a>. Or recently <a href="https://www.nature.com/articles/nmeth.4396">Omni-ATAC method</a> uses detergents[洗涤剂] to remove mitochondria and is likely to be more accessible for most researchers ( <a href="https://www.biorxiv.org/content/10.1101/496521v1">bad computational workflow</a>).</li><li>Method 1 : <strong>Remove the mitochondrial genome from the reference genome before aligning the reads</strong>. In human&#x2F;mouse genome builds, the mitochondrial genome is labeled ‘<code>chrM</code>‘. That sequence can be deleted from the reference prior to building the genome indexes. The downside of this approach is that the alignment numbers will look much worse; all of the mitochondrial reads will count as unaligned. [植物？]</li><li>Method 2 : <strong>Remove the mitochondrial reads after alignment</strong>. A python script, creatively named removeChrom, is available in the ATAC-seq module to accomplish this. For example, to remove all ‘chrM’ reads from a BAM file, one would run this:</li></ul><figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs vim">samtools <span class="hljs-keyword">view</span> -h  <span class="hljs-symbol">&lt;inBAM&gt;</span>  |  removeChrom - - chrM  |  samtools <span class="hljs-keyword">view</span> -<span class="hljs-keyword">b</span> -  &gt;  <span class="hljs-symbol">&lt;outBAM&gt;</span><br></code></pre></td></tr></table></figure><h5 id="PCR-duplicates"><a href="#PCR-duplicates" class="headerlink" title="PCR duplicates"></a>PCR duplicates</h5><p> Picard’s <a href="http://broadinstitute.github.io/picard/command-line-overview.html#MarkDuplicates">MarkDuplicates</a>. The output file specified by <code>M=</code> lists counts of alignments analyzed and duplicates identified.</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs routeros">java -jar <span class="hljs-variable">$PICARD_TOOLS_HOME</span>/picard.jar MarkDuplicates <span class="hljs-attribute">I</span>=&lt;inBAM&gt; <span class="hljs-attribute">O</span>=&lt;outBAM&gt; <span class="hljs-attribute">M</span>=dups.txt <span class="hljs-attribute">REMOVE_DUPLICATES</span>=<span class="hljs-literal">true</span><br></code></pre></td></tr></table></figure><h5 id="Non-unique-alignments"><a href="#Non-unique-alignments" class="headerlink" title="Non-unique alignments"></a>Non-unique alignments</h5><p>重复区域多的参考序列可能导致reads多处mapping. 用samtools view的-q <code>去除非唯一比对</code>. For reads with multiple alignments, <code>Bowtie2</code> (or <code>BWA</code>) will <code>report only one alignment</code> (by <code>default</code>) and will assign it a low mapping quality (MAPQ) score, which is defined as -10 * log10Pr{mapping position is wrong}. To eliminate alignments with <code>MAPQ &lt; 10</code> (i.e., where <code>Bowtie2</code> has determined <code>Pr&#123;mapping position is wrong&#125; &gt; 0.1</code>), one would run the following:</p><figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs vim">samtools <span class="hljs-keyword">view</span> -<span class="hljs-keyword">b</span>  -q <span class="hljs-number">10</span>  <span class="hljs-symbol">&lt;inBAM&gt;</span>  &gt;  <span class="hljs-symbol">&lt;outBAM&gt;</span><br></code></pre></td></tr></table></figure><h4 id="Peak-calling-1"><a href="#Peak-calling-1" class="headerlink" title="Peak calling"></a>Peak calling</h4><ul><li>Model-based Analysis of ChIP-Seq (<a href="https://github.com/taoliu/MACS">MACS2</a>) is a program for detecting regions of <code>genomic enrichment</code>. Though designed for ChIP-seq, it works just <code>as well on ATAC-seq and other genome-wide enrichment assays that have narrow peaks</code>. The main program in MACS2 is <code>callpeak</code>, and its options are described below. (Note that the latest version of MACS2 on Odyssey (v2.1.2_dev) is different from the updated official MACS2 release (v2.1.2), although the latter does incorporate many of the bug fixes made in the Odyssey <code>version？</code>.)</li><li>It is important to remember that the <code>read alignments indicate only a portion of the DNA fragments generated by the ATAC？</code>. Therefore, one must consider how one wants MACS2 to interpret the alignments.<h5 id="Alignments-to-analyze"><a href="#Alignments-to-analyze" class="headerlink" title="Alignments to analyze"></a>Alignments to analyze</h5></li><li>alignments分为两类：”<strong>properly paired</strong>“ and “<strong>singletons</strong>“ 。<code>-f</code> 选择其类型。</li><li><strong>Analyze only properly paired alignments, but ignore R2 reads and treat R1 reads as singletons</strong>. This is the default option (<code>-f AUTO</code>). MACS2 creates a model of the fragment lengths and extends the 3’ ends of the R1 reads to the calculated average length. An alternative is to skip this model building and instead extend each read to a specified length (e.g., <code>--nomodel --extsize 300</code> for 300bp fragments). The value of the length parameter is usually determined from the average size during library preparation (the default value is 200bp if no value is specified). However, <code>neither of these approaches utilizes the value of paired-end sequencing</code>, which defines both fragment ends.</li><li><strong>Analyze only properly paired alignments with <code>-f BAMPE</code></strong>. Here, the fragments are defined by the paired alignments’ ends, and there is <code>no modeling or artificial extension</code>. Singleton alignments are ignored. This is the <code>preferred option</code> for using only properly paired alignments.</li><li><strong>Analyze all alignments</strong>. For this approach, a python script, SAMtoBED, is available in the ATAC-seq module. This script converts the read alignments to BED intervals, treating the properly paired alignments as such and extending the singleton alignments as specified. There are <code>four options for the singletons</code>: ignore them, keep them as is, extend them to an arbitrary length (similar to the <code>--extsize</code> option of MACS2), or extend them to the average length calculated from the properly paired alignments. </li><li>Here is an example command, using the “extend to average length” option (<code>-x</code>):</li></ul><figure class="highlight pf"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs pf">samtools view -h  <span class="hljs-variable">&lt;BAM&gt;</span>  |  SAM<span class="hljs-keyword">to</span>BED  -i -  -o <span class="hljs-variable">&lt;BED&gt;</span>  -x  -v<br></code></pre></td></tr></table></figure><p>The output from SAMtoBED is a <a href="https://genome.ucsc.edu/FAQ/FAQformat.html#format1">BED file</a> that should be analyzed by MACS2 with <code>-f BEDPE</code>.<br>(Note that the BEDTools program <a href="http://bedtools.readthedocs.io/en/latest/content/tools/bamtobed.html"></a> cannot be used here, since its output is in a nonstandard BED format that MACS2 cannot analyze.)</p><ul><li>In deciding among these analysis options, it may help to consider the counts produced by Bowtie2, which indicate <code>how many alignments fall into each category</code>. For example, if most of the reads are aligned in proper pairs, it may be sufficient to use <code>option #2</code>. On the other hand, <code>option #3</code> is preferred if a substantial fraction of the reads consists of singletons.<h5 id="Other-arguments"><a href="#Other-arguments" class="headerlink" title="Other arguments"></a>Other arguments</h5></li><li>MACS2 is <code>not multithreaded</code></li></ul><figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs vim">macs2 callpeak  -t <span class="hljs-symbol">&lt;BED&gt;</span>  -<span class="hljs-keyword">f</span> BEDPE  -n NAME  -g <span class="hljs-keyword">ce</span>  --keep-dup <span class="hljs-keyword">all</span><br></code></pre></td></tr></table></figure><blockquote><p><code>-n &lt;str&gt;</code>Name of the sample. The output files  name prefix.<br><code>-g &lt;int&gt;</code>Effective genome size, the size of the organism’s genome that can be analyzed (not including Ns, repetitive sequences, etc.). This will be less than the actual genome size. Parameters are provided for some model organisms, and the <code>default value is hs</code> (for Homo sapiens), which corresponds to a value of 2.7e9.<br><code>-q &lt;float&gt;</code><code>Maximum q-value</code> (FDR-adjusted p-value) for peak calling (default <code>0.05</code>). Reducing this threshold will decrease the number of peaks identified by MACS2 but increase the confidence in the called peaks.<br><code>--keep-dup &lt;arg&gt;</code>How to handle PCR duplicates (default: –keep-dup 1, i.e. remove all potential duplicates). If PCR duplicates have been removed by another program, such as Picard’s MarkDuplicates, then specify <code>--keep-dup all</code>.<br><code>--max-gap &lt;int&gt;</code>Maximum gap between significant sites to cluster them together (default 50bp). (v2.1.2_dev only)<br><code>--min-length &lt;int&gt;</code>Minimum length of a peak (default 100bp). (v2.1.2_dev only)</p></blockquote><h5 id="Output-files"><a href="#Output-files" class="headerlink" title="Output files"></a>Output files</h5><ul><li>NAME_peaks.xls</li><li>NAME_peaks.narrowPeak</li><li>NAME_summits.bed</li><li>The most useful file is <code>NAME_peaks.narrowPeak</code>, a plain-text <code>BED</code> file that lists the <code>genomic coordinates of each peak called</code>, along with various <code>statistics</code> (fold-change, p- and q-values, etc.).</li></ul>]]></content>
    
    
    <categories>
      
      <category>NGS</category>
      
    </categories>
    
    
    <tags>
      
      <tag>atac-seq</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【ATAC-seq-1】【Background】</title>
    <link href="/GeekFocus/2021/10/11/2021-10-30-ATAC-seq-1-background/"/>
    <url>/GeekFocus/2021/10/11/2021-10-30-ATAC-seq-1-background/</url>
    
    <content type="html"><![CDATA[<h3 id="ATAC-seq意义"><a href="#ATAC-seq意义" class="headerlink" title="ATAC-seq意义"></a>ATAC-seq意义</h3><span id="more"></span><p><img src="https://img-blog.csdnimg.cn/2eb44c70d00b45bab31b0eb915e91cac.png" alt="在这里插入图片描述"></p><ul><li>为何同样DNA序列的细胞的表型会不同，为何肝细胞是肝细胞，神经细胞是神经细胞？是什么造成了他们生产蛋白不同，决定蛋白生成的RNA不同呢？原因可以用<code>表观遗传</code>来解释。<br><img src="https://img-blog.csdnimg.cn/9bf2e2d5d25a4e2eab27321b99b0b0b8.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAYmFubmVyRHI=,size_15,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></li><li>DNA转录成RNA过程复杂，包括：<code>染色质可及性</code>，<code>DNA修饰</code>，<code>组蛋白修饰</code>等等（选择性表达）。</li><li><code>染色质可及性即DNA开放区域</code>，尤为重要。<code>核小体</code>由<code>8个组蛋白</code>组成复合物，每个核小体约<code>147bpDNA</code>。转录时DNA将从核小体复合物松开。许多因素，如<code>染色质结构</code>、<code>核小体位置</code>和<code>组蛋白修饰</code>，在染色质的组织和可及性起重要作用。致密核小体结构被破坏后，<code>启动子、增强子、绝缘子、沉默子</code>等<code>顺式调控元件和反式作用因子可以接近</code>的特性，叫<code>染色质的可及性</code>，也叫<code>染色质开放性</code>(chromatin accessibility ），这段区域叫开放染色质（open chromatin） 。</li><li>什么是组蛋白修饰<ul><li>定义：组蛋白包含5个部分，按分子量大小分别称为<code>H1，H3，H2A，H2B和H4</code>。组蛋白在相关酶作用下发生<code>甲基化，乙酰化，磷酸化，腺苷酸化，泛素化，ADP核糖基化</code>等修饰</li><li><code>H3·H4乙酰化</code>形成<code>开放染色质结构</code>，<code>增加基因表达</code></li><li>组蛋白<code>甲基化</code>修饰多发生在<code>H3H4</code>，与基因<code>抑制及激活</code>相关，取决于被<code>修饰位置和程度</code></li><li>组蛋白<code>磷酸化</code>修饰一般与基因<code>活化</code>有关</li><li>组蛋白<code>泛素化</code>则是<code>启动基因表达</code></li></ul></li><li>2013年由斯坦福大学William J. Greenleaf和Howard Y. Chang实验室开发的ATAC-seq（<code>Assay</code> for <code>Transposase</code>-<code>Accessible</code> <code>Chromatin</code> with high throughput sequencing），一种捕获染色质可及性（染色质开放性）的测序方法。</li><li>ATAC-seq<code>检测染色质可及性</code>，<code>确定基因表达调控机制</code>。识别<code>启动子区域</code>、<code>潜在的增强子或抑制子</code>。<code>启动子</code>是靠近转录起始点(TSS)的DNA区域。包含<code>转录因子的结合位点</code>，转录因子招募RNA聚合酶。<code>增强子</code>是位于<code>启动子下游或上游1Mb</code>的DNA区域。<code>当转录因子与增强子结合，并与启动子区域接触时，该基因的转录增加</code>。相反<code>抑制子</code>会<code>减少或抑制基因表达</code>。</li><li>ATAC-seq的<code>峰</code>往往是<code>启动子</code>，<code>增强子序列</code>以及一些<code>反式调控因子</code>结合位点。</li><li>为找到开放染色质区，基因组被<code>TN5转座酶</code>处理。在ATAC-Seq中，<code>修饰后的TN5将与NextEra接头相对应的DNA序列插入到基因组的开放区域</code>，同时，DNA被转座酶活性剪切。</li><li>开放染色质的研究方法除了ATAC-seq，还有DNase-Seq，FAIRE-seq，MNase-seq 等。ATAC-Seq<code>所需样本少，建库快，重复性更高</code></li><li>技术：制备细胞悬液-&gt;裂解细胞膜，获取细胞核-&gt;采用Tn5进行酶切-&gt;回收DNA片段，PCR扩增建库-&gt;高通量测序-&gt;生信分析</li><li><img src="https://img-blog.csdnimg.cn/00f06cb4758b44c7a35b8c5c3ff74eda.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAYmFubmVyRHI=,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></li><li><code>ATAC-seq</code>与<code>Chip-seq</code> call出来的<code>peak</code>代表的<code>意义不同</code>。<code>Chip-seq</code> peak是被<code>目的蛋白结合拉下来的DNA</code>，一般只有<code>一个峰</code>，而<code>ATAC-seq</code>是被<code>Tn5转座酶切开</code>、没有被组蛋白结合、染色质开放的DNA位点，<code>如果是TF结合的区域，一般会有一个山谷般的存在</code>。ChIP-seq和ATAC-seq在TF或者Tn5结合区域<code>都会形成一个双峰的reads结合模式</code>，但<code>判断peak的时会有不同的标准</code>。chip-seq是由于<code>TF一起沉淀下来的DNA fragment一般会大于TF的结合区域</code>，<code>read的位置并不是真实TF结合位置</code>，需要<code>向内shift</code>；而<code>ATAC-seq一般是往两边shift</code>。<br><img src="https://img-blog.csdnimg.cn/e501e5a398b34d0e8fd514fba8333cdb.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAYmFubmVyRHI=,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></li><li><code>ATAC-seq</code>与<code>Chip-seq</code>应用上的区别:</li><li>ATAC-Seq可<code>检测全基因组DNA结合蛋白</code>，<code>转录结合位点</code> ，一般用于<code>不知道特定的转录因子</code>，用此方法与其他方法结合<code>筛查感兴趣的特定调控因子</code>；</li><li>ChIP-Seq是已知转录因子，根据<code>感兴趣的转录因子设计抗体</code>去做ChIP实验<code>富集结合的DNA片段</code>。在测定转录因子的 ChIP-seq 中<code>独有的峰可能是先驱转录因子</code>，其<code>先结合到封闭染色质</code>，然后<code>招募染色质重塑因子或其他转录因子起始转录</code>。这些转录因子 <code>ATAC-seq检测不到</code>。</li><li>得到DNA片段后，为测序准备建库，包括<code>用完整的NextEra接头</code>和<code>纯化</code>、<code>PCR扩增</code>等。基于上述原因，<code>ATAC-Seq推荐使用双端配对</code>的方法。</li></ul><h3 id="ATACseq应用"><a href="#ATACseq应用" class="headerlink" title="ATACseq应用"></a>ATACseq应用</h3><ul><li><p>染色质<code>开放性图谱绘制</code>，表观基因组图谱</p></li><li><p>找<code>调控</code>生物学过程的<code>关键转录因子</code></p></li><li><p>找<code>哪个转录因子</code>调控了研究的基因</p></li><li><p>找转录因子调控的<code>靶基因</code></p></li><li><p>得到<code>不同组织或不同条件下对应可及性区域</code>。</p></li><li><p>得到核小体位置</p></li><li><p>生成转录因子结合区域的特征(footprinting)</p><h3 id="技术限制"><a href="#技术限制" class="headerlink" title="技术限制"></a>技术限制</h3></li><li><p>Tn5通过<code>插入剪断DNA 并将测序接头连接到剪断的两个DNA 片段的末端</code>，因此对于一个DNA 片段而言，其两端的接头连接是随机的，导致<code>同一片段两端的接头有50%的概率是同一接头</code>。而<code>只有连接不同接头的片段才可用于富集扩增及测序</code>，因此<code>一半的片段无法利用</code>； </p></li><li><p><code>大量剪断的DNA 由于片段过大，无法进行PCR富集</code>; </p></li><li><p>Tn5 的<code>活性</code>受反应溶液的组成及反应条件<code>影响</code>，仍然需要优化以便提高剪切效果； </p></li><li><p>ATAC-seq在<code>植物细胞存在以下难点</code>：<code>细胞壁</code>，<code>叶绿体线粒体等细胞器污染</code>，<code>缺少稳定遗传的细胞系</code>;</p></li></ul><h3 id="ATAC-Seq、Dnase-Seq、MNase-Seq、FAIRE-Seq"><a href="#ATAC-Seq、Dnase-Seq、MNase-Seq、FAIRE-Seq" class="headerlink" title="ATAC-Seq、Dnase-Seq、MNase-Seq、FAIRE-Seq"></a>ATAC-Seq、Dnase-Seq、MNase-Seq、FAIRE-Seq</h3><ul><li>整体的分析思路一致，<code>找富集区域</code>，对富集区域进行功能分析。</li><li>ChIP-Seq是<code>揭示特定转录因子</code>或<code>蛋白复合物</code>的结合区域，实际是<code>研究DNA和蛋白质的相互作用</code>，利用<code>抗体将蛋白质和DNA一起富集</code>，并对<code>富集的DNA测序</code>。</li><li>DNase-Seq、ATAC-Seq、FAIRE-Seq都<code>研究开放染色质区域</code>：</li><li>DNase-Seq用<code>DNase I内切酶识别</code>开放染色质区域，</li><li>ATAC-seq用<code>Tn5转座酶</code>，随后进行<code>富集扩增</code>；</li><li>FAIRE-Seq先超声裂解，后用酚-氯仿富集；</li><li>MNase-Seq鉴定核小体区域。</li></ul><p>下图是不同测序方法获取的峰形：</p><p><img src="https://img-blog.csdnimg.cn/aea5161044eb40e1a1cc4c1a65d63cbb.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAYmFubmVyRHI=,size_18,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"><br>检测染色质可及性的方法中，ATAC-seq尤其受欢迎。<br><img src="https://img-blog.csdnimg.cn/96808dfcce9446298f1d0d4cc0db6eee.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAYmFubmVyRHI=,size_10,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></p><ul><li>ATAC-seq的优点：<code>Tn5转座酶的高活性</code>使ATAC-seq简单，省时，而且只需500-50,000个细胞。灵敏度特异性与DNase-seq相当，优于FAIRE-seq。</li></ul><h3 id="整合分析"><a href="#整合分析" class="headerlink" title="整合分析"></a>整合分析</h3><ul><li><p>由于开放染色质是大多数TF结合的先决条件，因此<code>ATAC-seq峰通常与TF ChIP-seq峰重叠，但通常更宽</code>。因此，<code>TF ChIP-seq和ATAC-seq可以在同一实验系统中相互验证</code>彼此的质量和可靠性。 </p></li><li><p>ATAC-seq与 histone marker ChIP-seq集成，发现与活跃染色质标 H3K4me3，H3K4me1，H3K27ac等正相关，与不活跃的染色质标记 H3K27me3 负相关。 <code>？</code></p></li><li><p><code>ATAC-seq+RNA-seq</code>： 一般RNA-seq会优先于ATAC-seq先测，但<code>差异基因富集的基因通路只是一种相关性</code>。要分析出其中谁调控目的基因，可通过<code>ATAC-seq做motif分析</code>，<code>寻找潜在的调控因子</code>，然后再后续的<code>实验验证</code>或者<code>chip-seq验证</code>。&#x2F; 看ATAC上丰度高的DNA序列区域是否对应转录本表达量增加，找到对应转录本相关基因的上游调控序列，整体分析转录。对基因功能分析，结合实验表型，推测表达调控-表达-功能-表型。<br><img src="https://img-blog.csdnimg.cn/4a3016bfa5c74598a5b7d660fe1cfe84.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAYmFubmVyRHI=,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></p></li><li><p><code>ATAC-seq+HiC</code>： 对于一些想了解<code>染色质高级结构对生命行为的作用</code>的时候，通常会需要用到ATAC-seq等技术，因为<code>Hi-C分析</code>得到高级结构compartmentA&#x2F;B、TADs、Loops等信息，通常只是相关性，但通过ATAC-seq，可以<code>获得promoter、enhancer等信息</code>，更能知道高级结构是如何影响启动子、增强子从而影响基因表达的。<br><img src="https://img-blog.csdnimg.cn/e38ba32597a14ca7a5d4d6b2f36c1b73.png" alt="在这里插入图片描述"></p></li><li><p><code>ATAC-seq+组蛋白修饰</code>： ATAC-seq预测一个位点的开放程度以及可能有某种转录因子的结合，但<code>不知道</code>该因子是<code>促进</code>基因表达，还是<code>抑制</code>，只通过<code>基因层面鉴定</code>来判断转录因子对基因的促进或者是不够的，它只是一种<code>相关性</code>。而这时候如果能提供像<code>H3K27ac这类激活型组蛋白</code>、<code>H3K27me3这类抑制型组蛋白</code>将能使数据结果可信。国内较早研究iPSCs的学者如裴端卿的工作可以看到，在解析iPSCs重编程中的染色质可及性的时候，不仅用到ATAC-seq来描述细胞的身份转变，还<code>通过H3K27ac指征该区域的激活</code>。其中一篇还通过<code>调控成纤维细胞关键基因启动子区去乙酰化修饰</code>，达到了促进重编程的进程。<br><img src="https://img-blog.csdnimg.cn/abb3dc6c3bb0476985a9f1b2e77c4fcc.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAYmFubmVyRHI=,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></p></li><li><p><code>scATAC-seq+scRNA-seq</code>： 更前沿的技术一个细胞里同时进行RNA-seq和ATAC-seq，并且是单细胞水平的检测。SHARE-seq，能够实现在单细胞中同时高质量，高通量的检测基因表达和染色质可及性。该技术可以使用<code>染色质潜力算法</code>（chromatin potential），<code>用ATAC和RNA的差异来预测细胞的变化方向</code>。<code>相对于以往仅依赖于RNA的预测手段，染色质潜力能够大大提前预测的时间</code>。<br><img src="https://img-blog.csdnimg.cn/df76c6e5f3184d58a00a1fa53a398cd5.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAYmFubmVyRHI=,size_19,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></p></li><li><p><a href="https://pubmed.ncbi.nlm.nih.gov/27374332/">ATAC-seq与ChIP联合分析</a><br>研究课题为人小细胞肺癌促进癌症扩散转移的背景机制。主要比较原发性和肝转移性的小细胞肺癌细胞之间的差异。利用ATAC-seq，发现NFI家族转录因子富集在具有差异的染色质开放位点中，预示着NFI家族转录因子在调控肿瘤细胞转移中扮演着重要角色。在染色质高开放性位点区域伴随着Nfib拷贝数量增多，且Nfib在侵袭性原发性肿瘤和转移性肿瘤内高表达，Nfib表现出维持染色质及远端调控区域开放和促进神经基因表达的功能，说明了Nfib对促进癌细胞增殖和迁移具有重要的作用。</p></li><li><p><a href="https://pubmed.ncbi.nlm.nih.gov/25679813/">motif分析转录因子结合蛋白</a>。对处于发育过程中的黑腹果蝇眼睛及其通过遗传诱导的肿瘤模型，利用ATAC-seq技术分析染色质开放区域已在活体中发现驱动肿瘤发育的转录因子及调控区域。然后对找到的染色质活性开放区域进行转录因子预测分析，发现了两个关键的转录因子，猜测它们可能与染色质图谱的变化有关。通过对候选的一个转录因子进行功能验证和靶标分析，发现其为肿瘤转录组中的一个关键的转录调控因子。</p></li></ul><hr><ul><li><strong>思考</strong>：</li><li>ATAC-Seq与ChIP-Seq的异同在哪里？</li><li>用和ChIP-Seq一样的参数Call peaks正确吗？</li><li>得到peaks后怎么进行质量评估？</li><li>样本内的重复怎么处理？</li><li>样本间的差异怎么分析？</li><li>怎么对peaks进行功能注释分析？</li><li>如何找motif?</li><li>ATAC-Seq和ChIP-Seq和RNA-Seq的整合分析怎么做？<br><img src="https://img-blog.csdnimg.cn/0920f7a6c41148b2825b189e709a5fbc.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAYmFubmVyRHI=,size_20,color_FFFFFF,t_70,g_se,x_16" alt="ATAC-seq/CHIP-seq流程"></li></ul><p>待学习内容：</p><ol><li><p>ATAC-seq data analysis: from FASTQ to peaks</p></li><li><p>ATAC-seq Data Standards and Processing Pipeline in ENCODE</p></li><li><p>ATAC-seq数据分析实战</p></li><li><p>Harvard FAS Informatics - ATAC-seq Guidelines</p></li><li><p>Harvard Chan Bioinformatics Core (HBC)深度NGS数据分析课程，第5部分关于ChIP-Seq，整体思路和绝大部分分析方法适合ATAC-seq。</p><p>HBC深度NGS数据分析课程：<br><a href="https://github.com/hbctraining/In-depth-NGS-Data-Analysis-Course">https://github.com/hbctraining/In-depth-NGS-Data-Analysis-Course</a><br>第五部分ChIP-Seq课程：</p><p><a href="https://github.com/hbctraining/In-depth-NGS-Data-Analysis-Course/tree/master/sessionV/lessons">https://github.com/hbctraining/In-depth-NGS-Data-Analysis-Course/tree/master/sessionV/lessons</a></p></li></ol><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs awk">参考文献：<br>https:<span class="hljs-regexp">//m</span>p.weixin.qq.com/s?src=<span class="hljs-number">11</span>&amp;timestamp=<span class="hljs-number">1633159169</span>&amp;ver=<span class="hljs-number">3349</span>&amp;signature=*MwqLr1J-qdZoNiKVxF32vEKh5-<span class="hljs-number">6</span>TRystOXAJ3UOZ3Pl8XTBIB8Ly95IJM0L2EzGFVWOM-TdKnuhnb0gfMfsUTfahWJ5i3hcM2TcR9UDFSVWuyYw7CONzMjsMaYQG2Ca&amp;new=<span class="hljs-number">1</span><br>https:<span class="hljs-regexp">//m</span>p.weixin.qq.com/s?src=<span class="hljs-number">11</span>&amp;timestamp=<span class="hljs-number">1633159169</span>&amp;ver=<span class="hljs-number">3349</span>&amp;signature=rtYw5NsC62rUZvctQsUg3*w*NFFDdOHgSMu0pcp0HTQdCyqxpgril8yx7GWlJaID*lfd2HRLUWs59zuszSEFeean0jEwdRs4PzYy*T5b7nSpZRWqCs4SHcEQ2jyjDtwQ&amp;new=<span class="hljs-number">1</span><br></code></pre></td></tr></table></figure><hr><blockquote><p>1：ATAC-seq的背景介绍以及与ChIP-Seq的异同<br>2：原始数据的质控、比对和过滤<br>3：用MACS2软件call peaks<br>4：对ATAC-Seq&#x2F;ChIP-seq的质量评估（一）——phantompeakqualtools<br>5：对ATAC-Seq&#x2F;ChIP-seq的质量评估（二）——ChIPQC<br>6：重复样本的处理——IDR<br>7：用Y叔的ChIPseeker做功能注释<br>8：用网页版工具进行motif分析<br>9：差异peaks分析——DiffBind<br>10：ATAC-Seq、ChIP-Seq、RNA-Seq整合分析</p></blockquote><h3 id="简洁版ATACseq分析流程"><a href="#简洁版ATACseq分析流程" class="headerlink" title="简洁版ATACseq分析流程"></a>简洁版ATACseq分析流程</h3><ul><li>数据预处理<ul><li>（1）比对前质量控制FastQC</li><li>（2）原始序列比对 </li><li>（3）比对后处理和质量控制：去除重复序列，细胞器序列<ul><li>序列比对后，Picard&#x2F;SAMtools收集unique mapping reads&#x2F;rate，duplicated rate百分比和片段大小分布</li><li>成功的ATACseq实验应生成<code>片段大小分布图</code>（从<code>bam文件</code>得到），具有递减性和周期性的峰，对应于<code>无核小体区域</code>（NFR）（&lt;100bp）和<code>单核双核和三核</code>小体（200，400，600bp）。大多数Linker DNA大小介于10-80bp间，故大多数片段都会是<code>小于100bp</code>。每个Nucleosome的DNA大小为180bp，加上两边插入的冗余，会得到大约<code>200bp</code>长度的mono-nucleosome的DNA。</li><li><code>无核小体区域的片段应该在基因的转录起始位点（TSS）周围富集</code>，而<code>核小体结合区域片段TSS处形成低谷</code>，TSS周围<code>侧翼区域稍微富集</code>。<code>ATACseqQC评估</code>。</li></ul></li></ul></li><li>Peak-calling：从比对得到的bam文件找出reads覆盖区，就是峰出现的位置。</li><li>高级分析<ul><li>（1）peak 差异分析：寻找不同分组差异peaks</li><li>（2）peak注释：峰的注释可将染色质的可及性与基因调控联系。通常峰会被注释到最接近的基因或调控原件。获得最接近的基因列表后，使用GOKEGGReactome等数据库功能富集分析</li><li>（3）motif富集分析：得到每个peak region里motif的位置和频率，再和随机背景或其他条件比较，可做motif富集分析</li><li>（4）footprint分析 ：ATACseq中footprint指一个TF结合在DNA上，组织Tn5切割，在染色质开放区域留下一个相对缺失的位置。而TF周围的组蛋白因为TF造成空间的推挤反而形成开放度较高区域。</li></ul></li></ul><hr>]]></content>
    
    
    <categories>
      
      <category>NGS</category>
      
    </categories>
    
    
    <tags>
      
      <tag>atac-seq</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
